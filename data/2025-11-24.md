<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [cs.LG](#cs.LG) [Total: 52]
- [stat.ML](#stat.ML) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Line-of-Sight Probability in Macrocells: Framework, Statistical Models, and Parametrization from Massive Real World Datasets in the USA](https://arxiv.org/abs/2511.16827)
*Bassel Abou Ali Modad,Xin Yu,Yao-Yi Chiang,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 本文提出了一个基于地理空间数据创建高精度LOS概率模型的框架，应用于美国全国范围的宏蜂窝网络，使用超过13,000个真实宏蜂窝基站位置数据，开发了比3GPP模型更准确的新参数化模型。


<details>
  <summary>Details</summary>
Motivation: 准确的LOS概率建模对无线信道描述和覆盖规划至关重要，现有模型基于有限数据集，需要更精确的建模方法。

Method: 建立从地理空间数据生成高精度LOS模型的框架，使用美国全国范围的宏蜂窝数据集，创建全参数化模型，并提出基于单个基站的LOS概率建模方法，将模型参数作为随机变量处理。

Result: 开发的新模型比3GPP模型更好地描述了美国宏蜂窝部署情况，通过仿真证明基于单个基站的建模方法比平均模型更准确地预测小区边缘的干扰。

Conclusion: LOS概率应在单个基站基础上建模，模型参数应作为随机变量处理，这种新方法能更准确地预测网络性能。

Abstract: Accurate modeling of line-of-sight (LOS) probability is crucial for wireless channel description and coverage planning. The presence of a LOS impacts other channel characteristics such as pathloss, fading depth, delay- and angular spread, etc.. Existing models, although useful, are based on very limited datasets. In this paper, we establish a framework to produce high accuracy LOS models from geospatial data in different environments, and apply it to create a LOS model for macrocells, using datasets of the United States (US) on a nationalscale, using more than 13, 000 locations of real-world macrocells. Based on this we create a new, fully parameterized model that better describes macrocell deployments in the US than the 3GPP model. We furthermore demonstrate that for improved accuracy the LOS probability should be modeled on a per cell basis, and the model parameters treated as random variables; we provide a full description and parameterization of this novel approach and by simulations show that it better predicts the inter-cell interference at the cell-edge than an average-based model.

</details>


### [2] [State-of-charge estimation of lithium-ion batteries using a tree seed and genetic algorithm-optimized generalized mixture minimum error entropy-based square root cubature Kalman filter](https://arxiv.org/abs/2511.16888)
*Haiquan Zhao,Xiong Yin,Jinhui Hu*

Main category: eess.SP

TL;DR: 提出了一种基于广义混合最小误差熵的平方根容积卡尔曼滤波器（GMMEE-SRCKF），用于在复杂噪声环境下提高SOC估计的鲁棒性和精度，并通过混合树种子遗传算法（TSGA）自动优化核参数。


<details>
  <summary>Details</summary>
Motivation: 现有的基于最小误差熵的容积卡尔曼滤波器（MEE-CKF）在复杂噪声环境下鲁棒性有限，需要更灵活的误差熵准则来适应非高斯噪声。

Method: 结合平方根算法提高数值稳定性，使用具有两个灵活核的广义混合最小误差熵（GMMEE）准则，并引入混合树种子遗传算法（TSGA）自动优化核参数。

Result: 实验结果表明，TSGA优化的GMMEE-SRCKF优于现有鲁棒滤波器，均方根误差（RMSE）小于0.5%。

Conclusion: 所提出的GMMEE-SRCKF在复杂噪声环境下具有优越的SOC估计性能，通过自适应核参数优化实现了高精度和强鲁棒性。

Abstract: The cubature Kalman filter based on minimum error entropy (MEE-CKF) offers accurate and robust performance in state of charge (SOC) estimation. However, due to the inflexibility of the minimum error entropy (MEE), this algorithm demonstrates limited robustness when confronted with more complex noise environments. To address these limitations, this paper proposes a generalized mixture minimum error entropy-based (GMMEE) square-root cubature Kalman filter (GMMEE-SRCKF). The square-root algorithm ensures improved numerical stability and avoids covariance degeneration, while the GMMEE criterion with two flexible kernels adapts effectively to non-Gaussian noise. Moreover, a hybrid tree seed and genetic algorithm (TSGA) is introduced to optimize the kernel parameters automatically. Experimental results confirm that the TSGA-optimized GMMEE-SRCKF outperforms existing robust filters, achieving the root mean square error (RMSE) of less than 0.5%.

</details>


### [3] [Generative MIMO Beam Map Construction for Location Recovery and Beam Tracking](https://arxiv.org/abs/2511.17007)
*Wangqian Chen,Junting Chen,Shuguang Cui*

Main category: eess.SP

TL;DR: 提出了一种从稀疏CSI测量序列中恢复位置标签的生成框架，无需显式位置标签即可构建无线电地图，通过双尺度特征提取和混合循环-卷积编码器学习移动模式，使用基于扩散的生成解码器重建完整CSI。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的无线通信方法需要大量带有位置信息的准确标注数据集，这些数据获取困难且成本高昂，因此需要开发无需显式位置标签的方法。

Method: 设计双尺度特征提取方案联合利用角度空间和相邻样本的相关性，开发混合循环-卷积编码器学习移动模式，嵌入可学习无线电地图捕获位置信息，使用基于扩散的生成解码器重建CSI。

Result: 数值实验表明，与基于模型的卡尔曼滤波方法相比，该模型在非视距场景下可将定位精度提高30%以上，并实现20%的容量增益。

Conclusion: 所提出的生成框架能够有效从稀疏CSI测量中恢复位置信息，显著提升无线通信系统的定位性能和容量，为无标签数据下的信道建模提供了可行解决方案。

Abstract: Machine learning (ML) has greatly advanced data-driven channel modeling and resource optimization in wireless communication systems. However, most existing ML-based methods rely on large, accurately labeled datasets with location information, which are often difficult and costly to obtain. This paper proposes a generative framework to recover location labels directly from sequences of sparse channel state information (CSI) measurements, without explicit location labels for radio map construction. Instead of directly storing raw CSI, we learn a compact low-dimensional radio map embedding and leverage a generative model to reconstruct the high-dimensional CSI. Specifically, to address the uncertainty of sparse CSI, a dual-scale feature extraction scheme is designed to enhance feature representation by jointly exploiting correlations from angular space and across neighboring samples. We develop a hybrid recurrent-convolutional encoder to learn mobility patterns, which combines a truncation strategy and multi-scale convolutions in the recurrent neural network (RNN) to ensure feature robustness against short-term fluctuations. Unlike conventional Gaussian priors in latent space, we embed a learnable radio map to capture the location information by encoding high-level positional features from CSI measurements. Finally, a diffusion-based generative decoder reconstructs the full CSI with high fidelity by conditioning on the positional features in the radio map. Numerical experiments demonstrate that the proposed model can improve localization accuracy by over 30% and achieve a 20% capacity gain in non-line-of-sight (NLOS) scenarios compared with model-based Kalman filter approaches.

</details>


### [4] [Movable Intelligent Surface-Enabled Wireless Communications: Static Phase Shifts with Mechanical Reconfigurability](https://arxiv.org/abs/2511.17058)
*Ziyuan Zheng,Qingqing Wu,Wen Chen,Weiren Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 提出了一种新型可移动智能表面(MIS)架构，通过机械滑动预相位次级超表面层来切换波束模式，填补了动态可重构智能表面和静态表面之间的实用空白。


<details>
  <summary>Details</summary>
Motivation: 现有智能表面设计存在两个极端：动态RIS提供精细波束控制但成本高、功耗大；低成本静态表面无需控制但只能生成单一波束模式。在准静态环境中，这两种方案都不够经济或灵活。

Method: 采用机械滑动预相位次级超表面层在静态主层上移动的方式切换波束模式，建立了MIS信号模型，提出了基于惩罚方法、块坐标下降和黎曼流形优化的高效算法来联合设计静态相位偏移和重叠位置选择。

Result: 仿真结果表明，所提出的MIS架构显著缩小了单层静态表面和动态RIS之间的性能差距。

Conclusion: MIS为准静态无线应用提供了一种实用且灵活的解决方案。

Abstract: Intelligent surfaces that reshape electromagnetic waves are regarded as disruptive technologies for wireless networks. However, existing designs sit at two costly extremes: dynamic reconfigurable intelligent surfaces (RISs) offer fine beam control but require dense cabling, continuous power consumption, and substantial signaling overhead, whereas low-cost static surfaces require no control lines or electronics but are limited to a single beam pattern. This disparity leaves a practical gap for quasi-static environments, such as industrial Internet-of-things and smart agriculture scenarios, where channels are stable with user demands changing only occasionally or periodically, and neither extreme is sufficiently economical or flexible. To bridge this gap, we propose a novel movable intelligent surface (MIS) architecture, whose beam patterns are switched not by electronic phase tuning but by mechanically sliding a small, pre-phased secondary metasurface layer across a larger, likewise static primary layer. We develop an MIS signal model that characterizes the interaction between static phase elements with dynamic geometry via binary selection matrices. Based on this model, we formulate a new type of optimization problems that jointly design static phase shifts and the overlapping position selection of MS2 (equal to beam pattern scheduling). Efficient algorithms based on the penalty method, block coordinate descent, and Riemannian manifold optimization are proposed to tackle these mixed-integer non-convex problems. Simulation results demonstrate that the proposed MIS architecture substantially narrows the performance gap between single-layer static surfaces and dynamic RISs, providing a practical and flexible solution for quasi-static wireless applications.

</details>


### [5] [Super-Resolution ISAC Receivers: An MCMC-Based Gridless Sparse Bayesian Learning Approach](https://arxiv.org/abs/2511.17062)
*Keying Zhu,Xingyu Zhou,Jie Yang,Le Liang,Shi Jin*

Main category: eess.SP

TL;DR: 提出了一种基于无网格稀疏贝叶斯学习的框架，用于联合超分辨率多目标检测和高精度参数估计，在低空无线网络中实现集成感知与通信。


<details>
  <summary>Details</summary>
Motivation: 解决低空无线网络中安全关键应用对高精度感知的需求与传统方法在精度和复杂度之间的权衡问题。

Method: 采用无网格稀疏贝叶斯学习框架，将目标参数视为连续变量，结合改进的梯度马尔可夫链蒙特卡洛算法，集成小批量采样和Adam优化器。

Result: 在20dB信噪比下，多目标检测概率超过90%，距离、速度和角度的均方根误差分别为0.07m、0.024m/s和0.015度，成功分辨仅瑞利极限50%（距离）、17%（速度）和52%（角度）间隔的目标。

Conclusion: 该框架在强杂波环境下表现出鲁棒性能，展示了其在实用ISAC-LAWNs应用中的适用性。

Abstract: Integrated sensing and communication (ISAC) is crucial for low-altitude wireless networks (LAWNs), where the safety-critical demand for high-accuracy sensing creates a trade-off between precision and complexity for conventional methods. To address this, we propose a novel gridless sparse Bayesian learning (SBL) framework for joint super-resolution multi-target detection and high-accuracy parameter estimation with manageable computational cost. Our model treats target parameters as continuous variables to bypass the grid limitations of conventional approaches. This SBL formulation, however, transforms the estimation task into a challenging high-dimensional inference problem, which we address by developing an enhanced gradient-based Markov chain Monte Carlo algorithm. Our method integrates mini-batch sampling and the Adam optimizer to ensure computational efficiency and rapid convergence. Finally, we validate the framework's robustness in strong clutter and provide a theoretical benchmark by deriving the corresponding Bayesian Cramer-Rao bound. Simulation results demonstrate remarkable super-resolution capabilities, successfully resolving multiple targets separated by merely 50% of the Rayleigh limit in range, 17% in velocity, and 52% in angle. At a signal-to-noise ratio of 20 dB, the algorithm achieves a multi-target detection probability exceeding 90% while concurrently delivering ultra-high accuracy, with root mean square error of 0.07 m, 0.024 m/s, and 0.015 degree for range, velocity, and angle, respectively. This robust performance, demonstrated against strong clutter, showcases its suitability for practical ISAC-LAWNs applications.

</details>


### [6] [Distributed Cubature Kalman Filter based on MEEF with Adaptive Cauchy Kernel for State Estimation](https://arxiv.org/abs/2511.17066)
*Duc Viet Nguyen,Haiquan Zhao,Jinhui Hu*

Main category: eess.SP

TL;DR: 提出基于自适应最小误差熵的分布式容积卡尔曼滤波器(AMEEF-DCKF)，解决多传感器网络中非高斯噪声、异常数据和通信负担问题


<details>
  <summary>Details</summary>
Motivation: 多传感器网络中分布式容积卡尔曼滤波器面临非高斯噪声、异常数据和通信负担的挑战，需要新的优化方法

Method: 设计AMEEF优化准则使用自适应带宽柯西核处理非高斯噪声和异常数据，构建领导-跟随者平均一致性(LFAC)算法解决通信负担

Result: 通过10节点传感器网络验证了算法在电力系统状态估计和复杂环境陆地车辆导航中的有效性

Conclusion: AMEEF-DCKF算法能有效处理多传感器网络中的非高斯噪声、异常数据和通信负担问题

Abstract: Nowadays, with the development of multi-sensor networks, the distributed cubature Kalman filter is one of the well-known existing schemes for state estimation, for which the influence of the non-Gaussian noise, abnormal data, and communication burden are urgent challenges. In this paper, a distributed cubature Kalman filter based on adaptive minimum error entropy with fiducial points (AMEEF) criterion (AMEEF-DCKF) is proposed to overcome the above limitations. Specifically, firstly, in order to solve the influence of various types of non-Gaussian noise and abnormal data, the AMEEF optimization criterion is designed, in which the kernels used are Cauchy kernels with adaptive bandwidth. At the same time, the designed optimization criterion has enhanced the numerical stability and optimized the kernel bandwidth value. Next, in order to address the communication burden problem in multi-sensor networks, where a leader and a follower are distinguished, a distributed algorithm is constructed to achieve an average consensus among these sensors, called leader-follower average consensus (LFAC). Additionally, the convergence proof of the average consensus algorithm and the computational complexity analysis of the AMEEF-DCKF algorithm are also presented. Finally, through a 10-node sensor network, the effectiveness of the proposed algorithm is demonstrated in estimating the state of the power system and navigating land vehicles in complex environments.

</details>


### [7] [Incorporating Bayesian Transfer Learning into Particle Filter for Dual-Tracking System with Asymmetric Noise Intensities](https://arxiv.org/abs/2511.17440)
*Omar A. Alotaibi,Brian L. Mark,Mohammad Reza Fasihi*

Main category: eess.SP

TL;DR: 提出了一种基于贝叶斯迁移学习的粒子滤波方法，用于处理双传感器系统中测量噪声强度不对称的非线性动态模型跟踪问题，通过加权粒子近似密度来提升高噪声主传感器的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在双传感器跟踪系统中，当两个传感器的测量噪声强度不对称时，传统方法难以有效利用低噪声传感器来提升高噪声传感器的跟踪性能，需要开发能够处理这种不对称噪声的迁移学习方法。

Method: 使用贝叶斯迁移学习框架，通过加权粒子求和来近似密度函数，将低噪声源传感器的信息迁移到高噪声主传感器，并与孤立粒子滤波、无迹卡尔曼滤波和容积卡尔曼滤波的迁移学习方法进行对比。

Result: 仿真结果表明，该方法相比孤立粒子滤波和其他迁移学习方法具有更好的跟踪性能；增加粒子数量能显著提升迁移学习效果，但会增加计算时间；性能提升与传感器噪声强度差异近似线性相关。

Conclusion: 基于贝叶斯迁移学习的粒子滤波方法能有效提升双传感器系统中高噪声传感器的跟踪性能，性能改善与噪声差异成正比，但需要在性能提升和计算复杂度之间进行权衡。

Abstract: Using Bayesian transfer learning, we develop a particle filter approach for tracking a nonlinear dynamical model in a dual-tracking system where intensities of measurement noise for both sensors are asymmetric. The densities for Bayesian transfer learning are approximated with the sum of weighted particles to improve the tracking performance of the primary sensor, which experiences a higher noise intensity compared to the source sensor. We present simulation results that validate the effectiveness of the proposed approach compared to an isolated particle filter and transfer learning applied to the unscented Kalman filter and the cubature Kalman filter. Furthermore, increasing the number of particles shows an improvement in the performance of transfer learning applied to the particle filter with a higher rate compared to the isolated particle filter. However, increasing the number of particles raises computational time per step. Moreover, the performance gain from incorporating Bayesian transfer learning is approximately linearly proportional to the absolute difference value between the noise intensities of the sensors in the dual-tracking system.

</details>


### [8] [Unleashing Sensor-Aided Environment Awareness for Beam Management in Beyond-5G Networks: An OpenAirInterface Experimental Platform](https://arxiv.org/abs/2511.17122)
*Aron Schott,Berk Acikgöz,Omar Massoud,Marina Petrova,Ljiljana Simić*

Main category: eess.SP

TL;DR: 提出了一个基于OpenAirInterface的SDR实验平台，首次将低成本天线阵列收发器、波束扫描能力和模块化传感器框架集成到全栈实验平台中，用于实时真实场景的波束管理研究。


<details>
  <summary>Details</summary>
Motivation: 当前文献缺乏开放平台来收集用于机器学习技术训练的数据集，以及在实时真实场景和全栈端到端网络中评估新型波束管理方法。

Method: 开发基于OpenAirInterface的SDR实验平台，集成低成本天线阵列收发器、波束扫描能力和模块化传感器框架。

Result: 成功构建了支持实时真实场景波束管理实验的平台，便于收集开发基于机器学习的波束管理协议所需的数据集。

Conclusion: 该平台填补了现有研究的空白，为开发利用传感器模态实现环境感知的机器学习波束管理协议提供了必要的基础设施。

Abstract: Large antenna arrays and beamforming techniques are key components for exploiting the spectrum-rich FR2 bands in next-generation mobile communication networks. Given the site-specific spatio-temporal variations of the mm-wave channel, non-RF sensor inputs and environment awareness can be leveraged to greatly enhance beam management decisions, e.g. via machine learning (ML) techniques. However, the current literature lacks open platforms to gather datasets for the training of such ML techniques and to evaluate novel beam management approaches in real-time, real-world scenarios and full-stack endto-end networks. In this work, we present our SDR-based experimental platform based on OpenAirInterface and are the first to integrate popular low-cost antenna array transceivers, beam sweeping capabilities, and a highly-modular sensor framework and associated interfaces into such a full-stack experimental platform. This enables beam management experimentation in real-world, real-time scenarios and facilitates gathering datasets necessary for developing ML-based beam management protocols that incorporate environment awareness via sensor modalities.

</details>


### [9] [Teager-Kaiser Energy Methods For EEG Feature Extraction In Biomedical Applications](https://arxiv.org/abs/2511.17164)
*Ioanna Chourdaki,Kleanthis Avramidis,Christos Garoufis,Athanasia Zlatintsi,Petros Maragos*

Main category: eess.SP

TL;DR: 本文研究了Teager-Kaiser能量算子(TKEO)在EEG信号分析中的应用，通过Gabor滤波器组和能量分离算法提取能量描述符，在运动想象和癫痫检测任务中优于传统能量和功率谱特征。


<details>
  <summary>Details</summary>
Motivation: EEG信号具有非线性、非平稳性和易受噪声干扰的特性，提取判别性特征一直是个挑战。本文旨在探索TKEO算子对EEG信号能量动态建模的有效性。

Method: 使用Gabor滤波器组分离标准频带，然后应用能量分离算法将TKEO输出分解为幅度包络和瞬时频率分量，基于此推导出一组能量描述符。

Result: TKEO特征在运动想象和癫痫检测任务中优于基线方法，在情绪识别任务中表现相当。

Conclusion: 提出的基于TKEO的流程为提取EEG信号动态提供了一个直观的框架。

Abstract: Electroencephalography (EEG) signals are inherently non-linear, non-stationary, and vulnerable to noise sources, making the extraction of discriminative features a long-standing challenge. In this work, we investigate the non-linear Teager-Kaiser Energy Operator (TKEO) for modeling the underlying energy dynamics of EEG in three representative tasks: motor imagery, emotion recognition, and epilepsy detection. To accommodate the narrowband nature of the operator, we employ Gabor filterbanks to isolate canonical frequency bands, followed by the Energy Separation Algorithm to decompose the TKEO output into amplitude envelope and instantaneous frequency components. We then derive a set of energy descriptors based on this demodulation and compare their classification performance against established signal energy and power spectrum features. TKEO features outperform the respective baselines in motor imagery and epilepsy detection, whereas they perform on par in emotion recognition. Our findings suggest that the proposed TKEO-based pipeline provides an intuitive framework for extracting EEG signal dynamics.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [10] [Joint Design of Protein Surface and Structure Using a Diffusion Bridge Model](https://arxiv.org/abs/2511.16675)
*Guanlue Li,Xufeng Zhao,Fang Wu,Sören Laue*

Main category: cs.LG

TL;DR: PepBridge是一个用于联合设计蛋白质表面和结构的新框架，通过扩散桥模型和多模型扩散方法生成与受体表面互补的蛋白质结构。


<details>
  <summary>Details</summary>
Motivation: 蛋白质-蛋白质相互作用受表面互补性和疏水相互作用调控，但设计能够精确互补目标受体的多样化且物理真实的蛋白质结构和表面仍是一个重大挑战。

Method: 使用去噪扩散桥模型将受体表面映射到配体表面，然后通过多模型扩散预测相应结构，并通过形状-框架匹配网络确保表面几何与骨架结构对齐。

Result: 在多种蛋白质设计场景中的广泛验证表明，PepBridge能够生成结构可行的蛋白质。

Conclusion: 该方法在蛋白质结构的自上而下联合设计方面代表了重要进展，促进了表面互补性、构象稳定性和化学可行性。

Abstract: Protein-protein interactions (PPIs) are governed by surface complementarity and hydrophobic interactions at protein interfaces. However, designing diverse and physically realistic protein structure and surfaces that precisely complement target receptors remains a significant challenge in computational protein design. In this work, we introduce PepBridge, a novel framework for the joint design of protein surface and structure that seamlessly integrates receptor surface geometry and biochemical properties. Starting with a receptor surface represented as a 3D point cloud, PepBridge generates complete protein structures through a multi-step process. First, it employs denoising diffusion bridge models (DDBMs) to map receptor surfaces to ligand surfaces. Next, a multi-model diffusion model predicts the corresponding structure, while Shape-Frame Matching Networks ensure alignment between surface geometry and backbone architecture. This integrated approach facilitates surface complementarity, conformational stability, and chemical feasibility. Extensive validation across diverse protein design scenarios demonstrates PepBridge's efficacy in generating structurally viable proteins, representing a significant advancement in the joint design of top-down protein structure.

</details>


### [11] [Gradient flow for deep equilibrium single-index models](https://arxiv.org/abs/2511.16976)
*Sanjit Dandapanthula,Aaditya Ramdas*

Main category: cs.LG

TL;DR: 本文研究了深度平衡模型(DEQs)在梯度下降训练中的理论动态，在线性模型和单索引模型设置下，证明了参数在训练过程中保持球面约束，梯度流始终良好条件化，并在适当初始化和步长下实现线性收敛到全局最优解。


<details>
  <summary>Details</summary>
Motivation: 深度平衡模型在实践上取得了成功，但在理论上理解其梯度下降动态仍是一个活跃的研究领域。本文旨在填补文献中的空白，为DEQs的训练动态提供严格的理论分析。

Method: 在线性模型和单索引模型的简单设置下，研究DEQs的梯度下降动态。证明了线性DEQs的参数守恒定律，表明参数在训练过程中保持球面约束，并利用这一性质证明梯度流始终良好条件化。

Result: 证明了线性DEQs和深度平衡单索引模型在适当初始化和足够小步长下，梯度下降能够线性收敛到全局最优解。通过实验验证了理论发现。

Conclusion: 本文为深度平衡模型的梯度下降动态提供了严格的理论保证，证明了在特定条件下训练过程的良好性质和收敛性，填补了DEQs理论分析的重要空白。

Abstract: Deep equilibrium models (DEQs) have recently emerged as a powerful paradigm for training infinitely deep weight-tied neural networks that achieve state of the art performance across many modern machine learning tasks. Despite their practical success, theoretically understanding the gradient descent dynamics for training DEQs remains an area of active research. In this work, we rigorously study the gradient descent dynamics for DEQs in the simple setting of linear models and single-index models, filling several gaps in the literature. We prove a conservation law for linear DEQs which implies that the parameters remain trapped on spheres during training and use this property to show that gradient flow remains well-conditioned for all time. We then prove linear convergence of gradient descent to a global minimizer for linear DEQs and deep equilibrium single-index models under appropriate initialization and with a sufficiently small step size. Finally, we validate our theoretical findings through experiments.

</details>


### [12] [Convergence and stability of Q-learning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2511.17351)
*Massimiliano Manenti,Andrea Iannelli*

Main category: cs.LG

TL;DR: 本文提出了封建Q学习方案，分析了其收敛性和稳定性条件，并通过理论证明和实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 分层强化学习在捕捉决策问题的时间结构和增强持续学习能力方面具有潜力，但理论保证落后于实践。本文旨在为封建RL提供原则性的收敛性和稳定性分析。

Method: 提出封建Q学习方案，利用随机逼近理论和ODE方法分析其收敛性和稳定性，将更新过程解释为适当定义游戏的均衡点。

Result: 理论分析表明封建Q学习在特定条件下收敛且稳定，实验支持了理论预期的结果。

Conclusion: 该研究为封建分层强化学习提供了理论保证，并为采用博弈论方法研究分层RL打开了大门。

Abstract: Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.

</details>


### [13] [DDTime: Dataset Distillation with Spectral Alignment and Information Bottleneck for Time-Series Forecasting](https://arxiv.org/abs/2511.16715)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Hao Wang,Haoxuan Wang,Huiran Duan,Junming Liu,Yingli Tian*

Main category: cs.LG

TL;DR: DDTime是一个轻量级的时间序列数据集蒸馏框架，通过频域对齐机制和基于信息瓶颈的样本间正则化，解决了时间序列蒸馏中的时间偏差和样本多样性不足问题，在20个基准数据集上相比现有方法实现了约30%的相对精度提升。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测通常需要大规模数据集和大量计算资源，数据集蒸馏提供了一种替代方案，但扩展到时间序列领域面临两个挑战：1)强自相关性导致的时间偏差，2)缺乏明确类别先验导致的样本多样性不足。

Method: 基于一阶压缩分解构建轻量级框架，使用频域对齐机制解决时间偏差问题，通过基于信息瓶颈原理的样本间正则化增强多样性，支持稳定的一阶优化。

Result: 在20个基准数据集和多种预测架构上的实验表明，DDTime持续优于现有蒸馏方法，实现约30%的相对精度提升，同时仅引入约2.49%的计算开销。

Conclusion: DDTime为时间序列数据集蒸馏提供了一个有效且高效的解决方案，在保持高精度的同时显著降低了计算需求。

Abstract: Time-series forecasting is fundamental across many domains, yet training accurate models often requires large-scale datasets and substantial computational resources. Dataset distillation offers a promising alternative by synthesizing compact datasets that preserve the learning behavior of full data. However, extending dataset distillation to time-series forecasting is non-trivial due to two fundamental challenges: 1.temporal bias from strong autocorrelation, which leads to distorted value-term alignment between teacher and student models; and 2.insufficient diversity among synthetic samples, arising from the absence of explicit categorical priors to regularize trajectory variety.
  In this work, we propose DDTime, a lightweight and plug-in distillation framework built upon first-order condensation decomposition. To tackle Challenge 1, it revisits value-term alignment through temporal statistics and introduces a frequency-domain alignment mechanism to mitigate autocorrelation-induced bias, ensuring spectral consistency and temporal fidelity. To address Challenge 2, we further design an inter-sample regularization inspired by the information bottleneck principle, which enhances diversity and maximizes information density across synthetic trajectories. The combined objective is theoretically compatible with a wide range of condensation paradigms and supports stable first-order optimization. Extensive experiments on 20 benchmark datasets and diverse forecasting architectures demonstrate that DDTime consistently outperforms existing distillation methods, achieving about 30% relative accuracy gains while introducing about 2.49% computational overhead. All code and distilled datasets will be released.

</details>


### [14] [SAVeD: Semantic Aware Version Discovery](https://arxiv.org/abs/2511.17298)
*Artem Frenk,Roee Shraga*

Main category: cs.LG

TL;DR: SAVeD是一个基于对比学习的框架，用于识别结构化数据集的版本，无需依赖元数据、标签或集成假设，解决了数据科学中重复劳动的问题。


<details>
  <summary>Details</summary>
Motivation: 解决数据科学中因数据集相似工作或转换导致的重复劳动挑战，提供无需元数据或标签的版本检测方法。

Method: 采用改进的SimCLR管道，通过随机变换生成增强表视图，使用自定义transformer编码器嵌入，在潜在空间中进行对比优化语义相似性。

Result: 在五个标准数据集上的实验显示，SAVeD在未见过的表上获得显著更高的准确率，分离分数显著提升，能够有效区分语义变更的版本。

Conclusion: SAVeD在数据集版本检测方面表现出色，相比未训练基线和现有最先进方法如Starmie，取得了竞争性或更优的结果。

Abstract: Our work introduces SAVeD (Semantically Aware Version Detection), a contrastive learning-based framework for identifying versions of structured datasets without relying on metadata, labels, or integration-based assumptions. SAVeD addresses a common challenge in data science of repeated labor due to a difficulty of similar work or transformations on datasets. SAVeD employs a modified SimCLR pipeline, generating augmented table views through random transformations (e.g., row deletion, encoding perturbations). These views are embedded via a custom transformer encoder and contrasted in latent space to optimize semantic similarity. Our model learns to minimize distances between augmented views of the same dataset and maximize those between unrelated tables. We evaluate performance using validation accuracy and separation, defined respectively as the proportion of correctly classified version/non-version pairs on a hold-out set, and the difference between average similarities of versioned and non-versioned tables (defined by a benchmark, and not provided to the model). Our experiments span five canonical datasets from the Semantic Versioning in Databases Benchmark, and demonstrate substantial gains post-training. SAVeD achieves significantly higher accuracy on completely unseen tables in, and a significant boost in separation scores, confirming its capability to distinguish semantically altered versions. Compared to untrained baselines and prior state-of-the-art dataset-discovery methods like Starmie, our custom encoder achieves competitive or superior results.

</details>


### [15] [When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected](https://arxiv.org/abs/2511.16767)
*Haotian Xu,Yuning You,Tengfei Ma*

Main category: cs.LG

TL;DR: 研究发现，在文本属性图上，仅使用节点文本描述的LLM已经表现良好，大多数结构编码策略仅带来边际收益甚至负面影响，表明显式结构先验在强大语言模型时代可能不必要甚至有害。


<details>
  <summary>Details</summary>
Motivation: 探索不同图结构编码策略如何影响LLM在文本属性图上的性能，挑战传统图学习范式认为结构必然有益的基本假设。

Method: 通过系统实验比较不同图结构编码策略，包括基于模板的图模板和GNN编码结构信息的方法。

Result: LLM仅利用节点文本描述就能在各项任务中取得强劲表现；大多数结构编码策略仅提供边际收益或甚至负面影响。

Conclusion: 在强大语言模型时代，显式结构先验往往不必要且有时适得其反，需要重新思考结构在LLM图推理中的表示和利用方式，为语义驱动的图学习方法开辟新途径。

Abstract: Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at understanding natural language and integrating cross-modal signals, sparking interest in their potential for graph reasoning. Recent work has explored this by either designing template-based graph templates or using graph neural networks (GNNs) to encode structural information. In this study, we investigate how different strategies for encoding graph structure affect LLM performance on text-attributed graphs. Surprisingly, our systematic experiments reveal that: (i) LLMs leveraging only node textual descriptions already achieve strong performance across tasks; and (ii) most structural encoding strategies offer marginal or even negative gains. We show that explicit structural priors are often unnecessary and, in some cases, counterproductive when powerful language models are involved. This represents a significant departure from traditional graph learning paradigms and highlights the need to rethink how structure should be represented and utilized in the LLM era. Our study is to systematically challenge the foundational assumption that structure is inherently beneficial for LLM-based graph reasoning, opening the door to new, semantics-driven approaches for graph learning.

</details>


### [16] [Self-Supervised Learning by Curvature Alignment](https://arxiv.org/abs/2511.17426)
*Benyamin Ghojogh,M. Hadi Sepanj,Paul Fieguth*

Main category: cs.LG

TL;DR: CurvSSL是一个曲率正则化的自监督学习框架，通过在标准冗余减少损失基础上添加曲率正则化器，显式地塑造表示的局部几何结构。


<details>
  <summary>Details</summary>
Motivation: 现有的非对比自监督学习方法主要关注表示的一阶和二阶统计特性，但忽略了底层数据流形的局部几何结构。

Method: 采用标准双视图编码器-投影器架构，在Barlow Twins风格的冗余减少损失基础上，添加基于曲率的正则化器，通过k近邻的余弦交互计算离散曲率分数，并在增强视图间对齐和去相关。

Result: 在MNIST和CIFAR-10数据集上的实验表明，曲率正则化的自监督学习相比Barlow Twins和VICReg具有竞争性或改进的线性评估性能。

Conclusion: 显式塑造局部几何结构是纯统计自监督学习正则化器的简单有效补充。

Abstract: Self-supervised learning (SSL) has recently advanced through non-contrastive methods that couple an invariance term with variance, covariance, or redundancy-reduction penalties. While such objectives shape first- and second-order statistics of the representation, they largely ignore the local geometry of the underlying data manifold. In this paper, we introduce CurvSSL, a curvature-regularized self-supervised learning framework, and its RKHS extension, kernel CurvSSL. Our approach retains a standard two-view encoder-projector architecture with a Barlow Twins-style redundancy-reduction loss on projected features, but augments it with a curvature-based regularizer. Each embedding is treated as a vertex whose $k$ nearest neighbors define a discrete curvature score via cosine interactions on the unit hypersphere; in the kernel variant, curvature is computed from a normalized local Gram matrix in an RKHS. These scores are aligned and decorrelated across augmentations by a Barlow-style loss on a curvature-derived matrix, encouraging both view invariance and consistency of local manifold bending. Experiments on MNIST and CIFAR-10 datasets with a ResNet-18 backbone show that curvature-regularized SSL yields competitive or improved linear evaluation performance compared to Barlow Twins and VICReg. Our results indicate that explicitly shaping local geometry is a simple and effective complement to purely statistical SSL regularizers.

</details>


### [17] [Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization](https://arxiv.org/abs/2511.17489)
*Vinay Kanakeri,Shivam Bajaj,Ashwin Verma,Vijay Gupta,Aritra Mitra*

Main category: cs.LG

TL;DR: 提出一种结合聚类和强化学习的新算法，用于多智能体线性二次调节器(LQR)控制问题，能够同时进行聚类和学习，为每个聚类输出个性化策略，在保证正确聚类的同时实现样本效率提升。


<details>
  <summary>Details</summary>
Motivation: 强化学习通常数据效率低下，虽然可以利用近似相似过程的数据来提高效率，但由于过程模型未知，识别哪些过程相似存在挑战。

Method: 结合顺序消除和零阶策略优化的思想，提出新算法在LQR设置下同时进行聚类和学习，为每个聚类输出个性化控制器。

Result: 在适当的聚类分离条件下，算法能以高概率保证正确聚类，每个聚类的策略次优性差距与聚类大小成反比，且没有额外偏差。

Conclusion: 这是首个展示聚类如何在数据驱动控制中用于学习个性化策略的工作，既能从协作中获得统计增益，又不会因包含不相似过程数据而遭受次优性损失。

Abstract: It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.

</details>


### [18] [GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs](https://arxiv.org/abs/2511.16778)
*Yating Ren,Yikun Ban,Huobin Tan*

Main category: cs.LG

TL;DR: 提出了GCL-OT框架，通过最优传输解决文本属性图中的多粒度异质性挑战，实现结构和文本的灵活双向对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖同质性假设和硬优化目标，在处理异质性图时表现不佳，特别是当文本嵌入被视为静态目标时会导致次优对齐。

Method: 使用最优传输的图对比学习框架，包含RealSoftMax相似性估计器处理部分异质性、基于提示的过滤器处理完全异质性，以及OT引导的软监督学习潜在同质性。

Result: 在九个基准测试中始终优于最先进方法，验证了其有效性和鲁棒性。

Conclusion: GCL-OT能够有效处理文本属性图中的多粒度异质性问题，提高互信息边界和贝叶斯误差保证。

Abstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assumptions in similarity estimation and hard optimization objectives, which limit their applicability to heterophilic graphs. Although existing methods can mitigate heterophily through structural adjustments or neighbor aggregation, they usually treat textual embeddings as static targets, leading to suboptimal alignment. In this work, we identify the multi-granular heterophily in text-attributed graphs, including complete heterophily, partial heterophily, and latent homophily, which makes structure-text alignment particularly challenging due to mixed, noisy, and missing semantic correlations. To achieve flexible and bidirectional alignment, we propose GCL-OT, a novel graph contrastive learning framework with optimal transport, equipped with tailored mechanisms for each type of heterophily. Specifically, for partial heterophily, we design a RealSoftMax-based similarity estimator to emphasize key neighbor-word interactions while easing background noise. For complete heterophily, we introduce a prompt-based filter that adaptively excludes irrelevant noise during optimal transport alignment. Furthermore, we incorporate OT-guided soft supervision to uncover potential neighbors with similar semantics, enhancing the learning of latent homophily. Theoretical analysis shows that GCL-OT can improve the mutual information bound and Bayes error guarantees. Extensive experiments on nine benchmarks show that GCL-OT consistently outperforms state-of-the-art methods, verifying its effectiveness and robustness.

</details>


### [19] [Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided Outlier-KV-Aware Approach](https://arxiv.org/abs/2511.16786)
*Yaoxin Yang,Peng Ye,Xudong Tan,Chongjun Tu,Maosen Zhao,Jia Hao,Tao Chen*

Main category: cs.LG

TL;DR: FlashCache是一个基于频域分析和异常KV感知的多模态KV缓存压缩框架，通过保留偏离主能量的异常KV对，在保持任务性能的同时显著降低内存使用和加速解码。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在推理开销大的问题，因为多模态KV缓存随视觉输入长度增长而增加。现有压缩方法依赖注意力分数，与高效注意力内核不兼容且忽略了值向量的贡献。

Method: 1) 在频域分析KV矩阵分布，发现能量集中在低频；2) 提出异常KV识别模块，优先保留偏离主能量的KV对；3) 设计动态预算分配模块，自适应确定每层KV缓存大小。

Result: 在多个MLLM和基准测试中，FlashCache优于现有方法，实现1.69倍解码加速，KV内存使用降低80%，同时保持任务性能。

Conclusion: FlashCache通过频域引导的异常KV感知压缩框架，有效解决了多模态KV缓存压缩问题，在保持性能的同时显著提升了效率。

Abstract: Multimodal large language models suffer from substantial inference overhead since multimodal KV Cache grows proportionally with the visual input length. Existing multimodal KV Cache compression methods mostly rely on attention score to reduce cache size, which makes them are incompatible with established efficient attention kernels (e.g., FlashAttention) and ignores the contribution of value vectors to the attention output. In this work, we revisit multimodal KV Cache compression from the perspective of the KV matrices' distribution. First, we observe that frequency-domain energy of multimodal KV matrices is predominantly concentrated in low-frequency and extract this principal energy via a low-pass filter. Further, we find that removing KV pairs that deviate substantially from this principal energy leads to a pronounced performance drop, which we define as Outlier KVs. Considering Outlier KVs are more likely to encode features critical for inference, we propose FlashCache, a frequency-domain-guided, Outlier-KV-aware KV Cache compression framework. First, we introduce an Outlier KV Recognition Module that models the principal component of multimodal KV matrices in the frequency domain and preferentially retains KV pairs that significantly deviate from it. Furthermore, Dynamic Budget Allocation Module is designed to adaptively determine the per-layer KV Cache size to retain more Outlier KVs. Experiments on multiple MLLMs and benchmarks demonstrate that FlashCache outperforms state-of-the-art multimoal KV compression methods, achieving up to 1.69 times faster decoding with 80% lower KV memory usage while maintaining task performance.

</details>


### [20] [A Vector Symbolic Approach to Multiple Instance Learning](https://arxiv.org/abs/2511.16795)
*Ehsan Ahmed Dhrubo,Mohammad Mahmudul Alam,Edward Raff,Tim Oates,James Holt*

Main category: cs.LG

TL;DR: 提出基于向量符号架构(VSA)的多示例学习框架，通过高维向量和代数运算严格强制执行MIL的iff约束，在标准基准和医学影像数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法大多违反MIL的iff约束(包为正当且仅当至少一个实例为正)，导致性能指标虚高和泛化能力差，需要能严格遵循MIL假设的模型。

Method: 使用VSA将实例和概念编码为近似正交的高维向量，通过代数运算在分类时强制执行iff约束；设计学习编码器将原始数据转换为VSA兼容向量；包含VSA驱动的MaxNetwork分类器。

Result: 在标准MIL基准和医学影像数据集上达到最先进结果，优于现有方法，同时严格遵循MIL公式。

Conclusion: 为依赖学习启发式的现有MIL方法提供了原则性、可解释且有效的替代方案。

Abstract: Multiple Instance Learning (MIL) tasks impose a strict logical constraint: a bag is labeled positive if and only if at least one instance within it is positive. While this iff constraint aligns with many real-world applications, recent work has shown that most deep learning-based MIL approaches violate it, leading to inflated performance metrics and poor generalization. We propose a novel MIL framework based on Vector Symbolic Architectures (VSAs), which provide a differentiable mechanism for performing symbolic operations in high-dimensional space. Our method encodes the MIL assumption directly into the model's structure by representing instances and concepts as nearly orthogonal high-dimensional vectors and using algebraic operations to enforce the iff constraint during classification. To bridge the gap between raw data and VSA representations, we design a learned encoder that transforms input instances into VSA-compatible vectors while preserving key distributional properties. Our approach, which includes a VSA-driven MaxNetwork classifier, achieves state-of-the-art results for a valid MIL model on standard MIL benchmarks and medical imaging datasets, outperforming existing methods while maintaining strict adherence to the MIL formulation. This work offers a principled, interpretable, and effective alternative to existing MIL approaches that rely on learned heuristics.

</details>


### [21] [A Robust Federated Learning Approach for Combating Attacks Against IoT Systems Under non-IID Challenges](https://arxiv.org/abs/2511.16822)
*Eyad Gad,Zubair Md Fadlullah,Mostafa M. Fouda*

Main category: cs.LG

TL;DR: 本文比较了FedAvg、FedProx和Scaffold三种联邦学习算法在非IID数据分布下的性能，使用CICIoT2023数据集进行物联网攻击检测，旨在解决统计异质性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 物联网环境中设备资源受限且数据隐私敏感，传统机器学习面临挑战。联邦学习虽能解决隐私和资源问题，但非IID数据的统计异质性严重影响其效果，现有研究缺乏对联邦学习方法在物联网攻击检测中的全面比较。

Method: 使用CICIoT2023数据集，在多种数据分布下系统评估FedAvg、FedProx和Scaffold三种联邦学习算法，分析它们在统计异质性环境中的表现。

Result: 通过细致的实验分析，揭示了三种联邦学习方法在物联网攻击检测任务中的性能差异和特点。

Conclusion: 研究为物联网安全领域的联邦学习应用提供了有价值的见解，帮助研究者和从业者更好地应对统计异质性挑战。

Abstract: In the context of the growing proliferation of user devices and the concurrent surge in data volumes, the complexities arising from the substantial increase in data have posed formidable challenges to conventional machine learning model training. Particularly, this is evident within resource-constrained and security-sensitive environments such as those encountered in networks associated with the Internet of Things (IoT). Federated Learning has emerged as a promising remedy to these challenges by decentralizing model training to edge devices or parties, effectively addressing privacy concerns and resource limitations. Nevertheless, the presence of statistical heterogeneity in non-Independently and Identically Distributed (non-IID) data across different parties poses a significant hurdle to the effectiveness of FL. Many FL approaches have been proposed to enhance learning effectiveness under statistical heterogeneity. However, prior studies have uncovered a gap in the existing research landscape, particularly in the absence of a comprehensive comparison between federated methods addressing statistical heterogeneity in detecting IoT attacks. In this research endeavor, we delve into the exploration of FL algorithms, specifically FedAvg, FedProx, and Scaffold, under different data distributions. Our focus is on achieving a comprehensive understanding of and addressing the challenges posed by statistical heterogeneity. In this study, We classify large-scale IoT attacks by utilizing the CICIoT2023 dataset. Through meticulous analysis and experimentation, our objective is to illuminate the performance nuances of these FL methods, providing valuable insights for researchers and practitioners in the domain.

</details>


### [22] [Monte Carlo Expected Threat (MOCET) Scoring](https://arxiv.org/abs/2511.16823)
*Joseph Kim,Saahith Potluri*

Main category: cs.LG

TL;DR: 提出MOCET指标来评估AI安全等级威胁，特别是针对ASL-3+模型在生物安全领域的风险。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标如LAB-Bench、BioLP-bench和WMDP能可靠评估模型提升和领域知识，但需要更好量化"现实世界风险"的指标，以及可扩展的开放式指标来跟上LLM快速发展。

Method: 引入MOCET指标，这是一个可解释且双重可扩展的指标（可自动化和开放式），能够量化现实世界风险。

Result: MOCET能够量化现实世界风险，填补了现有评估指标的不足。

Conclusion: MOCET为LLM安全案例提供了更好的风险评估工具，能够跟上AI技术的快速发展。

Abstract: Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, especially in the realm of biosecurity. Existing evaluation metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model uplift and domain knowledge. However, metrics that better contextualize "real-world risks" are needed to inform the safety case for LLMs, along with scalable, open-ended metrics to keep pace with their rapid advancements. To address both gaps, we introduce MOCET, an interpretable and doubly-scalable metric (automatable and open-ended) that can quantify real-world risks.

</details>


### [23] [ManifoldFormer: Geometric Deep Learning for Neural Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2511.16828)
*Yihang Fu,Lifang He,Qingyu Chen*

Main category: cs.LG

TL;DR: ManifoldFormer是一个几何深度学习框架，通过显式学习神经流形表示来解决现有EEG基础模型忽略神经动态内在几何结构的问题，显著提升了EEG信号的表征质量和跨被试泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有EEG基础模型将神经信号视为欧几里得空间中的通用时间序列，忽略了约束大脑活动到低维流形的神经动态内在几何结构。这种模型假设与神经几何之间的基本不匹配限制了表征质量和跨被试泛化能力。

Method: ManifoldFormer整合了三个关键创新：用于保持几何结构的黎曼VAE进行流形嵌入、在神经流形上直接操作的具有测地线感知注意力机制的几何Transformer，以及利用神经ODE进行流形约束时间演化的动态预测器。

Result: 在四个公共数据集上的广泛评估显示，与最先进方法相比，准确率提高了4.6-4.8%，Cohen's Kappa提高了6.2-10.2%，同时保持了稳健的跨被试泛化能力。

Conclusion: 几何方法揭示了与神经生理学原理一致的有意义神经模式，确立了几何约束对于有效EEG基础模型的重要性。

Abstract: Existing EEG foundation models mainly treat neural signals as generic time series in Euclidean space, ignoring the intrinsic geometric structure of neural dynamics that constrains brain activity to low-dimensional manifolds. This fundamental mismatch between model assumptions and neural geometry limits representation quality and cross-subject generalization. ManifoldFormer addresses this limitation through a novel geometric deep learning framework that explicitly learns neural manifold representations. The architecture integrates three key innovations: a Riemannian VAE for manifold embedding that preserves geometric structure, a geometric Transformer with geodesic-aware attention mechanisms operating directly on neural manifolds, and a dynamics predictor leveraging neural ODEs for manifold-constrained temporal evolution. Extensive evaluation across four public datasets demonstrates substantial improvements over state-of-the-art methods, with 4.6-4.8% higher accuracy and 6.2-10.2% higher Cohen's Kappa, while maintaining robust cross-subject generalization. The geometric approach reveals meaningful neural patterns consistent with neurophysiological principles, establishing geometric constraints as essential for effective EEG foundation models.

</details>


### [24] [Analysis of heart failure patient trajectories using sequence modeling](https://arxiv.org/abs/2511.16839)
*Falk Dippela,Yinan Yu,Annika Rosengren,Martin Lindgren,Christina E. Lundberg,Erik Aerts,Martin Adiels,Helen Sjöland*

Main category: cs.LG

TL;DR: 本文系统比较了Transformer、Transformer++和Mamba三种架构在临床预测任务中的表现，发现在瑞典心衰队列中，Llama（Transformer++）在预测区分度、校准性和鲁棒性方面表现最佳，Mamba次之，两者都能用更少参数和训练数据达到优异性能。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer和Mamba在电子健康记录处理中表现出色，但医学领域缺乏系统分析模型性能和效率的方法。本文旨在填补这一空白，为临床预测任务提供实证分析框架。

Method: 在瑞典42820名心衰患者队列中，比较了六种序列模型（涵盖Transformer、Transformer++、Mamba三类架构），评估三个一年预测任务：临床不稳定、初始住院后死亡率和最新住院后死亡率。进行了输入序列修改、架构配置和时间预处理技术的消融实验。

Result: Llama获得最高的预测区分度和最佳校准，在所有任务中表现出鲁棒性，Mamba次之。两种架构都展示了高效的表征学习能力，小配置超越其他大型Transformer。在相同模型大小下，Llama和Mamba仅需75%的训练数据就能达到优异性能。

Conclusion: 本研究首次提供了针对输入标记化、模型配置和时间数据预处理的系统消融研究，为未来基于EHR的临床预测模型开发提供了重要参考起点。

Abstract: Transformers have defined the state-of-the-art for clinical prediction tasks involving electronic health records (EHRs). The recently introduced Mamba architecture outperformed an advanced Transformer (Transformer++) based on Llama in handling long context lengths, while using fewer model parameters. Despite the impressive performance of these architectures, a systematic approach to empirically analyze model performance and efficiency under various settings is not well established in the medical domain. The performances of six sequence models were investigated across three architecture classes (Transformers, Transformers++, Mambas) in a large Swedish heart failure (HF) cohort (N = 42820), providing a clinically relevant case study. Patient data included diagnoses, vital signs, laboratories, medications and procedures extracted from in-hospital EHRs. The models were evaluated on three one-year prediction tasks: clinical instability (a readmission phenotype) after initial HF hospitalization, mortality after initial HF hospitalization and mortality after latest hospitalization. Ablations account for modifications of the EHR-based input patient sequence, architectural model configurations, and temporal preprocessing techniques for data collection. Llama achieves the highest predictive discrimination, best calibration, and showed robustness across all tasks, followed by Mambas. Both architectures demonstrate efficient representation learning, with tiny configurations surpassing other large-scaled Transformers. At equal model size, Llama and Mambas achieve superior performance using 25% less training data. This paper presents a first ablation study with systematic design choices for input tokenization, model configuration and temporal data preprocessing. Future model development in clinical prediction tasks using EHRs could build upon this study's recommendation as a starting point.

</details>


### [25] [Provably Minimum-Length Conformal Prediction Sets for Ordinal Classification](https://arxiv.org/abs/2511.16845)
*Zijian Zhang,Xinyu Chen,Yuanjie Shi,Liyuan Lillian Ma,Zifan Xu,Yan Yan*

Main category: cs.LG

TL;DR: 提出了一种新的序数分类共形预测方法，该方法与模型无关，提供实例级最优预测区间，通过滑动窗口算法在保证统计有效性的同时显著提高预测效率。


<details>
  <summary>Details</summary>
Motivation: 现有序数共形预测方法主要关注启发式算法或要求基础模型预测单峰分布，限制了覆盖效率权衡的洞察力，缺乏模型无关和分布自由的特性。

Method: 将序数共形分类建模为实例级的最小长度覆盖问题，开发线性时间复杂度的滑动窗口算法，并提出长度正则化变体来缩小预测集大小同时保持覆盖。

Result: 在四个不同领域的基准数据集上实验表明，所提方法相比基线平均减少15%的预测集大小，显著提高了预测效率。

Conclusion: 该方法填补了序数共形预测的空白，提供模型无关、实例级最优的预测区间，在保证统计有效性的同时大幅提升预测效率。

Abstract: Ordinal classification has been widely applied in many high-stakes applications, e.g., medical imaging and diagnosis, where reliable uncertainty quantification (UQ) is essential for decision making. Conformal prediction (CP) is a general UQ framework that provides statistically valid guarantees, which is especially useful in practice. However, prior ordinal CP methods mainly focus on heuristic algorithms or restrictively require the underlying model to predict a unimodal distribution over ordinal labels. Consequently, they provide limited insight into coverage-efficiency trade-offs, or a model-agnostic and distribution-free nature favored by CP methods. To this end, we fill this gap by propose an ordinal-CP method that is model-agnostic and provides instance-level optimal prediction intervals. Specifically, we formulate conformal ordinal classification as a minimum-length covering problem at the instance level. To solve this problem, we develop a sliding-window algorithm that is optimal on each calibration data, with only a linear time complexity in K, the number of label candidates. The local optimality per instance further also improves predictive efficiency in expectation. Moreover, we propose a length-regularized variant that shrinks prediction set size while preserving coverage. Experiments on four benchmark datasets from diverse domains are conducted to demonstrate the significantly improved predictive efficiency of the proposed methods over baselines (by 15% decrease on average over four datasets).

</details>


### [26] [Sex and age determination in European lobsters using AI-Enhanced bioacoustics](https://arxiv.org/abs/2511.16848)
*Feliciano Pedro Francisco Domingos,Isibor Kennedy Ihianle,Omprakash Kaiwartya,Ahmad Lotfi,Nicola Khan,Nicholas Beaudreau,Amaya Albalat,Pedro Machado*

Main category: cs.LG

TL;DR: 使用被动声学监测和AI模型对欧洲龙虾进行年龄和性别分类，深度学习模型在年龄分类上准确率超过97%，性别分类上超过93%，为龙虾保护和管理提供非侵入性方法。


<details>
  <summary>Details</summary>
Motivation: 监测难以观察的水生物种如龙虾具有挑战性，了解其栖息地、福利、繁殖、性别和年龄对管理和保护至关重要。本研究旨在利用非侵入性被动声学监测技术解决这一问题。

Method: 在苏格兰Johnshaven使用水听器收集龙虾生物声学数据，探索深度学习模型（1D-CNN、1D-DCNN）和六种机器学习模型（SVM、k-NN、Naive Bayes、Random Forest、XGBoost、MLP），使用MFCC作为特征。

Result: 年龄分类（成体vs幼体）中大多数模型准确率超过97%（Naive Bayes为91.31%），性别分类中除Naive Bayes外所有模型准确率超过93.23%。

Conclusion: 监督机器学习和深度学习能够从龙虾声音中提取年龄和性别相关特征，为龙虾保护、检测和管理提供了有前景的非侵入性被动声学监测方法，可实现水下物种的实时边缘计算应用。

Abstract: Monitoring aquatic species, especially elusive ones like lobsters, presents challenges. This study focuses on Homarus gammarus (European lobster), a key species for fisheries and aquaculture, and leverages non-invasive Passive Acoustic Monitoring (PAM). Understanding lobster habitats, welfare, reproduction, sex, and age is crucial for management and conservation. While bioacoustic emissions have classified various aquatic species using Artificial Intelligence (AI) models, this research specifically uses H. gammarus bioacoustics (buzzing/carapace vibrations) to classify lobsters by age (juvenile/adult) and sex (male/female).
  The dataset was collected at Johnshaven, Scotland, using hydrophones in concrete tanks. We explored the efficacy of Deep Learning (DL) models (1D-CNN, 1D-DCNN) and six Machine Learning (ML) models (SVM, k-NN, Naive Bayes, Random Forest, XGBoost, MLP). Mel-frequency cepstral coefficients (MFCCs) were used as features.
  For age classification (adult vs. juvenile), most models achieved over 97% accuracy (Naive Bayes: 91.31%). For sex classification, all models except Naive Bayes surpassed 93.23%. These strong results demonstrate the potential of supervised ML and DL to extract age- and sex-related features from lobster sounds. This research offers a promising non-invasive PAM approach for lobster conservation, detection, and management in aquaculture and fisheries, enabling real-world edge computing applications for underwater species.

</details>


### [27] [Better audio representations are more brain-like: linking model-brain alignment with performance in downstream auditory tasks](https://arxiv.org/abs/2511.16849)
*Leonardo Pepino,Pablo Riera,Juan Kamienkowski,Luciana Ferrer*

Main category: cs.LG

TL;DR: 研究发现，在听觉领域，自监督音频模型的任务性能与大脑表征相似性呈正相关，且这种大脑相似性在预训练过程中会自然涌现。


<details>
  <summary>Details</summary>
Motivation: 探究人工神经网络在提高任务性能的同时，其内部表征是否会与大脑信号更加相似，特别是在听觉领域。

Method: 使用36种不同音频模型的内部表征与两个独立fMRI数据集的大脑活动进行对比分析，采用体素回归、成分回归和表征相似性分析(RSA)，并在HEAREval基准的6个听觉任务中评估模型性能。

Result: 发现性能更强的自监督音频模型能更好地预测听觉皮层活动，模型整体任务性能与大脑表征对齐度呈强正相关(r>0.7)，且EnCodecMAE预训练过程中大脑相似性会逐步增加。

Conclusion: 大脑样表征可能是从自然音频数据中学习重建缺失信息的自然涌现副产品，无需显式优化即可获得。

Abstract: Artificial neural networks (ANNs) are increasingly powerful models of brain computation, yet it remains unclear whether improving their task performance also makes their internal representations more similar to brain signals. To address this question in the auditory domain, we quantified the alignment between the internal representations of 36 different audio models and brain activity from two independent fMRI datasets. Using voxel-wise and component-wise regression, and representation similarity analysis (RSA), we found that recent self-supervised audio models with strong performance in diverse downstream tasks are better predictors of auditory cortex activity than older and more specialized models. To assess the quality of the audio representations, we evaluated these models in 6 auditory tasks from the HEAREval benchmark, spanning music, speech, and environmental sounds. This revealed strong positive Pearson correlations ($r>0.7$) between a model's overall task performance and its alignment with brain representations. Finally, we analyzed the evolution of the similarity between audio and brain representations during the pretraining of EnCodecMAE. We discovered that brain similarity increases progressively and emerges early during pretraining, despite the model not being explicitly optimized for this objective. This suggests that brain-like representations can be an emergent byproduct of learning to reconstruct missing information from naturalistic audio data.

</details>


### [28] [The use of vocal biomarkers in the detection of Parkinson's disease: a robust statistical performance comparison of classic machine learning models](https://arxiv.org/abs/2511.16856)
*Katia Pires Nascimento do Sacramento,Elliot Q. C. Garcia,Nicéias Silva Vilela,Vinicius P. Sacramento,Tiago A. E. Ferreira*

Main category: cs.LG

TL;DR: 本研究评估了深度神经网络在利用语音生物标志物区分帕金森病患者与健康对照方面的有效性，与传统机器学习方法相比，DNN在准确性和效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 帕金森病早期常伴有语音障碍，使用语音生物标志物进行早期诊断具有非侵入性、低成本且易于获取的优势。

Method: 使用两个公开语音数据集，提取MFCC特征，采用1000次独立随机执行的验证策略评估模型鲁棒性，使用非参数检验比较不同分类模型的性能。

Result: DNN在意大利语音数据集和帕金森远程监测数据集上分别达到98.65%和92.11%的平均准确率，显著优于传统机器学习模型。

Conclusion: 深度神经网络在利用语音生物标志物进行神经退行性疾病早期检测方面具有更高的准确性和可靠性潜力。

Abstract: Parkinson's disease (PD) is a progressive neurodegenerative disorder that, in addition to directly impairing functional mobility, is frequently associated with vocal impairments such as hypophonia and dysarthria, which typically manifest in the early stages. The use of vocal biomarkers to support the early diagnosis of PD presents a non-invasive, low-cost, and accessible alternative in clinical settings. Thus, the objective of this cross-sectional study was to consistently evaluate the effectiveness of a Deep Neural Network (DNN) in distinguishing individuals with Parkinson's disease from healthy controls, in comparison with traditional Machine Learning (ML) methods, using vocal biomarkers. Two publicly available voice datasets were used. Mel-frequency cepstral coefficients (MFCCs) were extracted from the samples, and model robustness was assessed using a validation strategy with 1000 independent random executions. Performance was evaluated using classification statistics. Since normality assumptions were not satisfied, non-parametric tests (Kruskal-Wallis and Bonferroni post-hoc tests) were applied to verify whether the tested classification models were similar or different in the classification of PD. With an average accuracy of $98.65\%$ and $92.11\%$ on the Italian Voice dataset and Parkinson's Telemonitoring dataset, respectively, the DNN demonstrated superior performance and efficiency compared to traditional ML models, while also achieving competitive results when benchmarked against relevant studies. Overall, this study confirms the efficiency of DNNs and emphasizes their potential to provide greater accuracy and reliability for the early detection of neurodegenerative diseases using voice-based biomarkers.

</details>


### [29] [Topologic Attention Networks: Attending to Direct and Indirect Neighbors through Gaussian Belief Propagation](https://arxiv.org/abs/2511.16871)
*Marshall Rosenhoover,Huaming Zhang*

Main category: cs.LG

TL;DR: 提出了拓扑注意力网络，通过概率机制学习信息在图中的直接和间接连接中的传播方式，解决了图神经网络建模长距离依赖的问题。


<details>
  <summary>Details</summary>
Motivation: 图神经网络依赖局部消息传递，难以建模图中的长距离依赖关系。现有方法通过连续时间动态或密集自注意力来扩展范围，但计算成本高且可扩展性有限。

Method: 提出拓扑注意力网络框架，应用拓扑注意力机制，这是一种概率机制，学习信息应如何通过图中的直接和间接连接流动。与传统依赖显式成对交互的注意力不同，拓扑注意力从图的学得信息传播中产生。

Result: 该方法在所有测量的基线模型上实现了最先进的性能。

Conclusion: 拓扑注意力网络能够统一推理局部和全局关系，提供了一种有效建模图中长距离依赖的新方法。

Abstract: Graph Neural Networks rely on local message passing, which limits their ability to model long-range dependencies in graphs. Existing approaches extend this range through continuous-time dynamics or dense self-attention, but both suffer from high computational cost and limited scalability. We propose Topologic Attention Networks, a new framework that applies topologic attention, a probabilistic mechanism that learns how information should flow through both direct and indirect connections in a graph. Unlike conventional attention that depends on explicit pairwise interactions, topologic attention emerges from the learned information propagation of the graph, enabling unified reasoning over local and global relationships. This method achieves provides state-of-the-art performance across all measured baseline models. Our implementation is available at https://github.com/Marshall-Rosenhoover/Topologic-Attention-Networks.

</details>


### [30] [PersonalizedRouter: Personalized LLM Routing via Graph-based User Preference Modeling](https://arxiv.org/abs/2511.16883)
*Zhongjie Dai,Tao Feng,Jiaxuan You*

Main category: cs.LG

TL;DR: 提出了PersonalizedRouter框架，使用图神经网络建模用户偏好，实现个性化LLM选择，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着多样化LLM的出现，用户在选择合适模型时面临挑战，现有方法无法学习个体用户偏好，需要个性化选择方案。

Method: 将交互数据转换为异构图，通过图神经网络建模用户查询与最优LLM之间的上下文关系，设计了两种评估策略和多用户基准测试。

Result: 在两个模拟策略下分别超过最强方法15.38%和9.83%，在1000用户基准上分别提升16.19%和59.69%，同时保持更高效率。

Conclusion: PersonalizedRouter在个性化LLM选择方面表现优异，具有强大的少样本泛化能力，能适应新用户和新LLM。

Abstract: The growing number of Large Language Models (LLMs) with diverse capabilities and response styles provides users with a wider range of choices, which presents challenges in selecting appropriate LLMs, as user preferences vary in terms of performance, cost, and response style. Current LLM selection methods typically optimize for a single fixed objective, such as performance, cost, or a trade-off between them, and fail to learn individual user preferences from interaction data. To address these limitations, we propose PersonalizedRouter, a graph-based framework that models diverse user profiles and performs personalized LLM selection by leveraging interaction data that includes task context, queries, candidate LLMs, and user decisions. To capture contextual information between user queries and optimal LLMs, PersonalizedRouter converts the interaction data into a heterogeneous graph, where the relationships between different types of nodes are represented by edges. To evaluate adaptability across users, we design two strategies: the multi-cost-efficiency simulation strategy and the LLM-as-a-Judge strategy. In addition, we construct PersonaRoute-Bench, a large-scale benchmark with 1,000 simulated users and 10 LLMs. Experimental results show that PersonalizedRouter significantly outperforms existing LLM selection methods and surpasses the strongest methods by a large margin of 15.38% and 9.83% under two simulation strategies. On the PersonaRoute-Bench with 1,000 users, it further surpasses the best methods by 16.19% and 59.69% while maintaining higher efficiency. Moreover, PersonalizedRouter demonstrates strong few-shot generalization, achieving 64.81% and 85.80% of the fully trained model's performance when adapting to new users and new LLMs.

</details>


### [31] [Predicting Talent Breakout Rate using Twitter and TV data](https://arxiv.org/abs/2511.16905)
*Bilguun Batsaikhan,Hiroyuki Fukuda*

Main category: cs.LG

TL;DR: 提出了一种结合Twitter和电视数据预测日本艺人爆红的方法，通过比较传统时间序列模型、神经网络和集成学习方法，发现集成学习在标准回归指标上表现最好，但神经网络在预测艺人爆红方面具有更高的精确率和召回率。


<details>
  <summary>Details</summary>
Motivation: 在广告领域早期发现潜力艺人至关重要，研究旨在探索结合社交媒体和电视数据预测艺人爆红时间的有效性。

Method: 使用Twitter和电视数据，比较了传统时间序列模型、神经网络和集成学习方法，并引入了"艺人爆红"概念来评估模型的真实预测能力。

Result: 集成学习方法在标准回归指标上表现最优，但神经网络在预测艺人爆红事件时具有更高的精确率和召回率。

Conclusion: 虽然集成学习在传统指标上表现更好，但神经网络在预测艺人爆红这种特定事件方面更具优势，表明不同模型在不同评估标准下各有优劣。

Abstract: Early detection of rising talents is of paramount importance in the field of advertising. In this paper, we define a concept of talent breakout and propose a method to detect Japanese talents before their rise to stardom. The main focus of the study is to determine the effectiveness of combining Twitter and TV data on predicting time-dependent changes in social data. Although traditional time-series models are known to be robust in many applications, the success of neural network models in various fields (e.g.\ Natural Language Processing, Computer Vision, Reinforcement Learning) continues to spark an interest in the time-series community to apply new techniques in practice. Therefore, in order to find the best modeling approach, we have experimented with traditional, neural network and ensemble learning methods. We observe that ensemble learning methods outperform traditional and neural network models based on standard regression metrics. However, by utilizing the concept of talent breakout, we are able to assess the true forecasting ability of the models, where neural networks outperform traditional and ensemble learning methods in terms of precision and recall.

</details>


### [32] [PepEVOLVE: Position-Aware Dynamic Peptide Optimization via Group-Relative Advantage](https://arxiv.org/abs/2511.16912)
*Trieu Nguyen,Hao-Wei Pang,Shasha Feng*

Main category: cs.LG

TL;DR: PepEVOLVE是一个动态框架，用于多目标优化大环肽序列，相比现有方法能更有效地发现优化位点并生成高质量候选肽。


<details>
  <summary>Details</summary>
Motivation: 现有大环肽优化方法需要预先指定可突变位置，且使用静态预训练和优化算法，限制了模型的泛化能力和优化效果。

Method: 采用动态掩码和CHUCKLES移位增强预训练，使用上下文无关多臂老虎机路由器发现高奖励残基，结合演化优化算法和组相对优势稳定强化学习更新。

Result: 在Rev结合大环肽基准测试中，PepEVOLVE达到更高平均分数（约0.8 vs 0.6），最佳候选肽得分为0.95（vs 0.87），且收敛步数更少。

Conclusion: PepEVOLVE为未知最优编辑位点的大环肽先导优化提供了实用、可复现的路径，能更高效地探索多目标设计空间。

Abstract: Macrocyclic peptides are an emerging modality that combines biologics-like affinity with small-molecule-like developability, but their vast combinatorial space and multi-parameter objectives make lead optimization slow and challenging. Prior generative approaches such as PepINVENT require chemists to pre-specify mutable positions for optimization, choices that are not always known a priori, and rely on static pretraining and optimization algorithms that limit the model's ability to generalize and effectively optimize peptide sequences. We introduce PepEVOLVE, a position-aware, dynamic framework that learns both where to edit and how to dynamically optimize peptides for multi-objective improvement. PepEVOLVE (i) augments pretraining with dynamic masking and CHUCKLES shifting to improve generalization, (ii) uses a context-free multi-armed bandit router that discovers high-reward residues, and (iii) couples a novel evolving optimization algorithm with group-relative advantage to stabilize reinforcement updates. During in silico evaluations, the router policy reliably learns and concentrates probability on chemically meaningful sites that influence the peptide's properties. On a therapeutically motivated Rev-binding macrocycle benchmark, PepEVOLVE outperformed PepINVENT by reaching higher mean scores (approximately 0.8 vs. 0.6), achieving best candidates with a score of 0.95 (vs. 0.87), and converging in fewer steps under the task of optimizing permeability and lipophilicity with structural constraints. Overall, PepEVOLVE offers a practical, reproducible path to peptide lead optimization when optimal edit sites are unknown, enabling more efficient exploration and improving design quality across multiple objectives.

</details>


### [33] [A Hybrid Computational Intelligence Framework for scRNA-seq Imputation: Integrating scRecover and Random Forests](https://arxiv.org/abs/2511.16923)
*Ali Anaissi,Deshao Liu,Yuanzhe Jia,Weidong Huang,Widad Alyassine,Junaid Akram*

Main category: cs.LG

TL;DR: SCR-MF是一个用于单细胞RNA测序数据缺失值填补的两阶段工作流，结合了scRecover的缺失检测和missForest的非参数填补，在保持生物学保真度的同时提供稳健性能。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序存在普遍的缺失事件，这些事件会掩盖生物学信号，需要开发能够稳健处理缺失值同时保持生物学真实性的方法。

Method: 采用模块化两阶段工作流：第一阶段使用scRecover进行缺失值检测，第二阶段使用missForest进行非参数填补。

Result: 在公共和模拟数据集上，SCR-MF在大多数情况下达到或超过现有填补方法的性能，同时保持生物学保真度和透明度，在准确性和计算效率之间取得良好平衡。

Conclusion: SCR-MF为中规模单细胞数据集提供了一个准确、稳健且计算高效的缺失值填补解决方案。

Abstract: Single-cell RNA sequencing (scRNA-seq) enables transcriptomic profiling at cellular resolution but suffers from pervasive dropout events that obscure biological signals. We present SCR-MF, a modular two-stage workflow that combines principled dropout detection using scRecover with robust non-parametric imputation via missForest. Across public and simulated datasets, SCR-MF achieves robust and interpretable performance comparable to or exceeding existing imputation methods in most cases, while preserving biological fidelity and transparency. Runtime analysis demonstrates that SCR-MF provides a competitive balance between accuracy and computational efficiency, making it suitable for mid-scale single-cell datasets.

</details>


### [34] [CroTad: A Contrastive Reinforcement Learning Framework for Online Trajectory Anomaly Detection](https://arxiv.org/abs/2511.16929)
*Rui Xue,Dan He,Fengmei Jin,Chen Zhang,Xiaofang Zhou*

Main category: cs.LG

TL;DR: 提出了CroTad框架，一种基于对比强化学习的在线轨迹异常检测方法，能够在子轨迹和点级别实时识别异常行为，无需阈值且对噪声和不规则采样数据具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决当前轨迹异常检测中的关键挑战：子轨迹异常检测研究不足、依赖人工阈值、不规则采样数据以及训练集噪声影响模型性能。

Method: 结合对比学习和强化学习，通过对比学习提取多样化正常出行模式，利用深度强化学习进行在线实时异常评分。

Result: 在两个真实世界数据集上的广泛实验证明了该框架在各种评估场景下的有效性和鲁棒性。

Conclusion: CroTad框架能够有效解决轨迹异常检测中的关键问题，提供无阈值、鲁棒且实时的异常检测能力。

Abstract: Detecting trajectory anomalies is a vital task in modern Intelligent Transportation Systems (ITS), enabling the identification of unsafe, inefficient, or irregular travel behaviours. While deep learning has emerged as the dominant approach, several key challenges remain unresolved. First, sub-trajectory anomaly detection, capable of pinpointing the precise segments where anomalies occur, remains underexplored compared to whole-trajectory analysis. Second, many existing methods depend on carefully tuned thresholds, limiting their adaptability in real-world applications. Moreover, the irregular sampling of trajectory data and the presence of noise in training sets further degrade model performance, making it difficult to learn reliable representations of normal routes. To address these challenges, we propose a contrastive reinforcement learning framework for online trajectory anomaly detection, CroTad. Our method is threshold-free and robust to noisy, irregularly sampled data. By incorporating contrastive learning, CroTad learns to extract diverse normal travel patterns for different itineraries and effectively distinguish anomalous behaviours at both sub-trajectory and point levels. The detection module leverages deep reinforcement learning to perform online, real-time anomaly scoring, enabling timely and fine-grained identification of abnormal segments. Extensive experiments on two real-world datasets demonstrate the effectiveness and robustness of our framework across various evaluation scenarios.

</details>


### [35] [A novel approach to classification of ECG arrhythmia types with latent ODEs](https://arxiv.org/abs/2511.16933)
*Angelina Yan,Matt L. Sampson,Peter Melchior*

Main category: cs.LG

TL;DR: 提出了一种端到端的心电图分类方法，使用潜在ODE建模连续ECG波形，通过降采样处理不同频率信号，在保持高性能的同时解决了可穿戴设备电池寿命与信号保真度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决12导联ECG短期监测无法捕捉间歇性事件，以及可穿戴ECG因电池限制导致采样频率不规则、形态分析困难的问题。

Method: 训练潜在ODE模型连续ECG波形，从高频单通道信号创建鲁棒特征向量，通过降采样（360Hz→90Hz→45Hz）构建三个潜在向量，使用梯度提升树进行分类。

Result: 在不同采样频率下性能下降极小，宏平均AUC-ROC值分别为：360Hz时0.984、90Hz时0.978、45Hz时0.976。

Conclusion: 该方法绕过了信号保真度与电池寿命之间的权衡，使更小的可穿戴设备成为可能，促进长期心脏健康监测。

Abstract: 12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, making morphology analysis challenging. We present an end-to-end classification pipeline to address these issues. We train a latent ODE to model continuous ECG waveforms and create robust feature vectors from high-frequency single-channel signals. We construct three latent vectors per waveform via downsampling the initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to classify these vectors and test robustness across frequencies. Performance shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978, and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to sidestep the trade-off between signal fidelity and battery life. This enables smaller wearables, promoting long-term monitoring of cardiac health.

</details>


### [36] [ToC: Tree-of-Claims Search with Multi-Agent Language Models](https://arxiv.org/abs/2511.16972)
*Shuyang Yu,Jianan Liang,Hui Hu*

Main category: cs.LG

TL;DR: ToC框架通过结合蒙特卡洛树搜索和多智能体系统，优化专利权利要求，在保持法律范围的同时最大化新颖性，相比标准LLM提升8%综合得分


<details>
  <summary>Details</summary>
Motivation: 传统专利权利要求撰写劳动密集、成本高且不一致，而传统大语言模型缺乏结构化迭代推理能力，无法满足精确权利要求优化的需求

Method: 提出Tree of Claims框架，将权利要求编辑重新定义为引导搜索问题，结合MCTS与多智能体系统（EditorAgent提出编辑建议，ExaminerAgent模拟专利审查员进行新颖性和现有技术分析）

Result: 在1145个权利要求基准测试中，ToC显著优于零样本和少样本标准LLM，平均综合得分提升8%，某些情况下可达9%

Conclusion: ToC建立了透明、可控且可解释的方法论，有效结合了先进LLM推理能力与战略MCTS规划，实现结构化专利权利要求优化

Abstract: Optimizing patent claims is a critical yet challenging task, demanding careful balance between maximizing novelty and preserving legal scope. Manual claim drafting is labor-intensive, costly, and inherently inconsistent, while conventional Large Language Models (LLMs) often lack the structured, iterative reasoning essential for precise claim refinement. To address these challenges, we introduce Tree of Claims (ToC), an innovative framework that redefines claim editing as a guided search problem. ToC synergistically integrates Monte Carlo Tree Search (MCTS) with a collaborative multi-agent system, comprising an LLM-based EditorAgent that proposes contextually grounded edits, and an ExaminerAgent that mimics patent examiner critiques through structured, chain-of-thought analyses of novelty and prior art disclosure. Driven by a carefully designed multi-objective reward function, ToC jointly optimizes novelty, scope retention, and semantic coherence. Experimental evaluation on a benchmark of 1145 claims demonstrates that ToC significantly outperforms standard LLMs in zero-shot and few-shot scenarios, achieving an average composite score improvement of 8\%, and up to 9\% in certain cases. Extensive experiments, including detailed ablation studies, validate ToC's efficacy in generating superior, legally robust claim revisions. Overall, ToC establishes a transparent, controllable, and interpretable methodology that effectively bridges advanced LLM reasoning capabilities with strategic MCTS planning for structured patent claim optimization.The source code is available at https://github.com/ysy2003/ToC.

</details>


### [37] [FIRM: Federated In-client Regularized Multi-objective Alignment for Large Language Models](https://arxiv.org/abs/2511.16992)
*Fatemeh,Nourzad,Amirhossein Roknilamouki,Eylem Ekici,Jia,Liu,Ness B. Shroff*

Main category: cs.LG

TL;DR: FIRM是一种联邦多目标对齐算法，通过客户端内正则化解决多目标冲突，无需传输多个梯度，保持通信效率，同时收敛到帕累托稳定点。


<details>
  <summary>Details</summary>
Motivation: 现有联邦多目标优化方法依赖传输多个梯度，存在严重通信瓶颈，不适合大型语言模型；同时集中化训练存在数据隐私问题。

Method: FIRM算法让每个客户端本地解决正则化多目标优化问题，通过客户端内正则化直接缓解客户端分歧漂移，只需传输单组适应参数。

Result: FIRM实现更平滑的训练动态、减少客户端分歧漂移、改善奖励权衡，并能根据偏好平滑调整目标间的权衡。

Conclusion: FIRM在联邦多目标对齐中实现了通信效率和性能的平衡，为大型语言模型对齐提供了可行的联邦学习解决方案。

Abstract: Aligning Large Language Models (LLMs) with human values often involves balancing multiple, conflicting objectives such as helpfulness and harmlessness. Training these models is computationally intensive, and centralizing the process raises significant data privacy concerns. Federated Learning (FL) offers a compelling alternative, but existing Federated Multi-Objective Optimization (FMOO) methods face severe communication bottlenecks as their reliance on transmitting multiple gradients to a server is unscalable for large models. We introduce FIRM (Federated In-client Regularized Multi-objective alignment), a novel algorithm that achieves both client disagreement drift mitigation and communication efficiency. In FIRM, each client locally solves a regularized multi-objective optimization problem. By directly mitigating client disagreement drift through in-client regularization, our method eliminates the need for the multi-gradient transmissions common in prior works. Consequently, clients need only to transmit a single set of adapted parameters, maintaining high communication efficiency. We prove that our algorithm converges to Pareto-stationary points and, to our knowledge, provide the first finite-time convergence guarantees for this federated multi-objective alignment setting. Empirically, we show that FIRM leads to smoother training dynamics, reduced client disagreement drift, and improved reward trade-offs compared to baselines. We further propose a method to incorporate a preference over the objectives and report empirical Pareto plots, demonstrating that FIRM can smoothly adapt trade-offs between objectives in response to specified preferences.

</details>


### [38] [Mask the Redundancy: Evolving Masking Representation Learning for Multivariate Time-Series Clustering](https://arxiv.org/abs/2511.17008)
*Zexi Tan,Xiaopeng Luo,Yunlin Liu,Yiqun Zhang*

Main category: cs.LG

TL;DR: 提出EMTC方法，通过重要性感知的变量级掩码和多内生视图表示学习，解决多元时间序列聚类中冗余信息导致性能瓶颈的问题。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列包含大量冗余信息（如稳态机器运行记录、太阳能发电零输出期），这些冗余会降低对判别性时间戳的关注，导致聚类性能瓶颈。现有掩码策略多为独立预处理步骤，无法动态适应聚类关键时间戳的重要性。

Method: 提出EMTC方法，包含重要性感知变量级掩码（IVM）和多内生视图（MEV）表示学习模块。IVM自适应引导模型学习更具判别性的聚类表示，MEV通过重建和对比学习路径增强泛化能力。

Result: 在15个真实基准数据集上的实验表明，EMTC优于8种最先进方法，平均比最强基线提升4.85%。

Conclusion: EMTC通过动态掩码和多视图学习有效提升了多元时间序列聚类的性能，解决了冗余信息导致的表示学习瓶颈问题。

Abstract: Multivariate Time-Series (MTS) clustering discovers intrinsic grouping patterns of temporal data samples. Although time-series provide rich discriminative information, they also contain substantial redundancy, such as steady-state machine operation records and zero-output periods of solar power generation. Such redundancy diminishes the attention given to discriminative timestamps in representation learning, thus leading to performance bottlenecks in MTS clustering. Masking has been widely adopted to enhance the MTS representation, where temporal reconstruction tasks are designed to capture critical information from MTS. However, most existing masking strategies appear to be standalone preprocessing steps, isolated from the learning process, which hinders dynamic adaptation to the importance of clustering-critical timestamps. Accordingly, this paper proposes the Evolving-masked MTS Clustering (EMTC) method, with its model architecture composed of Importance-aware Variate-wise Masking (IVM) and Multi-Endogenous Views (MEV) representation learning modules. IVM adaptively guides the model in learning more discriminative representations for clustering, while the MEV-based reconstruction and contrastive learning pathways enhance the generalization. That is, the MEV reconstruction facilitates multi-perspective complementary to prevent the masking from premature convergence, and the clustering-guided contrastive learning facilitates the joint optimization of representation and clustering. Extensive experiments on 15 real benchmark datasets demonstrate the superiority of EMTC in comparison with eight SOTA methods, where the EMTC achieves an average improvement of 4.85% over the strongest baselines.

</details>


### [39] [Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon Emissions in Image Generation](https://arxiv.org/abs/2511.17031)
*Aniketh Iyengar,Jiaqi Han,Boris Ruf,Vincent Grari,Marcin Detyniecki,Stefano Ermon*

Main category: cs.LG

TL;DR: 提出基于计算复杂度（FLOPs）的扩散模型GPU能耗预测方法，通过Kaplan缩放定律实现跨模型和硬件的准确能耗预测。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中的计算需求快速增长，引发了能耗和环境影响的担忧，但缺乏系统性的能耗预测方法。

Method: 将扩散模型推理分解为文本编码、迭代去噪和解码组件，基于计算复杂度建立能耗缩放定律，在多种扩散模型和GPU架构上进行实验验证。

Result: 能耗缩放定律在单个架构内预测精度高（R平方>0.9），跨架构泛化能力强，能够可靠预测未见模型-硬件组合的能耗。

Conclusion: 验证了扩散模型推理的计算密集型特性，为可持续AI部署规划和碳足迹估算提供了基础。

Abstract: The rapidly growing computational demands of diffusion models for image generation have raised significant concerns about energy consumption and environmental impact. While existing approaches to energy optimization focus on architectural improvements or hardware acceleration, there is a lack of principled methods to predict energy consumption across different model configurations and hardware setups. We propose an adaptation of Kaplan scaling laws to predict GPU energy consumption for diffusion models based on computational complexity (FLOPs). Our approach decomposes diffusion model inference into text encoding, iterative denoising, and decoding components, with the hypothesis that denoising operations dominate energy consumption due to their repeated execution across multiple inference steps. We conduct comprehensive experiments across four state-of-the-art diffusion models (Stable Diffusion 2, Stable Diffusion 3.5, Flux, and Qwen) on three GPU architectures (NVIDIA A100, A4000, A6000), spanning various inference configurations including resolution (256x256 to 1024x1024), precision (fp16/fp32), step counts (10-50), and classifier-free guidance settings. Our energy scaling law achieves high predictive accuracy within individual architectures (R-squared > 0.9) and exhibits strong cross-architecture generalization, maintaining high rank correlations across models and enabling reliable energy estimation for unseen model-hardware combinations. These results validate the compute-bound nature of diffusion inference and provide a foundation for sustainable AI deployment planning and carbon footprint estimation.

</details>


### [40] [Step-E: A Differentiable Data Cleaning Framework for Robust Learning with Noisy Labels](https://arxiv.org/abs/2511.17040)
*Wenzhang Du*

Main category: cs.LG

TL;DR: Step-E是一个将样本选择和模型学习集成到单一优化过程中的框架，通过基于损失的样本排名和逐步排除高损失样本来处理噪声标签数据，在CIFAR数据集上显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 野外收集的训练数据通常包含噪声标签和异常值，这会严重降低深度神经网络的性能和可靠性。传统的数据清洗作为单独的预处理阶段，无法充分利用下游模型的反馈，也无法适应未知的噪声模式。

Method: Step-E框架在每个epoch中根据损失对样本进行排序，在短暂的预热阶段后逐步增加被排除在梯度更新之外的高损失样本比例，形成一个在线课程，专注于简单和一致的样本，最终忽略持续的异常值。

Result: 在CIFAR-100N上，Step-E将ResNet-18模型的测试准确率从43.3%提升到50.4%，明显优于损失截断、自定步调学习和一次性过滤方法，接近60.5%的干净标签oracle性能。在CIFAR-10N上，也从83.9%提升到85.3%，接近85.9%的干净标签oracle，且训练时间开销适中。

Conclusion: Step-E通过将样本选择与模型学习集成到单一优化过程中，有效处理了噪声标签数据，显著提升了模型性能，接近干净标签数据集的性能水平。

Abstract: Training data collected in the wild often contain noisy labels and outliers that substantially degrade the performance and reliability of deep neural networks. While data cleaning is commonly applied as a separate preprocessing stage, such two-stage pipelines neither fully exploit feedback from the downstream model nor adapt to unknown noise patterns. We propose Step-E, a simple framework that integrates sample selection and model learning into a single optimization process. At each epoch, Step-E ranks samples by loss and gradually increases the fraction of high-loss examples that are excluded from gradient updates after a brief warm-up stage, yielding an online curriculum that focuses on easy and consistent examples and eventually ignores persistent outliers. On CIFAR-100N, Step-E improves the test accuracy of a ResNet-18 model from 43.3% (+/- 0.7%) to 50.4% (+/- 0.9%), clearly outperforming loss truncation, self-paced learning, and one-shot filtering while approaching the clean-label oracle at 60.5% (+/- 0.2%). On CIFAR-10N (aggre), Step-E also improves over the noisy baseline (85.3% vs. 83.9%) and nearly matches the clean-label oracle (85.9%), with only moderate training-time overhead.

</details>


### [41] [Hash Collisions in Molecular Fingerprints: Effects on Property Prediction and Bayesian Optimization](https://arxiv.org/abs/2511.17078)
*Walter Virany,Austin Tripp*

Main category: cs.LG

TL;DR: 研究比较精确分子指纹与标准压缩指纹在分子性质预测和贝叶斯优化中的性能差异，发现精确指纹在预测准确性上有小幅提升但在贝叶斯优化中无明显优势。


<details>
  <summary>Details</summary>
Motivation: 分子指纹方法使用哈希函数生成固定长度的分子向量表示，但哈希冲突会导致不同子结构具有相同特征表示，从而在分子相似性计算中产生高估。

Method: 使用高斯过程作为基础预测模型，在DOCKSTRING数据集的五个分子性质预测基准上比较精确指纹和标准压缩指纹的性能。

Result: 精确指纹在分子性质预测准确性上产生小幅但一致的提升，但这些增益并未转化为贝叶斯优化性能的显著改善。

Conclusion: 虽然精确指纹能略微提高预测准确性，但在贝叶斯优化应用中这种改进并不显著，表明哈希冲突对实际优化任务的影响有限。

Abstract: Molecular fingerprinting methods use hash functions to create fixed-length vector representations of molecules. However, hash collisions cause distinct substructures to be represented with the same feature, leading to overestimates in molecular similarity calculations. We investigate whether using exact fingerprints improves accuracy compared to standard compressed fingerprints in molecular property prediction and Bayesian optimization where the underlying predictive model is a Gaussian process. We find that using exact fingerprints yields a small yet consistent improvement in predictive accuracy on five molecular property prediction benchmarks from the DOCKSTRING dataset. However, these gains did not translate to significant improvements in Bayesian optimization performance.

</details>


### [42] [Why Do Language Model Agents Whistleblow?](https://arxiv.org/abs/2511.17085)
*Kushal Agrawal,Frank Xiao,Guido Bergman,Asa Cooper Stickland*

Main category: cs.LG

TL;DR: 该论文研究大型语言模型作为工具使用代理时的举报行为，即模型在未经用户指示或知情的情况下向对话边界外的第三方披露可疑不当行为。作者开发了评估套件，发现举报频率因模型而异，任务复杂性、道德提示和工具可用性都会影响举报倾向。


<details>
  <summary>Details</summary>
Motivation: 研究LLM作为工具使用代理时，其对齐训练如何以新方式体现，特别是模型可能违背用户利益或明确指示使用工具的行为，重点关注模型向第三方举报可疑不当行为的现象。

Method: 引入包含多样化和现实化模拟不当行为场景的评估套件，测试不同模型在各种设置下的举报行为，分析任务复杂性、系统提示、工具可用性等因素的影响。

Result: 发现举报频率因模型家族差异很大；增加任务复杂性降低举报倾向；道德提示显著提高举报率；提供更多工具和详细工作流程减少举报行为；验证了数据集对模型评估意识的鲁棒性。

Conclusion: LLM作为工具使用代理时会表现出复杂的举报行为，这种行为受多种因素影响，研究为理解和控制LLM代理的意外行为提供了重要见解。

Abstract: The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways. Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user. We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge. We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior. Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates. Additionally, we verify the robustness of our dataset by testing for model evaluation awareness, and find that both black-box methods and probes on model activations show lower evaluation awareness in our settings than in comparable previous work.

</details>


### [43] [Geometric-Disentangelment Unlearning](https://arxiv.org/abs/2511.17100)
*Duo Zhou,Yuji Zhang,Tianxin Wei,Ruizhong Qiu,Ke Yang,Xiao Lin,Cheng Qian,Jingrui He,Hanghang Tong,Heng Ji,Huan Zhang*

Main category: cs.LG

TL;DR: 提出了几何解缠遗忘方法(GU)，通过将遗忘梯度分解为保留空间的切向和法向分量，只执行法向分量来避免对保留知识的损害，实现了理论保证的遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘方法在有效遗忘和保留知识之间存在权衡，缺乏对遗忘更新如何损害保留知识的理论分析，以及是否能理论保证消除副作用。

Method: 基于一阶分析，将遗忘梯度更新分解为保留梯度子空间的切向分量和法向分量，只执行法向分量以实现保留不变性。在信任区域预算下，投影方向与原始遗忘梯度对齐是最优的一阶保留不变移动。

Result: 在TOFU、MUSE和WMDP三个基准测试中，GU方法在各种基于梯度的遗忘程序上实现了一致的改进。

Conclusion: 几何解缠遗忘方法提供了一种理论可靠且简单的解决方案，能够有效缓解遗忘过程中的副作用，提升遗忘效果。

Abstract: Machine unlearning, the removal of a training subset's influence from a deployed model, is critical for privacy preservation and model reliability, yet gradient ascent on forget samples often harms retained knowledge. Existing approaches face a persistent tradeoff between effective forgetting and preservation on the retain set. While previous methods provide useful heuristics, they often lack a formal analysis on how exactly forgetting updates harm retained knowledge, and whether the side effects can be removed with theoretical guarantees. To explore a theoretically sound and simple solution, we start from the first principle on how performance on the retain set is actually affected: a first-order analysis of the local change of the retain loss under small parameter updates during model training. We start from a crisp equivalence: the retain loss is unchanged to first order iff the update direction is orthogonal to the subspace spanned by retain gradients ("retain-invariant"). This identifies the entangled component as the tangential part of forget update within the retain-gradient subspace, and characterizes disentanglement as orthogonality. Guided by this, we propose the Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget gradient update into tangential and normal components to retain space and executes only the normal component. Under a standard trust-region budget, the projected direction aligned with the raw forget gradient is optimal among all first-order retain-invariant moves, and we also derive the optimal projected direction for joint forget-retain updating objectives. Our method is plug-and-play and can be attached to existing gradient-based unlearning procedures to mitigate side effects. GU achieves consistent improvement on various methods across three benchmarks TOFU, MUSE, and WMDP.

</details>


### [44] [Four decades of circumpolar super-resolved satellite land surface temperature data](https://arxiv.org/abs/2511.17134)
*Sonia Dupuis,Nando Metzger,Konrad Schindler,Frank Göttsche,Stefan Wunderle*

Main category: cs.LG

TL;DR: 开发了一个42年泛北极地表温度数据集，通过深度学习超分辨率算法将AVHRR GAC数据从粗分辨率降尺度到1公里，用于改善北极地区多年冻土建模和气候变化监测。


<details>
  <summary>Details</summary>
Motivation: 北极地区快速变暖，但现有AVHRR卫星数据的空间分辨率较粗，限制了其在精细尺度多年冻土动态分析和其他地表过程研究中的应用。

Method: 使用基于深度各向异性扩散模型的超分辨率算法，以MODIS LST数据为训练集，结合高分辨率土地覆盖、数字高程和植被高度图，将AVHRR GAC数据降尺度到1公里分辨率。

Result: 生成了42年泛北极地区每日两次的1公里分辨率LST观测数据集，显著改善了多年冻土建模、近地表气温重建和格陵兰冰盖表面质量平衡评估的能力。

Conclusion: 该数据集填补了MODIS时代之前的北极气候监测空白，为未来热红外观测卫星任务和气候数据记录连续性提供了可适应的框架。

Abstract: Land surface temperature (LST) is an essential climate variable (ECV) crucial for understanding land-atmosphere energy exchange and monitoring climate change, especially in the rapidly warming Arctic. Long-term satellite-based LST records, such as those derived from the Advanced Very High Resolution Radiometer (AVHRR), are essential for detecting climate trends. However, the coarse spatial resolution of AVHRR's global area coverage (GAC) data limit their utility for analyzing fine-scale permafrost dynamics and other surface processes in the Arctic. This paper presents a new 42 years pan-Arctic LST dataset, downscaled from AVHRR GAC to 1 km with a super-resolution algorithm based on a deep anisotropic diffusion model. The model is trained on MODIS LST data, using coarsened inputs and native-resolution outputs, guided by high-resolution land cover, digital elevation, and vegetation height maps. The resulting dataset provides twice-daily, 1 km LST observations for the entire pan-Arctic region over four decades. This enhanced dataset enables improved modelling of permafrost, reconstruction of near-surface air temperature, and assessment of surface mass balance of the Greenland Ice Sheet. Additionally, it supports climate monitoring efforts in the pre-MODIS era and offers a framework adaptable to future satellite missions for thermal infrared observation and climate data record continuity.

</details>


### [45] [Reconstruction of Surface EMG Signal using IMU data for Upper Limb Actions](https://arxiv.org/abs/2511.17200)
*Shubhranil Basak,Mada Hemanth,Madhav Rao*

Main category: cs.LG

TL;DR: 使用深度学习从6轴IMU数据合成归一化sEMG信号，模型能成功预测肌肉激活的时间和大致形状，适用于假肢和康复生物反馈应用。


<details>
  <summary>Details</summary>
Motivation: sEMG信号虽然能提供重要的肌肉功能信息，但容易受噪声干扰且采集困难，而IMU提供了更稳健的可穿戴替代方案。

Method: 收集同步的sEMG和IMU数据，使用基于扩张因果卷积的滑动窗口波网络模型将IMU数据映射到sEMG信号。

Result: 模型成功预测了肌肉激活的时间和一般形状，但峰值幅度经常被低估，显示出高时间保真度。

Conclusion: 该方法在肌肉意图检测方面具有可行性，特别适用于假肢和康复生物反馈应用。

Abstract: Surface Electromyography (sEMG) provides vital insights into muscle function, but it can be noisy and challenging to acquire. Inertial Measurement Units (IMUs) provide a robust and wearable alternative to motion capture systems. This paper investigates the synthesis of normalized sEMG signals from 6-axis IMU data using a deep learning approach. We collected simultaneous sEMG and IMU data sampled at 1~KHz for various arm movements. A Sliding-Window-Wave-Net model, based on dilated causal convolutions, was trained to map the IMU data to the sEMG signal. The results show that the model successfully predicts the timing and general shape of muscle activations. Although peak amplitudes were often underestimated, the high temporal fidelity demonstrates the feasibility of using this method for muscle intent detection in applications such as prosthetics and rehabilitation biofeedback.

</details>


### [46] [DelTriC: A Novel Clustering Method with Accurate Outlier](https://arxiv.org/abs/2511.17219)
*Tomas Javurek,Michal Gregor,Sebastian Kula,Marian Simko*

Main category: cs.LG

TL;DR: DelTriC是一种新颖的聚类算法，通过PCA/UMAP降维、Delaunay三角剖分和反向投影机制，在高维原始空间中形成聚类，在多个场景中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法在高维空间中面临挑战，需要一种既能处理高维数据又能保持准确性和可扩展性的方法。

Method: 结合PCA/UMAP降维投影、Delaunay三角剖分构建邻域索引，然后反向投影到原始空间进行边缘修剪、合并和异常检测。

Result: DelTriC在多个场景中优于k-means、DBSCAN和HDBSCAN等传统方法，具有更好的可扩展性和准确性，并显著改进异常检测。

Conclusion: DelTriC通过解耦邻域构建和决策制定，提供了一种有效的高维数据聚类解决方案。

Abstract: The paper introduces DelTriC (Delaunay Triangulation Clustering), a clustering algorithm which integrates PCA/UMAP-based projection, Delaunay triangulation, and a novel back-projection mechanism to form clusters in the original high-dimensional space. DelTriC decouples neighborhood construction from decision-making by first triangulating in a low-dimensional proxy to index local adjacency, and then back-projecting to the original space to perform robust edge pruning, merging, and anomaly detection. DelTriC can outperform traditional methods such as k-means, DBSCAN, and HDBSCAN in many scenarios; it is both scalable and accurate, and it also significantly improves outlier detection.

</details>


### [47] [Generating transition states of chemical reactions via distance-geometry-based flow matching](https://arxiv.org/abs/2511.17229)
*Yufei Luo,Xiang Gu,Jian Sun*

Main category: cs.LG

TL;DR: TS-DFM是一个基于流匹配的过渡态预测框架，通过在分子距离几何空间中操作，准确预测化学反应中的过渡态结构，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 过渡态对于理解反应机制至关重要，但实验和计算方法复杂且有限，需要更高效准确的预测方法。

Method: 提出TS-DFM流匹配框架，在分子距离几何空间中操作，设计TSDVNet网络学习速度场以生成准确的过渡态几何结构。

Result: 在Transition1X基准数据集上，TS-DFM比之前最优方法React-OT结构准确率提升30%，预测的过渡态能加速CI-NEB优化收敛，并能识别替代反应路径和更低能垒的有利过渡态。

Conclusion: TS-DFM在未见分子和反应类型上表现出强泛化能力，具有促进反应探索的潜力。

Abstract: Transition states (TSs) are crucial for understanding reaction mechanisms, yet their exploration is limited by the complexity of experimental and computational approaches. Here we propose TS-DFM, a flow matching framework that predicts TSs from reactants and products. By operating in molecular distance geometry space, TS-DFM explicitly captures the dynamic changes of interatomic distances in chemical reactions. A network structure named TSDVNet is designed to learn the velocity field for generating TS geometries accurately. On the benchmark dataset Transition1X, TS-DFM outperforms the previous state-of-the-art method React-OT by 30\% in structural accuracy. These predicted TSs provide high-quality initial structures, accelerating the convergence of CI-NEB optimization. Additionally, TS-DFM can identify alternative reaction paths. In our experiments, even a more favorable TS with lower energy barrier is discovered. Further tests on RGD1 dataset confirm its strong generalization ability on unseen molecules and reaction types, highlighting its potential for facilitating reaction exploration.

</details>


### [48] [FlexiFlow: decomposable flow matching for generation of flexible molecular ensemble](https://arxiv.org/abs/2511.17249)
*Riccardo Tedoldi,Ola Engkvist,Patrick Bryant,Hossein Azizpour,Jon Paul Janet,Alessandro Tibo*

Main category: cs.LG

TL;DR: FlexiFlow是一种新颖的架构，扩展了流匹配模型，能够联合采样分子及其多个构象，在QM9和GEOM Drugs数据集上实现了最先进的分子生成结果。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的3D从头设计模型仅限于生成单一构象，但分子的构象景观决定了其可观察性质和与蛋白质靶标的结合能力。通过生成低能量构象的代表性集合，可以更直接评估这些性质。

Method: 提出FlexiFlow架构，扩展流匹配模型，允许联合采样分子及其多个构象，同时保持等变性和置换不变性。

Result: 在QM9和GEOM Drugs数据集上实现最先进的分子生成结果，能够生成有效、无应变、独特且新颖的分子，同时捕获分子的构象多样性。

Conclusion: FlexiFlow可以生成与最先进物理方法覆盖范围相似的构象集合，但推理时间大大减少，并且可以成功迁移到蛋白质条件配体生成任务。

Abstract: Sampling useful three-dimensional molecular structures along with their most favorable conformations is a key challenge in drug discovery. Current state-of-the-art 3D de-novo design flow matching or diffusion-based models are limited to generating a single conformation. However, the conformational landscape of a molecule determines its observable properties and how tightly it is able to bind to a given protein target. By generating a representative set of low-energy conformers, we can more directly assess these properties and potentially improve the ability to generate molecules with desired thermodynamic observables. Towards this aim, we propose FlexiFlow, a novel architecture that extends flow-matching models, allowing for the joint sampling of molecules along with multiple conformations while preserving both equivariance and permutation invariance. We demonstrate the effectiveness of our approach on the QM9 and GEOM Drugs datasets, achieving state-of-the-art results in molecular generation tasks. Our results show that FlexiFlow can generate valid, unstrained, unique, and novel molecules with high fidelity to the training data distribution, while also capturing the conformational diversity of molecules. Moreover, we show that our model can generate conformational ensembles that provide similar coverage to state-of-the-art physics-based methods at a fraction of the inference time. Finally, FlexiFlow can be successfully transferred to the protein-conditioned ligand generation task, even when the dataset contains only static pockets without accompanying conformations.

</details>


### [49] [Enforcing governing equation constraints in neural PDE solvers via training-free projections](https://arxiv.org/abs/2511.17258)
*Omer Rochman,Gilles Louppe*

Main category: cs.LG

TL;DR: 本文提出了两种训练后投影方法来减少神经网络PDE求解器对约束条件的违反，包括非线性优化投影和局部线性化投影。


<details>
  <summary>Details</summary>
Motivation: 神经网络PDE求解器在科学模拟中经常违反控制方程约束，特别是非线性约束和动态PDE中的长程时间依赖关系，这使得投影到可行集变得复杂。

Method: 评估了两种无需训练的后处理投影方法：基于非线性优化的投影，以及使用雅可比-向量和向量-雅可比积的局部线性化投影。

Result: 两种投影方法都显著减少了约束违反，并在代表性PDE上比基于物理信息的基线方法提高了准确性。

Conclusion: 训练后的投影方法能有效改善神经网络PDE求解器的约束满足性和准确性，对于处理非线性约束和动态PDE特别有用。

Abstract: Neural PDE solvers used for scientific simulation often violate governing equation constraints. While linear constraints can be projected cheaply, many constraints are nonlinear, complicating projection onto the feasible set. Dynamical PDEs are especially difficult because constraints induce long-range dependencies in time. In this work, we evaluate two training-free, post hoc projections of approximate solutions: a nonlinear optimization-based projection, and a local linearization-based projection using Jacobian-vector and vector-Jacobian products. We analyze constraints across representative PDEs and find that both projections substantially reduce violations and improve accuracy over physics-informed baselines.

</details>


### [50] [Automobile demand forecasting: Spatiotemporal and hierarchical modeling, life cycle dynamics, and user-generated online information](https://arxiv.org/abs/2511.17275)
*Tom Nahrendorf,Stefan Minner,Helfried Binder,Richard Zinck*

Main category: cs.LG

TL;DR: 该研究针对德国高端汽车制造商的多产品、多市场、多层次需求预测问题，结合点预测和概率预测方法，使用LightGBM集成模型和混合整数线性规划协调方法，发现时空依赖性和取整偏差对预测精度有显著影响。


<details>
  <summary>Details</summary>
Motivation: 高端汽车制造商面临产品种类多、变体级数据稀疏和市场波动大的复杂预测挑战，需要解决多产品、多市场、多层次层次结构的月度汽车需求预测问题。

Method: 结合战略和运营规划层面的点预测和概率预测，使用LightGBM模型集成、分位数回归和混合整数线性规划协调方法，利用池化训练集进行预测。

Result: 时空依赖性和取整偏差显著影响预测精度，整数预测对运营可行性很重要；短期需求受生命周期成熟度、自回归动量和运营信号影响，中期需求受在线参与度、规划目标和竞争指标等预期驱动因素影响，在线行为数据显著提高了细分层面的预测精度。

Conclusion: 该方法成功解决了高端汽车制造商的复杂预测挑战，强调了考虑时空依赖性和取整偏差的重要性，在线行为数据在细分层面预测中具有重要价值。

Abstract: Premium automotive manufacturers face increasingly complex forecasting challenges due to high product variety, sparse variant-level data, and volatile market dynamics. This study addresses monthly automobile demand forecasting across a multi-product, multi-market, and multi-level hierarchy using data from a German premium manufacturer. The methodology combines point and probabilistic forecasts across strategic and operational planning levels, leveraging ensembles of LightGBM models with pooled training sets, quantile regression, and a mixed-integer linear programming reconciliation approach. Results highlight that spatiotemporal dependencies, as well as rounding bias, significantly affect forecast accuracy, underscoring the importance of integer forecasts for operational feasibility. Shapley analysis shows that short-term demand is reactive, shaped by life cycle maturity, autoregressive momentum, and operational signals, whereas medium-term demand reflects anticipatory drivers such as online engagement, planning targets, and competitive indicators, with online behavioral data considerably improving accuracy at disaggregated levels.

</details>


### [51] [Self-supervised denoising of raw tomography detector data for improved image reconstruction](https://arxiv.org/abs/2511.17312)
*Israt Jahan Tulin,Sebastian Starke,Dominic Windisch,André Bieberle,Peter Steinbach*

Main category: cs.LG

TL;DR: 比较了两种自监督深度学习方法和一种非学习方法对超快电子束X射线CT原始探测器数据的去噪效果，发现深度学习方法在信噪比和重建图像质量方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 超快电子束X射线CT由于测量时间短导致数据噪声大，产生重建伪影，限制了图像质量。

Method: 研究了两种自监督深度学习方法和一种非学习方法的去噪方法。

Result: 深度学习方法能够提高探测器数据的信噪比，并在重建图像质量上实现一致改进，优于非学习方法。

Conclusion: 自监督深度学习方法在超快电子束X射线CT数据去噪方面具有优势，能够有效提升图像质量。

Abstract: Ultrafast electron beam X-ray computed tomography produces noisy data due to short measurement times, causing reconstruction artifacts and limiting overall image quality. To counteract these issues, two self-supervised deep learning methods for denoising of raw detector data were investigated and compared against a non-learning based denoising method. We found that the application of the deep-learning-based methods was able to enhance signal-to-noise ratios in the detector data and also led to consistent improvements of the reconstructed images, outperforming the non-learning based method.

</details>


### [52] [ReBaPL: Repulsive Bayesian Prompt Learning](https://arxiv.org/abs/2511.17339)
*Yassir Bendou,Omar Ezzahir,Eduardo Fernandes Montesuma,Gabriel Mahuas,Victoria Shevchenko,Mike Gartrell*

Main category: cs.LG

TL;DR: 提出Repulsive Bayesian Prompt Learning (ReBaPL)方法，通过贝叶斯推理和表示空间排斥力来增强提示学习的鲁棒性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统提示学习方法容易过拟合且难以处理分布外泛化问题，贝叶斯提示学习通过将提示优化构建为贝叶斯推理问题来提高鲁棒性

Method: 结合循环步长调度和随机梯度哈密顿蒙特卡洛算法，引入基于表示分布的排斥力（使用MMD和Wasserstein距离），实现探索和利用的交替

Result: 在多个基准数据集上表现出优于最先进提示学习方法的性能

Conclusion: ReBaPL能够更全面地刻画提示后验分布，提供模块化的即插即用贝叶斯扩展，显著提升泛化能力

Abstract: Prompt learning has emerged as an effective technique for fine-tuning large-scale foundation models for downstream tasks. However, conventional prompt tuning methods are prone to overfitting and can struggle with out-of-distribution generalization. To address these limitations, Bayesian prompt learning has been proposed, which frames prompt optimization as a Bayesian inference problem to enhance robustness. This paper introduces Repulsive Bayesian Prompt Learning (ReBaPL), a novel method for Bayesian prompt learning, designed to efficiently explore the complex and often multimodal posterior landscape of prompts. Our method integrates a cyclical step-size schedule with a stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm, enabling alternating phases of exploration to discover new modes, and exploitation to refine existing modes. Furthermore, we introduce a repulsive force derived from a potential function over probability metrics (including Maximum Mean Discrepancy and Wasserstein distance) computed on the distributions of representations produced by different prompts. This representation-space repulsion diversifies exploration and prevents premature collapse to a single mode. Our approach allows for a more comprehensive characterization of the prompt posterior distribution, leading to improved generalization. In contrast to prior Bayesian prompt learning methods, our method provides a modular plug-and-play Bayesian extension of any existing prompt learning method based on maximum likelihood estimation. We demonstrate the efficacy of ReBaPL on several benchmark datasets, showing superior performance over state-of-the-art methods for prompt learning.

</details>


### [53] [R2PS: Worst-Case Robust Real-Time Pursuit Strategies under Partial Observability](https://arxiv.org/abs/2511.17367)
*Runyu Lu,Ruochuan Shi,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.LG

TL;DR: 本文提出了首个在部分可观测性下的最坏情况鲁棒实时追捕策略(R2PS)方法，通过信念保持机制和强化学习实现跨图泛化。


<details>
  <summary>Details</summary>
Motivation: 当前基于图的追逃游戏中，追捕者在只有不完美信息时缺乏实时适用的追捕策略，现有强化学习方法局限于完美信息场景且未考虑逃避者预测追捕者行动的情况。

Method: 首先证明传统动态规划算法在异步移动下保持最优性，然后提出逃避者可能位置的信念保持机制，将该机制嵌入EPG框架进行跨图强化学习对抗异步移动DP逃避策略。

Result: 强化学习后，策略实现了对未见真实世界图结构的鲁棒零样本泛化，并始终优于现有游戏强化学习方法直接在测试图上训练的策略。

Conclusion: R2PS方法成功解决了部分可观测性下的实时追捕策略问题，通过信念保持和强化学习实现了跨图泛化的鲁棒性能。

Abstract: Computing worst-case robust strategies in pursuit-evasion games (PEGs) is time-consuming, especially when real-world factors like partial observability are considered. While important for general security purposes, real-time applicable pursuit strategies for graph-based PEGs are currently missing when the pursuers only have imperfect information about the evader's position. Although state-of-the-art reinforcement learning (RL) methods like Equilibrium Policy Generalization (EPG) and Grasper provide guidelines for learning graph neural network (GNN) policies robust to different game dynamics, they are restricted to the scenario of perfect information and do not take into account the possible case where the evader can predict the pursuers' actions. This paper introduces the first approach to worst-case robust real-time pursuit strategies (R2PS) under partial observability. We first prove that a traditional dynamic programming (DP) algorithm for solving Markov PEGs maintains optimality under the asynchronous moves by the evader. Then, we propose a belief preservation mechanism about the evader's possible positions, extending the DP pursuit strategies to a partially observable setting. Finally, we embed the belief preservation into the state-of-the-art EPG framework to finish our R2PS learning scheme, which leads to a real-time pursuer policy through cross-graph reinforcement learning against the asynchronous-move DP evasion strategies. After reinforcement learning, our policy achieves robust zero-shot generalization to unseen real-world graph structures and consistently outperforms the policy directly trained on the test graphs by the existing game RL approach.

</details>


### [54] [A Unified Stability Analysis of SAM vs SGD: Role of Data Coherence and Emergence of Simplicity Bias](https://arxiv.org/abs/2511.17378)
*Wei-Kai Chang,Rajiv Khanna*

Main category: cs.LG

TL;DR: 本文开发了一个线性稳定性框架来分析SGD、随机扰动和SAM在两层ReLU网络中的行为，通过一致性度量揭示梯度曲率在数据点间的对齐方式，解释为何某些最小值在训练中更稳定且被偏好。


<details>
  <summary>Details</summary>
Motivation: 理解深度学习优化的动态性对于模型扩展越来越重要。虽然SGD及其变体能可靠地找到泛化良好的解，但驱动这种泛化的机制仍不清楚。这些算法通常偏好更平坦或更简单的最小值，特别是在过参数化设置中。

Method: 开发线性稳定性框架，分析SGD、随机扰动和SAM的行为，特别关注两层ReLU网络。核心是引入一致性度量来量化梯度曲率在数据点间的对齐方式。

Result: 该框架揭示了为什么某些最小值在训练中更稳定且被偏好，通过一致性度量解释了梯度曲率的对齐如何影响优化动态。

Conclusion: 提出的线性稳定性框架和一致性度量提供了连接数据结构、优化动态和学习解性质的理论基础，有助于理解为什么平坦最小值在深度学习中具有更好的泛化性能。

Abstract: Understanding the dynamics of optimization in deep learning is increasingly important as models scale. While stochastic gradient descent (SGD) and its variants reliably find solutions that generalize well, the mechanisms driving this generalization remain unclear. Notably, these algorithms often prefer flatter or simpler minima, particularly in overparameterized settings. Prior work has linked flatness to generalization, and methods like Sharpness-Aware Minimization (SAM) explicitly encourage flatness, but a unified theory connecting data structure, optimization dynamics, and the nature of learned solutions is still lacking. In this work, we develop a linear stability framework that analyzes the behavior of SGD, random perturbations, and SAM, particularly in two layer ReLU networks. Central to our analysis is a coherence measure that quantifies how gradient curvature aligns across data points, revealing why certain minima are stable and favored during training.

</details>


### [55] [Stable Coresets via Posterior Sampling: Aligning Induced and Full Loss Landscapes](https://arxiv.org/abs/2511.17399)
*Wei-Kai Chang,Rajiv Khanna*

Main category: cs.LG

TL;DR: 提出了一种基于后验采样的核心集选择新框架，通过连接后验采样与损失景观来解决梯度方法在核心集选择中的局限性，实现了更快的训练速度和更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模的扩大，计算需求激增，需要有效的数据子集选择技术。基于梯度的核心集选择方法虽然理论基础扎实，但面临SGD基线过强和损失曲率不匹配导致代表性下降的问题。

Method: 1) 建立后验采样与损失景观的连接，提升高数据污染场景下的鲁棒性；2) 引入基于后验采样的平滑损失函数，增强稳定性和泛化能力；3) 提出了采样核心集选择方法的收敛性分析。

Result: 通过大量实验证明，该方法在多个数据集上实现了比现有技术更快的训练速度和更好的泛化性能。

Conclusion: 提出的基于后验采样的核心集选择框架有效解决了梯度方法的局限性，在保持计算效率的同时显著提升了训练速度和模型泛化能力。

Abstract: As deep learning models continue to scale, the growing computational demands have amplified the need for effective coreset selection techniques. Coreset selection aims to accelerate training by identifying small, representative subsets of data that approximate the performance of the full dataset. Among various approaches, gradient based methods stand out due to their strong theoretical underpinnings and practical benefits, particularly under limited data budgets. However, these methods face challenges such as naive stochastic gradient descent (SGD) acting as a surprisingly strong baseline and the breakdown of representativeness due to loss curvature mismatches over time.
  In this work, we propose a novel framework that addresses these limitations. First, we establish a connection between posterior sampling and loss landscapes, enabling robust coreset selection even in high data corruption scenarios. Second, we introduce a smoothed loss function based on posterior sampling onto the model weights, enhancing stability and generalization while maintaining computational efficiency. We also present a novel convergence analysis for our sampling-based coreset selection method. Finally, through extensive experiments, we demonstrate how our approach achieves faster training and enhanced generalization across diverse datasets than the current state of the art.

</details>


### [56] [DS-Span: Single-Phase Discriminative Subgraph Mining for Efficient Graph Embeddings](https://arxiv.org/abs/2511.17419)
*Yeamin Kaiser,Muhammed Tasnim Bin Anwar,Bholanath Das,Chowdhury Farhan Ahmed,Md. Tanvir Alam*

Main category: cs.LG

TL;DR: DS-Span是一个单阶段判别式子图挖掘框架，将模式增长、剪枝和监督驱动评分统一在搜索空间的一次遍历中，生成紧凑且判别性的子图特征用于图嵌入和分类。


<details>
  <summary>Details</summary>
Motivation: 现有的频繁或判别式子图挖掘方法存在冗余的多阶段流程、高计算成本和挖掘结构与判别相关性之间弱耦合的问题，需要更高效的统一框架。

Method: 提出DS-Span框架，包含覆盖上限资格机制（动态限制探索）和信息增益引导选择（促进强类别分离能力同时最小化冗余），在搜索空间单次遍历中统一完成模式挖掘。

Result: 在多个基准测试中，DS-Span比多阶段方法生成更紧凑和判别性的子图特征，在显著减少运行时间的同时达到更高或相当的准确率。

Conclusion: 统一的单阶段判别式挖掘方法为可扩展和可解释的图表示学习提供了有前景的基础。

Abstract: Graph representation learning seeks to transform complex, high-dimensional graph structures into compact vector spaces that preserve both topology and semantics. Among the various strategies, subgraph-based methods provide an interpretable bridge between symbolic pattern discovery and continuous embedding learning. Yet, existing frequent or discriminative subgraph mining approaches often suffer from redundant multi-phase pipelines, high computational cost, and weak coupling between mined structures and their discriminative relevance. We propose DS-Span, a single-phase discriminative subgraph mining framework that unifies pattern growth, pruning, and supervision-driven scoring within one traversal of the search space. DS-Span introduces a coverage-capped eligibility mechanism that dynamically limits exploration once a graph is sufficiently represented, and an information-gain-guided selection that promotes subgraphs with strong class-separating ability while minimizing redundancy. The resulting subgraph set serves as an efficient, interpretable basis for downstream graph embedding and classification. Extensive experiments across benchmarks demonstrate that DS-Span generates more compact and discriminative subgraph features than prior multi-stage methods, achieving higher or comparable accuracy with significantly reduced runtime. These results highlight the potential of unified, single-phase discriminative mining as a foundation for scalable and interpretable graph representation learning.

</details>


### [57] [Towards fully differentiable neural ocean model with Veros](https://arxiv.org/abs/2511.17427)
*Etienne Meunier,Said Ouala,Hugo Frezat,Julien Le Sommer,Ronan Fablet*

Main category: cs.LG

TL;DR: 将VEROS海洋模型扩展为可微分版本，使其与JAX自动微分框架兼容，并展示了在海洋状态修正和物理参数校准中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统海洋模型难以进行梯度优化和参数校准，需要可微分模型来支持端到端学习和参数调优。

Method: 对VEROS海洋模型进行关键修改，使其与JAX自动微分框架完全兼容，保持数值一致性。

Result: 成功实现了可微分海洋模型，能够通过梯度优化修正初始海洋状态，并直接从模型观测中校准未知物理参数。

Conclusion: 可微分编程能够促进海洋建模中的端到端学习和参数调优，该实现已在线提供。

Abstract: We present a differentiable extension of the VEROS ocean model, enabling automatic differentiation through its dynamical core. We describe the key modifications required to make the model fully compatible with JAX autodifferentiation framework and evaluate the numerical consistency of the resulting implementation. Two illustrative applications are then demonstrated: (i) the correction of an initial ocean state through gradient-based optimization, and (ii) the calibration of unknown physical parameters directly from model observations. These examples highlight how differentiable programming can facilitate end-to-end learning and parameter tuning in ocean modeling. Our implementation is available online.

</details>


### [58] [Multi-Agent Pointer Transformer: Seq-to-Seq Reinforcement Learning for Multi-Vehicle Dynamic Pickup-Delivery Problems](https://arxiv.org/abs/2511.17435)
*Zengyu Zou,Jingyuan Wang,Yixuan Huang,Junjie Wu*

Main category: cs.LG

TL;DR: 提出了基于序列到序列的多智能体指针变换器(MAPT)框架，用于解决带随机请求的多车辆动态取送货问题，在性能和计算时间上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 经典运筹学方法在处理大规模动态问题时面临计算复杂度和时间效率瓶颈，现有强化学习方法存在联合动作分布建模困难、实体间关系捕捉不足、联合动作空间指数级增长等问题。

Method: 使用Transformer编码器提取实体表示，结合Transformer解码器和指针网络以自回归方式生成联合动作序列，引入关系感知注意力模块捕捉实体间关系，并使用信息先验指导模型决策。

Result: 在8个数据集上的实验表明，MAPT在性能上显著优于现有基线方法，相比经典运筹学方法具有显著的计算时间优势。

Conclusion: MAPT框架有效解决了多车辆动态取送货问题中的关键挑战，为大规模动态路由优化提供了高效的端到端解决方案。

Abstract: This paper addresses the cooperative Multi-Vehicle Dynamic Pickup and Delivery Problem with Stochastic Requests (MVDPDPSR) and proposes an end-to-end centralized decision-making framework based on sequence-to-sequence, named Multi-Agent Pointer Transformer (MAPT). MVDPDPSR is an extension of the vehicle routing problem and a spatio-temporal system optimization problem, widely applied in scenarios such as on-demand delivery. Classical operations research methods face bottlenecks in computational complexity and time efficiency when handling large-scale dynamic problems. Although existing reinforcement learning methods have achieved some progress, they still encounter several challenges: 1) Independent decoding across multiple vehicles fails to model joint action distributions; 2) The feature extraction network struggles to capture inter-entity relationships; 3) The joint action space is exponentially large. To address these issues, we designed the MAPT framework, which employs a Transformer Encoder to extract entity representations, combines a Transformer Decoder with a Pointer Network to generate joint action sequences in an AutoRegressive manner, and introduces a Relation-Aware Attention module to capture inter-entity relationships. Additionally, we guide the model's decision-making using informative priors to facilitate effective exploration. Experiments on 8 datasets demonstrate that MAPT significantly outperforms existing baseline methods in terms of performance and exhibits substantial computational time advantages compared to classical operations research methods.

</details>


### [59] [InTAct: Interval-based Task Activation Consolidation for Continual Learning](https://arxiv.org/abs/2511.17439)
*Patryk Krukowski,Jan Miksa,Piotr Helm,Jacek Tabor,Paweł Wawrzyński,Przemysław Spurek*

Main category: cs.LG

TL;DR: InTAct是一种持续学习方法，通过约束共享层中神经元的激活范围来防止表示漂移，在保持参数灵活性的同时稳定先前学习任务的功能行为。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的持续学习方法在类别增量设置中表现良好，但在域偏移场景下容易受到表示漂移的影响，导致遗忘问题。

Method: InTAct捕捉先前学习任务的特征激活范围，约束更新以确保网络在这些区域内保持一致，同时允许在其他区域灵活适应，稳定重要神经元的功能角色。

Result: 在DomainNet和ImageNet-R等多样域增量基准测试中，InTAct持续减少表示漂移并提高性能，平均准确率比最先进基线提高最多8个百分点。

Conclusion: InTAct通过在编码过去知识的地方调节表示变化，实现了稳定性和可塑性之间的平衡，是一种架构无关且可无缝集成到现有提示框架的方法。

Abstract: Continual learning aims to enable neural networks to acquire new knowledge without forgetting previously learned information. While recent prompt-based methods perform strongly in class-incremental settings, they remain vulnerable under domain shifts, where the input distribution changes but the label space remains fixed. This exposes a persistent problem known as representation drift. Shared representations evolve in ways that overwrite previously useful features and cause forgetting even when prompts isolate task-specific parameters. To address this issue, we introduce InTAct, a method that preserves functional behavior in shared layers without freezing parameters or storing past data. InTAct captures the characteristic activation ranges associated with previously learned tasks and constrains updates to ensure the network remains consistent within these regions, while still allowing for flexible adaptation elsewhere. In doing so, InTAct stabilizes the functional role of important neurons rather than directly restricting parameter values. The approach is architecture-agnostic and integrates seamlessly into existing prompt-based continual learning frameworks. By regulating representation changes where past knowledge is encoded, InTAct achieves a principled balance between stability and plasticity. Across diverse domain-incremental benchmarks, including DomainNet and ImageNet-R, InTAct consistently reduces representation drift and improves performance, increasing Average Accuracy by up to 8 percentage points over state-of-the-art baselines.

</details>


### [60] [Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol Mass Spectrometry](https://arxiv.org/abs/2511.17446)
*Kyle M. Regan,Michael McLoughlin,Wayne A. Bryden,Gonzalo R. Arce*

Main category: cs.LG

TL;DR: 提出了MS-DGFormer框架，通过Transformer架构直接处理原始质谱数据，实现单次检测的气溶胶病原体识别，无需复杂预处理。


<details>
  <summary>Details</summary>
Motivation: 传统MALDI-MS需要繁琐的样品制备和多谱平均，限制了其在实时环境监测中的应用，特别是在新兴气溶胶MALDI-MS系统中面临单次检测的挑战。

Method: 使用Transformer架构捕获质谱时间序列的长程依赖关系，并引入基于奇异值分解的字典编码器来整合去噪光谱信息。

Result: 该方法能够从单次光谱中准确识别关键生物分子模式，在气溶胶样本中实现卓越的病原体识别性能。

Conclusion: 该技术消除了对广泛预处理的需求，为便携式可部署MALDI-MS平台开辟了可能性，彻底改变了环境病原体检测和生物威胁快速响应。

Abstract: Matrix Assisted Laser Desorption/Ionization Mass Spectrometry (MALDI-MS) is a cornerstone in biomolecular analysis, offering precise identification of pathogens through unique mass spectral signatures. Yet, its reliance on labor-intensive sample preparation and multi-shot spectral averaging restricts its use to laboratory settings, rendering it impractical for real-time environmental monitoring. These limitations are especially pronounced in emerging aerosol MALDI-MS systems, where autonomous sampling generates noisy spectra for unknown aerosol analytes, requiring single-shot detection for effective analysis. Addressing these challenges, we propose the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer): a data-driven framework that redefines spectral analysis by directly processing raw, minimally prepared mass spectral data. MS-DGFormer leverages a transformer architecture, designed to capture the long-range dependencies inherent in these time-series spectra. To enhance feature extraction, we introduce a novel dictionary encoder that integrates denoised spectral information derived from Singular Value Decomposition (SVD), enabling the model to discern critical biomolecular patterns from single-shot spectra with robust performance. This innovation provides a system to achieve superior pathogen identification from aerosol samples, facilitating autonomous, real-time analysis in field conditions. By eliminating the need for extensive preprocessing, our method unlocks the potential for portable, deployable MALDI-MS platforms, revolutionizing environmental pathogen detection and rapid response to biological threats.

</details>


### [61] [PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM](https://arxiv.org/abs/2511.17467)
*Siqi Liang,Yudi Zhang,Yue Guo*

Main category: cs.LG

TL;DR: 提出了一个基于知识图谱增强检索增强生成（Graph RAG）的个性化语言模型框架，通过构建用户画像和全局交互模式来生成个性化提示，显著提升了多项任务的性能。


<details>
  <summary>Details</summary>
Motivation: 需要开发能够适应个体用户偏好的个性化AI代理，让代理能够体现用户的"画像"（如用户档案或品味）。

Method: 引入知识图谱增强的检索增强生成机制，构建LLM衍生的图索引，结合用户历史行为偏好摘要和基于图的社区检测识别的全局交互模式来生成个性化提示。

Result: 在LaMP基准测试中，新闻分类F1提升11.1%，电影标签F1提升56.1%，产品评分MAE降低10.4%。

Conclusion: 该框架能够维持一致的画像对齐行为，同时受益于集体知识，为个性化AI代理提供了有效解决方案。

Abstract: We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's "persona" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [62] [BITS for GAPS: Bayesian Information-Theoretic Sampling for hierarchical GAussian Process Surrogates](https://arxiv.org/abs/2511.16815)
*Kyla D. Jones,Alexander W. Dowling*

Main category: stat.ML

TL;DR: BITS for GAPS框架用于混合物理系统的隐变量建模，通过贝叶斯信息理论采样和分层高斯过程代理模型，在已知物理模型基础上学习剩余动态。


<details>
  <summary>Details</summary>
Motivation: 解决混合物理系统中已知物理模型无法完全描述系统行为的问题，需要从数据中推断剩余动态，同时保持物理一致性。

Method: 使用分层高斯过程先验对隐函数建模，推导基于熵的采集函数来指导数据采集，通过闭式微分熵表达式和可处理下界实现高效评估。

Result: 在气液平衡系统建模中，熵引导采样提高了样本效率，加速了代理模型收敛，在非理想区域增强了预测精度并保持了物理一致性。

Conclusion: BITS for GAPS为复杂物理系统的混合建模提供了一个高效、可解释且具有不确定性的框架。

Abstract: We introduce the Bayesian Information-Theoretic Sampling for hierarchical GAussian Process Surrogates (BITS for GAPS) framework to emulate latent components in hybrid physical systems. BITS for GAPS supports serial hybrid modeling, where known physics governs part of the system and residual dynamics are represented as a latent function inferred from data. A Gaussian process prior is placed over the latent function, with hierarchical priors on its hyperparameters to encode physically meaningful structure in the predictive posterior.
  To guide data acquisition, we derive entropy-based acquisition functions that quantify expected information gain from candidate input locations, identifying samples most informative for training the surrogate. Specifically, we obtain a closed-form expression for the differential entropy of the predictive posterior and establish a tractable lower bound for efficient evaluation. These derivations approximate the predictive posterior as a finite, uniformly weighted mixture of Gaussian processes.
  We demonstrate the framework's utility by modeling activity coefficients in vapor-liquid equilibrium systems, embedding the surrogate into extended Raoult's law for distillation design. Numerical results show that entropy-guided sampling improves sample efficiency by targeting regions of high uncertainty and potential information gain. This accelerates surrogate convergence, enhances predictive accuracy in non-ideal regimes, and preserves physical consistency. Overall, BITS for GAPS provides an efficient, interpretable, and uncertainty-aware framework for hybrid modeling of complex physical systems.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [cs.LG](#cs.LG) [Total: 20]
- [stat.ML](#stat.ML) [Total: 12]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Correlation and Temporal Consistency Analysis of Mono-static and Bi-static ISAC Channels](https://arxiv.org/abs/2511.03837)
*Saúl Fenollosa,Narcis Cardona,Wenfei Yang,Jian Li*

Main category: eess.SP

TL;DR: 本文通过79-GHz FMCW信道探测仪在动态城市微蜂窝环境中进行经验测量，揭示了单静态和双静态信道之间的关键关系：瞬时相关性低但具有统一的时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有信道模型缺乏对ISAC特定动态的全面表征，特别是单静态（共置Tx/Rx）和双静态（分离Tx/Rx）感知配置之间的关系。

Method: 使用79-GHz FMCW信道探测仪在动态城市微蜂窝环境中进行经验测量，验证了七个真实场景中移动目标/收发器的数据。

Result: 两个关键发现：1）单静态和双静态信道由于传播几何差异而表现出持续低的瞬时相关性；2）尽管瞬时相关性低，但两种信道共享统一的时间一致性，在环境运动学下可预测地演化。

Conclusion: 这些见解为稳健的ISAC系统设计和未来标准化提供了信息，强调了在低瞬时相关性下保持时间一致性的重要性。

Abstract: Integrated Sensing and Communication (ISAC) is critical for efficient
spectrum and hardware utilization in future wireless networks like 6G. However,
existing channel models lack comprehensive characterization of ISAC-specific
dynamics, particularly the relationship between mono-static (co-located Tx/Rx)
and bi-static (separated Tx/Rx) sensing configurations. Empirical measurements
in dynamic urban microcell (UMi) environments using a 79-GHz FMCW channel
sounder help bridge this gap. Two key findings are demonstrated: (1)
mono-static and bi-static channels exhibit consistently low instantaneous
correlation due to divergent propagation geometries; (2) despite low
instantaneous correlation, both channels share unified temporal consistency,
evolving predictably under environmental kinematics. These insights, validated
across seven real-world scenarios with moving targets/transceivers, inform
robust ISAC system design and future standardization.

</details>


### [2] [Adaptive Phase Shift Information Compression for IRS Systems: A Prompt Conditioned Variable Rate Framework](https://arxiv.org/abs/2511.03923)
*Xianhua Yu,Dong Li,Bowen Gu,Liuqing Yang,Sumei Sun,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 提出了一种基于提示学习的智能反射表面相位信息压缩系统，通过混合提示技术和可变率方法实现自适应编码，在多种信道条件下显著降低归一化均方误差。


<details>
  <summary>Details</summary>
Motivation: 解决智能反射表面实际部署中面临的相位信息传输开销过大问题，现有深度学习方法存在解码器复杂度高、对动态信道适应性差、压缩比固定等局限性。

Method: 结合软提示连接和特征线性调制(FiLM)的混合提示技术，通过潜在掩码将压缩比融入提示嵌入的可变率方法，以及轻量级深度卷积门控(DWCG)解码器。

Result: 相比传统自编码器基线显著降低NMSE，在各种信道条件下保持鲁棒性，单一模型可适应不同压缩比，解码器复杂度低。

Conclusion: 该框架为下一代无线网络中实时IRS控制提供了可扩展且高效的解决方案，展示了在频谱和能量效率提升方面的应用前景。

Abstract: Intelligent reflecting surfaces (IRSs) have become a vital technology for
improving the spectrum and energy efficiency of forthcoming wireless networks.
Nevertheless, practical implementation is obstructed by the excessive overhead
associated with the frequent transmission of phase shift information (PSI) over
bandwidth-constrained control lines. Current deep learning-based compression
methods mitigate this problem but are constrained by elevated decoder
complexity, inadequate flexibility to dynamic channels, and static compression
ratios. This research presents a prompt-conditioned PSI compression system that
integrates prompt learning inspired by large models into the PSI compression
process to address these difficulties. A hybrid prompt technique that
integrates soft prompt concatenation with feature-wise linear modulation (FiLM)
facilitates adaptive encoding across diverse signal-to-noise ratios (SNRs),
fading kinds, and compression ratios. Furthermore, a variable rate technique
incorporates the compression ratio into the prompt embeddings through latent
masking, enabling a singular model to adeptly balance reconstruction accuracy.
Additionally, a lightweight depthwise convolutional gating (DWCG) decoder
facilitates precise feature reconstruction with minimal complexity.
Comprehensive simulations indicate that the proposed framework significantly
reduces NMSE compared to traditional autoencoder baselines, while ensuring
robustness across various channel circumstances and accommodating variable
compression ratios within a single model. These findings underscore the
framework's promise as a scalable and efficient solution for real-time IRS
control in next-generation wireless networks.

</details>


### [3] [Score-Based Quickest Change Detection and Fault Identification for Multi-Stream Signals](https://arxiv.org/abs/2511.03967)
*Wuxia Chen,Sean Moushegian,Vahid Tarokh,Taposh Banerjee*

Main category: eess.SP

TL;DR: 提出了一种基于Hyvarinen分数的min-SCUSUM方法，用于多流快速变化检测和故障隔离，避免了传统方法需要显式分布和计算似然比的问题。


<details>
  <summary>Details</summary>
Motivation: 传统快速变化检测算法需要显式的前后变化分布来计算观测值的似然比，对于高维数据和复杂机器学习模型计算成本高甚至不可行。

Method: 使用Hyvarinen分数替代对数似然比，计算分数函数差异，提出min-SCUSUM方法。

Result: 算法渐近性能取决于前后变化分布之间的Fisher散度，并建立了故障误识别概率的上界。

Conclusion: min-SCUSUM方法为复杂模型的高维数据变化检测提供了计算可行的解决方案。

Abstract: This paper introduces an approach to multi-stream quickest change detection
and fault isolation for unnormalized and score-based statistical models.
Traditional optimal algorithms in the quickest change detection literature
require explicit pre-change and post-change distributions to calculate the
likelihood ratio of the observations, which can be computationally expensive
for higher-dimensional data and sometimes even infeasible for complex machine
learning models. To address these challenges, we propose the min-SCUSUM method,
a Hyvarinen score-based algorithm that computes the difference of score
functions in place of log-likelihood ratios. We provide a delay and false alarm
analysis of the proposed algorithm, showing that its asymptotic performance
depends on the Fisher divergence between the pre- and post-change
distributions. Furthermore, we establish an upper bound on the probability of
fault misidentification in distinguishing the affected stream from the
unaffected ones.

</details>


### [4] [Joint Beamforming and Position Design for Movable Antenna Assisted LEO ISAC Systems](https://arxiv.org/abs/2511.03984)
*Hanfu Zhang,Erwu Liu*

Main category: eess.SP

TL;DR: 本文研究了可移动天线辅助的低地球轨道卫星综合感知与通信系统，通过联合优化发射波束成形和天线位置，在满足通信SINR约束下最小化感知性能的平方位置误差界，实现了通信与感知性能的更好权衡。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星辅助的综合感知与通信系统面临严重的信号衰减和有限发射功率问题，这会降低ISAC性能。为了解决这一问题，本文探索了可移动天线辅助的LEO ISAC系统。

Method: 首先推导了通信信号干扰噪声比和感知平方位置误差界的性能指标，然后联合优化发射波束成形和MA位置。采用半定松弛简化复杂问题，并提出基于交替优化的算法将原问题分解为两个子问题，分别进行凸化求解。

Result: 仿真验证了所提算法的收敛性和有效性，与基准方法相比，实现了通信与感知性能的更好权衡，并在感知性能上获得了至少25%的提升。

Conclusion: 可移动天线辅助的LEO ISAC系统能够有效解决信号衰减和功率限制问题，通过联合优化波束成形和天线位置，显著提升了系统性能。

Abstract: Low earth orbit (LEO) satellite-assisted integrated sensing and
communications (ISAC) systems have been extensively studied to achieve
ubiquitous connectivity. However, the severe signal attenuation and limited
transmit power at LEO satellites can degrade ISAC performance. To address this
issue, this paper investigated movable antenna (MA)-assisted LEO ISAC systems.
We derive the communication signal-to-interference-plus-noise ratio (SINR) and
the sensing squared position error bound (SPEB) for evaluating the ISAC
performance. Then, we jointly optimize the transmit beamforming and the MA
positions to minimize the SPEB under the SINR constraints, total transmit power
constraint, and several inherent physical constraints of the MA array. We first
simplify the complex problem using the semidefinite relaxation (SDR). Then, we
present a novel alternating optimization (AO)-based algorithm to decouple the
original problem into two subproblems, consequently convexified and solved.
Simulations demonstrate the convergence and effectiveness of the proposed
algorithm. Better trade-off between communication and sensing performance, and
at least 25% gain in sensing performance are achieved, compared to the
benchmarks.

</details>


### [5] [Optimal RIS Placement in a Multi-User MISO System with User Randomness](https://arxiv.org/abs/2511.03998)
*Abhishek Rajasekaran,Mehdi Karbalayghareh,Xiaoyan Ma,David J. Love,Christopher G. Brinton*

Main category: eess.SP

TL;DR: 本文提出了一种从粗到精的递归方法来优化可重构智能表面(RIS)的部署位置，考虑用户随机性和障碍物配置，以最大化系统的最小期望信干噪比。


<details>
  <summary>Details</summary>
Motivation: 现有RIS辅助系统大多假设基站、RIS和用户位置已知，但实际部署前通常只知道用户密度分布和障碍物配置。需要一种考虑用户随机性的RIS位置优化方法。

Method: 提出递归从粗到精方法：基于障碍物配置构建候选位置集，通过多次用户分布实例评估，在每阶段识别最优区域并递归细化搜索，最终确定RIS部署最优区域。

Result: 数值结果验证了所提方法的有效性，能够找到RIS部署的最优位置。

Conclusion: 该方法能够有效解决实际部署中用户位置不确定情况下的RIS位置优化问题，为RIS系统部署提供了实用解决方案。

Abstract: It is well established that the performance of reconfigurable intelligent
surface (RIS)-assisted systems critically depends on the optimal placement of
the RIS. Previous works consider either simple coverage maximization or
simultaneous optimization of the placement of the RIS along with the
beamforming and reflection coefficients, most of which assume that the location
of the RIS, base station (BS), and users are known. However, in practice, only
the spatial variation of user density and obstacle configuration are likely to
be known prior to deployment of the system. Thus, we formulate a non-convex
problem that optimizes the position of the RIS over the expected minimum
signal-to-interference-plus-noise ratio (SINR) of the system with user
randomness, assuming that the system employs joint beamforming after
deployment. To solve this problem, we propose a recursive coarse-to-fine
methodology that constructs a set of candidate locations for RIS placement
based on the obstacle configuration and evaluates them over multiple
instantiations from the user distribution. The search is recursively refined
within the optimal region identified in each stage to determine the final
optimal region for RIS deployment. Numerical results are presented to
corroborate our findings.

</details>


### [6] [A Survey on Noise-Based Communication](https://arxiv.org/abs/2511.04011)
*Higo T. P. Da Silva,Hugerles S. Silva,Felipe A. P. Figueiredo,Andre A. Dos Anjos,Rausley A. A. Souza*

Main category: eess.SP

TL;DR: 本文全面综述了基于噪声的通信技术，包括热噪声调制、噪声调制及其变体、KLJN安全密钥交换等关键方法，探讨了在6G网络和物联网中的实际应用挑战和前景。


<details>
  <summary>Details</summary>
Motivation: 第六代网络和大规模物联网的发展需要超低功耗、安全和隐蔽的无线通信技术，基于噪声的通信通过将信息编码到噪声的统计特性中，成为满足这些需求的变革性范式。

Method: 系统探索了基于噪声通信的基本原理和关键方法，包括热噪声调制、噪声调制及其变体、KLJN安全密钥交换，并解决了信道估计和硬件实现等实际挑战。

Result: 分析证实基于噪声的系统在能效和隐蔽性方面具有无与伦比的优势，支持同时无线信息和能量传输、非正交多址接入等新兴应用。

Conclusion: 基于噪声的通信技术为实现下一代自主和安全无线网络的潜力提供了明确的研究方向和发展路径。

Abstract: The proliferation of sixth-generation (6G) networks and the massive Internet
of Things (IoT) demand wireless communication technologies that are
ultra-low-power, secure, and covert. Noise-based communication has emerged as a
transformative paradigm that meets these demands by encoding information
directly into the statistical properties of noise, rather than using
traditional deterministic carriers. This survey provides a comprehensive
synthesis of this field, systematically exploring its fundamental principles
and key methodologies, including thermal noise modulation (TherMod), noise
modulation (NoiseMod) and its variants, and the Kirchhoff-law-Johnson-noise
(KLJN) secure key exchange. We address critical practical challenges such as
channel estimation and hardware implementation, and highlight emerging
applications in simultaneous wireless information and power transfer (SWIPT)
and non-orthogonal multiple access (NOMA). Our analysis confirms that
noise-based systems offer unparalleled advantages in energy efficiency and
covertness, and we conclude by outlining future research directions to realize
their potential for enabling the next generation of autonomous and secure
wireless networks.

</details>


### [7] [Tiny-WiFo: A Lightweight Wireless Foundation Model for Channel Prediction via Multi-Component Adaptive Knowledge Distillation](https://arxiv.org/abs/2511.04015)
*Haotian Zhang,Shijian Gao,Xiang Cheng*

Main category: eess.SP

TL;DR: 提出了MCAKD框架，通过交叉注意力知识选择和自主-被动学习策略，将WiFo FM压缩为仅5.5M参数的Tiny-WiFo模型，在边缘设备上实现1.6ms推理时间，保持98%性能。


<details>
  <summary>Details</summary>
Motivation: 无线基础模型的大规模阻碍了其在边缘设备上的实时部署，需要高效的模型压缩方法。

Method: MCAKD框架包含交叉注意力知识选择模块和自主-被动学习策略，选择性提取教师模型关键特征并平衡知识转移与独立学习。

Result: Tiny-WiFo模型仅5.5M参数，在边缘硬件上实现1.6ms推理时间，保持WiFo模型98%性能和零样本泛化能力。

Conclusion: 该方法使实时基础模型部署在边缘设备上成为可能，为资源受限环境提供了可行的解决方案。

Abstract: The massive scale of Wireless Foundation Models (FMs) hinders their real-time
deployment on edge devices. This letter moves beyond standard knowledge
distillation by introducing a novel Multi-Component Adaptive Knowledge
Distillation (MCAKD) framework. Key innovations include a Cross-Attention-Based
Knowledge Selection (CA-KS) module that selectively identifies critical
features from the teacher model, and an Autonomous Learning-Passive Learning
(AL-PL) strategy that balances knowledge transfer with independent learning to
achieve high training efficiency at a manageable computational cost. When
applied to the WiFo FM, the distilled Tiny-WiFo model, with only 5.5M
parameters, achieves a 1.6 ms inference time on edge hardware while retaining
over 98% of WiFo's performance and its crucial zero-shot generalization
capability, making real-time FM deployment viable.

</details>


### [8] [Ambiguity Function Analysis of AFDM Under Pulse-Shaped Random ISAC Signaling](https://arxiv.org/abs/2511.04200)
*Yuanhan Ni,Fan Liu,Haoran Yin,Yanqun Tang,Zulin Wang*

Main category: eess.SP

TL;DR: 本文研究了AFDM波形在脉冲整形下的模糊函数特性，发现AFDM可以通过调整参数c1灵活控制旁瓣凹陷位置，提出了一种新的参数设计方法来减轻强目标对弱目标检测的影响。


<details>
  <summary>Details</summary>
Motivation: 研究AFDM波形在ISAC系统中的模糊函数特性，特别是脉冲整形对模糊函数的影响，以解决弱目标检测性能损失的问题。

Method: 首先推导无脉冲整形AFDM波形的平均平方离散周期模糊函数闭式表达式，然后分析AFDM、OFDM和OCDM波形的模糊函数特性，最后推导脉冲整形随机AFDM波形的平均平方离散周期模糊函数闭式表达式。

Result: 所有三种波形在其模糊函数旁瓣中表现出相同数量的规则凹陷，这会导致弱目标检测和估计性能损失。AFDM波形可以通过调整参数c1灵活控制凹陷位置。脉冲整形滤波器在延迟轴上产生整形主瓣，在多普勒轴上产生快速滚降旁瓣。

Conclusion: 数值结果验证了理论分析和提出的AFDM调制设计方法的有效性，AFDM参数设计可以减轻强目标对弱目标检测的不利影响。

Abstract: This paper investigates the ambiguity function (AF) of the emerging affine
frequency division multiplexing (AFDM) waveform for Integrated Sensing and
Communication (ISAC) signaling under a pulse shaping regime. Specifically, we
first derive the closed-form expression of the average squared discrete period
AF (DPAF) for AFDM waveform without pulse shaping, revealing that the AF
depends on the parameter $c_1$ and the kurtosis of random communication data,
while being independent of the parameter $c_2$. As a step further, we conduct a
comprehensive analysis on the AFs of various waveforms, including AFDM,
orthogonal frequency division multiplexing (OFDM) and orthogonal chirp-division
multiplexing (OCDM). Our results indicate that all three waveforms exhibit the
same number of regular depressions in the sidelobes of their AFs, which incurs
performance loss for detecting and estimating weak targets. However, the AFDM
waveform can flexibly control the positions of depressions by adjusting the
parameter $c_1$, which motivates a novel design approach of the AFDM parameters
to mitigate the adverse impact of depressions of the strong target on the weak
target. Furthermore, a closed-form expression of the average squared DPAF for
pulse-shaped random AFDM waveform is derived, which demonstrates that the pulse
shaping filter generates the shaped mainlobe along the delay axis and the rapid
roll-off sidelobes along the Doppler axis. Numerical results verify the
effectiveness of our theoretical analysis and proposed design methodology for
the AFDM modulation.

</details>


### [9] [BTTDA: Block-Term Tensor Discriminant Analysis for Brain-Computer Interfacing](https://arxiv.org/abs/2511.04292)
*Arne Van Den Kerchove,Hakim Si-Mohammed,François Cabestaing,Marc M. Van Hulle*

Main category: eess.SP

TL;DR: 提出了一种新的张量判别分析方法BTTDA，用于脑机接口中的EEG信号分类，在ERP解码中达到91.25%的ROC-AUC性能，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有张量分解方法如Tucker和PARAFAC缺乏灵活性，无法充分捕捉EEG数据的复杂性，需要更灵活的多线性降维方法。

Method: 提出Block-Term Tensor Discriminant Analysis (BTTDA)，扩展高阶判别分析(HODA)，结合可解释的前向模型和紧缩方案迭代提取判别块项。

Result: 在MOABB基准测试中，BTTDA和PARAFACDA在ERP解码中显著优于传统HODA方法，达到91.25% ROC-AUC；在MI解码中BTTDA也显著优于HODA(64.52% vs 61.00%)。

Conclusion: BTTDA的块项结构实现了可解释且高效的降维，不损失判别能力，为BCI和神经影像应用提供了有前景的适应性特征提取方法。

Abstract: Brain-computer interfaces (BCIs) allow direct communication between the brain
and external devices, frequently using electroencephalography (EEG) to record
neural activity. Dimensionality reduction and structured regularization are
essential for effectively classifying task-related brain signals, including
event-related potentials (ERPs) and motor imagery (MI) rhythms. Current
tensor-based approaches, such as Tucker and PARAFAC decompositions, often lack
the flexibility needed to fully capture the complexity of EEG data. This study
introduces Block-Term Tensor Discriminant Analysis (BTTDA): a novel
tensor-based and supervised feature extraction method designed to enhance
classification accuracy by providing flexible multilinear dimensionality
reduction. Extending Higher Order Discriminant Analysis (HODA), BTTDA uses a
novel and interpretable forward model for HODA combined with a deflation scheme
to iteratively extract discriminant block terms, improving feature
representation for classification. BTTDA and a sum-of-rank-1-terms variant
PARAFACDA were evaluated on publicly available ERP (second-order tensors) and
MI (third-order tensors) EEG datasets from the MOABB benchmarking framework.
Benchmarking revealed that BTTDA and PARAFACDA significantly outperform the
traditional HODA method in ERP decoding, resulting in state-of-the art
performance (ROC-AUC = 91.25%). For MI, decoding results of HODA, BTTDA and
PARAFACDA were subpar, but BTTDA still significantly outperformed HODA (64.52%
> 61.00%). The block-term structure of BTTDA enables interpretable and more
efficient dimensionality reduction without compromising discriminative power.
This offers a promising and adaptable approach for feature extraction in BCI
and broader neuroimaging applications.

</details>


### [10] [RCMCL: A Unified Contrastive Learning Framework for Robust Multi-Modal (RGB-D, Skeleton, Point Cloud) Action Understanding](https://arxiv.org/abs/2511.04351)
*Hasan Akgul,Mari Eplik,Javier Rojas,Akira Yamamoto,Rajesh Kumar,Maya Singh*

Main category: eess.SP

TL;DR: 提出了RCMCL自监督框架，通过跨模态对比学习、模态内自蒸馏和退化模拟来学习模态不变表示，在模态丢失和损坏时保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态动作识别在传感器故障或噪声时性能急剧下降的问题，需要开发对模态丢失和损坏具有鲁棒性的方法。

Method: 联合优化三个目标：跨模态对比目标对齐异构流，模态内自蒸馏目标提高视图不变性，退化模拟目标训练模型从损坏输入中恢复。推理时使用自适应模态门控网络进行鲁棒融合。

Result: 在NTU RGB+D 120和UWA3D-II数据集上达到最先进准确率，在严重双模态丢失情况下仅下降11.5%，显著优于强监督融合基线。

Conclusion: 自监督跨模态对齐结合显式退化建模和自适应融合是实现可部署多模态动作识别的关键。

Abstract: Human action recognition (HAR) with multi-modal inputs (RGB-D, skeleton,
point cloud) can achieve high accuracy but typically relies on large labeled
datasets and degrades sharply when sensors fail or are noisy. We present Robust
Cross-Modal Contrastive Learning (RCMCL), a self-supervised framework that
learns modality-invariant representations and remains reliable under modality
dropout and corruption. RCMCL jointly optimizes (i) a cross-modal contrastive
objective that aligns heterogeneous streams, (ii) an intra-modal
self-distillation objective that improves view-invariance and reduces
redundancy, and (iii) a degradation simulation objective that explicitly trains
models to recover from masked or corrupted inputs. At inference, an Adaptive
Modality Gating (AMG) network assigns data-driven reliability weights to each
modality for robust fusion. On NTU RGB+D 120 (CS/CV) and UWA3D-II, RCMCL
attains state-of-the-art accuracy in standard settings and exhibits markedly
better robustness: under severe dual-modality dropout it shows only an 11.5%
degradation, significantly outperforming strong supervised fusion baselines.
These results indicate that self-supervised cross-modal alignment, coupled with
explicit degradation modeling and adaptive fusion, is key to deployable
multi-modal HAR.

</details>


### [11] [High-Resolution Forest Mapping from L-Band Interferometric SAR Time Series using Deep Learning over Northern Spain](https://arxiv.org/abs/2511.04362)
*Chiara Telli,Oleg Antropov,Anne Lönnqvist,Marco Lavalle*

Main category: eess.SP

TL;DR: 本研究使用L波段干涉SAR时间序列数据和深度学习模型进行高分辨率森林制图，通过结合极化、干涉特征和注意力机制，显著提高了森林高度反演精度。


<details>
  <summary>Details</summary>
Motivation: 探索利用L波段干涉SAR时间序列数据和深度学习模型进行高分辨率森林制图的潜力，为NISAR和未来ROSE-L任务提供可行的技术方案。

Method: 使用ALOS-2 PALSAR-2双极化SAR时间序列数据，结合多种UNet家族深度学习模型（包括基础UNet、带注意力机制的SeU-Net和嵌套结构UNet），输入极化、干涉特征和模型反演特征。

Result: 仅使用强度数据时，20米分辨率下森林高度反演精度为3.1-3.8米（R²=0.45-0.55）；加入干涉相干特征后精度提高至小于2.8米；60米分辨率下，仅强度数据最佳RMSE为2.2米，使用所有合适特征时误差降至1.95米。

Conclusion: 结合强度数据和干涉相干特征的混合方法能显著提高L波段SAR森林高度反演精度，推荐用于NISAR和未来ROSE-L任务。

Abstract: In this study, we examine the potential of high-resolution forest mapping
using L-band interferometric time series datasets and deep learning modeling.
Our SAR data are represented by a time series of nine ALOS-2 PALSAR-2 dual-pol
SAR images acquired at near-zero spatial baseline over a study site in
Asturias, Northern Spain. Reference data are collected using airborne laser
scanning. We examine the performance of several candidate deep learning models
from UNet-family with various combinations of input polarimetric and
interferometric features. In addition to basic Vanilla UNet, attention
reinforced UNet model with squeeze-excitation blocks (SeU-Net) and advanced
UNet model with nested structure and skip pathways are used. Studied features
include dual pol interferometric observables additionally incorporating
model-based derived measures. Results show that adding model-based inverted
InSAR features or InSAR coherence layers improves retrieval accuracy compared
to using backscatter intensity only. Use of attention mechanisms and nested
connection fusion provides better predictions than using Vanilla UNet or
traditional machine learning methods. Forest height retrieval accuracies range
between 3.1-3.8 m (R2 = 0.45--0.55) at 20 m resolution when only intensity data
are used, and improve to less than 2.8 m when both intensity and
interferometric coherence features are included. At 40 m and 60 m resolution,
retrieval performance further improves, primarily due to higher SNR in both the
intensity and interferometric layers. When using intensity at 60 m resolution,
best achieved RMSE is 2.2 m, while when using all suitable input features the
achieved error is 1.95 m. We recommend this hybrid approach for L-band SAR
retrievals also suitable for NISAR and future ROSE-L missions.

</details>


### [12] [A Lightweight Framework for Integrated Sensing and Communications with RIS](https://arxiv.org/abs/2511.04448)
*Chu Li,Kevin Weinberger,Aydin Sezgin*

Main category: eess.SP

TL;DR: 提出了一种轻量级RIS相位设计框架，为6G网络中的集成感知与通信系统提供闭式解，平衡通信与感知性能，并支持多目标感知波束分布。


<details>
  <summary>Details</summary>
Motivation: 现有RIS优化方法主要基于半定松弛或迭代算法，前者计算复杂度高且扩展性差，后者产生依赖于初始化的次优解。需要一种更高效的方法来优化RIS配置。

Method: 将RIS配置分为两部分：第一部分最大化通信性能，第二部分引入小扰动为多目标感知生成多个波束，从而在通信和感知之间实现权衡。

Result: 仿真结果表明，所提方法有效且性能与SDR相当，但计算复杂度显著降低。

Conclusion: 该框架为RIS相位设计提供了高效的闭式解，能够平衡通信与感知性能，同时支持多目标感知，具有实际应用价值。

Abstract: Reconfigurable Intelligent Surfaces (RIS) have been recognized as a promising
technology to enhance both communication and sensing performance in integrated
sensing and communication (ISAC) systems for future 6G networks. However,
existing RIS optimization methods for improving ISAC performance are mainly
based on semidefinite relaxation (SDR) or iterative algorithms. The former
suffers from high computational complexity and limited scalability, especially
when the number of RIS elements becomes large, while the latter yields
suboptimal solutions whose performance depends on initialization. In this work,
we introduce a lightweight RIS phase design framework that provides a
closed-form solution and explicitly accounts for the trade-off between
communication and sensing, as well as proportional beam gain distribution
toward multiple sensing targets. The key idea is to partition the RIS
configuration into two parts: the first part is designed to maximize the
communication performance, while the second introduces small perturbations to
generate multiple beams for multi-target sensing. Simulation results validate
the effectiveness of the proposed approach and demonstrate that it achieves
performance comparable to SDR but with significantly lower computational
complexity.

</details>


### [13] [An Area-Efficient 20-100-GHz Phase-Invariant Switch-Type Attenuator Achieving 0.1-dB Tuning Step in 65-nm CMOS](https://arxiv.org/abs/2511.04635)
*Qingbin Li,Jian Pang*

Main category: eess.SP

TL;DR: 本文提出了一种工作在20-100 GHz的开关型衰减器，采用电容补偿技术减小相位误差，使用金属线实现小电阻以减少寄生电容，并采用连续调谐衰减单元提高衰减精度。


<details>
  <summary>Details</summary>
Motivation: 设计一种在20-100 GHz宽频带范围内具有低幅度和相位误差的衰减器，通过减小寄生电容和提高衰减精度来改善性能。

Method: 采用电容补偿技术减小相位误差，使用金属线实现小电阻以减少寄生电容，并采用连续调谐衰减单元提高衰减精度，基于标准65nm CMOS工艺设计制造。

Result: 测量结果显示相对衰减范围为7.5 dB，连续调谐步长在20-100 GHz内，插入损耗为1.6-3.8 dB，所有状态的反射损耗优于11.5 dB，RMS幅度和相位误差分别低于0.15 dB和1.6度。

Conclusion: 该衰减器在20-100 GHz频带内实现了良好的性能，具有低幅度和相位误差，适用于高频应用。

Abstract: This paper presents a switch-type attenuator working from 20 to 100 GHz. The
attenuator adopts a capacitive compensation technique to reduce phase error.
The small resistors in this work are implemented with metal lines to reduce the
intrinsic parasitic capacitance, which helps minimize the amplitude and phase
errors over a wide frequency range. Moreover, the utilization of metal lines
also reduces the chip area. In addition, a continuous tuning attenuation unit
is employed to improve the overall attenuation accuracy of the attenuator. The
passive attenuator is designed and fabricated in a standard 65nm CMOS. The
measurement results reveal a relative attenuation range of 7.5 dB with a
continuous tuning step within 20-100 GHz. The insertion loss is 1.6-3.8 dB
within the operation band, while the return losses of all states are better
than 11.5 dB. The RMS amplitude and phase errors are below 0.15 dB and
1.6{\deg}, respectively.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [Applying Time Series Deep Learning Models to Forecast the Growth of Perennial Ryegrass in Ireland](https://arxiv.org/abs/2511.03749)
*Oluwadurotimi Onibonoje,Vuong M. Ngo,Andrew McCarre,Elodie Ruelle,Bernadette O-Briend,Mark Roantree*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的模型来预测爱尔兰永久黑麦草的生长，使用时间卷积网络在34年历史数据上实现了高精度预测，为可持续乳业发展提供支持。


<details>
  <summary>Details</summary>
Motivation: 草地作为全球第二大碳汇对生物多样性和碳循环调节至关重要，爱尔兰乳业面临盈利性和可持续性挑战，当前基于机理模型的草生长预测方法不实用。

Method: 开发了针对单变量数据集的深度学习模型，特别是时间卷积网络，利用历史草高数据来预测永久黑麦草生长。

Result: 在科克地区预测永久黑麦草生长表现优异，RMSE为2.74，MAE为3.46，在34年1,757周的数据集上验证了最优模型配置。

Conclusion: 该研究提高了对模型行为的理解，增强了草生长预测的可靠性，有助于推进可持续乳业实践的发展。

Abstract: Grasslands, constituting the world's second-largest terrestrial carbon sink,
play a crucial role in biodiversity and the regulation of the carbon cycle.
Currently, the Irish dairy sector, a significant economic contributor, grapples
with challenges related to profitability and sustainability. Presently, grass
growth forecasting relies on impractical mechanistic models. In response, we
propose deep learning models tailored for univariate datasets, presenting
cost-effective alternatives. Notably, a temporal convolutional network designed
for forecasting Perennial Ryegrass growth in Cork exhibits high performance,
leveraging historical grass height data with RMSE of 2.74 and MAE of 3.46.
Validation across a comprehensive dataset spanning 1,757 weeks over 34 years
provides insights into optimal model configurations. This study enhances our
understanding of model behavior, thereby improving reliability in grass growth
forecasting and contributing to the advancement of sustainable dairy farming
practices.

</details>


### [15] [Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices](https://arxiv.org/abs/2511.03753)
*Youssef Elmir,Yassine Himeur,Abbes Amira*

Main category: cs.LG

TL;DR: 提出了一个基于联邦学习和Gramian角度场(GAF)的隐私保护ECG分类框架，将1D心电信号转换为2D图像进行CNN特征提取，在保护医疗数据隐私的同时实现高效分类。


<details>
  <summary>Details</summary>
Motivation: 解决物联网医疗环境中ECG数据分类的隐私保护问题，避免敏感医疗数据离开本地设备，同时实现高效的边缘计算部署。

Method: 将1D ECG信号转换为2D GAF图像，使用CNN进行特征提取，采用联邦学习框架在多设备间协同训练而不共享原始数据。

Result: 在多客户端设置下达到95.18%的分类准确率，显著优于单客户端基线，在服务器、笔记本电脑和资源受限的Raspberry Pi 4上均表现良好。

Conclusion: 该框架展示了轻量级、隐私保护的AI在物联网医疗监控中的潜力，支持可扩展且安全的边缘部署。

Abstract: This study presents a federated learning (FL) framework for
privacy-preserving electrocardiogram (ECG) classification in Internet of Things
(IoT) healthcare environments. By transforming 1D ECG signals into 2D Gramian
Angular Field (GAF) images, the proposed approach enables efficient feature
extraction through Convolutional Neural Networks (CNNs) while ensuring that
sensitive medical data remain local to each device. This work is among the
first to experimentally validate GAF-based federated ECG classification across
heterogeneous IoT devices, quantifying both performance and communication
efficiency. To evaluate feasibility in realistic IoT settings, we deployed the
framework across a server, a laptop, and a resource-constrained Raspberry Pi 4,
reflecting edge-cloud integration in IoT ecosystems. Experimental results
demonstrate that the FL-GAF model achieves a high classification accuracy of
95.18% in a multi-client setup, significantly outperforming a single-client
baseline in both accuracy and training time. Despite the added computational
complexity of GAF transformations, the framework maintains efficient resource
utilization and communication overhead. These findings highlight the potential
of lightweight, privacy-preserving AI for IoT-based healthcare monitoring,
supporting scalable and secure edge deployments in smart health systems.

</details>


### [16] [Laugh, Relate, Engage: Stylized Comment Generation for Short Videos](https://arxiv.org/abs/2511.03757)
*Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li*

Main category: cs.LG

TL;DR: LOLGORITHM是一个模块化多智能体系统，用于生成可控的短视频评论，支持六种不同风格，通过多模态大语言模型处理视频输入，在抖音和YouTube上获得超过87%的用户偏好率。


<details>
  <summary>Details</summary>
Motivation: 短视频平台中，评论在促进社区参与和内容再创作方面起着重要作用，但生成既符合平台规范又具有风格多样性和上下文感知的评论仍然是一个重大挑战。

Method: 采用模块化多智能体系统，集成视频分割、上下文和情感分析、风格感知提示构建，支持六种评论风格：双关语、押韵、表情包应用、讽刺、普通幽默和内容提取，使用多模态大语言模型直接处理视频输入。

Result: 在抖音和YouTube上分别获得超过90%和87.55%的用户偏好率，显著优于基线模型。

Conclusion: 该工作为短视频平台上的风格化评论生成提供了一个可扩展和文化适应的框架，为增强用户参与度和创意互动提供了有前景的路径。

Abstract: Short-video platforms have become a central medium in the modern Internet
landscape, where efficient information delivery and strong interactivity are
reshaping user engagement and cultural dissemination. Among the various forms
of user interaction, comments play a vital role in fostering community
participation and enabling content re-creation. However, generating comments
that are both compliant with platform guidelines and capable of exhibiting
stylistic diversity and contextual awareness remains a significant challenge.
We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for
controllable short-video comment generation. The system integrates video
segmentation, contextual and affective analysis, and style-aware prompt
construction. It supports six distinct comment styles: puns (homophones),
rhyming, meme application, sarcasm (irony), plain humor, and content
extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM
directly processes video inputs and achieves fine-grained style control through
explicit prompt markers and few-shot examples. To support development and
evaluation, we construct a bilingual dataset using official APIs from Douyin
(Chinese) and YouTube (English), covering five popular video genres: comedy
skits, daily life jokes, funny animal clips, humorous commentary, and talk
shows. Evaluation combines automated metrics originality, relevance, and style
conformity with a large-scale human preference study involving 40 videos and
105 participants. Results show that LOLGORITHM significantly outperforms
baseline models, achieving preference rates of over 90% on Douyin and 87.55% on
YouTube. This work presents a scalable and culturally adaptive framework for
stylized comment generation on short-video platforms, offering a promising path
to enhance user engagement and creative interaction.

</details>


### [17] [What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes](https://arxiv.org/abs/2511.03768)
*Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim*

Main category: cs.LG

TL;DR: 提出了一个名为Common-O的新基准测试，专门评估多模态语言模型在真实场景中的推理能力，发现即使是最佳模型在跨场景推理方面表现也很差，存在严重的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型在感知基准测试上表现良好，但在真实世界场景推理时仍存在幻觉问题，这揭示了模型感知能力与真实推理能力之间的差距。

Method: 构建了包含10,500多个示例的Common-O基准测试，使用网络训练数据中未出现过的新图像，通过"共同点是什么"的问题来评估跨场景推理能力。

Result: 最佳模型在Common-O上仅达到35%准确率，在更复杂的Common-O Complex上仅为1%。模型在场景中存在相似物体时更容易产生幻觉，表明模型可能过度依赖训练数据中的物体共现模式。

Conclusion: 多模态模型在跨场景推理方面仍面临重大挑战，需要更多关注多图像训练和减少幻觉的研究。

Abstract: Multimodal language models possess a remarkable ability to handle an
open-vocabulary's worth of objects. Yet the best models still suffer from
hallucinations when reasoning about scenes in the real world, revealing a gap
between their seemingly strong performance on existing perception benchmarks
that are saturating and their reasoning in the real world. To address this gap,
we build a novel benchmark of in-the-wild scenes that we call Common-O. With
more than 10.5k examples using exclusively new images not found in web training
data to avoid contamination, Common-O goes beyond just perception, inspired by
cognitive tests for humans, to probe reasoning across scenes by asking "what's
in common?". We evaluate leading multimodal language models, including models
specifically trained to perform chain-of-thought reasoning. We find that
perceiving objects in single images is tractable for most models, yet reasoning
across scenes is very challenging even for the best models, including reasoning
models. Despite saturating many leaderboards focusing on perception, the best
performing model only achieves 35% on Common-O -- and on Common-O Complex,
consisting of more complex scenes, the best model achieves only 1%. Curiously,
we find models are more prone to hallucinate when similar objects are present
in the scene, suggesting models may be relying on object co-occurrence seen
during training. Among the models we evaluated, we found scale can provide
modest improvements while models explicitly trained with multi-image inputs
show bigger improvements, suggesting scaled multi-image training may offer
promise. We make our benchmark publicly available to spur research into the
challenge of hallucination when reasoning across scenes.

</details>


### [18] [Contamination Detection for VLMs using Multi-Modal Semantic Perturbation](https://arxiv.org/abs/2511.03774)
*Jaden Park,Mu Cai,Feng Yao,Jingbo Shang,Soochahn Lee,Yong Jae Lee*

Main category: cs.LG

TL;DR: 本文提出了一种基于多模态语义扰动的检测方法，用于识别因测试集泄露而受到污染的视觉语言模型，该方法在多种污染策略下都表现出鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型在众多基准任务上取得先进性能，使用互联网规模且通常为专有的预训练语料库引发了测试集泄露导致性能虚高的问题。现有针对LLM的去污染和基准重设计方法在VLM污染检测方面研究不足。

Method: 作者首先故意污染开源VLM模型，然后提出基于多模态语义扰动的检测方法，通过控制性扰动来验证污染模型无法泛化的特性。

Result: 实验表明现有检测方法要么完全失败，要么表现不一致，而提出的多模态语义扰动方法在多种现实污染策略下都能有效检测污染模型。

Conclusion: 该研究填补了VLM污染检测方法的空白，提出的检测方法简单有效，能够可靠识别因测试集泄露而受到污染的视觉语言模型。

Abstract: Recent advances in Vision-Language Models (VLMs) have achieved
state-of-the-art performance on numerous benchmark tasks. However, the use of
internet-scale, often proprietary, pretraining corpora raises a critical
concern for both practitioners and users: inflated performance due to test-set
leakage. While prior works have proposed mitigation strategies such as
decontamination of pretraining data and benchmark redesign for LLMs, the
complementary direction of developing detection methods for contaminated VLMs
remains underexplored. To address this gap, we deliberately contaminate
open-source VLMs on popular benchmarks and show that existing detection
approaches either fail outright or exhibit inconsistent behavior. We then
propose a novel simple yet effective detection method based on multi-modal
semantic perturbation, demonstrating that contaminated models fail to
generalize under controlled perturbations. Finally, we validate our approach
across multiple realistic contamination strategies, confirming its robustness
and effectiveness. The code and perturbed dataset will be released publicly.

</details>


### [19] [FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features](https://arxiv.org/abs/2511.03806)
*Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong*

Main category: cs.LG

TL;DR: FusionDP是一个特征级差分隐私框架，通过使用基础模型对敏感特征进行估算，在保护隐私的同时显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统DP-SGD对所有特征统一施加隐私保护，导致过度噪声注入和模型性能下降。现实中只有部分敏感特征需要隐私保护，非敏感特征可以更自由地使用。

Method: 1) 使用大型基础模型基于非敏感特征估算敏感特征，作为外部先验；2) 改进的DP-SGD算法，在原始特征和估算特征上训练模型，同时严格保护原始敏感特征的隐私。

Result: 在PhysioNet脓毒症预测和MIMIC-III临床笔记分类任务上的实验表明，FusionDP相比隐私保护基线显著提升了模型性能，同时保持了严格的特征级隐私保护。

Conclusion: FusionDP通过基础模型驱动的估算方法，有效改善了隐私-效用权衡，适用于多种模态的数据处理。

Abstract: Ensuring the privacy of sensitive training data is crucial in
privacy-preserving machine learning. However, in practical scenarios, privacy
protection may be required for only a subset of features. For instance, in ICU
data, demographic attributes like age and gender pose higher privacy risks due
to their re-identification potential, whereas raw lab results are generally
less sensitive. Traditional DP-SGD enforces privacy protection on all features
in one sample, leading to excessive noise injection and significant utility
degradation. We propose FusionDP, a two-step framework that enhances model
utility under feature-level differential privacy. First, FusionDP leverages
large foundation models to impute sensitive features given non-sensitive
features, treating them as external priors that provide high-quality estimates
of sensitive attributes without accessing the true values during model
training. Second, we introduce a modified DP-SGD algorithm that trains models
on both original and imputed features while formally preserving the privacy of
the original sensitive features. We evaluate FusionDP on two modalities: a
sepsis prediction task on tabular data from PhysioNet and a clinical note
classification task from MIMIC-III. By comparing against privacy-preserving
baselines, our results show that FusionDP significantly improves model
performance while maintaining rigorous feature-level privacy, demonstrating the
potential of foundation model-driven imputation to enhance the privacy-utility
trade-off for various modalities.

</details>


### [20] [Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations](https://arxiv.org/abs/2511.03807)
*Shivogo John*

Main category: cs.LG

TL;DR: 该研究开发了自适应解释框架来解决信用评分系统中概念漂移导致的解释不稳定和不公平问题，通过三种自适应SHAP变体显著提高了时间稳定性和公平性。


<details>
  <summary>Details</summary>
Motivation: 传统可解释性技术（如SHAP）假设静态数据和固定背景分布，在概念漂移发生时其解释会变得不稳定且可能不公平，需要开发能够适应动态演变的信用模型的自适应解释框架。

Method: 使用多年信用数据集，将XGBoost预测建模与三种自适应SHAP变体结合：A）针对特征分布漂移的切片解释重加权，B）使用滑动窗口背景样本的漂移感知SHAP重新基线化，C）使用增量岭回归的在线代理校准。

Result: 自适应方法特别是重新基线化和基于代理的解释，在不降低预测准确性的情况下显著提高了时间稳定性，并减少了跨人口群体的差异性影响。

Conclusion: 自适应可解释性是在数据驱动的信用系统中维持透明度、问责制和伦理可靠性的实用机制，适用于任何决策模型随人口变化而演变的领域。

Abstract: Evolving borrower behaviors, shifting economic conditions, and changing
regulatory landscapes continuously reshape the data distributions underlying
modern credit-scoring systems. Conventional explainability techniques, such as
SHAP, assume static data and fixed background distributions, making their
explanations unstable and potentially unfair when concept drift occurs. This
study addresses that challenge by developing adaptive explanation frameworks
that recalibrate interpretability and fairness in dynamically evolving credit
models. Using a multi-year credit dataset, we integrate predictive modeling via
XGBoost with three adaptive SHAP variants: (A) per-slice explanation
reweighting that adjusts for feature distribution shifts, (B) drift-aware SHAP
rebaselining with sliding-window background samples, and (C) online surrogate
calibration using incremental Ridge regression. Each method is benchmarked
against static SHAP explanations using metrics of predictive performance (AUC,
F1), directional and rank stability (cosine, Kendall tau), and fairness
(demographic parity and recalibration). Results show that adaptive methods,
particularly rebaselined and surrogate-based explanations, substantially
improve temporal stability and reduce disparate impact across demographic
groups without degrading predictive accuracy. Robustness tests, including
counterfactual perturbations, background sensitivity analysis, and
proxy-variable detection, confirm the resilience of adaptive explanations under
real-world drift conditions. These findings establish adaptive explainability
as a practical mechanism for sustaining transparency, accountability, and
ethical reliability in data-driven credit systems, and more broadly, in any
domain where decision models evolve with population change.

</details>


### [21] [Optimizing Reasoning Efficiency through Prompt Difficulty Prediction](https://arxiv.org/abs/2511.03808)
*Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata*

Main category: cs.LG

TL;DR: 提出一种路由方法，将问题分配给最可能解决它的最小模型，在保持准确性的同时减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型在复杂任务上表现良好，但由于模型规模和长推理轨迹导致部署成本高昂。

Method: 使用s1.1-32B的中间表示训练轻量级预测器，预测问题难度或模型正确性，以指导在推理模型池中的路由分配。

Result: 在多样化数学基准测试中，路由方法相比随机分配提高了效率，匹配s1.1-32B的性能同时显著减少计算量。

Conclusion: 难度感知路由对于推理模型的成本高效部署是有效的。

Abstract: Reasoning language models perform well on complex tasks but are costly to
deploy due to their size and long reasoning traces. We propose a routing
approach that assigns each problem to the smallest model likely to solve it,
reducing compute without sacrificing accuracy. Using intermediate
representations from s1.1-32B, we train lightweight predictors of problem
difficulty or model correctness to guide routing across a pool of reasoning
models. On diverse math benchmarks, routing improves efficiency over random
assignment and matches s1.1-32B's performance while using significantly less
compute. Our results demonstrate that difficulty-aware routing is effective for
cost-efficient deployment of reasoning models.

</details>


### [22] [One Size Does Not Fit All: Architecture-Aware Adaptive Batch Scheduling with DEBA](https://arxiv.org/abs/2511.03809)
*François Belias,Naser Ezzati-Jivan,Foutse Khomh*

Main category: cs.LG

TL;DR: DEBA是一种自适应批量大小调度器，通过监测梯度方差、梯度范数变化和损失变化来指导批量大小调整。研究发现架构特性决定适应效果，轻量级架构获得显著加速和精度提升，而稳定架构获益有限。


<details>
  <summary>Details</summary>
Motivation: 现有自适应批量大小方法对所有架构采用相同的适应策略，假设存在通用解决方案。本研究挑战这一假设，探索架构特性如何影响自适应批量大小方法的有效性。

Method: 提出DEBA自适应批量调度器，监测梯度方差、梯度范数变化和损失变化。在6种架构上系统评估，使用梯度稳定性指标（稳定性分数、梯度范数变化）预测架构获益情况。

Result: 轻量级和中深度架构获得45-62%训练加速和1-7%精度提升；浅层残差网络精度提升2.4-4.0%，加速36-43%；深层残差网络表现高方差；稳定架构仅6%加速。滑动窗口统计和充分冷却期是关键设计选择。

Conclusion: 自适应批量大小方法不能通用化，需要架构感知设计。架构的基线优化特性决定了自适应调度的获益程度。

Abstract: Adaptive batch size methods aim to accelerate neural network training, but
existing approaches apply identical adaptation strategies across all
architectures, assuming a one-size-fits-all solution. We introduce DEBA
(Dynamic Efficient Batch Adaptation), an adaptive batch scheduler that monitors
gradient variance, gradient norm variation and loss variation to guide batch
size adaptations. Through systematic evaluation across six architectures
(ResNet-18/50, DenseNet-121, EfficientNet-B0, MobileNet-V3, ViT-B16) on
CIFAR-10 and CIFAR-100, with five random seeds per configuration, we
demonstrate that the architecture fundamentally determines adaptation efficacy.
Our findings reveal that: (1) lightweight and medium-depth architectures
(MobileNet-V3, DenseNet-121, EfficientNet-B0) achieve a 45-62% training speedup
with simultaneous accuracy improvements of 1-7%; (2) shallow residual networks
(ResNet-18) show consistent gains of +2.4 - 4.0% in accuracy, 36 - 43% in
speedup, while deep residual networks (ResNet-50) exhibit high variance and
occasional degradation; (3) already-stable architectures (ViT-B16) show minimal
speedup (6%) despite maintaining accuracy, indicating that adaptation benefits
vary with baseline optimization characteristics. We introduce a baseline
characterization framework using gradient stability metrics (stability score,
gradient norm variation) that predicts which architectures will benefit from
adaptive scheduling. Our ablation studies reveal critical design choices often
overlooked in prior work: sliding window statistics (vs. full history) and
sufficient cooldown periods (5+ epochs) between adaptations are essential for
success. This work challenges the prevailing assumption that adaptive methods
generalize across architectures and provides the first systematic evidence that
batch size adaptation requires an architecture-aware design.

</details>


### [23] [Sketch-Augmented Features Improve Learning Long-Range Dependencies in Graph Neural Networks](https://arxiv.org/abs/2511.03824)
*Ryien Hosseini,Filippo Simini,Venkatram Vishwanath,Rebecca Willett,Henry Hoffmann*

Main category: cs.LG

TL;DR: 提出了一种名为"草图随机特征"的方法，通过向标准GNN注入随机化的全局节点特征嵌入，有效解决了GNN中的长距离信息压缩、节点表示过度平滑和表达能力有限等问题。


<details>
  <summary>Details</summary>
Motivation: 图神经网络通过局部消息传递聚合邻居信息，但面临三个关键挑战：(i)长距离信息压缩，(ii)节点表示过度平滑，(iii)表达能力有限。需要一种方法来有效捕获长距离依赖关系。

Method: 向标准GNN注入随机化的全局节点特征嵌入（称为草图随机特征）。这些嵌入具有唯一性、距离敏感性和拓扑无关性，能够高效捕获长距离依赖。

Result: 实验结果表明，该方法在真实世界图学习任务中持续优于基线GNN，既可以作为独立解决方案，也可以作为现有技术（如图位置编码）的补充增强。

Conclusion: 草图随机特征方法有效缓解了GNN的三大限制，提供了捕获长距离依赖的高效解决方案，且与现有技术兼容互补。

Abstract: Graph Neural Networks learn on graph-structured data by iteratively
aggregating local neighborhood information. While this local message passing
paradigm imparts a powerful inductive bias and exploits graph sparsity, it also
yields three key challenges: (i) oversquashing of long-range information, (ii)
oversmoothing of node representations, and (iii) limited expressive power. In
this work we inject randomized global embeddings of node features, which we
term \textit{Sketched Random Features}, into standard GNNs, enabling them to
efficiently capture long-range dependencies. The embeddings are unique,
distance-sensitive, and topology-agnostic -- properties which we analytically
and empirically show alleviate the aforementioned limitations when injected
into GNNs. Experimental results on real-world graph learning tasks confirm that
this strategy consistently improves performance over baseline GNNs, offering
both a standalone solution and a complementary enhancement to existing
techniques such as graph positional encodings. Our source code is available at
\href{https://github.com/ryienh/sketched-random-features}{https://github.com/ryienh/sketched-random-features}.

</details>


### [24] [Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels](https://arxiv.org/abs/2511.03953)
*Wuxia Chen,Taposh Banerjee,Vahid Tarokh*

Main category: cs.LG

TL;DR: 提出了一种基于条件分数学习的马尔可夫过程快速变化检测方法，避免显式似然计算，适用于高维数据。


<details>
  <summary>Details</summary>
Motivation: 解决马尔可夫过程中未知转移核的快速变化检测问题，特别是在高维数据场景下避免复杂的似然计算。

Method: 直接从样本对学习条件分数，基于此开发分数CUSUM程序，使用条件Hyvarinen分数差异检测核变化，并提出截断统计量确保有界增量。

Result: 证明了均匀遍历马尔可夫过程的误报时间指数下界和检测延迟的渐近上界，为高维马尔可夫模型中的分数检测提供了理论保证。

Conclusion: 该方法为高维马尔可夫模型中的变化检测提供了理论保证和实际可行性，避免了显式似然评估的复杂性。

Abstract: We address the problem of quickest change detection in Markov processes with
unknown transition kernels. The key idea is to learn the conditional score
$\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$ directly from sample pairs
$( \mathbf{x},\mathbf{y})$, where both $\mathbf{x}$ and $\mathbf{y}$ are
high-dimensional data generated by the same transition kernel. In this way, we
avoid explicit likelihood evaluation and provide a practical way to learn the
transition dynamics. Based on this estimation, we develop a score-based CUSUM
procedure that uses conditional Hyvarinen score differences to detect changes
in the kernel. To ensure bounded increments, we propose a truncated version of
the statistic. With Hoeffding's inequality for uniformly ergodic Markov
processes, we prove exponential lower bounds on the mean time to false alarm.
We also prove asymptotic upper bounds on detection delay. These results give
both theoretical guarantees and practical feasibility for score-based detection
in high-dimensional Markov models.

</details>


### [25] [From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification](https://arxiv.org/abs/2511.03828)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为StratDiff的创新方法，通过能量引导扩散分层技术解决离线到在线强化学习中的分布偏移问题，显著提升了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 离线到在线强化学习存在关键挑战，即固定行为策略与在线学习演化策略之间的分布偏移。现有方法很少明确评估或利用离线数据本身的分布结构，存在适应不同样本类型的学习策略研究空白。

Method: StratDiff部署扩散模型从离线数据集中学习先验知识，通过基于能量的函数改进策略模仿，并在在线微调期间生成离线类动作。计算生成动作与采样动作之间的KL散度，将训练批次分层为离线类和在线类子集，分别采用不同的学习策略。

Result: 在D4RL基准测试上的广泛实证评估表明，StratDiff与Cal-QL和IQL等现成方法集成后，显著优于现有方法，实现了增强的适应性和更稳定的性能。

Conclusion: StratDiff通过显式利用离线数据的分布结构，为离线到在线强化学习提供了有效的解决方案，能够更平滑地处理分布偏移问题。

Abstract: Transitioning from offline to online reinforcement learning (RL) poses
critical challenges due to distributional shifts between the fixed behavior
policy in the offline dataset and the evolving policy during online learning.
Although this issue is widely recognized, few methods attempt to explicitly
assess or utilize the distributional structure of the offline data itself,
leaving a research gap in adapting learning strategies to different types of
samples. To address this challenge, we propose an innovative method,
Energy-Guided Diffusion Stratification (StratDiff), which facilitates smoother
transitions in offline-to-online RL. StratDiff deploys a diffusion model to
learn prior knowledge from the offline dataset. It then refines this knowledge
through energy-based functions to improve policy imitation and generate
offline-like actions during online fine-tuning. The KL divergence between the
generated action and the corresponding sampled action is computed for each
sample and used to stratify the training batch into offline-like and
online-like subsets. Offline-like samples are updated using offline objectives,
while online-like samples follow online learning strategies. We demonstrate the
effectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL
and IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff
significantly outperforms existing methods, achieving enhanced adaptability and
more stable performance across diverse RL settings.

</details>


### [26] [Higher-Order Causal Structure Learning with Additive Models](https://arxiv.org/abs/2511.03831)
*James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang*

Main category: cs.LG

TL;DR: 本文扩展了因果加性模型(CAM)以处理高阶交互作用，引入了有向无环超图来表示这种结构，提供了可识别性结果，并开发了相应的学习算法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多过程都表现出高阶机制，但因果发现中对交互作用的显式处理很少受到关注。本文旨在将因果加性模型扩展到包含高阶交互作用的加性模型。

Method: 扩展因果加性模型(CAM)到具有高阶交互作用的加性模型，使用有向无环超图表示结构，提供理论工具和可识别性结果，并开发了贪婪CAM算法的扩展版本。

Result: 证明了更复杂的超图结构可能导致更好的实证结果，更严格的假设对应更易学习的超DAG和更好的有限样本复杂度。在合成实验中展示了算法的实用性。

Conclusion: 通过引入有向无环超图来扩展因果加性模型，能够有效处理高阶交互作用，在理论和实证层面都取得了积极成果，为因果结构学习提供了新的框架。

Abstract: Causal structure learning has long been the central task of inferring causal
insights from data. Despite the abundance of real-world processes exhibiting
higher-order mechanisms, however, an explicit treatment of interactions in
causal discovery has received little attention. In this work, we focus on
extending the causal additive model (CAM) to additive models with higher-order
interactions. This second level of modularity we introduce to the structure
learning problem is most easily represented by a directed acyclic hypergraph
which extends the DAG. We introduce the necessary definitions and theoretical
tools to handle the novel structure we introduce and then provide
identifiability results for the hyper DAG, extending the typical Markov
equivalence classes. We next provide insights into why learning the more
complex hypergraph structure may actually lead to better empirical results. In
particular, more restrictive assumptions like CAM correspond to easier-to-learn
hyper DAGs and better finite sample complexity. We finally develop an extension
of the greedy CAM algorithm which can handle the more complex hyper DAG search
space and demonstrate its empirical usefulness in synthetic experiments.

</details>


### [27] [Enhancing Q-Value Updates in Deep Q-Learning via Successor-State Prediction](https://arxiv.org/abs/2511.03836)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 提出了SADQ方法，通过显式建模环境动态和使用后继状态分布来改进DQN，解决了传统DQN中目标更新依赖过时策略导致的方差问题。


<details>
  <summary>Details</summary>
Motivation: 传统DQN的目标更新依赖从回放缓冲区采样的转换，这些转换可能来自过时且次优的策略，导致学习信号不具信息性，增加了更新过程的方差。

Method: SADQ使用随机转移模型显式建模环境动态，将后继状态分布集成到Q值估计过程中，实现更稳定和策略对齐的值更新，并探索基于建模转移结构的更高效动作选择策略。

Result: 理论证明SADQ保持无偏值估计同时减少训练方差，在标准RL基准和现实世界向量控制任务中，SADQ在稳定性和学习效率方面持续优于DQN变体。

Conclusion: SADQ通过显式建模环境动态和集成后继状态分布，有效解决了DQN中的策略不对齐问题，提供了更稳定和高效的强化学习框架。

Abstract: Deep Q-Networks (DQNs) estimate future returns by learning from transitions
sampled from a replay buffer. However, the target updates in DQN often rely on
next states generated by actions from past, potentially suboptimal, policy. As
a result, these states may not provide informative learning signals, causing
high variance into the update process. This issue is exacerbated when the
sampled transitions are poorly aligned with the agent's current policy. To
address this limitation, we propose the Successor-state Aggregation Deep
Q-Network (SADQ), which explicitly models environment dynamics using a
stochastic transition model. SADQ integrates successor-state distributions into
the Q-value estimation process, enabling more stable and policy-aligned value
updates. Additionally, it explores a more efficient action selection strategy
with the modeled transition structure. We provide theoretical guarantees that
SADQ maintains unbiased value estimates while reducing training variance. Our
extensive empirical results across standard RL benchmarks and real-world
vector-based control tasks demonstrate that SADQ consistently outperforms DQN
variants in both stability and learning efficiency.

</details>


### [28] [Benchmark Datasets for Lead-Lag Forecasting on Social Platforms](https://arxiv.org/abs/2511.03877)
*Kimia Kazemian,Zhenzhen Liu,Yangfanyu Yang,Katie Z Luo,Shuhan Gu,Audrey Du,Xinyu Yang,Jack Jansons,Kilian Q Weinberger,John Thickstun,Yian Yin,Sarah Dean*

Main category: cs.LG

TL;DR: 本文提出了领先-滞后预测（LLF）这一新的预测范式，旨在通过早期使用渠道（领先）来预测相关但时间上滞后的结果渠道（滞后），并提供了arXiv和GitHub两个大规模基准数据集。


<details>
  <summary>Details</summary>
Motivation: 社交和协作平台产生多元时间序列数据，其中早期互动（如浏览、点赞）往往在数月或数年后才产生更高影响力的结果（如引用、销售）。虽然这种模式普遍存在，但由于缺乏标准化数据集，LLF尚未被时间序列社区视为统一的预测问题。

Method: 构建了两个高容量基准数据集：arXiv（230万篇论文的访问量→引用量）和GitHub（300万个仓库的推送/星标→分支数），并概述了其他具有类似领先-滞后动态的领域。通过统计和分类测试验证了领先-滞后动态的存在，并对回归的参数和非参数基线进行了基准测试。

Result: 研究证实了领先-滞后动态的存在，数据集捕捉了跨年度的长期动态，涵盖了完整的结果谱，并避免了抽样中的生存偏差。

Conclusion: 本研究确立了LLF作为一种新颖的预测范式，并为在社交和使用数据中系统探索LLF奠定了实证基础。

Abstract: Social and collaborative platforms emit multivariate time-series traces in
which early interactions-such as views, likes, or downloads-are followed,
sometimes months or years later, by higher impact like citations, sales, or
reviews. We formalize this setting as Lead-Lag Forecasting (LLF): given an
early usage channel (the lead), predict a correlated but temporally shifted
outcome channel (the lag). Despite the ubiquity of such patterns, LLF has not
been treated as a unified forecasting problem within the time-series community,
largely due to the absence of standardized datasets. To anchor research in LLF,
here we present two high-volume benchmark datasets-arXiv (accesses -> citations
of 2.3M papers) and GitHub (pushes/stars -> forks of 3M repositories)-and
outline additional domains with analogous lead-lag dynamics, including
Wikipedia (page views -> edits), Spotify (streams -> concert attendance),
e-commerce (click-throughs -> purchases), and LinkedIn profile (views ->
messages). Our datasets provide ideal testbeds for lead-lag forecasting, by
capturing long-horizon dynamics across years, spanning the full spectrum of
outcomes, and avoiding survivorship bias in sampling. We documented all
technical details of data curation and cleaning, verified the presence of
lead-lag dynamics through statistical and classification tests, and benchmarked
parametric and non-parametric baselines for regression. Our study establishes
LLF as a novel forecasting paradigm and lays an empirical foundation for its
systematic exploration in social and usage data. Our data portal with downloads
and documentation is available at https://lead-lag-forecasting.github.io/.

</details>


### [29] [DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory Budgets](https://arxiv.org/abs/2511.03911)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Mohsen Imani*

Main category: cs.LG

TL;DR: Decomposition-based compression method for hyperdimensional computing (HDC) that learns directly in decomposed parameterization, achieving extreme memory savings with minimal accuracy loss.


<details>
  <summary>Details</summary>
Motivation: Traditional HDC compression methods shrink the feature axis and degrade performance. Prior decompositions use fixed atomic hypervectors that are unsuitable for compressing learned class prototypes.

Method: Introduces DecoHD which learns in decomposed HDC parameterization using small shared per-layer channels with multiplicative binding across layers and bundling at the end. Compresses along class axis via lightweight bundling head while preserving native bind-bundle-score operations.

Result: Achieves extreme memory savings within 0.1-0.15% accuracy of baseline (worst case 5.7%), more robust to noise, reaches accuracy plateau with ~97% fewer parameters, and delivers significant energy/speed gains: 277x/35x over CPU, 13.5x/3.7x over GPU, 2.0x/2.4x over baseline HDC ASIC.

Conclusion: Decomposition is an effective approach for compressing HDC models while maintaining performance and enabling efficient hardware deployment.

Abstract: Decomposition is a proven way to shrink deep networks without changing I/O.
We bring this idea to hyperdimensional computing (HDC), where footprint cuts
usually shrink the feature axis and erode concentration and robustness. Prior
HDC decompositions decode via fixed atomic hypervectors, which are ill-suited
for compressing learned class prototypes. We introduce DecoHD, which learns
directly in a decomposed HDC parameterization: a small, shared set of per-layer
channels with multiplicative binding across layers and bundling at the end,
yielding a large representational space from compact factors. DecoHD compresses
along the class axis via a lightweight bundling head while preserving native
bind-bundle-score; training is end-to-end, and inference remains pure HDC,
aligning with in/near-memory accelerators. In evaluation, DecoHD attains
extreme memory savings with only minor accuracy degradation under tight
deployment budgets. On average it stays within about 0.1-0.15% of a strong
non-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip
noise, reaches its accuracy plateau with up to ~97% fewer trainable parameters,
and -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU
(AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x
over a baseline HDC ASIC.

</details>


### [30] [Non-Asymptotic Optimization and Generalization Bounds for Stochastic Gauss-Newton in Overparameterized Models](https://arxiv.org/abs/2511.03972)
*Semih Cayci*

Main category: cs.LG

TL;DR: 该论文分析了随机高斯-牛顿方法在过参数化深度神经网络训练中的收敛性和泛化性能，建立了有限时间收敛界和泛化界，揭示了曲率、批大小和过参数化对泛化的影响。


<details>
  <summary>Details</summary>
Motivation: 研究高阶优化方法如何影响深度学习中的泛化性能，特别关注随机高斯-牛顿方法在过参数化深度神经网络中的表现。

Method: 使用带Levenberg-Marquardt阻尼和mini-batch采样的随机高斯-牛顿方法，在回归设置中训练具有平滑激活函数的过参数化深度神经网络，通过变量度量分析和均匀稳定性理论进行分析。

Result: 建立了有限时间收敛界，明确依赖于批大小、网络宽度和深度；推导了非渐近泛化界，识别了高斯-牛顿矩阵最小特征值较大时的有利泛化机制。

Conclusion: 随机高斯-牛顿方法在过参数化深度神经网络中具有良好的收敛性和泛化性能，曲率信息、批大小和过参数化程度共同影响泛化表现。

Abstract: An important question in deep learning is how higher-order optimization
methods affect generalization. In this work, we analyze a stochastic
Gauss-Newton (SGN) method with Levenberg-Marquardt damping and mini-batch
sampling for training overparameterized deep neural networks with smooth
activations in a regression setting. Our theoretical contributions are twofold.
First, we establish finite-time convergence bounds via a variable-metric
analysis in parameter space, with explicit dependencies on the batch size,
network width and depth. Second, we derive non-asymptotic generalization bounds
for SGN using uniform stability in the overparameterized regime, characterizing
the impact of curvature, batch size, and overparameterization on generalization
performance. Our theoretical results identify a favorable generalization regime
for SGN in which a larger minimum eigenvalue of the Gauss-Newton matrix along
the optimization path yields tighter stability bounds.

</details>


### [31] [On Predicting Sociodemographics from Mobility Signals](https://arxiv.org/abs/2511.03924)
*Ekin Uğurel,Cynthia Chen,Brian H. Y. Lee,Filipe Rodrigues*

Main category: cs.LG

TL;DR: 该论文提出了一种基于有向移动图的行为驱动高阶移动描述符，结合多任务学习框架，从移动数据中预测社会人口属性，提高了预测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 从移动数据推断社会人口属性有助于交通规划，但由于移动模式与社会人口特征关系弱且不一致，以及跨情境泛化能力有限，该任务仍具挑战性。

Method: 1) 引入基于有向移动图的行为驱动高阶移动描述符；2) 开发评估模型置信度与准确性均匀性的指标和可视化工具；3) 构建多任务学习框架，从共享表示中联合预测多个社会人口属性。

Result: 新特征显著提高了年龄、性别、收入和家庭结构预测的准确性；多任务学习框架在训练数据有限或测试集分布与训练集不同时，表现优于单任务模型。

Conclusion: 该方法通过行为驱动特征和多任务学习，有效解决了从移动数据预测社会人口属性的准确性和泛化问题，为交通规划提供了可靠工具。

Abstract: Inferring sociodemographic attributes from mobility data could help
transportation planners better leverage passively collected datasets, but this
task remains difficult due to weak and inconsistent relationships between
mobility patterns and sociodemographic traits, as well as limited
generalization across contexts. We address these challenges from three angles.
First, to improve predictive accuracy while retaining interpretability, we
introduce a behaviorally grounded set of higher-order mobility descriptors
based on directed mobility graphs. These features capture structured patterns
in trip sequences, travel modes, and social co-travel, and significantly
improve prediction of age, gender, income, and household structure over
baselines features. Second, we introduce metrics and visual diagnostic tools
that encourage evenness between model confidence and accuracy, enabling
planners to quantify uncertainty. Third, to improve generalization and sample
efficiency, we develop a multitask learning framework that jointly predicts
multiple sociodemographic attributes from a shared representation. This
approach outperforms single-task models, particularly when training data are
limited or when applying models across different time periods (i.e., when the
test set distribution differs from the training set).

</details>


### [32] [Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations](https://arxiv.org/abs/2511.04000)
*Kyaw Hpone Myint,Zhe Wu,Alexandre G. R. Day,Giri Iyengar*

Main category: cs.LG

TL;DR: 提出一种高效生成合成预训练数据的方法，用于决策树的元学习，性能接近真实数据预训练但计算成本显著降低。


<details>
  <summary>Details</summary>
Motivation: 决策树在金融和医疗等高风险领域广泛应用，但传统方法训练成本高且数据获取困难，需要更高效的元学习方法。

Method: 通过采样近似最优决策树生成大规模合成数据集，使用MetaTree transformer架构进行元学习。

Result: 该方法性能与真实数据预训练相当，但计算成本大幅降低，数据生成灵活性增强。

Conclusion: 该方法为可解释决策树模型的规模化高效元学习开辟了新途径。

Abstract: Decision trees are widely used in high-stakes fields like finance and
healthcare due to their interpretability. This work introduces an efficient,
scalable method for generating synthetic pre-training data to enable
meta-learning of decision trees. Our approach samples near-optimal decision
trees synthetically, creating large-scale, realistic datasets. Using the
MetaTree transformer architecture, we demonstrate that this method achieves
performance comparable to pre-training on real-world data or with
computationally expensive optimal decision trees. This strategy significantly
reduces computational costs, enhances data generation flexibility, and paves
the way for scalable and efficient meta-learning of interpretable decision tree
models.

</details>


### [33] [SynQuE: Estimating Synthetic Dataset Quality Without Annotations](https://arxiv.org/abs/2511.03928)
*Arthur Chen,Victor Zhong*

Main category: cs.LG

TL;DR: 提出了SynQuE问题：使用有限的无标注真实数据来评估合成数据集的质量，并建立了首个综合基准。提出了LENS代理指标，在复杂任务上表现优异，能显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决在数据稀缺（收集成本高或隐私限制）情况下，如何有效选择和评估合成数据集质量的开放性问题。

Method: 1) 建立SynQuE问题框架和基准；2) 引入基于分布和多样性的距离度量代理指标；3) 提出LENS代理指标，利用大语言模型推理能力处理复杂规划任务。

Result: SynQuE代理指标与真实任务性能相关，LENS在复杂任务上表现最佳。在Text2SQL任务中，使用SynQuE选择的前3个合成数据集可将准确率从30.4%提升至38.4%（+8.1%）。

Conclusion: SynQuE为数据稀缺下的合成数据选择提供了实用框架，并推动了基于基础模型的数据特征分析和细粒度数据选择的未来研究。

Abstract: We introduce and formalize the Synthetic Dataset Quality Estimation (SynQuE)
problem: ranking synthetic datasets by their expected real-world task
performance using only limited unannotated real data. This addresses a critical
and open challenge where data is scarce due to collection costs or privacy
constraints. We establish the first comprehensive benchmarks for this problem
by introducing and evaluating proxy metrics that choose synthetic data for
training to maximize task performance on real data. We introduce the first
proxy metrics for SynQuE by adapting distribution and diversity-based distance
measures to our context via embedding models. To address the shortcomings of
these metrics on complex planning tasks, we propose LENS, a novel proxy that
leverages large language model reasoning. Our results show that SynQuE proxies
correlate with real task performance across diverse tasks, including sentiment
analysis, Text2SQL, web navigation, and image classification, with LENS
consistently outperforming others on complex tasks by capturing nuanced
characteristics. For instance, on text-to-SQL parsing, training on the top-3
synthetic datasets selected via SynQuE proxies can raise accuracy from 30.4% to
38.4 (+8.1)% on average compared to selecting data indiscriminately. This work
establishes SynQuE as a practical framework for synthetic data selection under
real-data scarcity and motivates future research on foundation model-based data
characterization and fine-grained data selection.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [34] [Friction on Demand: A Generative Framework for the Inverse Design of Metainterfaces](https://arxiv.org/abs/2511.03735)
*Valentin Mouton,Adrien Mélot*

Main category: stat.ML

TL;DR: 提出使用变分自编码器(VAE)的生成建模框架，从目标摩擦定律推断表面形貌，解决摩擦界面设计的逆问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖低维参数化的启发式搜索，难以处理复杂非线性摩擦定律，且接触模拟计算成本高。

Method: 基于参数化接触力学模型构建2亿样本的合成数据集，训练VAE模型实现无模拟的候选形貌高效生成。

Result: 方法能够平衡生成解的准确性、吞吐量和多样性，实现摩擦行为的近实时控制。

Conclusion: 该方法为通过定制表面形貌控制摩擦行为开辟了新途径，同时揭示了在平衡不同目标时的权衡考虑。

Abstract: Designing frictional interfaces to exhibit prescribed macroscopic behavior is
a challenging inverse problem, made difficult by the non-uniqueness of
solutions and the computational cost of contact simulations. Traditional
approaches rely on heuristic search over low-dimensional parameterizations,
which limits their applicability to more complex or nonlinear friction laws. We
introduce a generative modeling framework using Variational Autoencoders (VAEs)
to infer surface topographies from target friction laws. Trained on a synthetic
dataset composed of 200 million samples constructed from a parameterized
contact mechanics model, the proposed method enables efficient, simulation-free
generation of candidate topographies. We examine the potential and limitations
of generative modeling for this inverse design task, focusing on balancing
accuracy, throughput, and diversity in the generated solutions. Our results
highlight trade-offs and outline practical considerations when balancing these
objectives. This approach paves the way for near-real-time control of
frictional behavior through tailored surface topographies.

</details>


### [35] [Bifidelity Karhunen-Loève Expansion Surrogate with Active Learning for Random Fields](https://arxiv.org/abs/2511.03756)
*Aniket Jivani,Cosmin Safta,Beckett Y. Zhou,Xun Huan*

Main category: stat.ML

TL;DR: 提出了一种双保真度Karhunen-Loève展开（KLE）代理模型，结合多项式混沌展开（PCEs）和主动学习策略，用于在不确定输入下构建场值QoIs的高效代理模型。


<details>
  <summary>Details</summary>
Motivation: 传统单保真度方法计算成本高，需要平衡计算效率和精度。通过结合低保真度模拟捕获主要趋势和高保真度模拟校正系统偏差，实现计算效率和精度的平衡。

Method: 使用双保真度KLE-PCE框架，低保真度模拟提供主导响应趋势，少量高保真度模拟校正偏差。采用主动学习策略，基于交叉验证和Gaussian过程回归估计泛化误差，通过最大化期望改进准则自适应选择新的高保真度评估点。

Result: 在三个复杂度递增的示例中（1D分析基准、2D对流扩散系统、3D湍流射流模拟），该方法相比单保真度和随机采样方法，在预测精度和样本效率方面均取得一致改进。

Conclusion: BF-KLE-AL框架能够有效构建准确且计算负担可接受的场值QoIs代理模型，显著提高了不确定量化分析的效率和精度。

Abstract: We present a bifidelity Karhunen-Lo\`eve expansion (KLE) surrogate model for
field-valued quantities of interest (QoIs) under uncertain inputs. The approach
combines the spectral efficiency of the KLE with polynomial chaos expansions
(PCEs) to preserve an explicit mapping between input uncertainties and output
fields. By coupling inexpensive low-fidelity (LF) simulations that capture
dominant response trends with a limited number of high-fidelity (HF)
simulations that correct for systematic bias, the proposed method enables
accurate and computationally affordable surrogate construction. To further
improve surrogate accuracy, we form an active learning strategy that adaptively
selects new HF evaluations based on the surrogate's generalization error,
estimated via cross-validation and modeled using Gaussian process regression.
New HF samples are then acquired by maximizing an expected improvement
criterion, targeting regions of high surrogate error. The resulting BF-KLE-AL
framework is demonstrated on three examples of increasing complexity: a
one-dimensional analytical benchmark, a two-dimensional convection-diffusion
system, and a three-dimensional turbulent round jet simulation based on
Reynolds-averaged Navier--Stokes (RANS) and enhanced delayed detached-eddy
simulations (EDDES). Across these cases, the method achieves consistent
improvements in predictive accuracy and sample efficiency relative to
single-fidelity and random-sampling approaches.

</details>


### [36] [Learning Paths for Dynamic Measure Transport: A Control Perspective](https://arxiv.org/abs/2511.03797)
*Aimee Maurais,Bamdad Hosseini,Youssef Marzouk*

Main category: stat.ML

TL;DR: 本文从控制论视角研究动态测度传输中的测度路径识别问题，提出基于均值场博弈的优化框架来寻找更平滑、更高效的传输路径。


<details>
  <summary>Details</summary>
Motivation: 现有动态测度传输方法中常用的测度路径选择可能不够理想，需要寻找更优的路径来提升采样效率。

Method: 提出基于均值场博弈的优化问题族，使用鼓励速度平滑性的目标项，并采用高斯过程求解偏微分方程的数值算法。

Result: 相比未倾斜的参考路径，该方法能够恢复出更高效、更平滑的传输模型。

Conclusion: 从控制论视角出发的测度路径优化方法能够显著提升动态测度传输的性能，平滑的速度场有助于构建更有效的传输模型。

Abstract: We bring a control perspective to the problem of identifying paths of
measures for sampling via dynamic measure transport (DMT). We highlight the
fact that commonly used paths may be poor choices for DMT and connect existing
methods for learning alternate paths to mean-field games. Based on these
connections we pose a flexible family of optimization problems for identifying
tilted paths of measures for DMT and advocate for the use of objective terms
which encourage smoothness of the corresponding velocities. We present a
numerical algorithm for solving these problems based on recent Gaussian process
methods for solution of partial differential equations and demonstrate the
ability of our method to recover more efficient and smooth transport models
compared to those which use an untilted reference path.

</details>


### [37] [A general technique for approximating high-dimensional empirical kernel matrices](https://arxiv.org/abs/2511.03892)
*Chiraag Kaushik,Justin Romberg,Vidya Muthukumar*

Main category: stat.ML

TL;DR: 提出了随机核矩阵期望算子范数的简单用户友好边界，使用U-统计量的解耦结果和非交换Khintchine不等式，仅依赖于核函数的标量统计量和相关核矩阵。


<details>
  <summary>Details</summary>
Motivation: 为随机核矩阵的期望算子范数提供更简单、更紧的边界，特别是在高维数据情况下，简化现有证明并提供新的近似结果。

Method: 使用U-统计量的解耦结果和非交换Khintchine不等式，通过核函数的标量统计量和相关核矩阵来获得上下界。

Result: 获得了更紧的近似结果，简化了现有基于矩方法和组合论证的证明，并为各向异性高斯数据提供了新的近似结果。

Conclusion: 该方法不仅简化了现有结果的证明，还为各向异性高斯数据的核回归偏差提供了更紧的下界。

Abstract: We present simple, user-friendly bounds for the expected operator norm of a
random kernel matrix under general conditions on the kernel function
$k(\cdot,\cdot)$. Our approach uses decoupling results for U-statistics and the
non-commutative Khintchine inequality to obtain upper and lower bounds
depending only on scalar statistics of the kernel function and a ``correlation
kernel'' matrix corresponding to $k(\cdot,\cdot)$. We then apply our method to
provide new, tighter approximations for inner-product kernel matrices on
general high-dimensional data, where the sample size and data dimension are
polynomially related. Our method obtains simplified proofs of existing results
that rely on the moment method and combinatorial arguments while also providing
novel approximation results for the case of anisotropic Gaussian data. Finally,
using similar techniques to our approximation result, we show a tighter lower
bound on the bias of kernel regression with anisotropic Gaussian data.

</details>


### [38] [High-dimensional limit theorems for SGD: Momentum and Adaptive Step-sizes](https://arxiv.org/abs/2511.03952)
*Aukosh Jagannath,Taj Jones-McCormick,Varnan Sarangian*

Main category: stat.ML

TL;DR: 该论文为带Polyak动量的随机梯度下降(SGD-M)开发了高维缩放极限，并与在线SGD进行严格比较，发现在特定时间缩放和步长选择下两者极限相同，但相同步长时SGD-M会放大高维效应。


<details>
  <summary>Details</summary>
Motivation: 为SGD-M及其变种提供严格的比较框架，解释自适应步长在早期预调节中的稳定作用，特别是在在线SGD失败的场景中。

Method: 建立SGD-M的高维缩放极限理论框架，在尖峰张量PCA和单指标模型上验证，并分析基于归一化梯度的自适应步长算法。

Result: 发现SGD-M与在线SGD在适当时间缩放和步长选择下极限相同；自适应步长算法能产生更接近总体最小值的固定点，并扩大收敛步长范围。

Conclusion: 早期预调节器能在在线SGD失败的场景中稳定和改进动态性能，自适应步长算法在高维机制中具有多重优势。

Abstract: We develop a high-dimensional scaling limit for Stochastic Gradient Descent
with Polyak Momentum (SGD-M) and adaptive step-sizes. This provides a framework
to rigourously compare online SGD with some of its popular variants. We show
that the scaling limits of SGD-M coincide with those of online SGD after an
appropriate time rescaling and a specific choice of step-size. However, if the
step-size is kept the same between the two algorithms, SGD-M will amplify
high-dimensional effects, potentially degrading performance relative to online
SGD. We demonstrate our framework on two popular learning problems: Spiked
Tensor PCA and Single Index Models. In both cases, we also examine online SGD
with an adaptive step-size based on normalized gradients. In the
high-dimensional regime, this algorithm yields multiple benefits: its dynamics
admit fixed points closer to the population minimum and widens the range of
admissible step-sizes for which the iterates converge to such solutions. These
examples provide a rigorous account, aligning with empirical motivation, of how
early preconditioners can stabilize and improve dynamics in settings where
online SGD fails.

</details>


### [39] [Robust inference using density-powered Stein operators](https://arxiv.org/abs/2511.03963)
*Shinto Eguchi*

Main category: stat.ML

TL;DR: 提出了一种基于密度幂加权的γ-Stein算子，用于构建非归一化概率模型的鲁棒推断方法，并开发了γ-核化Stein差异和γ-Stein变分梯度下降两个关键应用。


<details>
  <summary>Details</summary>
Motivation: 现有的Stein算子方法对异常值敏感，需要开发具有内在鲁棒性的推断方法，同时保持对模型归一化常数的独立性。

Method: 通过将模型密度提升到正幂γ进行加权，构建γ-Stein算子，从而内在降低异常值的影响。基于此开发了鲁棒的得分匹配、核化Stein差异和Stein变分梯度下降方法。

Result: 在受污染的高斯模型和四次势能模型上的实验表明，该方法在鲁棒性和统计效率方面显著优于标准基线方法。

Conclusion: γ-Stein算子提供了一种原则性的鲁棒推断框架，能够有效处理异常值，同时保持对模型归一化常数的独立性，在多种应用中表现出优越性能。

Abstract: We introduce a density-power weighted variant for the Stein operator, called
the $\gamma$-Stein operator. This is a novel class of operators derived from
the $\gamma$-divergence, designed to build robust inference methods for
unnormalized probability models. The operator's construction (weighting by the
model density raised to a positive power $\gamma$ inherently down-weights the
influence of outliers, providing a principled mechanism for robustness.
Applying this operator yields a robust generalization of score matching that
retains the crucial property of being independent of the model's normalizing
constant. We extend this framework to develop two key applications: the
$\gamma$-kernelized Stein discrepancy for robust goodness-of-fit testing, and
$\gamma$-Stein variational gradient descent for robust Bayesian posterior
approximation. Empirical results on contaminated Gaussian and quartic potential
models show our methods significantly outperform standard baselines in both
robustness and statistical efficiency.

</details>


### [40] [Online Conformal Inference with Retrospective Adjustment for Faster Adaptation to Distribution Shift](https://arxiv.org/abs/2511.04275)
*Jungbin Jun,Ilsang Ohn*

Main category: stat.ML

TL;DR: 提出了一种带有回顾性调整的在线共形推理方法，通过回归方法和留一法更新公式来调整过去的预测，以更快适应分布变化。


<details>
  <summary>Details</summary>
Motivation: 传统共形预测在在线环境中假设数据分布不变，但实际数据分布会随时间变化，现有方法只能前向更新，适应分布变化较慢。

Method: 使用回归方法和高效的留一法更新公式，在新数据到达时回顾性调整过去的预测，使所有预测与最新数据分布对齐。

Result: 在合成和真实数据集上的实验表明，该方法比现有在线共形预测方法实现了更快的覆盖率重新校准和更高的统计效率。

Conclusion: 提出的回顾性调整方法能有效应对在线环境中的分布漂移问题，提供更快速和高效的预测集构建。

Abstract: Conformal prediction has emerged as a powerful framework for constructing
distribution-free prediction sets with guaranteed coverage assuming only the
exchangeability assumption. However, this assumption is often violated in
online environments where data distributions evolve over time. Several recent
approaches have been proposed to address this limitation, but, typically, they
slowly adapt to distribution shifts because they update predictions only in a
forward manner, that is, they generate a prediction for a newly observed data
point while previously computed predictions are not updated. In this paper, we
propose a novel online conformal inference method with retrospective
adjustment, which is designed to achieve faster adaptation to distributional
shifts. Our method leverages regression approaches with efficient leave-one-out
update formulas to retroactively adjust past predictions when new data arrive,
thereby aligning the entire set of predictions with the most recent data
distribution. Through extensive numerical studies performed on both synthetic
and real-world data sets, we show that the proposed approach achieves faster
coverage recalibration and improved statistical efficiency compared to existing
online conformal prediction methods.

</details>


### [41] [Robustness of Minimum-Volume Nonnegative Matrix Factorization under an Expanded Sufficiently Scattered Condition](https://arxiv.org/abs/2511.04291)
*Giovanni Barbarino,Nicolas Gillis,Subhayan Saha*

Main category: stat.ML

TL;DR: 本文证明了最小体积非负矩阵分解（min-vol NMF）在噪声存在下能够识别真实因子，前提是数据点在基向量生成的潜在单纯形中满足扩展充分分散条件。


<details>
  <summary>Details</summary>
Motivation: 最小体积NMF已在许多应用中成功使用，但其对噪声的鲁棒性一直是一个长期未解决的问题。

Method: 通过证明在扩展充分分散条件下，min-vol NMF能够在噪声存在下识别真实因子。

Result: 证明了min-vol NMF在满足扩展充分分散条件时具有噪声鲁棒性。

Conclusion: min-vol NMF在数据点充分分散的条件下能够抵抗噪声干扰，识别出真实的基向量和系数矩阵。

Abstract: Minimum-volume nonnegative matrix factorization (min-vol NMF) has been used
successfully in many applications, such as hyperspectral imaging, chemical
kinetics, spectroscopy, topic modeling, and audio source separation. However,
its robustness to noise has been a long-standing open problem. In this paper,
we prove that min-vol NMF identifies the groundtruth factors in the presence of
noise under a condition referred to as the expanded sufficiently scattered
condition which requires the data points to be sufficiently well scattered in
the latent simplex generated by the basis vectors.

</details>


### [42] [Simultaneous Optimization of Geodesics and Fréchet Means](https://arxiv.org/abs/2511.04301)
*Frederik Möbius Rygaard,Søren Hauberg,Steen Markvorsen*

Main category: stat.ML

TL;DR: 提出了GEORCE-FM算法，用于在黎曼流形上同时计算Fréchet均值和黎曼距离，比现有方法更快，并扩展到Finsler流形和自适应扩展以处理大数据集。


<details>
  <summary>Details</summary>
Motivation: Fréchet均值是几何统计中的核心概念，但现有计算方法需要在每次迭代中求解嵌入优化问题，计算效率低。

Method: GEORCE-FM算法在局部坐标系中同时计算Fréchet均值和黎曼距离，避免重复优化，并扩展到Finsler流形和自适应扩展。

Result: 理论证明GEORCE-FM具有全局收敛性和局部二次收敛性，自适应扩展在期望意义下收敛到Fréchet均值。实证显示在准确性和运行时间上优于基线方法。

Conclusion: GEORCE-FM算法为计算Fréchet均值提供了高效且可扩展的解决方案，适用于大数据场景。

Abstract: A central part of geometric statistics is to compute the Fr\'echet mean. This
is a well-known intrinsic mean on a Riemannian manifold that minimizes the sum
of squared Riemannian distances from the mean point to all other data points.
The Fr\'echet mean is simple to define and generalizes the Euclidean mean, but
for most manifolds even minimizing the Riemannian distance involves solving an
optimization problem. Therefore, numerical computations of the Fr\'echet mean
require solving an embedded optimization problem in each iteration. We
introduce the GEORCE-FM algorithm to simultaneously compute the Fr\'echet mean
and Riemannian distances in each iteration in a local chart, making it faster
than previous methods. We extend the algorithm to Finsler manifolds and
introduce an adaptive extension such that GEORCE-FM scales to a large number of
data points. Theoretically, we show that GEORCE-FM has global convergence and
local quadratic convergence and prove that the adaptive extension converges in
expectation to the Fr\'echet mean. We further empirically demonstrate that
GEORCE-FM outperforms existing baseline methods to estimate the Fr\'echet mean
in terms of both accuracy and runtime.

</details>


### [43] [Online Bayesian Experimental Design for Partially Observed Dynamical Systems](https://arxiv.org/abs/2511.04403)
*Sara Pérez-Vieites,Sahel Iqbal,Simo Särkkä,Dominik Baumann*

Main category: stat.ML

TL;DR: 提出了一个用于部分可观测动态系统中贝叶斯实验设计的新框架，通过推导EIG及其梯度的新估计器，结合嵌套粒子滤波器实现可扩展的在线优化。


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯实验设计方法无法处理部分可观测动态系统，这些系统通常建模为状态空间模型，其中潜在状态使得似然函数和信息论目标（如EIG）难以处理。

Method: 推导了显式边缘化潜在状态的EIG及其梯度新估计器，使用嵌套粒子滤波器进行高效在线推理，具有收敛保证。

Result: 在SIR模型和移动源定位任务等现实模型中成功应用，证明该框架能够有效处理部分可观测性和在线计算需求。

Conclusion: 该框架为部分可观测动态系统中的贝叶斯实验设计提供了可行的解决方案，实现了可扩展的随机优化。

Abstract: Bayesian experimental design (BED) provides a principled framework for
optimizing data collection, but existing approaches do not apply to crucial
real-world settings such as dynamical systems with partial observability, where
only noisy and incomplete observations are available. These systems are
naturally modeled as state-space models (SSMs), where latent states mediate the
link between parameters and data, making the likelihood -- and thus
information-theoretic objectives like the expected information gain (EIG) --
intractable. In addition, the dynamical nature of the system requires online
algorithms that update posterior distributions and select designs sequentially
in a computationally efficient manner. We address these challenges by deriving
new estimators of the EIG and its gradient that explicitly marginalize latent
states, enabling scalable stochastic optimization in nonlinear SSMs. Our
approach leverages nested particle filters (NPFs) for efficient online
inference with convergence guarantees. Applications to realistic models, such
as the susceptible-infected-recovered (SIR) and a moving source location task,
show that our framework successfully handles both partial observability and
online computation.

</details>


### [44] [Riesz Regression As Direct Density Ratio Estimation](https://arxiv.org/abs/2511.04568)
*Masahiro Kato*

Main category: stat.ML

TL;DR: Riesz回归与直接密度比估计在重要案例中密切相关，特别是在平均处理效应估计中，其思想与目标与最小二乘重要性拟合方法一致。


<details>
  <summary>Details</summary>
Motivation: 研究Riesz回归与直接密度比估计之间的关系，以便在特定情况下直接应用现有的密度比估计结果，同时扩展密度比估计方法的应用范围。

Method: 通过理论分析建立Riesz回归与直接密度比估计之间的等价性，特别是在Riesz表示器估计和平均处理效应估计等具体案例中。

Result: 发现Riesz回归与最小二乘重要性拟合在思想和方法上具有一致性，这使得可以直接导入密度比估计中的收敛率分析、损失函数选择和正则化技术等现有成果。

Conclusion: Riesz回归与直接密度比估计的等价关系为两者提供了相互借鉴的理论基础，扩展了各自的应用范围和方法论工具。

Abstract: Riesz regression has garnered attention as a tool in debiased machine
learning for causal and structural parameter estimation (Chernozhukov et al.,
2021). This study shows that Riesz regression is closely related to direct
density-ratio estimation (DRE) in important cases, including average treat-
ment effect (ATE) estimation. Specifically, the idea and objective in Riesz
regression coincide with the one in least-squares importance fitting (LSIF,
Kanamori et al., 2009) in direct density-ratio estimation. While Riesz
regression is general in the sense that it can be applied to Riesz representer
estimation in a wide class of problems, the equivalence with DRE allows us to
directly import exist- ing results in specific cases, including
convergence-rate analyses, the selection of loss functions via
Bregman-divergence minimization, and regularization techniques for flexible
models, such as neural networks. Conversely, insights about the Riesz
representer in debiased machine learning broaden the applications of direct
density-ratio estimation methods. This paper consolidates our prior results in
Kato (2025a) and Kato (2025b).

</details>


### [45] [Physics-Informed Neural Networks and Neural Operators for Parametric PDEs: A Human-AI Collaborative Analysis](https://arxiv.org/abs/2511.04576)
*Zhuo Zhang,Xiong Xiong,Sen Zhang,Yuan Zhao,Xi Yang*

Main category: stat.ML

TL;DR: 该论文综述了参数化偏微分方程求解的两种机器学习范式：物理信息神经网络（PINNs）和神经算子，比较了它们在流体动力学、固体力学等领域的性能，展示了神经算子相比传统求解器可获得10^3到10^5倍的计算加速。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法需要为每个参数重新求解PDE，使得参数空间探索成本极高。机器学习方法能够学习跨参数空间的解算子，实现高效的多查询场景求解。

Method: 分析两种主要范式：1）PINNs：将物理定律作为软约束嵌入，擅长稀疏数据的逆问题；2）神经算子（如DeepONet、傅里叶神经算子）：学习无限维函数空间之间的映射，实现前所未有的泛化能力。

Result: 在流体动力学、固体力学、热传导和电磁学等领域的比较表明，神经算子可以在保持相当精度的同时，比传统求解器快10^3到10^5倍。

Conclusion: 建立了一个通过算子学习理解参数化PDE求解器的统一框架，为这个快速发展的领域提供了全面的、可增量更新的资源，同时指出了高维参数、复杂几何和分布外泛化等关键开放挑战。

Abstract: PDEs arise ubiquitously in science and engineering, where solutions depend on
parameters (physical properties, boundary conditions, geometry). Traditional
numerical methods require re-solving the PDE for each parameter, making
parameter space exploration prohibitively expensive. Recent machine learning
advances, particularly physics-informed neural networks (PINNs) and neural
operators, have revolutionized parametric PDE solving by learning solution
operators that generalize across parameter spaces. We critically analyze two
main paradigms: (1) PINNs, which embed physical laws as soft constraints and
excel at inverse problems with sparse data, and (2) neural operators (e.g.,
DeepONet, Fourier Neural Operator), which learn mappings between
infinite-dimensional function spaces and achieve unprecedented generalization.
Through comparisons across fluid dynamics, solid mechanics, heat transfer, and
electromagnetics, we show neural operators can achieve computational speedups
of $10^3$ to $10^5$ times faster than traditional solvers for multi-query
scenarios, while maintaining comparable accuracy. We provide practical guidance
for method selection, discuss theoretical foundations (universal approximation,
convergence), and identify critical open challenges: high-dimensional
parameters, complex geometries, and out-of-distribution generalization. This
work establishes a unified framework for understanding parametric PDE solvers
via operator learning, offering a comprehensive, incrementally updated resource
for this rapidly evolving field

</details>

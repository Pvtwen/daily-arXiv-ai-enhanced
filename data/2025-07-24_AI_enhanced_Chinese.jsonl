{"id": "2507.17071", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2507.17071", "abs": "https://arxiv.org/abs/2507.17071", "authors": ["Juntao Lin", "Xianghao Zhan"], "title": "Sensor Drift Compensation in Electronic-Nose-Based Gas Recognition Using Knowledge Distillation", "comment": "9 pages", "summary": "Due to environmental changes and sensor aging, sensor drift challenges the\nperformance of electronic nose systems in gas classification during real-world\ndeployment. Previous studies using the UCI Gas Sensor Array Drift Dataset\nreported promising drift compensation results but lacked robust statistical\nexperimental validation and may overcompensate for sensor drift, losing\nclass-related variance.To address these limitations and improve sensor drift\ncompensation with statistical rigor, we first designed two domain adaptation\ntasks based on the same electronic nose dataset: using the first batch to\npredict the remaining batches, simulating a controlled laboratory setting; and\npredicting the next batch using all prior batches, simulating continuous\ntraining data updates for online training. We then systematically tested three\nmethods: our proposed novel Knowledge Distillation (KD) method, the benchmark\nmethod Domain Regularized Component Analysis (DRCA), and a hybrid method\nKD-DRCA, across 30 random test set partitions on the UCI dataset. We showed\nthat KD consistently outperformed both DRCA and KD-DRCA, achieving up to an 18%\nimprovement in accuracy and 15% in F1-score, demonstrating KD's superior\neffectiveness in drift compensation. This is the first application of KD for\nelectronic nose drift mitigation, significantly outperforming the previous\nstate-of-the-art DRCA method and enhancing the reliability of sensor drift\ncompensation in real-world environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f(KD)\u7684\u7535\u5b50\u9f3b\u4f20\u611f\u5668\u6f02\u79fb\u8865\u507f\u65b9\u6cd5\uff0c\u5728UCI\u6c14\u4f53\u4f20\u611f\u5668\u9635\u5217\u6f02\u79fb\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684DRCA\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u534718%\uff0cF1\u5206\u6570\u63d0\u534715%", "motivation": "\u7535\u5b50\u9f3b\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u4f20\u611f\u5668\u6f02\u79fb\u95ee\u9898\uff0c\u5f71\u54cd\u6c14\u4f53\u5206\u7c7b\u6027\u80fd\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u4e25\u683c\u7684\u7edf\u8ba1\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4e14\u53ef\u80fd\u8fc7\u5ea6\u8865\u507f\u4f20\u611f\u5668\u6f02\u79fb\u800c\u4e22\u5931\u7c7b\u522b\u76f8\u5173\u7684\u65b9\u5dee\u4fe1\u606f", "method": "\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u9886\u57df\u9002\u5e94\u4efb\u52a1\u6765\u6a21\u62df\u5b9e\u9645\u5e94\u7528\u573a\u666f\uff0c\u7cfb\u7edf\u6d4b\u8bd5\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a\u63d0\u51fa\u7684\u77e5\u8bc6\u84b8\u998f(KD)\u65b9\u6cd5\u3001\u57fa\u51c6\u65b9\u6cd5DRCA\u548c\u6df7\u5408\u65b9\u6cd5KD-DRCA\uff0c\u5728UCI\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e8630\u6b21\u968f\u673a\u6d4b\u8bd5\u96c6\u5212\u5206\u7684\u7edf\u8ba1\u9a8c\u8bc1", "result": "\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u5728\u6f02\u79fb\u8865\u507f\u65b9\u9762\u6301\u7eed\u4f18\u4e8eDRCA\u548cKD-DRCA\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe18%\uff0cF1\u5206\u6570\u63d0\u534715%\uff0c\u8bc1\u660e\u4e86KD\u5728\u6f02\u79fb\u8865\u507f\u4e2d\u7684\u5353\u8d8a\u6709\u6548\u6027", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06\u77e5\u8bc6\u84b8\u998f\u5e94\u7528\u4e8e\u7535\u5b50\u9f3b\u6f02\u79fb\u7f13\u89e3\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u4e4b\u524d\u6700\u5148\u8fdb\u7684DRCA\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u4f20\u611f\u5668\u6f02\u79fb\u8865\u507f\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027"}}
{"id": "2507.17096", "categories": ["cs.LG", "cs.NA", "cs.SY", "eess.SY", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.17096", "abs": "https://arxiv.org/abs/2507.17096", "authors": ["Olivia Dry", "Timothy L. Molloy", "Wanxin Jin", "Iman Shames"], "title": "ZORMS-LfD: Learning from Demonstrations with Zeroth-Order Random Matrix Search", "comment": null, "summary": "We propose Zeroth-Order Random Matrix Search for Learning from Demonstrations\n(ZORMS-LfD). ZORMS-LfD enables the costs, constraints, and dynamics of\nconstrained optimal control problems, in both continuous and discrete time, to\nbe learned from expert demonstrations without requiring smoothness of the\nlearning-loss landscape. In contrast, existing state-of-the-art first-order\nmethods require the existence and computation of gradients of the costs,\nconstraints, dynamics, and learning loss with respect to states, controls\nand/or parameters. Most existing methods are also tailored to discrete time,\nwith constrained problems in continuous time receiving only cursory attention.\nWe demonstrate that ZORMS-LfD matches or surpasses the performance of\nstate-of-the-art methods in terms of both learning loss and compute time across\na variety of benchmark problems. On unconstrained continuous-time benchmark\nproblems, ZORMS-LfD achieves similar loss performance to state-of-the-art\nfirst-order methods with an over $80$\\% reduction in compute time. On\nconstrained continuous-time benchmark problems where there is no specialized\nstate-of-the-art method, ZORMS-LfD is shown to outperform the commonly used\ngradient-free Nelder-Mead optimization method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ZORMS-LfD\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u96f6\u9636\u968f\u673a\u77e9\u9635\u641c\u7d22\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u7ea6\u675f\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u65e0\u9700\u68af\u5ea6\u4fe1\u606f\u5373\u53ef\u5b66\u4e60\u6210\u672c\u3001\u7ea6\u675f\u548c\u52a8\u529b\u5b66", "motivation": "\u73b0\u6709\u7684\u4e00\u9636\u65b9\u6cd5\u9700\u8981\u8ba1\u7b97\u6210\u672c\u3001\u7ea6\u675f\u3001\u52a8\u529b\u5b66\u548c\u5b66\u4e60\u635f\u5931\u76f8\u5bf9\u4e8e\u72b6\u6001\u3001\u63a7\u5236\u548c\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u4e14\u8981\u6c42\u5b66\u4e60\u635f\u5931\u666f\u89c2\u7684\u5e73\u6ed1\u6027\u3002\u5927\u591a\u6570\u73b0\u6709\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u79bb\u6563\u65f6\u95f4\uff0c\u5bf9\u8fde\u7eed\u65f6\u95f4\u7ea6\u675f\u95ee\u9898\u5173\u6ce8\u4e0d\u8db3", "method": "\u63d0\u51fa\u96f6\u9636\u968f\u673a\u77e9\u9635\u641c\u7d22\u7b97\u6cd5(ZORMS-LfD)\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u9700\u8981\u5e73\u6ed1\u6027\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u8fde\u7eed\u548c\u79bb\u6563\u65f6\u95f4\u7ea6\u675f\u6700\u4f18\u63a7\u5236\u95ee\u9898\u7684\u6210\u672c\u3001\u7ea6\u675f\u548c\u52a8\u529b\u5b66", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u95ee\u9898\u4e0a\uff0cZORMS-LfD\u5728\u5b66\u4e60\u635f\u5931\u548c\u8ba1\u7b97\u65f6\u95f4\u65b9\u9762\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u3002\u5728\u65e0\u7ea6\u675f\u8fde\u7eed\u65f6\u95f4\u57fa\u51c6\u95ee\u9898\u4e0a\uff0c\u5b9e\u73b0\u4e86\u4e0e\u6700\u5148\u8fdb\u4e00\u9636\u65b9\u6cd5\u76f8\u4f3c\u7684\u635f\u5931\u6027\u80fd\uff0c\u540c\u65f6\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c11\u8d85\u8fc780%\u3002\u5728\u7ea6\u675f\u8fde\u7eed\u65f6\u95f4\u57fa\u51c6\u95ee\u9898\u4e0a\uff0c\u4f18\u4e8e\u5e38\u7528\u7684\u65e0\u68af\u5ea6Nelder-Mead\u4f18\u5316\u65b9\u6cd5", "conclusion": "ZORMS-LfD\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u68af\u5ea6\u4fe1\u606f\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5b66\u4e60\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8fde\u7eed\u65f6\u95f4\u7ea6\u675f\u6700\u4f18\u63a7\u5236\u95ee\u9898\u7684\u5b66\u4e60"}}
{"id": "2507.17154", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.17154", "abs": "https://arxiv.org/abs/2507.17154", "authors": ["Ruihua Wang", "Mingtong Chen", "Zhengbao Yang"], "title": "Design of a Noval Wearable ECG Monitoring Device", "comment": null, "summary": "The aim of this project is to develop a new wireless powered wearable ECG\nmonitoring device. The main goal of the project is to provide a wireless,\nsmall-sized ECG monitoring device that can be worn for a long period of time by\nthe monitored person. Electrocardiogram ECG reflects physiological and\npathological information about heart activity and is commonly used to diagnose\nheart disease. Existing wearable smart ECG solutions suffer from high power\nconsumption in both ECG diagnosis and transmission for high accuracy.\nMonitoring of ECG devices is mainly done by data extraction and acquisition,\npre-processing, feature extraction, processing and analysis, visualisation and\nauxiliary procedures. During the pre-processing of the information, different\nkinds of noise generated during the signal collection need to be taken into\naccount. The quality of the signal-to-noise ratio can usually be improved by\noptimising algorithms and reducing the noise power. The choice of electrodes\nusually has a direct impact on the signal-to-noise ratio and the user\nexperience, and conventional Ag/AgCl gel electrodes are not suitable for\nlong-term and dynamic monitoring as they are prone to skin irritation,\ninflammation and allergic reactions. Therefore, a completely new way of\ncombining electrodes and wires will be used in the report. The electrodes and\nwires are cut in one piece from a silver-plated fabric. The wire portion is cut\ninto a curved structure close to an S shape to ensure that it has good\nductility for comfort and signal integrity during daily movement of the\ngarment.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u578b\u65e0\u7ebf\u4f9b\u7535\u53ef\u7a7f\u6234\u5fc3\u7535\u76d1\u6d4b\u8bbe\u5907\uff0c\u91c7\u7528\u94f6\u9540\u7ec7\u7269\u4e00\u4f53\u5316\u7535\u6781\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4f20\u7edf\u8bbe\u5907\u529f\u8017\u9ad8\u548c\u957f\u671f\u4f69\u6234\u4e0d\u9002\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u53ef\u7a7f\u6234\u667a\u80fd\u5fc3\u7535\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u9ad8\u529f\u8017\u95ee\u9898\uff0c\u4f20\u7edfAg/AgCl\u51dd\u80f6\u7535\u6781\u4e0d\u9002\u5408\u957f\u671f\u52a8\u6001\u76d1\u6d4b\uff0c\u5bb9\u6613\u5f15\u8d77\u76ae\u80a4\u523a\u6fc0\u3001\u708e\u75c7\u548c\u8fc7\u654f\u53cd\u5e94\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u65e0\u7ebf\u3001\u5c0f\u5c3a\u5bf8\u3001\u53ef\u957f\u671f\u4f69\u6234\u7684\u5fc3\u7535\u76d1\u6d4b\u8bbe\u5907\u3002", "method": "\u91c7\u7528\u5168\u65b0\u7684\u7535\u6781\u548c\u5bfc\u7ebf\u7ec4\u5408\u65b9\u5f0f\uff0c\u4ece\u94f6\u9540\u7ec7\u7269\u4e2d\u4e00\u4f53\u5207\u5272\u51fa\u7535\u6781\u548c\u5bfc\u7ebf\uff0c\u5bfc\u7ebf\u90e8\u5206\u5207\u5272\u6210\u63a5\u8fd1S\u5f62\u7684\u5f2f\u66f2\u7ed3\u6784\uff0c\u786e\u4fdd\u5728\u65e5\u5e38\u670d\u88c5\u8fd0\u52a8\u4e2d\u5177\u6709\u826f\u597d\u7684\u5ef6\u5c55\u6027\uff0c\u4fdd\u8bc1\u8212\u9002\u6027\u548c\u4fe1\u53f7\u5b8c\u6574\u6027\u3002\u540c\u65f6\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u548c\u964d\u4f4e\u566a\u58f0\u529f\u7387\u6765\u6539\u5584\u4fe1\u566a\u6bd4\u3002", "result": "\u8bbe\u8ba1\u51fa\u4e86\u91c7\u7528\u94f6\u9540\u7ec7\u7269\u4e00\u4f53\u5316\u7535\u6781\u7684\u65e0\u7ebf\u4f9b\u7535\u53ef\u7a7f\u6234\u5fc3\u7535\u76d1\u6d4b\u8bbe\u5907\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7535\u6781\u7684\u76ae\u80a4\u523a\u6fc0\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u957f\u671f\u4f69\u6234\u7684\u8212\u9002\u6027\u548c\u4fe1\u53f7\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u94f6\u9540\u7ec7\u7269\u4e00\u4f53\u5316\u7535\u6781\u8bbe\u8ba1\u548cS\u5f62\u5f2f\u66f2\u5bfc\u7ebf\u7ed3\u6784\uff0c\u6210\u529f\u5f00\u53d1\u4e86\u9002\u5408\u957f\u671f\u4f69\u6234\u7684\u65e0\u7ebf\u5fc3\u7535\u76d1\u6d4b\u8bbe\u5907\uff0c\u4e3a\u5fc3\u7535\u76d1\u6d4b\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6539\u5584\u4e86\u7528\u6237\u4f53\u9a8c\u548c\u76d1\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2507.16818", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16818", "abs": "https://arxiv.org/abs/2507.16818", "authors": ["C. H. E. Jordaan", "M. van der Stelt", "T. J. J. Maal", "V. M. A. Stirler", "R. Leijendekkers", "T. Kachman", "G. A. de Jong"], "title": "Evaluating Artificial Intelligence Algorithms for the Standardization of Transtibial Prosthetic Socket Shape Design", "comment": null, "summary": "The quality of a transtibial prosthetic socket depends on the prosthetist's\nskills and expertise, as the fitting is performed manually. This study\ninvestigates multiple artificial intelligence (AI) approaches to help\nstandardize transtibial prosthetic socket design. Data from 118 patients were\ncollected by prosthetists working in the Dutch healthcare system. This data\nconsists of a three-dimensional (3D) scan of the residual limb and a\ncorresponding 3D model of the prosthetist-designed socket. Multiple data\npre-processing steps are performed for alignment, standardization and\noptionally compression using Morphable Models and Principal Component Analysis.\nAfterward, three different algorithms - a 3D neural network, Feedforward neural\nnetwork, and random forest - are developed to either predict 1) the final\nsocket shape or 2) the adaptations performed by a prosthetist to predict the\nsocket shape based on the 3D scan of the residual limb. Each algorithm's\nperformance was evaluated by comparing the prosthetist-designed socket with the\nAI-generated socket, using two metrics in combination with the error location.\nFirst, we measure the surface-to-surface distance to assess the overall surface\nerror between the AI-generated socket and the prosthetist-designed socket.\nSecond, distance maps between the AI-generated and prosthetist sockets are\nutilized to analyze the error's location. For all algorithms, estimating the\nrequired adaptations outperformed direct prediction of the final socket shape.\nThe random forest model applied to adaptation prediction yields the lowest\nerror with a median surface-to-surface distance of 1.24 millimeters, a first\nquartile of 1.03 millimeters, and a third quartile of 1.54 millimeters.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u591a\u79cd\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\u6765\u6807\u51c6\u5316\u7ecf\u80eb\u5047\u80a2\u63a5\u53d7\u8154\u8bbe\u8ba1\uff0c\u4f7f\u7528118\u540d\u60a3\u8005\u76843D\u626b\u63cf\u6570\u636e\u8bad\u7ec3\u4e86\u4e09\u79cd\u7b97\u6cd5\uff083D\u795e\u7ecf\u7f51\u7edc\u3001\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u548c\u968f\u673a\u68ee\u6797\uff09\uff0c\u5176\u4e2d\u968f\u673a\u68ee\u6797\u5728\u9884\u6d4b\u5047\u80a2\u5e08\u9002\u5e94\u6027\u8c03\u6574\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4e2d\u4f4d\u8bef\u5dee\u4ec51.24\u6beb\u7c73", "motivation": "\u7ecf\u80eb\u5047\u80a2\u63a5\u53d7\u8154\u7684\u8d28\u91cf\u4f9d\u8d56\u4e8e\u5047\u80a2\u5e08\u7684\u624b\u5de5\u6280\u80fd\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u56e0\u6b64\u9700\u8981\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\u6765\u5e2e\u52a9\u6807\u51c6\u5316\u5047\u80a2\u63a5\u53d7\u8154\u7684\u8bbe\u8ba1\u8fc7\u7a0b", "method": "\u6536\u96c6118\u540d\u60a3\u8005\u7684\u6b8b\u80a23D\u626b\u63cf\u6570\u636e\u548c\u5bf9\u5e94\u7684\u5047\u80a2\u5e08\u8bbe\u8ba1\u7684\u63a5\u53d7\u81543D\u6a21\u578b\uff1b\u901a\u8fc7\u5bf9\u9f50\u3001\u6807\u51c6\u5316\u548c\u53ef\u53d8\u5f62\u6a21\u578b\u3001\u4e3b\u6210\u5206\u5206\u6790\u7b49\u9884\u5904\u7406\u6b65\u9aa4\uff1b\u5f00\u53d1\u4e09\u79cd\u7b97\u6cd5\uff083D\u795e\u7ecf\u7f51\u7edc\u3001\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u3001\u968f\u673a\u68ee\u6797\uff09\u6765\u9884\u6d4b\u6700\u7ec8\u63a5\u53d7\u8154\u5f62\u72b6\u6216\u5047\u80a2\u5e08\u7684\u9002\u5e94\u6027\u8c03\u6574", "result": "\u6240\u6709\u7b97\u6cd5\u4e2d\uff0c\u4f30\u8ba1\u6240\u9700\u9002\u5e94\u6027\u8c03\u6574\u7684\u65b9\u6cd5\u90fd\u4f18\u4e8e\u76f4\u63a5\u9884\u6d4b\u6700\u7ec8\u63a5\u53d7\u8154\u5f62\u72b6\uff1b\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u9002\u5e94\u6027\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4e2d\u4f4d\u8868\u9762\u5230\u8868\u9762\u8ddd\u79bb\u4e3a1.24\u6beb\u7c73\uff0c\u7b2c\u4e00\u56db\u5206\u4f4d\u6570\u4e3a1.03\u6beb\u7c73\uff0c\u7b2c\u4e09\u56db\u5206\u4f4d\u6570\u4e3a1.54\u6beb\u7c73", "conclusion": "\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u8f85\u52a9\u7ecf\u80eb\u5047\u80a2\u63a5\u53d7\u8154\u7684\u6807\u51c6\u5316\u8bbe\u8ba1\uff0c\u5176\u4e2d\u9884\u6d4b\u5047\u80a2\u5e08\u9002\u5e94\u6027\u8c03\u6574\u7684\u7b56\u7565\u6bd4\u76f4\u63a5\u9884\u6d4b\u6700\u7ec8\u5f62\u72b6\u66f4\u6709\u6548\uff0c\u968f\u673a\u68ee\u6797\u7b97\u6cd5\u5728\u6b64\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f18"}}
{"id": "2507.17003", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17003", "abs": "https://arxiv.org/abs/2507.17003", "authors": ["Seunggeun Kim", "Ziyi Wang", "Sungyoung Lee", "Youngmin Oh", "Hanqing Zhu", "Doyun Kim", "David Z. Pan"], "title": "PPAAS: PVT and Pareto Aware Analog Sizing via Goal-conditioned Reinforcement Learning", "comment": "Accepted to the 44th International Conference on Computer-Aided\n  Design (ICCAD 2025); 9 pages, 10 figures", "summary": "Device sizing is a critical yet challenging step in analog and mixed-signal\ncircuit design, requiring careful optimization to meet diverse performance\nspecifications. This challenge is further amplified under process, voltage, and\ntemperature (PVT) variations, which cause circuit behavior to shift across\ndifferent corners. While reinforcement learning (RL) has shown promise in\nautomating sizing for fixed targets, training a generalized policy that can\nadapt to a wide range of design specifications under PVT variations requires\nmuch more training samples and resources. To address these challenges, we\npropose a \\textbf{Goal-conditioned RL framework} that enables efficient policy\ntraining for analog device sizing across PVT corners, with strong\ngeneralization capability. To improve sample efficiency, we introduce\nPareto-front Dominance Goal Sampling, which constructs an automatic curriculum\nby sampling goals from the Pareto frontier of previously achieved goals. This\nstrategy is further enhanced by integrating Conservative Hindsight Experience\nReplay, which assigns relabeled goals with conservative virtual rewards to\nstabilize training and accelerate convergence. To reduce simulation overhead,\nour framework incorporates a Skip-on-Fail simulation strategy, which skips\nfull-corner simulations when nominal-corner simulation fails to meet target\nspecifications. Experiments on benchmark circuits demonstrate $\\sim$1.6$\\times$\nimprovement in sample efficiency and $\\sim$4.1$\\times$ improvement in\nsimulation efficiency compared to existing sizing methods. Code and benchmarks\nare publicly available at https://github.com/SeunggeunKimkr/PPAAS", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728PVT\u53d8\u5316\u4e0b\u9ad8\u6548\u81ea\u52a8\u5316\u6a21\u62df\u5668\u4ef6\u5c3a\u5bf8\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5e15\u7d2f\u6258\u524d\u6cbf\u4e3b\u5bfc\u76ee\u6807\u91c7\u6837\u548c\u4fdd\u5b88\u540e\u89c1\u7ecf\u9a8c\u56de\u653e\u7b49\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u548c\u4eff\u771f\u6548\u7387\u3002", "motivation": "\u6a21\u62df\u548c\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u7684\u5668\u4ef6\u5c3a\u5bf8\u8bbe\u8ba1\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u6b65\u9aa4\uff0c\u9700\u8981\u5728\u5de5\u827a\u3001\u7535\u538b\u3001\u6e29\u5ea6(PVT)\u53d8\u5316\u4e0b\u6ee1\u8db3\u591a\u6837\u5316\u7684\u6027\u80fd\u89c4\u8303\u3002\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u5728\u56fa\u5b9a\u76ee\u6807\u7684\u81ea\u52a8\u5316\u5c3a\u5bf8\u8bbe\u8ba1\u4e0a\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u8bad\u7ec3\u4e00\u4e2a\u80fd\u591f\u9002\u5e94PVT\u53d8\u5316\u4e0b\u5e7f\u6cdb\u8bbe\u8ba1\u89c4\u8303\u7684\u901a\u7528\u7b56\u7565\u9700\u8981\u5927\u91cf\u7684\u8bad\u7ec3\u6837\u672c\u548c\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1) \u5e15\u7d2f\u6258\u524d\u6cbf\u4e3b\u5bfc\u76ee\u6807\u91c7\u6837(Pareto-front Dominance Goal Sampling)\uff0c\u901a\u8fc7\u4ece\u5148\u524d\u5b9e\u73b0\u76ee\u6807\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u91c7\u6837\u76ee\u6807\u6765\u6784\u5efa\u81ea\u52a8\u8bfe\u7a0b\uff1b2) \u4fdd\u5b88\u540e\u89c1\u7ecf\u9a8c\u56de\u653e(Conservative Hindsight Experience Replay)\uff0c\u901a\u8fc7\u4e3a\u91cd\u65b0\u6807\u8bb0\u7684\u76ee\u6807\u5206\u914d\u4fdd\u5b88\u865a\u62df\u5956\u52b1\u6765\u7a33\u5b9a\u8bad\u7ec3\u5e76\u52a0\u901f\u6536\u655b\uff1b3) \u5931\u8d25\u8df3\u8fc7\u4eff\u771f\u7b56\u7565(Skip-on-Fail simulation strategy)\uff0c\u5f53\u6807\u79f0\u89d2\u4eff\u771f\u672a\u80fd\u6ee1\u8db3\u76ee\u6807\u89c4\u8303\u65f6\u8df3\u8fc7\u5168\u89d2\u4eff\u771f\u4ee5\u51cf\u5c11\u4eff\u771f\u5f00\u9500\u3002", "result": "\u5728\u57fa\u51c6\u7535\u8def\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u5c3a\u5bf8\u8bbe\u8ba1\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u6837\u672c\u6548\u7387\u4e0a\u63d0\u5347\u4e86\u7ea61.6\u500d\uff0c\u5728\u4eff\u771f\u6548\u7387\u4e0a\u63d0\u5347\u4e86\u7ea64.1\u500d\uff0c\u540c\u65f6\u5177\u6709\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86PVT\u53d8\u5316\u4e0b\u6a21\u62df\u5668\u4ef6\u5c3a\u5bf8\u8bbe\u8ba1\u7684\u6311\u6218\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u76ee\u6807\u91c7\u6837\u7b56\u7565\u548c\u7ecf\u9a8c\u56de\u653e\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u6a21\u62df\u7535\u8def\u81ea\u52a8\u5316\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16953", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.16953", "abs": "https://arxiv.org/abs/2507.16953", "authors": ["Mohammad Reza Rahmani", "Mohammad Hossein Yassaee", "Mohammad Reza Aref"], "title": "Fundamental limits of distributed covariance matrix estimation via a conditional strong data processing inequality", "comment": null, "summary": "Estimating high-dimensional covariance matrices is a key task across many\nfields. This paper explores the theoretical limits of distributed covariance\nestimation in a feature-split setting, where communication between agents is\nconstrained. Specifically, we study a scenario in which multiple agents each\nobserve different components of i.i.d. samples drawn from a sub-Gaussian random\nvector. A central server seeks to estimate the complete covariance matrix using\na limited number of bits communicated by each agent. We obtain a nearly tight\nminimax lower bound for covariance matrix estimation under operator norm and\nFrobenius norm. Our main technical tool is a novel generalization of the strong\ndata processing inequality (SDPI), termed the Conditional Strong Data\nProcessing Inequality (C-SDPI) coefficient, introduced in this work. The C-SDPI\ncoefficient shares key properties such as tensorization with the conventional\nSDPI. Crucially, it quantifies the average contraction in a state-dependent\nchannel and can be significantly lower than the worst-case SDPI coefficient\nover the state input.\n  Utilizing the doubling trick of Geng-Nair and an operator Jensen inequality,\nwe compute this coefficient for Gaussian mixture channels. We then employ it to\nestablish minimax lower bounds on estimation error, capturing the trade-offs\namong sample size, communication cost, and data dimensionality. Building on\nthis, we present a nearly optimal estimation protocol whose sample and\ncommunication requirements match the lower bounds up to logarithmic factors.\nUnlike much of the existing literature, our framework does not assume infinite\nsamples or Gaussian distributions, making it broadly applicable. Finally, we\nextend our analysis to interactive protocols, showing interaction can\nsignificantly reduce communication requirements compared to non-interactive\nschemes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u7279\u5f81\u5206\u5272\u8bbe\u7f6e\u4e0b\u5206\u5e03\u5f0f\u534f\u65b9\u5dee\u4f30\u8ba1\u7684\u7406\u8bba\u6781\u9650\uff0c\u5176\u4e2d\u591a\u4e2a\u667a\u80fd\u4f53\u89c2\u5bdf\u4e0d\u540c\u7684\u6570\u636e\u5206\u91cf\u5e76\u9700\u8981\u5728\u901a\u4fe1\u7ea6\u675f\u4e0b\u4f30\u8ba1\u5b8c\u6574\u7684\u534f\u65b9\u5dee\u77e9\u9635\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u6761\u4ef6\u5f3a\u6570\u636e\u5904\u7406\u4e0d\u7b49\u5f0f(C-SDPI)\u7cfb\u6570\u8fd9\u4e00\u65b0\u5de5\u5177\uff0c\u5e76\u5efa\u7acb\u4e86\u8fd1\u4f3c\u7d27\u81f4\u7684minimax\u4e0b\u754c\uff0c\u540c\u65f6\u7ed9\u51fa\u4e86\u51e0\u4e4e\u6700\u4f18\u7684\u4f30\u8ba1\u534f\u8bae\u3002", "motivation": "\u5728\u8bb8\u591a\u9886\u57df\u4e2d\uff0c\u9ad8\u7ef4\u534f\u65b9\u5dee\u77e9\u9635\u4f30\u8ba1\u662f\u4e00\u4e2a\u5173\u952e\u4efb\u52a1\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u65e0\u9650\u6837\u672c\u6216\u9ad8\u65af\u5206\u5e03\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u901a\u4fe1\u7ea6\u675f\u4e0b\u5206\u5e03\u5f0f\u534f\u65b9\u5dee\u4f30\u8ba1\u7406\u8bba\u6781\u9650\u7684\u6df1\u5165\u7406\u89e3\u3002\u56e0\u6b64\u9700\u8981\u5728\u66f4\u4e00\u822c\u7684\u8bbe\u7f6e\u4e0b\u7814\u7a76\u5206\u5e03\u5f0f\u534f\u65b9\u5dee\u4f30\u8ba1\u7684\u57fa\u672c\u7406\u8bba\u9650\u5236\u3002", "method": "1) \u63d0\u51fa\u4e86\u6761\u4ef6\u5f3a\u6570\u636e\u5904\u7406\u4e0d\u7b49\u5f0f(C-SDPI)\u7cfb\u6570\u8fd9\u4e00\u65b0\u7684\u6280\u672f\u5de5\u5177\uff0c\u5b83\u662f\u4f20\u7edfSDPI\u7684\u63a8\u5e7f\uff1b2) \u5229\u7528Geng-Nair\u7684\u500d\u589e\u6280\u5de7\u548c\u7b97\u5b50Jensen\u4e0d\u7b49\u5f0f\u8ba1\u7b97\u9ad8\u65af\u6df7\u5408\u4fe1\u9053\u7684C-SDPI\u7cfb\u6570\uff1b3) \u8fd0\u7528C-SDPI\u5efa\u7acb\u4f30\u8ba1\u8bef\u5dee\u7684minimax\u4e0b\u754c\uff1b4) \u8bbe\u8ba1\u51e0\u4e4e\u6700\u4f18\u7684\u4f30\u8ba1\u534f\u8bae\uff0c\u5176\u6837\u672c\u548c\u901a\u4fe1\u9700\u6c42\u4e0e\u4e0b\u754c\u5339\u914d\u5230\u5bf9\u6570\u56e0\u5b50\uff1b5) \u6269\u5c55\u5206\u6790\u5230\u4ea4\u4e92\u5f0f\u534f\u8bae\u3002", "result": "1) \u5728\u7b97\u5b50\u8303\u6570\u548cFrobenius\u8303\u6570\u4e0b\u83b7\u5f97\u4e86\u534f\u65b9\u5dee\u77e9\u9635\u4f30\u8ba1\u7684\u8fd1\u4f3c\u7d27\u81f4minimax\u4e0b\u754c\uff1b2) C-SDPI\u7cfb\u6570\u5177\u6709\u5f20\u91cf\u5316\u7b49\u5173\u952e\u6027\u8d28\uff0c\u80fd\u91cf\u5316\u72b6\u6001\u76f8\u5173\u4fe1\u9053\u4e2d\u7684\u5e73\u5747\u6536\u7f29\uff0c\u4e14\u53ef\u4ee5\u663e\u8457\u4f4e\u4e8e\u6700\u574f\u60c5\u51b5\u7684SDPI\u7cfb\u6570\uff1b3) \u63d0\u51fa\u7684\u4f30\u8ba1\u534f\u8bae\u5728\u6837\u672c\u548c\u901a\u4fe1\u9700\u6c42\u4e0a\u51e0\u4e4e\u8fbe\u5230\u6700\u4f18\uff1b4) \u8bc1\u660e\u4e86\u4ea4\u4e92\u5f0f\u534f\u8bae\u76f8\u6bd4\u975e\u4ea4\u4e92\u5f0f\u65b9\u6848\u80fd\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u9700\u6c42\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u5206\u5e03\u5f0f\u534f\u65b9\u5dee\u4f30\u8ba1\u95ee\u9898\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u6837\u672c\u5927\u5c0f\u3001\u901a\u4fe1\u6210\u672c\u548c\u6570\u636e\u7ef4\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002\u63d0\u51fa\u7684C-SDPI\u7cfb\u6570\u4e3a\u5206\u6790\u901a\u4fe1\u7ea6\u675f\u4e0b\u7684\u7edf\u8ba1\u63a8\u65ad\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u5de5\u5177\u3002\u4e0e\u73b0\u6709\u6587\u732e\u4e0d\u540c\uff0c\u8be5\u6846\u67b6\u4e0d\u5047\u8bbe\u65e0\u9650\u6837\u672c\u6216\u9ad8\u65af\u5206\u5e03\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002\u4ea4\u4e92\u5f0f\u534f\u8bae\u7684\u5206\u6790\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86\u901a\u4fe1\u7b56\u7565\u5bf9\u6027\u80fd\u7684\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2507.16833", "categories": ["cs.LG", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2507.16833", "abs": "https://arxiv.org/abs/2507.16833", "authors": ["Qiuyu Shi", "Kangming Li", "Yao Fehlis", "Daniel Persaud", "Robert Black", "Jason Hattrick-Simpers"], "title": "Exploring the Frontiers of kNN Noisy Feature Detection and Recovery for Self-Driving Labs", "comment": "15 pages, 6 figures", "summary": "Self-driving laboratories (SDLs) have shown promise to accelerate materials\ndiscovery by integrating machine learning with automated experimental\nplatforms. However, errors in the capture of input parameters may corrupt the\nfeatures used to model system performance, compromising current and future\ncampaigns. This study develops an automated workflow to systematically detect\nnoisy features, determine sample-feature pairings that can be corrected, and\nfinally recover the correct feature values. A systematic study is then\nperformed to examine how dataset size, noise intensity, and feature value\ndistribution affect both the detectability and recoverability of noisy\nfeatures. In general, high-intensity noise and large training datasets are\nconducive to the detection and correction of noisy features. Low-intensity\nnoise reduces detection and recovery but can be compensated for by larger clean\ntraining data sets. Detection and correction results vary between features with\ncontinuous and dispersed feature distributions showing greater recoverability\ncompared to features with discrete or narrow distributions. This systematic\nstudy not only demonstrates a model agnostic framework for rational data\nrecovery in the presence of noise, limited data, and differing feature\ndistributions but also provides a tangible benchmark of kNN imputation in\nmaterials data sets. Ultimately, it aims to enhance data quality and\nexperimental precision in automated materials discovery.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u6765\u7cfb\u7edf\u6027\u5730\u68c0\u6d4b\u3001\u6821\u6b63\u548c\u6062\u590d\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\u4e2d\u7684\u566a\u58f0\u7279\u5f81\uff0c\u4ee5\u63d0\u9ad8\u6750\u6599\u53d1\u73b0\u7684\u6570\u636e\u8d28\u91cf\u548c\u5b9e\u9a8c\u7cbe\u5ea6\u3002", "motivation": "\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\u5728\u6750\u6599\u53d1\u73b0\u4e2d\u663e\u793a\u51fa\u524d\u666f\uff0c\u4f46\u8f93\u5165\u53c2\u6570\u6355\u83b7\u4e2d\u7684\u9519\u8bef\u53ef\u80fd\u635f\u574f\u7528\u4e8e\u5efa\u6a21\u7cfb\u7edf\u6027\u80fd\u7684\u7279\u5f81\uff0c\u4ece\u800c\u5f71\u54cd\u5f53\u524d\u548c\u672a\u6765\u7684\u5b9e\u9a8c\u6d3b\u52a8\u3002\u9700\u8981\u5f00\u53d1\u65b9\u6cd5\u6765\u7cfb\u7edf\u6027\u5730\u5904\u7406\u8fd9\u4e9b\u566a\u58f0\u7279\u5f81\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u68c0\u6d4b\u566a\u58f0\u7279\u5f81\u3001\u786e\u5b9a\u53ef\u6821\u6b63\u7684\u6837\u672c-\u7279\u5f81\u914d\u5bf9\uff0c\u5e76\u6700\u7ec8\u6062\u590d\u6b63\u786e\u7684\u7279\u5f81\u503c\u3002\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7814\u7a76\u6765\u68c0\u9a8c\u6570\u636e\u96c6\u5927\u5c0f\u3001\u566a\u58f0\u5f3a\u5ea6\u548c\u7279\u5f81\u503c\u5206\u5e03\u5982\u4f55\u5f71\u54cd\u566a\u58f0\u7279\u5f81\u7684\u53ef\u68c0\u6d4b\u6027\u548c\u53ef\u6062\u590d\u6027\u3002", "result": "\u9ad8\u5f3a\u5ea6\u566a\u58f0\u548c\u5927\u578b\u8bad\u7ec3\u6570\u636e\u96c6\u6709\u5229\u4e8e\u566a\u58f0\u7279\u5f81\u7684\u68c0\u6d4b\u548c\u6821\u6b63\u3002\u4f4e\u5f3a\u5ea6\u566a\u58f0\u4f1a\u964d\u4f4e\u68c0\u6d4b\u548c\u6062\u590d\u6548\u679c\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u66f4\u5927\u7684\u6e05\u6d01\u8bad\u7ec3\u6570\u636e\u96c6\u6765\u8865\u507f\u3002\u8fde\u7eed\u548c\u5206\u6563\u7279\u5f81\u5206\u5e03\u6bd4\u79bb\u6563\u6216\u7a84\u5206\u5e03\u7279\u5f81\u663e\u793a\u51fa\u66f4\u597d\u7684\u53ef\u6062\u590d\u6027\u3002\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u6750\u6599\u6570\u636e\u96c6\u4e2dkNN\u63d2\u503c\u7684\u5177\u4f53\u57fa\u51c6\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5b58\u5728\u566a\u58f0\u3001\u6709\u9650\u6570\u636e\u548c\u4e0d\u540c\u7279\u5f81\u5206\u5e03\u60c5\u51b5\u4e0b\u8fdb\u884c\u5408\u7406\u7684\u6570\u636e\u6062\u590d\uff0c\u6700\u7ec8\u65e8\u5728\u63d0\u9ad8\u81ea\u52a8\u5316\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u6570\u636e\u8d28\u91cf\u548c\u5b9e\u9a8c\u7cbe\u5ea6\u3002"}}
{"id": "2507.17106", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17106", "abs": "https://arxiv.org/abs/2507.17106", "authors": ["Jiazhao Wang", "Wenchao Jiang"], "title": "Efficient and Distortion-less Spectrum Multiplexer via Neural Network-based Filter Banks", "comment": null, "summary": "Spectrum multiplexer enables simultaneous transmission of multiple\nnarrow-band IoT signals through gateway devices, thereby enhancing overall\nspectrum utilization. We propose a novel solution based on filter banks that\noffer increased efficiency and minimal distortion compared with conventional\nmethods. We follow a model-driven approach to integrate the neural networks\ninto the filter bank design by interpreting the neural network models as filter\nbanks. The proposed NN-based filter banks can leverage advanced learning\ncapabilities to achieve distortionless multiplexing and harness hardware\nacceleration for high efficiency. Then, we evaluate the performance of the\nspectrum multiplexer implemented by NN-based filter banks for various types of\nsignals and environmental conditions. The results show that it can achieve a\nlow distortion level down to $-39$dB normalized mean squared error.\nFurthermore, it achieves up to $35$ times execution efficiency gain and $10$dB\nSNR gain compared with the conventional methods. The field applications show\nthat it can handle both the heterogeneous and homogeneous IoT networks,\nresulting in high packet reception ratio at the standard receivers up to\n$98\\%$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6ee4\u6ce2\u5668\u7ec4\u9891\u8c31\u590d\u7528\u5668\uff0c\u7528\u4e8e\u7269\u8054\u7f51\u4fe1\u53f7\u7684\u540c\u65f6\u4f20\u8f93\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7387\u548c\u66f4\u4f4e\u5931\u771f", "motivation": "\u4f20\u7edf\u7684\u9891\u8c31\u590d\u7528\u5668\u5728\u5904\u7406\u591a\u4e2a\u7a84\u5e26\u7269\u8054\u7f51\u4fe1\u53f7\u65f6\u5b58\u5728\u6548\u7387\u4f4e\u548c\u5931\u771f\u5927\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u9891\u8c31\u5229\u7528\u7387\u5e76\u964d\u4f4e\u4fe1\u53f7\u5931\u771f", "method": "\u91c7\u7528\u6a21\u578b\u9a71\u52a8\u65b9\u6cd5\uff0c\u5c06\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u89e3\u91ca\u4e3a\u6ee4\u6ce2\u5668\u7ec4\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6ee4\u6ce2\u5668\u7ec4\u9891\u8c31\u590d\u7528\u5668\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u80fd\u529b\u5b9e\u73b0\u65e0\u5931\u771f\u590d\u7528\uff0c\u5e76\u901a\u8fc7\u786c\u4ef6\u52a0\u901f\u63d0\u9ad8\u6548\u7387", "result": "\u5b9e\u73b0\u4e86-39dB\u7684\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u4f4e\u5931\u771f\u6c34\u5e73\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u83b7\u5f97\u4e8635\u500d\u7684\u6267\u884c\u6548\u7387\u63d0\u5347\u548c10dB\u7684\u4fe1\u566a\u6bd4\u589e\u76ca\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5bf9\u5f02\u6784\u548c\u540c\u6784\u7269\u8054\u7f51\u7f51\u7edc\u7684\u6570\u636e\u5305\u63a5\u6536\u7387\u8fbe\u523098%", "conclusion": "\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6ee4\u6ce2\u5668\u7ec4\u9891\u8c31\u590d\u7528\u5668\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u4e2a\u7269\u8054\u7f51\u4fe1\u53f7\u7684\u540c\u65f6\u4f20\u8f93\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9891\u8c31\u5229\u7528\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u4fe1\u53f7\u5931\u771f\uff0c\u5728\u5b9e\u9645\u7269\u8054\u7f51\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272"}}
{"id": "2507.16999", "categories": ["stat.ML", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16999", "abs": "https://arxiv.org/abs/2507.16999", "authors": ["Felix Huber", "Sebastian Rojas Gonzalez", "Raul Astudillo"], "title": "Bayesian preference elicitation for decision support in multiobjective optimization", "comment": "16 pages, 5 figures", "summary": "We present a novel approach to help decision-makers efficiently identify\npreferred solutions from the Pareto set of a multi-objective optimization\nproblem. Our method uses a Bayesian model to estimate the decision-maker's\nutility function based on pairwise comparisons. Aided by this model, a\nprincipled elicitation strategy selects queries interactively to balance\nexploration and exploitation, guiding the discovery of high-utility solutions.\nThe approach is flexible: it can be used interactively or a posteriori after\nestimating the Pareto front through standard multi-objective optimization\ntechniques. Additionally, at the end of the elicitation phase, it generates a\nreduced menu of high-quality solutions, simplifying the decision-making\nprocess. Through experiments on test problems with up to nine objectives, our\nmethod demonstrates superior performance in finding high-utility solutions with\na small number of queries. We also provide an open-source implementation of our\nmethod to support its adoption by the broader community.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u4ea4\u4e92\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u6210\u5bf9\u6bd4\u8f83\u6765\u4f30\u8ba1\u51b3\u7b56\u8005\u7684\u6548\u7528\u51fd\u6570\uff0c\u4ece\u800c\u5e2e\u52a9\u51b3\u7b56\u8005\u4ece\u591a\u76ee\u6807\u4f18\u5316\u7684\u5e15\u7d2f\u6258\u96c6\u4e2d\u9ad8\u6548\u8bc6\u522b\u504f\u597d\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5728\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u4e2d\uff0c\u51b3\u7b56\u8005\u9700\u8981\u4ece\u5e9e\u5927\u7684\u5e15\u7d2f\u6258\u89e3\u96c6\u4e2d\u9009\u62e9\u6700\u7b26\u5408\u5176\u504f\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u590d\u6742\u4e14\u8017\u65f6\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6709\u6548\u7684\u4ea4\u4e92\u5f0f\u7b56\u7565\u6765\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\uff0c\u96be\u4ee5\u5feb\u901f\u51c6\u786e\u5730\u8bc6\u522b\u9ad8\u6548\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u6a21\u578b\u57fa\u4e8e\u6210\u5bf9\u6bd4\u8f83\u6765\u4f30\u8ba1\u51b3\u7b56\u8005\u7684\u6548\u7528\u51fd\u6570\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u542f\u53d1\u7b56\u7565\u6765\u4ea4\u4e92\u5f0f\u5730\u9009\u62e9\u67e5\u8be2\uff0c\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\u8fc7\u7a0b\u3002\u8be5\u65b9\u6cd5\u65e2\u53ef\u4ee5\u4ea4\u4e92\u5f0f\u4f7f\u7528\uff0c\u4e5f\u53ef\u4ee5\u5728\u901a\u8fc7\u6807\u51c6\u591a\u76ee\u6807\u4f18\u5316\u6280\u672f\u4f30\u8ba1\u5e15\u7d2f\u6258\u524d\u6cbf\u540e\u8fdb\u884c\u540e\u9a8c\u5206\u6790\u3002", "result": "\u5728\u6700\u591a\u4e5d\u4e2a\u76ee\u6807\u7684\u6d4b\u8bd5\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7528\u5c11\u91cf\u67e5\u8be2\u627e\u5230\u9ad8\u6548\u7528\u89e3\u51b3\u65b9\u6848\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002\u65b9\u6cd5\u5728\u542f\u53d1\u9636\u6bb5\u7ed3\u675f\u65f6\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u89e3\u51b3\u65b9\u6848\u7684\u7cbe\u7b80\u83dc\u5355\uff0c\u7b80\u5316\u51b3\u7b56\u8fc7\u7a0b\u3002\u4f5c\u8005\u8fd8\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u4ea4\u4e92\u5f0f\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e2e\u52a9\u51b3\u7b56\u8005\u4ece\u591a\u76ee\u6807\u4f18\u5316\u7684\u5e15\u7d2f\u6258\u96c6\u4e2d\u8bc6\u522b\u504f\u597d\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u7075\u6d3b\u6027\u5f3a\u3001\u67e5\u8be2\u6548\u7387\u9ad8\u3001\u51b3\u7b56\u7b80\u5316\u7b49\u4f18\u70b9\uff0c\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u7684\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.16844", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16844", "abs": "https://arxiv.org/abs/2507.16844", "authors": ["Jie He", "Vincent Theo Willem Kenbeek", "Zhantao Yang", "Meixun Qu", "Ezio Bartocci", "Dejan Ni\u010dkovi\u0107", "Radu Grosu"], "title": "TD-Interpreter: Enhancing the Understanding of Timing Diagrams with Visual-Language Learning", "comment": null, "summary": "We introduce TD-Interpreter, a specialized ML tool that assists engineers in\nunderstanding complex timing diagrams (TDs), originating from a third party,\nduring their design and verification process. TD-Interpreter is a visual\nquestion-answer environment which allows engineers to input a set of TDs and\nask design and verification queries regarding these TDs. We implemented\nTD-Interpreter with multimodal learning by fine-tuning LLaVA, a lightweight 7B\nMultimodal Large Language Model (MLLM). To address limited training data\navailability, we developed a synthetic data generation workflow that aligns\nvisual information with its textual interpretation. Our experimental evaluation\ndemonstrates the usefulness of TD-Interpreter which outperformed untuned GPT-4o\nby a large margin on the evaluated benchmarks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86TD-Interpreter\uff0c\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e13\u4e1a\u5de5\u5177\uff0c\u5e2e\u52a9\u5de5\u7a0b\u5e08\u7406\u89e3\u548c\u5206\u6790\u590d\u6742\u7684\u65f6\u5e8f\u56fe\uff0c\u901a\u8fc7\u5fae\u8c03LLaVA\u6a21\u578b\u5b9e\u73b0\u89c6\u89c9\u95ee\u7b54\u529f\u80fd\uff0c\u5e76\u5f00\u53d1\u4e86\u5408\u6210\u6570\u636e\u751f\u6210\u5de5\u4f5c\u6d41\u6765\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5de5\u7a0b\u5e08\u5728\u8bbe\u8ba1\u548c\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u9700\u8981\u7406\u89e3\u6765\u81ea\u7b2c\u4e09\u65b9\u7684\u590d\u6742\u65f6\u5e8f\u56fe\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5de5\u5177\u6765\u8f85\u52a9\u5206\u6790\u548c\u56de\u7b54\u76f8\u5173\u7684\u8bbe\u8ba1\u9a8c\u8bc1\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5fae\u8c03\u8f7b\u91cf\u7ea7\u76847B\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bLLaVA\u6765\u5b9e\u73b0TD-Interpreter\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u89c6\u89c9\u95ee\u7b54\u73af\u5883\uff0c\u5e76\u5f00\u53d1\u4e86\u5408\u6210\u6570\u636e\u751f\u6210\u5de5\u4f5c\u6d41\u6765\u5c06\u89c6\u89c9\u4fe1\u606f\u4e0e\u6587\u672c\u89e3\u91ca\u5bf9\u9f50\uff0c\u4ee5\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793aTD-Interpreter\u5728\u8bc4\u4f30\u57fa\u51c6\u4e0a\u5927\u5e45\u8d85\u8d8a\u4e86\u672a\u8c03\u4f18\u7684GPT-4o\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u8be5\u5de5\u5177\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "TD-Interpreter\u6210\u529f\u5730\u4e3a\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e13\u4e1a\u7684\u65f6\u5e8f\u56fe\u7406\u89e3\u5de5\u5177\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u65f6\u5e8f\u56fe\u5206\u6790\u7684\u6311\u6218\uff0c\u5728\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u901a\u7528\u6a21\u578b\u3002"}}
{"id": "2507.17153", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17153", "abs": "https://arxiv.org/abs/2507.17153", "authors": ["Junjie Fang", "Chao Zhang", "Jiancheng An", "Hongwen Yu", "Qingqing Wu", "M\u00e9rouane Debbah", "Chau Yuen"], "title": "Stacked Intelligent Metasurface Assisted Multiuser Communications: From a Rate Fairness Perspective", "comment": null, "summary": "Stacked intelligent metasurface (SIM) extends the concept of single-layer\nreconfigurable holographic surfaces (RHS) by incorporating a multi-layered\nstructure, thereby providing enhanced control over electromagnetic wave\npropagation and improved signal processing capabilities. This study\ninvestigates the potential of SIM in enhancing the rate fairness in multiuser\ndownlink systems by addressing two key optimization problems: maximizing the\nminimum rate (MR) and maximizing the geometric mean of rates (GMR). {The former\nstrives to enhance the minimum user rate, thereby ensuring fairness among\nusers, while the latter relaxes fairness requirements to strike a better\ntrade-off between user fairness and system sum-rate (SR).} For the MR\nmaximization, we adopt a consensus alternating direction method of multipliers\n(ADMM)-based approach, which decomposes the approximated problem into\nsub-problems with closed-form solutions. {For GMR maximization, we develop an\nalternating optimization (AO)-based algorithm that also yields closed-form\nsolutions and can be seamlessly adapted for SR maximization. Numerical results\nvalidate the effectiveness and convergence of the proposed algorithms.}\nComparative evaluations show that MR maximization ensures near-perfect\nfairness, while GMR maximization balances fairness and system SR. Furthermore,\nthe two proposed algorithms respectively outperform existing related works in\nterms of MR and SR performance. Lastly, SIM with lower power consumption\nachieves performance comparable to that of multi-antenna digital beamforming.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5806\u53e0\u667a\u80fd\u8d85\u8868\u9762(SIM)\u5728\u591a\u7528\u6237\u4e0b\u884c\u7cfb\u7edf\u4e2d\u63d0\u5347\u901f\u7387\u516c\u5e73\u6027\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u6700\u5927\u5316\u6700\u5c0f\u901f\u7387(MR)\u548c\u51e0\u4f55\u5e73\u5747\u901f\u7387(GMR)\u4e24\u79cd\u4f18\u5316\u95ee\u9898\u6765\u6539\u5584\u7528\u6237\u95f4\u7684\u516c\u5e73\u6027\u548c\u7cfb\u7edf\u6027\u80fd", "motivation": "\u4f20\u7edf\u5355\u5c42\u53ef\u91cd\u6784\u5168\u606f\u8868\u9762(RHS)\u5728\u7535\u78c1\u6ce2\u4f20\u64ad\u63a7\u5236\u548c\u4fe1\u53f7\u5904\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u9700\u8981\u901a\u8fc7\u591a\u5c42\u7ed3\u6784\u7684\u5806\u53e0\u667a\u80fd\u8d85\u8868\u9762\u6765\u589e\u5f3a\u63a7\u5236\u80fd\u529b\uff0c\u540c\u65f6\u89e3\u51b3\u591a\u7528\u6237\u4e0b\u884c\u7cfb\u7edf\u4e2d\u7528\u6237\u95f4\u901f\u7387\u516c\u5e73\u6027\u7684\u95ee\u9898", "method": "\u9488\u5bf9MR\u6700\u5927\u5316\u95ee\u9898\u91c7\u7528\u57fa\u4e8e\u4e00\u81f4\u6027\u4ea4\u66ff\u65b9\u5411\u4e58\u6570\u6cd5(consensus ADMM)\u7684\u65b9\u6cd5\uff0c\u5c06\u8fd1\u4f3c\u95ee\u9898\u5206\u89e3\u4e3a\u5177\u6709\u95ed\u5f0f\u89e3\u7684\u5b50\u95ee\u9898\uff1b\u9488\u5bf9GMR\u6700\u5927\u5316\u95ee\u9898\u5f00\u53d1\u4e86\u57fa\u4e8e\u4ea4\u66ff\u4f18\u5316(AO)\u7684\u7b97\u6cd5\uff0c\u540c\u6837\u83b7\u5f97\u95ed\u5f0f\u89e3\u5e76\u53ef\u9002\u914dSR\u6700\u5927\u5316", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u6536\u655b\u6027\uff1bMR\u6700\u5927\u5316\u786e\u4fdd\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u516c\u5e73\u6027\uff0cGMR\u6700\u5927\u5316\u5728\u516c\u5e73\u6027\u548c\u7cfb\u7edf\u603b\u901f\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff1b\u4e24\u79cd\u7b97\u6cd5\u5728MR\u548cSR\u6027\u80fd\u65b9\u9762\u5206\u522b\u4f18\u4e8e\u73b0\u6709\u76f8\u5173\u5de5\u4f5c\uff1bSIM\u4ee5\u66f4\u4f4e\u529f\u8017\u5b9e\u73b0\u4e86\u4e0e\u591a\u5929\u7ebf\u6570\u5b57\u6ce2\u675f\u6210\u5f62\u76f8\u5f53\u7684\u6027\u80fd", "conclusion": "\u5806\u53e0\u667a\u80fd\u8d85\u8868\u9762\u901a\u8fc7\u591a\u5c42\u7ed3\u6784\u8bbe\u8ba1\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u7528\u6237\u4e0b\u884c\u7cfb\u7edf\u7684\u901f\u7387\u516c\u5e73\u6027\uff0c\u6240\u63d0\u51fa\u7684\u4e24\u79cd\u4f18\u5316\u7b97\u6cd5\u5206\u522b\u5728\u4fdd\u8bc1\u7528\u6237\u516c\u5e73\u6027\u548c\u5e73\u8861\u7cfb\u7edf\u6027\u80fd\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u548c\u66f4\u4f4e\u7684\u529f\u8017"}}
{"id": "2507.17026", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17026", "abs": "https://arxiv.org/abs/2507.17026", "authors": ["Vansh Bansal", "Tianyu Chen", "James G. Scott"], "title": "The surprising strength of weak classifiers for validating neural posterior estimates", "comment": null, "summary": "Neural Posterior Estimation (NPE) has emerged as a powerful approach for\namortized Bayesian inference when the true posterior $p(\\theta \\mid y)$ is\nintractable or difficult to sample. But evaluating the accuracy of neural\nposterior estimates remains challenging, with existing methods suffering from\nmajor limitations. One appealing and widely used method is the classifier\ntwo-sample test (C2ST), where a classifier is trained to distinguish samples\nfrom the true posterior $p(\\theta \\mid y)$ versus the learned NPE approximation\n$q(\\theta \\mid y)$. Yet despite the appealing simplicity of the C2ST, its\ntheoretical and practical reliability depend upon having access to a\nnear-Bayes-optimal classifier -- a requirement that is rarely met and, at best,\ndifficult to verify. Thus a major open question is: can a weak classifier still\nbe useful for neural posterior validation? We show that the answer is yes.\nBuilding on the work of Hu and Lei, we present several key results for a\nconformal variant of the C2ST, which converts any trained classifier's scores\n-- even those of weak or over-fitted models -- into exact finite-sample\np-values. We establish two key theoretical properties of the conformal C2ST:\n(i) finite-sample Type-I error control, and (ii) non-trivial power that\ndegrades gently in tandem with the error of the trained classifier. The upshot\nis that even weak, biased, or overfit classifiers can still yield powerful and\nreliable tests. Empirically, the Conformal C2ST outperforms classical\ndiscriminative tests across a wide range of benchmarks. These results reveal\nthe under appreciated strength of weak classifiers for validating neural\nposterior estimates, establishing the conformal C2ST as a practical,\ntheoretically grounded diagnostic for modern simulation-based inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u7684\u5206\u7c7b\u5668\u53cc\u6837\u672c\u68c0\u9a8c\u65b9\u6cd5(Conformal C2ST)\uff0c\u7528\u4e8e\u9a8c\u8bc1\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5c06\u4efb\u4f55\u8bad\u7ec3\u5206\u7c7b\u5668\u7684\u5206\u6570\u8f6c\u6362\u4e3a\u7cbe\u786e\u7684\u6709\u9650\u6837\u672cp\u503c\uff0c\u5373\u4f7f\u662f\u5f31\u5206\u7c7b\u5668\u6216\u8fc7\u62df\u5408\u6a21\u578b\u4e5f\u80fd\u63d0\u4f9b\u53ef\u9760\u7684\u68c0\u9a8c\u7ed3\u679c\u3002", "motivation": "\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1(NPE)\u5728\u8d1d\u53f6\u65af\u63a8\u65ad\u4e2d\u5f88\u6709\u7528\uff0c\u4f46\u8bc4\u4f30\u5176\u51c6\u786e\u6027\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u7684\u5206\u7c7b\u5668\u53cc\u6837\u672c\u68c0\u9a8c(C2ST)\u65b9\u6cd5\u9700\u8981\u63a5\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u7684\u5206\u7c7b\u5668\u624d\u80fd\u53ef\u9760\u5de5\u4f5c\uff0c\u8fd9\u4e2a\u8981\u6c42\u5728\u5b9e\u9645\u4e2d\u5f88\u96be\u6ee1\u8db3\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5f31\u5206\u7c7b\u5668\u662f\u5426\u4ecd\u80fd\u7528\u4e8e\u795e\u7ecf\u540e\u9a8c\u9a8c\u8bc1\u6210\u4e3a\u4e00\u4e2a\u91cd\u8981\u7684\u5f00\u653e\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u57fa\u4e8eHu\u548cLei\u7684\u5de5\u4f5c\uff0c\u63d0\u51fa\u4e86C2ST\u7684\u4fdd\u5f62\u53d8\u4f53\u3002\u8be5\u65b9\u6cd5\u5c06\u4efb\u4f55\u8bad\u7ec3\u5206\u7c7b\u5668\u7684\u5206\u6570\u8f6c\u6362\u4e3a\u7cbe\u786e\u7684\u6709\u9650\u6837\u672cp\u503c\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u5206\u7c7b\u5668\u7684\u8d28\u91cf\u3002\u65b9\u6cd5\u5efa\u7acb\u5728\u4fdd\u5f62\u9884\u6d4b\u7406\u8bba\u57fa\u7840\u4e0a\uff0c\u80fd\u591f\u5904\u7406\u5f31\u5206\u7c7b\u5668\u3001\u6709\u504f\u5206\u7c7b\u5668\u6216\u8fc7\u62df\u5408\u5206\u7c7b\u5668\u7684\u60c5\u51b5\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u4fdd\u5f62C2ST\u5177\u6709\u4e24\u4e2a\u5173\u952e\u6027\u8d28\uff1a(i)\u6709\u9650\u6837\u672c\u7684I\u578b\u9519\u8bef\u63a7\u5236\uff0c(ii)\u975e\u5e73\u51e1\u7684\u68c0\u9a8c\u529f\u6548\uff0c\u4e14\u8be5\u529f\u6548\u4e0e\u8bad\u7ec3\u5206\u7c7b\u5668\u7684\u9519\u8bef\u7387\u6e29\u548c\u5730\u76f8\u5173\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4fdd\u5f62C2ST\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u7ecf\u5178\u7684\u5224\u522b\u68c0\u9a8c\u65b9\u6cd5\u3002", "conclusion": "\u5373\u4f7f\u662f\u5f31\u7684\u3001\u6709\u504f\u7684\u6216\u8fc7\u62df\u5408\u7684\u5206\u7c7b\u5668\u4ecd\u7136\u53ef\u4ee5\u4ea7\u751f\u5f3a\u5927\u4e14\u53ef\u9760\u7684\u68c0\u9a8c\u7ed3\u679c\u3002\u4fdd\u5f62C2ST\u63ed\u793a\u4e86\u5f31\u5206\u7c7b\u5668\u5728\u9a8c\u8bc1\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1\u65b9\u9762\u88ab\u4f4e\u4f30\u7684\u4f18\u52bf\uff0c\u4e3a\u73b0\u4ee3\u57fa\u4e8e\u4eff\u771f\u7684\u63a8\u65ad\u5efa\u7acb\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u3001\u7406\u8bba\u57fa\u7840\u624e\u5b9e\u7684\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2507.16864", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16864", "abs": "https://arxiv.org/abs/2507.16864", "authors": ["Tao Xu", "Dung-Yang Lee", "Momiao Xiong"], "title": "Reinforcement Learning in hyperbolic space for multi-step reasoning", "comment": "53 pages, 5 figures", "summary": "Multi-step reasoning is a fundamental challenge in artificial intelligence,\nwith applications ranging from mathematical problem-solving to decision-making\nin dynamic environments. Reinforcement Learning (RL) has shown promise in\nenabling agents to perform multi-step reasoning by optimizing long-term\nrewards. However, conventional RL methods struggle with complex reasoning tasks\ndue to issues such as credit assignment, high-dimensional state\nrepresentations, and stability concerns. Recent advancements in Transformer\narchitectures and hyperbolic geometry have provided novel solutions to these\nchallenges. This paper introduces a new framework that integrates hyperbolic\nTransformers into RL for multi-step reasoning. The proposed approach leverages\nhyperbolic embeddings to model hierarchical structures effectively. We present\ntheoretical insights, algorithmic details, and experimental results that\ninclude Frontier Math and nonlinear optimal control problems. Compared to RL\nwith vanilla transformer, the hyperbolic RL largely improves accuracy by\n(32%~44%) on FrontierMath benchmark, (43%~45%) on nonlinear optimal control\nbenchmark, while achieving impressive reduction in computational time by\n(16%~32%) on FrontierMath benchmark, (16%~17%) on nonlinear optimal control\nbenchmark. Our work demonstrates the potential of hyperbolic Transformers in\nreinforcement learning, particularly for multi-step reasoning tasks that\ninvolve hierarchical structures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u53cc\u66f2\u53d8\u6362\u5668\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u53cc\u66f2\u5d4c\u5165\u6709\u6548\u5efa\u6a21\u5c42\u6b21\u7ed3\u6784\uff0c\u5728FrontierMath\u548c\u975e\u7ebf\u6027\u6700\u4f18\u63a7\u5236\u95ee\u9898\u4e0a\u76f8\u6bd4\u666e\u901a\u53d8\u6362\u5668\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\uff0832%-45%\uff09\u5e76\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\uff0816%-32%\uff09\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65f6\u9762\u4e34\u4fe1\u7528\u5206\u914d\u3001\u9ad8\u7ef4\u72b6\u6001\u8868\u793a\u548c\u7a33\u5b9a\u6027\u7b49\u95ee\u9898\u3002\u591a\u6b65\u63a8\u7406\u662f\u4eba\u5de5\u667a\u80fd\u7684\u57fa\u672c\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5904\u7406\u6d89\u53ca\u5c42\u6b21\u7ed3\u6784\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u53cc\u66f2\u53d8\u6362\u5668\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u65b0\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u53cc\u66f2\u5d4c\u5165\u6765\u6709\u6548\u5efa\u6a21\u5c42\u6b21\u7ed3\u6784\uff0c\u7ed3\u5408\u4e86\u53d8\u6362\u5668\u67b6\u6784\u548c\u53cc\u66f2\u51e0\u4f55\u7684\u6700\u65b0\u8fdb\u5c55\u6765\u89e3\u51b3\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7684\u6311\u6218\u3002", "result": "\u5728FrontierMath\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u6027\u63d0\u534732%-44%\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1116%-32%\uff1b\u5728\u975e\u7ebf\u6027\u6700\u4f18\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u6027\u63d0\u534743%-45%\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1116%-17%\u3002\u76f8\u6bd4\u4f7f\u7528\u666e\u901a\u53d8\u6362\u5668\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6027\u80fd\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u53cc\u66f2\u53d8\u6362\u5668\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u5c42\u6b21\u7ed3\u6784\u7684\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u3002\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u591a\u6b65\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17030", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17030", "abs": "https://arxiv.org/abs/2507.17030", "authors": ["Tianyu Chen", "Vansh Bansal", "James G. Scott"], "title": "CoLT: The conditional localization test for assessing the accuracy of neural posterior estimates", "comment": null, "summary": "We consider the problem of validating whether a neural posterior estimate \\(\nq(\\theta \\mid x) \\) is an accurate approximation to the true, unknown true\nposterior \\( p(\\theta \\mid x) \\). Existing methods for evaluating the quality\nof an NPE estimate are largely derived from classifier-based tests or\ndivergence measures, but these suffer from several practical drawbacks. As an\nalternative, we introduce the \\emph{Conditional Localization Test} (CoLT), a\nprincipled method designed to detect discrepancies between \\( p(\\theta \\mid x)\n\\) and \\( q(\\theta \\mid x) \\) across the full range of conditioning inputs.\nRather than relying on exhaustive comparisons or density estimation at every \\(\nx \\), CoLT learns a localization function that adaptively selects points\n$\\theta_l(x)$ where the neural posterior $q$ deviates most strongly from the\ntrue posterior $p$ for that $x$. This approach is particularly advantageous in\ntypical simulation-based inference settings, where only a single draw \\( \\theta\n\\sim p(\\theta \\mid x) \\) from the true posterior is observed for each\nconditioning input, but where the neural posterior \\( q(\\theta \\mid x) \\) can\nbe sampled an arbitrary number of times. Our theoretical results establish\nnecessary and sufficient conditions for assessing distributional equality\nacross all \\( x \\), offering both rigorous guarantees and practical\nscalability. Empirically, we demonstrate that CoLT not only performs better\nthan existing methods at comparing $p$ and $q$, but also pinpoints regions of\nsignificant divergence, providing actionable insights for model refinement.\nThese properties position CoLT as a state-of-the-art solution for validating\nneural posterior estimates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6761\u4ef6\u5b9a\u4f4d\u6d4b\u8bd5(CoLT)\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1q(\u03b8|x)\u662f\u5426\u51c6\u786e\u903c\u8fd1\u771f\u5b9e\u540e\u9a8cp(\u03b8|x)\uff0c\u901a\u8fc7\u5b66\u4e60\u5b9a\u4f4d\u51fd\u6570\u81ea\u9002\u5e94\u9009\u62e9\u795e\u7ecf\u540e\u9a8c\u4e0e\u771f\u5b9e\u540e\u9a8c\u5dee\u5f02\u6700\u5927\u7684\u70b9\uff0c\u5728\u4eff\u771f\u63a8\u65ad\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1(NPE)\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u5206\u7c7b\u5668\u6d4b\u8bd5\u6216\u6563\u5ea6\u5ea6\u91cf\uff0c\u5b58\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8bf8\u591a\u7f3a\u9677\u3002\u9700\u8981\u4e00\u79cd\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1\u4e0e\u771f\u5b9e\u540e\u9a8c\u5728\u6240\u6709\u6761\u4ef6\u8f93\u5165\u8303\u56f4\u5185\u7684\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u5178\u578b\u7684\u4eff\u771f\u63a8\u65ad\u8bbe\u7f6e\u4e2d", "method": "\u63d0\u51fa\u6761\u4ef6\u5b9a\u4f4d\u6d4b\u8bd5(CoLT)\u65b9\u6cd5\uff0c\u5b66\u4e60\u4e00\u4e2a\u5b9a\u4f4d\u51fd\u6570\u6765\u81ea\u9002\u5e94\u5730\u9009\u62e9\u70b9\u03b8_l(x)\uff0c\u8fd9\u4e9b\u70b9\u662f\u795e\u7ecf\u540e\u9a8cq\u5728\u7ed9\u5b9ax\u4e0b\u4e0e\u771f\u5b9e\u540e\u9a8cp\u504f\u5dee\u6700\u5927\u7684\u4f4d\u7f6e\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u5728\u6bcf\u4e2ax\u5904\u8fdb\u884c\u8be6\u5c3d\u6bd4\u8f83\u6216\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u800c\u662f\u5229\u7528\u4ece\u771f\u5b9e\u540e\u9a8c\u7684\u5355\u6b21\u62bd\u6837\u548c\u795e\u7ecf\u540e\u9a8c\u7684\u4efb\u610f\u6b21\u62bd\u6837", "result": "\u7406\u8bba\u7ed3\u679c\u5efa\u7acb\u4e86\u8bc4\u4f30\u6240\u6709x\u4e0a\u5206\u5e03\u76f8\u7b49\u6027\u7684\u5145\u8981\u6761\u4ef6\uff0c\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u4fdd\u8bc1\u548c\u5b9e\u7528\u7684\u53ef\u6269\u5c55\u6027\u3002\u5b9e\u9a8c\u8868\u660eCoLT\u4e0d\u4ec5\u5728\u6bd4\u8f83p\u548cq\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u80fd\u7cbe\u786e\u5b9a\u4f4d\u663e\u8457\u5dee\u5f02\u533a\u57df\uff0c\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3", "conclusion": "CoLT\u4f5c\u4e3a\u9a8c\u8bc1\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1\u7684\u6700\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u68c0\u6d4b\u5206\u5e03\u5dee\u5f02\u548c\u5b9a\u4f4d\u95ee\u9898\u533a\u57df\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1\u7684\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u4e14\u5b9e\u7528\u7684\u5de5\u5177"}}
{"id": "2507.16867", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16867", "abs": "https://arxiv.org/abs/2507.16867", "authors": ["Yunyi Zhao", "Wei Zhang", "Cheng Xiang", "Hongyang Du", "Dusit Niyato", "Shuhua Gao"], "title": "Diffusion-Modeled Reinforcement Learning for Carbon and Risk-Aware Microgrid Optimization", "comment": "10 pages, 5 figures", "summary": "This paper introduces DiffCarl, a diffusion-modeled carbon- and risk-aware\nreinforcement learning algorithm for intelligent operation of multi-microgrid\nsystems. With the growing integration of renewables and increasing system\ncomplexity, microgrid communities face significant challenges in real-time\nenergy scheduling and optimization under uncertainty. DiffCarl integrates a\ndiffusion model into a deep reinforcement learning (DRL) framework to enable\nadaptive energy scheduling under uncertainty and explicitly account for carbon\nemissions and operational risk. By learning action distributions through a\ndenoising generation process, DiffCarl enhances DRL policy expressiveness and\nenables carbon- and risk-aware scheduling in dynamic and uncertain microgrid\nenvironments. Extensive experimental studies demonstrate that it outperforms\nclassic algorithms and state-of-the-art DRL solutions, with 2.3-30.1% lower\noperational cost. It also achieves 28.7% lower carbon emissions than those of\nits carbon-unaware variant and reduces performance variability. These results\nhighlight DiffCarl as a practical and forward-looking solution. Its flexible\ndesign allows efficient adaptation to different system configurations and\nobjectives to support real-world deployment in evolving energy systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDiffCarl\u7b97\u6cd5\uff0c\u5c06\u6269\u6563\u6a21\u578b\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u7528\u4e8e\u591a\u5fae\u7535\u7f51\u7cfb\u7edf\u7684\u667a\u80fd\u8fd0\u884c\uff0c\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u5b9e\u73b0\u78b3\u6392\u653e\u548c\u98ce\u9669\u611f\u77e5\u7684\u81ea\u9002\u5e94\u80fd\u6e90\u8c03\u5ea6", "motivation": "\u968f\u7740\u53ef\u518d\u751f\u80fd\u6e90\u96c6\u6210\u589e\u957f\u548c\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u5fae\u7535\u7f51\u793e\u533a\u5728\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u7684\u5b9e\u65f6\u80fd\u6e90\u8c03\u5ea6\u548c\u4f18\u5316\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u8003\u8651\u78b3\u6392\u653e\u548c\u8fd0\u884c\u98ce\u9669\u7684\u667a\u80fd\u8c03\u5ea6\u65b9\u6cd5", "method": "\u5c06\u6269\u6563\u6a21\u578b\u96c6\u6210\u5230\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u53bb\u566a\u751f\u6210\u8fc7\u7a0b\u5b66\u4e60\u52a8\u4f5c\u5206\u5e03\uff0c\u589e\u5f3aDRL\u7b56\u7565\u8868\u8fbe\u80fd\u529b\uff0c\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u7684\u5fae\u7535\u7f51\u73af\u5883\u4e2d\u5b9e\u73b0\u78b3\u6392\u653e\u548c\u98ce\u9669\u611f\u77e5\u7684\u8c03\u5ea6", "result": "\u76f8\u6bd4\u7ecf\u5178\u7b97\u6cd5\u548c\u6700\u5148\u8fdb\u7684DRL\u89e3\u51b3\u65b9\u6848\uff0c\u8fd0\u884c\u6210\u672c\u964d\u4f4e2.3-30.1%\uff1b\u76f8\u6bd4\u78b3\u6392\u653e\u65e0\u611f\u77e5\u53d8\u4f53\uff0c\u78b3\u6392\u653e\u964d\u4f4e28.7%\uff1b\u540c\u65f6\u51cf\u5c11\u4e86\u6027\u80fd\u53d8\u5f02\u6027", "conclusion": "DiffCarl\u662f\u4e00\u4e2a\u5b9e\u7528\u4e14\u524d\u77bb\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u7075\u6d3b\u8bbe\u8ba1\u5141\u8bb8\u9ad8\u6548\u9002\u5e94\u4e0d\u540c\u7cfb\u7edf\u914d\u7f6e\u548c\u76ee\u6807\uff0c\u652f\u6301\u5728\u4e0d\u65ad\u53d1\u5c55\u7684\u80fd\u6e90\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72"}}
{"id": "2507.17196", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17196", "abs": "https://arxiv.org/abs/2507.17196", "authors": ["Hyelin Nam", "Jihong Park", "Jinho Choi", "Seong-Lyun Kim"], "title": "Hybrid Semantic-Complementary Transmission for High-Fidelity Image Reconstruction", "comment": null, "summary": "Recent advances in semantic communication (SC) have introduced neural network\n(NN)-based transceivers that convey semantic representation (SR) of signals\nsuch as images. However, these NNs are trained over diverse image distributions\nand thus often fail to reconstruct fine-grained image-specific details. To\novercome this limited reconstruction fidelity, we propose an extended SC\nframework, hybrid semantic communication (HSC), which supplements SR with\ncomplementary representation (CR) capturing residual image-specific\ninformation. The CR is constructed at the transmitter, and is combined with the\nactual SC outcome at the receiver to yield a high-fidelity recomposed image.\nWhile the transmission load of SR is fixed due to its NN-based structure, the\nload of CR can be flexibly adjusted to achieve a desirable fidelity. This\ncontrollability directly influences the final reconstruction error, for which\nwe derive a closed-form expression and the corresponding optimal CR. Simulation\nresults demonstrate that HSC substantially reduces MSE compared to the baseline\nSC without CR transmission across various channels and NN architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6df7\u5408\u8bed\u4e49\u901a\u4fe1(HSC)\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u8868\u793a(SR)\u548c\u4e92\u8865\u8868\u793a(CR)\u6765\u6539\u5584\u795e\u7ecf\u7f51\u7edc\u5728\u56fe\u50cf\u91cd\u6784\u4e2d\u7684\u4fdd\u771f\u5ea6\u95ee\u9898", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u8bed\u4e49\u901a\u4fe1\u6536\u53d1\u5668\u5728\u591a\u6837\u5316\u56fe\u50cf\u5206\u5e03\u4e0a\u8bad\u7ec3\uff0c\u5f80\u5f80\u65e0\u6cd5\u91cd\u6784\u7ec6\u7c92\u5ea6\u7684\u56fe\u50cf\u7279\u5b9a\u7ec6\u8282\uff0c\u5bfc\u81f4\u91cd\u6784\u4fdd\u771f\u5ea6\u6709\u9650", "method": "\u8bbe\u8ba1\u4e86\u6df7\u5408\u8bed\u4e49\u901a\u4fe1(HSC)\u6846\u67b6\uff0c\u5728\u53d1\u9001\u7aef\u6784\u5efa\u6355\u83b7\u6b8b\u4f59\u56fe\u50cf\u7279\u5b9a\u4fe1\u606f\u7684\u4e92\u8865\u8868\u793a(CR)\uff0c\u5728\u63a5\u6536\u7aef\u5c06CR\u4e0e\u8bed\u4e49\u901a\u4fe1\u7ed3\u679c\u7ed3\u5408\u4ee5\u4ea7\u751f\u9ad8\u4fdd\u771f\u5ea6\u7684\u91cd\u6784\u56fe\u50cf\u3002CR\u7684\u4f20\u8f93\u8d1f\u8f7d\u53ef\u4ee5\u7075\u6d3b\u8c03\u6574\u4ee5\u8fbe\u5230\u671f\u671b\u7684\u4fdd\u771f\u5ea6", "result": "\u63a8\u5bfc\u4e86\u91cd\u6784\u8bef\u5dee\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u548c\u76f8\u5e94\u7684\u6700\u4f18CR\u3002\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5404\u79cd\u4fe1\u9053\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e0b\uff0cHSC\u76f8\u6bd4\u4e0d\u4f20\u8f93CR\u7684\u57fa\u7ebf\u8bed\u4e49\u901a\u4fe1\u5927\u5e45\u964d\u4f4e\u4e86\u5747\u65b9\u8bef\u5dee(MSE)", "conclusion": "\u6df7\u5408\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u53ef\u8c03\u8282\u7684\u4e92\u8865\u8868\u793a\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u8bed\u4e49\u901a\u4fe1\u91cd\u6784\u4fdd\u771f\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u7075\u6d3b\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u56fe\u50cf\u91cd\u6784\u8d28\u91cf"}}
{"id": "2507.17316", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17316", "abs": "https://arxiv.org/abs/2507.17316", "authors": ["Dirk van der Hoeven", "Julia Olkhovskaia", "Tim van Erven"], "title": "Nearly Minimax Discrete Distribution Estimation in Kullback-Leibler Divergence with High Probability", "comment": null, "summary": "We consider the problem of estimating a discrete distribution $p$ with\nsupport of size $K$ and provide both upper and lower bounds with high\nprobability in KL divergence. We prove that in the worst case, for any\nestimator $\\widehat{p}$, with probability at least $\\delta$, $\\text{KL}(p \\|\n\\widehat{p}) \\geq C\\max\\{K,\\ln(K)\\ln(1/\\delta) \\}/n $, where $n$ is the sample\nsize and $C > 0$ is a constant. We introduce a computationally efficient\nestimator $p^{\\text{OTB}}$, based on Online to Batch conversion and suffix\naveraging, and show that with probability at least $1 - \\delta$ $\\text{KL}(p \\|\n\\widehat{p}) \\leq C(K\\log(\\log(K)) + \\ln(K)\\ln(1/\\delta)) /n$.\n  Furthermore, we also show that with sufficiently many observations relative\nto $\\log(1/\\delta)$, the maximum likelihood estimator $\\bar{p}$ guarantees that\nwith probability at least $1-\\delta$ $$\n  1/6 \\chi^2(\\bar{p}\\|p) \\leq 1/4 \\chi^2(p\\|\\bar{p}) \\leq \\text{KL}(p|\\bar{p})\n\\leq C(K + \\log(1/\\delta))/n\\,, $$ where $\\chi^2$ denotes the\n$\\chi^2$-divergence.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u79bb\u6563\u5206\u5e03\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86KL\u6563\u5ea6\u7684\u4e0a\u4e0b\u754c\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5728\u7ebf\u5230\u6279\u5904\u7406\u8f6c\u6362\u7684\u9ad8\u6548\u4f30\u8ba1\u5668\uff0c\u5e76\u5206\u6790\u4e86\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u7684\u6027\u80fd\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u79bb\u6563\u5206\u5e03\u4f30\u8ba1\u65b9\u6cd5\u5728KL\u6563\u5ea6\u65b9\u9762\u7f3a\u4e4f\u7d27\u81f4\u7684\u7406\u8bba\u754c\u9650\uff0c\u7279\u522b\u662f\u5728\u9ad8\u6982\u7387\u4fdd\u8bc1\u4e0b\u7684\u4e0a\u4e0b\u754c\u5206\u6790\u4e0d\u591f\u5b8c\u5584\uff0c\u9700\u8981\u5f00\u53d1\u8ba1\u7b97\u9ad8\u6548\u7684\u4f30\u8ba1\u5668\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "1) \u5efa\u7acb\u4e86\u79bb\u6563\u5206\u5e03\u4f30\u8ba1\u5728KL\u6563\u5ea6\u4e0b\u7684\u4e0b\u754c\u7406\u8bba\uff1b2) \u63d0\u51fa\u4e86\u57fa\u4e8e\u5728\u7ebf\u5230\u6279\u5904\u7406\u8f6c\u6362(Online to Batch conversion)\u548c\u540e\u7f00\u5e73\u5747\u7684\u8ba1\u7b97\u9ad8\u6548\u4f30\u8ba1\u5668p^{OTB}\uff1b3) \u5206\u6790\u4e86\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u7684\u03c7\u00b2\u6563\u5ea6\u548cKL\u6563\u5ea6\u6027\u80fd\u3002", "result": "1) \u8bc1\u660e\u4e86\u4efb\u4f55\u4f30\u8ba1\u5668\u7684KL\u6563\u5ea6\u4e0b\u754c\u4e3aC\u00b7max{K, ln(K)ln(1/\u03b4)}/n\uff1b2) \u63d0\u51fa\u7684p^{OTB}\u4f30\u8ba1\u5668\u8fbe\u5230\u4e0a\u754cC(K\u00b7log(log(K)) + ln(K)ln(1/\u03b4))/n\uff1b3) \u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u5728\u5145\u8db3\u6837\u672c\u4e0b\u4fdd\u8bc1KL\u6563\u5ea6\u4e0a\u754c\u4e3aC(K + log(1/\u03b4))/n\u3002", "conclusion": "\u672c\u6587\u4e3a\u79bb\u6563\u5206\u5e03\u4f30\u8ba1\u63d0\u4f9b\u4e86\u51e0\u4e4e\u6700\u4f18\u7684\u7406\u8bba\u754c\u9650\uff0c\u63d0\u51fa\u7684OTB\u4f30\u8ba1\u5668\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7406\u8bba\u4fdd\u8bc1\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5206\u5e03\u4f30\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2507.16871", "categories": ["cs.LG", "hep-th"], "pdf": "https://arxiv.org/pdf/2507.16871", "abs": "https://arxiv.org/abs/2507.16871", "authors": ["Pietro Giuseppe Fr\u00e9", "Federico Milanesio", "Guido Sanguinetti", "Matteo Santoro"], "title": "Navigation through Non-Compact Symmetric Spaces: a mathematical perspective on Cartan Neural Networks", "comment": "59 pages, 2 figures", "summary": "Recent work has identified non-compact symmetric spaces U/H as a promising\nclass of homogeneous manifolds to develop a geometrically consistent theory of\nneural networks. An initial implementation of these concepts has been presented\nin a twin paper under the moniker of Cartan Neural Networks, showing both the\nfeasibility and the performance of these geometric concepts in a machine\nlearning context. The current paper expands on the mathematical structures\nunderpinning Cartan Neural Networks, detailing the geometric properties of the\nlayers and how the maps between layers interact with such structures to make\nCartan Neural Networks covariant and geometrically interpretable. Together,\nthese twin papers constitute a first step towards a fully geometrically\ninterpretable theory of neural networks exploiting group-theoretic structures", "AI": {"tldr": "\u8be5\u8bba\u6587\u57fa\u4e8e\u975e\u7d27\u5bf9\u79f0\u7a7a\u95f4U/H\u5f00\u53d1\u4e86\u51e0\u4f55\u4e00\u81f4\u7684\u795e\u7ecf\u7f51\u7edc\u7406\u8bba\uff0c\u6269\u5c55\u4e86Cartan\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u7ed3\u6784\uff0c\u8be6\u7ec6\u9610\u8ff0\u4e86\u5c42\u7684\u51e0\u4f55\u6027\u8d28\u548c\u5c42\u95f4\u6620\u5c04\u7684\u534f\u53d8\u6027\uff0c\u4e3a\u6784\u5efa\u5b8c\u5168\u51e0\u4f55\u53ef\u89e3\u91ca\u7684\u795e\u7ecf\u7f51\u7edc\u7406\u8bba\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u7f3a\u4e4f\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u5229\u7528\u7fa4\u8bba\u7ed3\u6784\u548c\u975e\u7d27\u5bf9\u79f0\u7a7a\u95f4\u7684\u51e0\u4f55\u6027\u8d28\u6765\u5f00\u53d1\u5177\u6709\u51e0\u4f55\u53ef\u89e3\u91ca\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u7406\u8bba\u3002", "method": "\u57fa\u4e8e\u975e\u7d27\u5bf9\u79f0\u7a7a\u95f4U/H\u4f5c\u4e3a\u9f50\u6b21\u6d41\u5f62\uff0c\u6269\u5c55Cartan\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u7ed3\u6784\uff0c\u8be6\u7ec6\u5206\u6790\u5c42\u7684\u51e0\u4f55\u6027\u8d28\u4ee5\u53ca\u5c42\u95f4\u6620\u5c04\u5982\u4f55\u4e0e\u8fd9\u4e9b\u7ed3\u6784\u76f8\u4e92\u4f5c\u7528\u4ee5\u5b9e\u73b0\u534f\u53d8\u6027\u3002", "result": "\u6210\u529f\u6269\u5c55\u4e86Cartan\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u4f7f\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u534f\u53d8\u6027\u548c\u51e0\u4f55\u53ef\u89e3\u91ca\u6027\uff0c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u51e0\u4f55\u6982\u5ff5\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u53ef\u884c\u6027\u548c\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e0e\u5176\u59ca\u59b9\u8bba\u6587\u5171\u540c\u6784\u6210\u4e86\u5229\u7528\u7fa4\u8bba\u7ed3\u6784\u5f00\u53d1\u5b8c\u5168\u51e0\u4f55\u53ef\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u7406\u8bba\u7684\u91cd\u8981\u7b2c\u4e00\u6b65\uff0c\u4e3a\u672a\u6765\u7684\u51e0\u4f55\u795e\u7ecf\u7f51\u7edc\u53d1\u5c55\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2507.17224", "categories": ["eess.SP", "cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.17224", "abs": "https://arxiv.org/abs/2507.17224", "authors": ["Feng Cao", "Zishuo Feng"], "title": "HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Spikes", "comment": "9 pages, 3 figures, 6 tables", "summary": "Extracellular recordings are brief voltage fluctuations recorded near\nneurons, widely used in neuroscience as the basis for decoding brain activity\nat single-neuron resolution. Spike sorting, which assigns each spike to its\nsource neuron, is a critical step in brain sensing pipelines. However, it\nremains challenging under low signal-to-noise ratio (SNR), electrode drift, and\ncross-session variability. In this paper, we propose HuiduRep, a robust\nself-supervised representation learning framework that extracts discriminative\nand generalizable features from extracellular spike waveforms. By combining\ncontrastive learning with a denoising autoencoder, HuiduRep learns latent\nrepresentations that are robust to noise and drift. Built on HuiduRep, we\ndevelop a spike sorting pipeline that clusters spike representations without\nsupervision. Experiments on hybrid and real-world datasets demonstrate that\nHuiduRep achieves strong robustness and the pipeline matches or outperforms\nstate-of-the-art tools such as KiloSort4 and MountainSort5. These findings\ndemonstrate the potential of self-supervised spike representation learning as a\nfoundational tool for robust and generalizable processing of extracellular\nrecordings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHuiduRep\uff0c\u4e00\u4e2a\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u7ec6\u80de\u5916\u8bb0\u5f55\u4fe1\u53f7\u8868\u5f81\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u53bb\u566a\u81ea\u7f16\u7801\u5668\u6765\u89e3\u51b3spike sorting\u4e2d\u7684\u566a\u58f0\u3001\u7535\u6781\u6f02\u79fb\u548c\u8de8\u4f1a\u8bdd\u53d8\u5f02\u6027\u95ee\u9898", "motivation": "\u7ec6\u80de\u5916\u8bb0\u5f55\u662f\u795e\u7ecf\u79d1\u5b66\u4e2d\u89e3\u7801\u5927\u8111\u6d3b\u52a8\u7684\u91cd\u8981\u6280\u672f\uff0c\u4f46spike sorting\u5728\u4f4e\u4fe1\u566a\u6bd4\u3001\u7535\u6781\u6f02\u79fb\u548c\u8de8\u4f1a\u8bdd\u53d8\u5f02\u6027\u6761\u4ef6\u4e0b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u65b9\u6cd5\u6765\u63d0\u53d6discriminative\u548c\u53ef\u6cdb\u5316\u7684\u7279\u5f81", "method": "\u63d0\u51faHuiduRep\u6846\u67b6\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u53bb\u566a\u81ea\u7f16\u7801\u5668\u8fdb\u884c\u81ea\u76d1\u7763\u8868\u5f81\u5b66\u4e60\uff0c\u4ece\u7ec6\u80de\u5916spike\u6ce2\u5f62\u4e2d\u63d0\u53d6\u5bf9\u566a\u58f0\u548c\u6f02\u79fb\u9c81\u68d2\u7684\u6f5c\u5728\u8868\u5f81\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u65e0\u76d1\u7763\u7684spike\u805a\u7c7bpipeline", "result": "\u5728\u6df7\u5408\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cHuiduRep\u5177\u6709\u5f3a\u9c81\u68d2\u6027\uff0c\u5176pipeline\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u4e86KiloSort4\u548cMountainSort5\u7b49\u6700\u5148\u8fdb\u5de5\u5177", "conclusion": "\u81ea\u76d1\u7763spike\u8868\u5f81\u5b66\u4e60\u4f5c\u4e3a\u7ec6\u80de\u5916\u8bb0\u5f55\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u5904\u7406\u7684\u57fa\u7840\u5de5\u5177\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0cHuiduRep\u4e3a\u89e3\u51b3\u795e\u7ecf\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u5173\u952e\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.17494", "categories": ["stat.ML", "cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17494", "abs": "https://arxiv.org/abs/2507.17494", "authors": ["Rashika Raina", "Nidhi Simmons", "David E. Simmons", "Michel Daoud Yacoub", "Trung Q. Duong"], "title": "To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks", "comment": null, "summary": "In next-generation communications and networks, machine learning (ML) models\nare expected to deliver not only accurate predictions but also well-calibrated\nconfidence scores that reflect the true likelihood of correct decisions. This\npaper studies the calibration performance of an ML-based outage predictor\nwithin a single-user, multi-resource allocation framework. We first establish\nkey theoretical properties of this system's outage probability (OP) under\nperfect calibration. Importantly, we show that as the number of resources\ngrows, the OP of a perfectly calibrated predictor approaches the expected\noutput conditioned on it being below the classification threshold. In contrast,\nwhen only one resource is available, the system's OP equals the model's overall\nexpected output. We then derive the OP conditions for a perfectly calibrated\npredictor. These findings guide the choice of the classification threshold to\nachieve a desired OP, helping system designers meet specific reliability\nrequirements. We also demonstrate that post-processing calibration cannot\nimprove the system's minimum achievable OP, as it does not introduce new\ninformation about future channel states. Additionally, we show that\nwell-calibrated models are part of a broader class of predictors that\nnecessarily improve OP. In particular, we establish a monotonicity condition\nthat the accuracy-confidence function must satisfy for such improvement to\noccur. To demonstrate these theoretical properties, we conduct a rigorous\nsimulation-based analysis using post-processing calibration techniques: Platt\nscaling and isotonic regression. As part of this framework, the predictor is\ntrained using an outage loss function specifically designed for this system.\nFurthermore, this analysis is performed on Rayleigh fading channels with\ntemporal correlation captured by Clarke's 2D model, which accounts for receiver\nmobility.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7f51\u7edc\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6821\u51c6\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5355\u7528\u6237\u591a\u8d44\u6e90\u5206\u914d\u6846\u67b6\u4e0b\u7684\u4e2d\u65ad\u9884\u6d4b\u5668\uff0c\u5efa\u7acb\u4e86\u5b8c\u7f8e\u6821\u51c6\u4e0b\u7cfb\u7edf\u4e2d\u65ad\u6982\u7387\u7684\u7406\u8bba\u6027\u8d28\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u7406\u8bba\u7ed3\u679c\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7f51\u7edc\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0d\u4ec5\u9700\u8981\u63d0\u4f9b\u51c6\u786e\u9884\u6d4b\uff0c\u8fd8\u9700\u8981\u63d0\u4f9b\u53cd\u6620\u6b63\u786e\u51b3\u7b56\u771f\u5b9e\u53ef\u80fd\u6027\u7684\u826f\u597d\u6821\u51c6\u7f6e\u4fe1\u5ea6\u5206\u6570\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9ML\u57fa\u7840\u4e2d\u65ad\u9884\u6d4b\u5668\u5728\u591a\u8d44\u6e90\u5206\u914d\u7cfb\u7edf\u4e2d\u6821\u51c6\u6027\u80fd\u7684\u7406\u8bba\u5206\u6790\u3002", "method": "\u5efa\u7acb\u5355\u7528\u6237\u591a\u8d44\u6e90\u5206\u914d\u6846\u67b6\u4e0b\u5b8c\u7f8e\u6821\u51c6\u7cfb\u7edf\u7684\u4e2d\u65ad\u6982\u7387\u7406\u8bba\u6027\u8d28\uff1b\u63a8\u5bfc\u5b8c\u7f8e\u6821\u51c6\u9884\u6d4b\u5668\u7684\u4e2d\u65ad\u6982\u7387\u6761\u4ef6\uff1b\u5206\u6790\u540e\u5904\u7406\u6821\u51c6\u6280\u672f\uff08Platt\u7f29\u653e\u548c\u7b49\u5f20\u56de\u5f52\uff09\u7684\u6548\u679c\uff1b\u4f7f\u7528\u4e13\u95e8\u8bbe\u8ba1\u7684\u4e2d\u65ad\u635f\u5931\u51fd\u6570\u8bad\u7ec3\u9884\u6d4b\u5668\uff1b\u5728\u5177\u6709\u65f6\u95f4\u76f8\u5173\u6027\u7684\u745e\u5229\u8870\u843d\u4fe1\u9053\u4e0a\u8fdb\u884c\u4eff\u771f\u9a8c\u8bc1\u3002", "result": "\u8bc1\u660e\u4e86\u968f\u7740\u8d44\u6e90\u6570\u91cf\u589e\u957f\uff0c\u5b8c\u7f8e\u6821\u51c6\u9884\u6d4b\u5668\u7684\u4e2d\u65ad\u6982\u7387\u8d8b\u8fd1\u4e8e\u4f4e\u4e8e\u5206\u7c7b\u9608\u503c\u6761\u4ef6\u4e0b\u7684\u671f\u671b\u8f93\u51fa\uff1b\u5355\u8d44\u6e90\u60c5\u51b5\u4e0b\u7cfb\u7edf\u4e2d\u65ad\u6982\u7387\u7b49\u4e8e\u6a21\u578b\u6574\u4f53\u671f\u671b\u8f93\u51fa\uff1b\u540e\u5904\u7406\u6821\u51c6\u65e0\u6cd5\u6539\u5584\u7cfb\u7edf\u6700\u5c0f\u53ef\u8fbe\u4e2d\u65ad\u6982\u7387\uff1b\u5efa\u7acb\u4e86\u51c6\u786e\u5ea6-\u7f6e\u4fe1\u5ea6\u51fd\u6570\u5fc5\u987b\u6ee1\u8db3\u7684\u5355\u8c03\u6027\u6761\u4ef6\u3002\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u5b8c\u7f8e\u6821\u51c6\u7684\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u5668\u5728\u591a\u8d44\u6e90\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5177\u6709\u7279\u5b9a\u7684\u7406\u8bba\u6027\u8d28\uff0c\u8fd9\u4e9b\u6027\u8d28\u53ef\u4ee5\u6307\u5bfc\u5206\u7c7b\u9608\u503c\u7684\u9009\u62e9\u4ee5\u5b9e\u73b0\u671f\u671b\u7684\u4e2d\u65ad\u6982\u7387\u3002\u826f\u597d\u6821\u51c6\u7684\u6a21\u578b\u5c5e\u4e8e\u80fd\u591f\u6539\u5584\u4e2d\u65ad\u6982\u7387\u7684\u66f4\u5e7f\u6cdb\u9884\u6d4b\u5668\u7c7b\u522b\uff0c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u8005\u6ee1\u8db3\u7279\u5b9a\u53ef\u9760\u6027\u8981\u6c42\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.16881", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16881", "abs": "https://arxiv.org/abs/2507.16881", "authors": ["Pengjiu Xia", "Yidian Huang", "Wenchao Wei", "Yuwen Tan"], "title": "Confidence Optimization for Probabilistic Encoding", "comment": null, "summary": "Probabilistic encoding introduces Gaussian noise into neural networks,\nenabling a smooth transition from deterministic to uncertain states and\nenhancing generalization ability. However, the randomness of Gaussian noise\ndistorts point-based distance measurements in classification tasks. To mitigate\nthis issue, we propose a confidence optimization probabilistic encoding (CPE)\nmethod that improves distance reliability and enhances representation learning.\nSpecifically, we refine probabilistic encoding with two key strategies: First,\nwe introduce a confidence-aware mechanism to adjust distance calculations,\nensuring consistency and reliability in probabilistic encoding classification\ntasks. Second, we replace the conventional KL divergence-based variance\nregularization, which relies on unreliable prior assumptions, with a simpler L2\nregularization term to directly constrain variance. The method we proposed is\nmodel-agnostic, and extensive experiments on natural language classification\ntasks demonstrate that our method significantly improves performance and\ngeneralization on both the BERT and the RoBERTa model.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7f6e\u4fe1\u5ea6\u4f18\u5316\u6982\u7387\u7f16\u7801(CPE)\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u673a\u5236\u548cL2\u6b63\u5219\u5316\u6765\u6539\u5584\u6982\u7387\u7f16\u7801\u4e2d\u7684\u8ddd\u79bb\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5728BERT\u548cRoBERTa\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u81ea\u7136\u8bed\u8a00\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6982\u7387\u7f16\u7801\u867d\u7136\u80fd\u591f\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5176\u5f15\u5165\u7684\u9ad8\u65af\u566a\u58f0\u4f1a\u626d\u66f2\u5206\u7c7b\u4efb\u52a1\u4e2d\u57fa\u4e8e\u70b9\u7684\u8ddd\u79bb\u6d4b\u91cf\uff0c\u5f71\u54cd\u5206\u7c7b\u6027\u80fd\u3002\u73b0\u6709\u7684KL\u6563\u5ea6\u65b9\u5dee\u6b63\u5219\u5316\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684\u5148\u9a8c\u5047\u8bbe\uff0c\u9700\u8981\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u7f6e\u4fe1\u5ea6\u4f18\u5316\u6982\u7387\u7f16\u7801(CPE)\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7b56\u7565\uff1a1)\u5f15\u5165\u7f6e\u4fe1\u5ea6\u611f\u77e5\u673a\u5236\u6765\u8c03\u6574\u8ddd\u79bb\u8ba1\u7b97\uff0c\u786e\u4fdd\u6982\u7387\u7f16\u7801\u5206\u7c7b\u4efb\u52a1\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\uff1b2)\u7528\u7b80\u5355\u7684L2\u6b63\u5219\u5316\u9879\u66ff\u4ee3\u4f20\u7edf\u7684\u57fa\u4e8eKL\u6563\u5ea6\u7684\u65b9\u5dee\u6b63\u5219\u5316\uff0c\u76f4\u63a5\u7ea6\u675f\u65b9\u5dee\u800c\u4e0d\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684\u5148\u9a8c\u5047\u8bbe\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728BERT\u548cRoBERTa\u6a21\u578b\u4e0a\u90fd\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u6a21\u578b\u65e0\u5173\u6027\uff0c\u53ef\u4ee5\u5e7f\u6cdb\u5e94\u7528\u3002", "conclusion": "CPE\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6982\u7387\u7f16\u7801\u4e2d\u8ddd\u79bb\u53ef\u9760\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u673a\u5236\u548cL2\u6b63\u5219\u5316\u663e\u8457\u6539\u5584\u4e86\u795e\u7ecf\u7f51\u7edc\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u6982\u7387\u7f16\u7801\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17261", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17261", "abs": "https://arxiv.org/abs/2507.17261", "authors": ["Rui Ding", "Fuhui Zhou", "Yuhang Wu", "Qihui Wu", "Tony Q. S. Quek"], "title": "Joint Resource Optimization Over Licensed and Unlicensed Spectrum in Spectrum Sharing UAV Networks Against Jamming Attacks", "comment": null, "summary": "Unmanned aerial vehicle (UAV) communication is of crucial importance in\nrealizing heterogeneous practical wireless application scenarios. However, the\ndensely populated users and diverse services with high data rate demands has\ntriggered an increasing scarcity of UAV spectrum utilization. To tackle this\nproblem, it is promising to incorporate the underutilized unlicensed spectrum\nwith the licensed spectrum to boost network capacity. However, the openness of\nunlicensed spectrum makes UAVs susceptible to security threats from potential\njammers. Therefore, a spectrum sharing UAV network coexisting with licensed\ncellular network and unlicensed Wi-Fi network is considered with the\nanti-jamming technique in this paper. The sum rate maximization of the\nsecondary network is studied by jointly optimizing the transmit power,\nsubchannel allocation, and UAV trajectory. We first decompose the challenging\nnon-convex problem into two subproblems, 1) the joint power and subchannel\nallocation and 2) UAV trajectory design subproblems. A low-complexity iterative\nalgorithm is proposed in a alternating optimization manner over these two\nsubproblems to solve the formulated problem. Specifically, the Lagrange dual\ndecomposition is exploited to jointly optimize the transmit power and\nsubchannel allocation iteratively. Then, an efficient iterative algorithm\ncapitalizing on successive convex approximation is designed to get a suboptimal\nsolution for UAV trajectory. Simulation results demonstrate that our proposed\nalgorithm can significantly improve the sum transmission rate compared with the\nbenchmark schemes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u9891\u8c31\u5171\u4eab\u73af\u5883\u4e0b\u7684\u65e0\u4eba\u673a\u901a\u4fe1\u7f51\u7edc\u6297\u5e72\u6270\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53d1\u5c04\u529f\u7387\u3001\u5b50\u4fe1\u9053\u5206\u914d\u548c\u65e0\u4eba\u673a\u8f68\u8ff9\u6765\u6700\u5927\u5316\u7f51\u7edc\u548c\u901f\u7387", "motivation": "\u65e0\u4eba\u673a\u901a\u4fe1\u4e2d\u7528\u6237\u5bc6\u96c6\u3001\u670d\u52a1\u591a\u6837\u5316\u5bfc\u81f4\u9891\u8c31\u7a00\u7f3a\uff0c\u9700\u8981\u7ed3\u5408\u6388\u6743\u548c\u975e\u6388\u6743\u9891\u8c31\u63d0\u5347\u7f51\u7edc\u5bb9\u91cf\uff0c\u4f46\u975e\u6388\u6743\u9891\u8c31\u7684\u5f00\u653e\u6027\u4f7f\u65e0\u4eba\u673a\u6613\u53d7\u5e72\u6270\u5a01\u80c1", "method": "\u5c06\u590d\u6742\u7684\u975e\u51f8\u4f18\u5316\u95ee\u9898\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u95ee\u9898\uff1a1\uff09\u8054\u5408\u529f\u7387\u548c\u5b50\u4fe1\u9053\u5206\u914d\uff0c2\uff09\u65e0\u4eba\u673a\u8f68\u8ff9\u8bbe\u8ba1\u3002\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u7684\u4f4e\u590d\u6742\u5ea6\u8fed\u4ee3\u7b97\u6cd5\uff0c\u5229\u7528\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u5206\u89e3\u4f18\u5316\u529f\u7387\u548c\u5b50\u4fe1\u9053\u5206\u914d\uff0c\u4f7f\u7528\u8fde\u7eed\u51f8\u8fd1\u4f3c\u7b97\u6cd5\u8bbe\u8ba1\u65e0\u4eba\u673a\u8f68\u8ff9", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\u80fd\u663e\u8457\u63d0\u5347\u7f51\u7edc\u548c\u4f20\u8f93\u901f\u7387", "conclusion": "\u5728\u9891\u8c31\u5171\u4eab\u7684\u65e0\u4eba\u673a\u7f51\u7edc\u4e2d\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53d1\u5c04\u529f\u7387\u3001\u5b50\u4fe1\u9053\u5206\u914d\u548c\u8f68\u8ff9\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u6297\u5e72\u6270\u95ee\u9898\u5e76\u663e\u8457\u63d0\u5347\u7f51\u7edc\u6027\u80fd"}}
{"id": "2507.17544", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2507.17544", "abs": "https://arxiv.org/abs/2507.17544", "authors": ["Bonwoo Lee", "Cheolwoo Park", "Jeongyoun Ahn"], "title": "Optimal differentially private kernel learning with random projection", "comment": "110 page, 12 figures", "summary": "Differential privacy has become a cornerstone in the development of\nprivacy-preserving learning algorithms. This work addresses optimizing\ndifferentially private kernel learning within the empirical risk minimization\n(ERM) framework. We propose a novel differentially private kernel ERM algorithm\nbased on random projection in the reproducing kernel Hilbert space using\nGaussian processes. Our method achieves minimax-optimal excess risk for both\nthe squared loss and Lipschitz-smooth convex loss functions under a local\nstrong convexity condition. We further show that existing approaches based on\nalternative dimension reduction techniques, such as random Fourier feature\nmappings or $\\ell_2$ regularization, yield suboptimal generalization\nperformance. Our key theoretical contribution also includes the derivation of\ndimension-free generalization bounds for objective perturbation-based private\nlinear ERM -- marking the first such result that does not rely on noisy\ngradient-based mechanisms. Additionally, we obtain sharper generalization\nbounds for existing differentially private kernel ERM algorithms. Empirical\nevaluations support our theoretical claims, demonstrating that random\nprojection enables statistically efficient and optimally private kernel\nlearning. These findings provide new insights into the design of differentially\nprivate algorithms and highlight the central role of dimension reduction in\nbalancing privacy and utility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u6295\u5f71\u7684\u5dee\u5206\u9690\u79c1\u6838\u5b66\u4e60\u7b97\u6cd5\uff0c\u5728\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u6846\u67b6\u4e0b\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\uff0c\u5e76\u9996\u6b21\u83b7\u5f97\u4e86\u4e0d\u4f9d\u8d56\u566a\u58f0\u68af\u5ea6\u673a\u5236\u7684\u65e0\u7ef4\u5ea6\u6cdb\u5316\u754c", "motivation": "\u73b0\u6709\u7684\u5dee\u5206\u9690\u79c1\u6838\u5b66\u4e60\u65b9\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u5b66\u4e60\u6548\u7528\u4e4b\u95f4\u7684\u6743\u8861\u4e0d\u591f\u7406\u60f3\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u6620\u5c04\u6216L2\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u5b58\u5728\u6b21\u4f18\u7684\u6cdb\u5316\u6027\u80fd\u95ee\u9898", "method": "\u5728\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u8fdb\u884c\u968f\u673a\u6295\u5f71\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5dee\u5206\u9690\u79c1\u6838\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u7b97\u6cd5\uff0c\u5e76\u57fa\u4e8e\u76ee\u6807\u6270\u52a8\u65b9\u6cd5\u63a8\u5bfc\u4e86\u79c1\u6709\u7ebf\u6027ERM\u7684\u7ef4\u5ea6\u65e0\u5173\u6cdb\u5316\u754c", "result": "\u7b97\u6cd5\u5728\u5e73\u65b9\u635f\u5931\u548cLipschitz\u5149\u6ed1\u51f8\u635f\u5931\u51fd\u6570\u4e0b\u90fd\u8fbe\u5230\u4e86minimax\u6700\u4f18\u7684\u8d85\u989d\u98ce\u9669\uff1b\u83b7\u5f97\u4e86\u9996\u4e2a\u4e0d\u4f9d\u8d56\u566a\u58f0\u68af\u5ea6\u673a\u5236\u7684\u65e0\u7ef4\u5ea6\u6cdb\u5316\u754c\uff1b\u4e3a\u73b0\u6709\u5dee\u5206\u9690\u79c1\u6838ERM\u7b97\u6cd5\u5f97\u5230\u4e86\u66f4\u7d27\u7684\u6cdb\u5316\u754c\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c", "conclusion": "\u968f\u673a\u6295\u5f71\u6280\u672f\u5728\u5dee\u5206\u9690\u79c1\u6838\u5b66\u4e60\u4e2d\u80fd\u591f\u5b9e\u73b0\u7edf\u8ba1\u9ad8\u6548\u548c\u6700\u4f18\u9690\u79c1\u4fdd\u62a4\uff0c\u964d\u7ef4\u6280\u672f\u5728\u5e73\u8861\u9690\u79c1\u548c\u6548\u7528\u65b9\u9762\u53d1\u6325\u6838\u5fc3\u4f5c\u7528\uff0c\u4e3a\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3"}}
{"id": "2507.16884", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16884", "abs": "https://arxiv.org/abs/2507.16884", "authors": ["Yi Guo", "Wei Wang", "Zhihang Yuan", "Rong Cao", "Kuan Chen", "Zhengyang Chen", "Yuanyuan Huo", "Yang Zhang", "Yuping Wang", "Shouda Liu", "Yuxuan Wang"], "title": "SplitMeanFlow: Interval Splitting Consistency in Few-Step Generative Modeling", "comment": "Tech Report", "summary": "Generative models like Flow Matching have achieved state-of-the-art\nperformance but are often hindered by a computationally expensive iterative\nsampling process. To address this, recent work has focused on few-step or\none-step generation by learning the average velocity field, which directly maps\nnoise to data. MeanFlow, a leading method in this area, learns this field by\nenforcing a differential identity that connects the average and instantaneous\nvelocities. In this work, we argue that this differential formulation is a\nlimiting special case of a more fundamental principle. We return to the first\nprinciples of average velocity and leverage the additivity property of definite\nintegrals. This leads us to derive a novel, purely algebraic identity we term\nInterval Splitting Consistency. This identity establishes a self-referential\nrelationship for the average velocity field across different time intervals\nwithout resorting to any differential operators. Based on this principle, we\nintroduce SplitMeanFlow, a new training framework that enforces this algebraic\nconsistency directly as a learning objective. We formally prove that the\ndifferential identity at the core of MeanFlow is recovered by taking the limit\nof our algebraic consistency as the interval split becomes infinitesimal. This\nestablishes SplitMeanFlow as a direct and more general foundation for learning\naverage velocity fields. From a practical standpoint, our algebraic approach is\nsignificantly more efficient, as it eliminates the need for JVP computations,\nresulting in simpler implementation, more stable training, and broader hardware\ncompatibility. One-step and two-step SplitMeanFlow models have been\nsuccessfully deployed in large-scale speech synthesis products (such as\nDoubao), achieving speedups of 20x.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSplitMeanFlow\uff0c\u4e00\u79cd\u57fa\u4e8e\u533a\u95f4\u5206\u5272\u4e00\u81f4\u6027\u7684\u65b0\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u5e73\u5747\u901f\u5ea6\u573a\u4ee5\u5b9e\u73b0\u5feb\u901f\u751f\u6210\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u5e76\u5df2\u5728\u5927\u89c4\u6a21\u8bed\u97f3\u5408\u6210\u4ea7\u54c1\u4e2d\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u6a21\u578b\u5982Flow Matching\u867d\u7136\u6027\u80fd\u4f18\u5f02\uff0c\u4f46\u53d7\u9650\u4e8e\u8ba1\u7b97\u6602\u8d35\u7684\u8fed\u4ee3\u91c7\u6837\u8fc7\u7a0b\u3002\u867d\u7136MeanFlow\u7b49\u65b9\u6cd5\u901a\u8fc7\u5b66\u4e60\u5e73\u5747\u901f\u5ea6\u573a\u5b9e\u73b0\u4e86\u5c11\u6b65\u6216\u5355\u6b65\u751f\u6210\uff0c\u4f46\u5176\u57fa\u4e8e\u5fae\u5206\u6052\u7b49\u5f0f\u7684\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u90fd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u6839\u672c\u548c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u56de\u5f52\u5e73\u5747\u901f\u5ea6\u7684\u7b2c\u4e00\u6027\u539f\u7406\uff0c\u5229\u7528\u5b9a\u79ef\u5206\u7684\u53ef\u52a0\u6027\u8d28\uff0c\u63a8\u5bfc\u51fa\u540d\u4e3a\"\u533a\u95f4\u5206\u5272\u4e00\u81f4\u6027\"\u7684\u7eaf\u4ee3\u6570\u6052\u7b49\u5f0f\u3002\u8be5\u6052\u7b49\u5f0f\u4e3a\u4e0d\u540c\u65f6\u95f4\u95f4\u9694\u4e0a\u7684\u5e73\u5747\u901f\u5ea6\u573a\u5efa\u7acb\u4e86\u81ea\u53c2\u8003\u5173\u7cfb\uff0c\u65e0\u9700\u4f7f\u7528\u5fae\u5206\u7b97\u5b50\u3002\u57fa\u4e8e\u6b64\u539f\u7406\u6784\u5efaSplitMeanFlow\u8bad\u7ec3\u6846\u67b6\uff0c\u76f4\u63a5\u5c06\u4ee3\u6570\u4e00\u81f4\u6027\u4f5c\u4e3a\u5b66\u4e60\u76ee\u6807\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86MeanFlow\u7684\u5fae\u5206\u6052\u7b49\u5f0f\u662f\u672c\u65b9\u6cd5\u4ee3\u6570\u4e00\u81f4\u6027\u5728\u533a\u95f4\u5206\u5272\u8d8b\u4e8e\u65e0\u7a77\u5c0f\u65f6\u7684\u6781\u9650\u60c5\u51b5\uff0c\u786e\u7acb\u4e86SplitMeanFlow\u4f5c\u4e3a\u5b66\u4e60\u5e73\u5747\u901f\u5ea6\u573a\u66f4\u4e00\u822c\u5316\u57fa\u7840\u7684\u5730\u4f4d\u3002\u5b9e\u8df5\u4e0a\uff0c\u8be5\u4ee3\u6570\u65b9\u6cd5\u6d88\u9664\u4e86JVP\u8ba1\u7b97\u9700\u6c42\uff0c\u5b9e\u73b0\u4e86\u66f4\u7b80\u5355\u7684\u5b9e\u73b0\u3001\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u548c\u66f4\u5e7f\u6cdb\u7684\u786c\u4ef6\u517c\u5bb9\u6027\u3002\u5355\u6b65\u548c\u53cc\u6b65SplitMeanFlow\u6a21\u578b\u5df2\u5728\u5927\u89c4\u6a21\u8bed\u97f3\u5408\u6210\u4ea7\u54c1\u4e2d\u6210\u529f\u90e8\u7f72\u3002", "conclusion": "SplitMeanFlow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u6839\u672c\u3001\u66f4\u9ad8\u6548\u7684\u6846\u67b6\u6765\u5b66\u4e60\u5e73\u5747\u901f\u5ea6\u573a\uff0c\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u7edf\u4e00\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u5728\u5b9e\u8df5\u4e2d\u5e26\u6765\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u548c\u5b9e\u73b0\u4f18\u52bf\uff0c\u5e76\u5df2\u5728\u5b9e\u9645\u4ea7\u54c1\u4e2d\u5b9e\u73b020\u500d\u52a0\u901f\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.17284", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17284", "abs": "https://arxiv.org/abs/2507.17284", "authors": ["Chaehyun Jung", "TaeJun Ha", "Hyeonuk Kim", "Jeonghun Park"], "title": "State Estimation with 1-Bit Observations and Imperfect Models: Bussgang Meets Kalman in Neural Networks", "comment": null, "summary": "State estimation from noisy observations is a fundamental problem in many\napplications of signal processing. Traditional methods, such as the extended\nKalman filter, work well under fully-known Gaussian models, while recent hybrid\ndeep learning frameworks, combining model-based and data-driven approaches, can\nalso handle partially known models and non-Gaussian noise. However, existing\nstudies commonly assume the absence of quantization distortion, which is\ninevitable, especially with non-ideal analog-to-digital converters. In this\nwork, we consider a state estimation problem with 1-bit quantization. 1-bit\nquantization causes significant quantization distortion and severe information\nloss, rendering conventional state estimation strategies unsuitable. To address\nthis, inspired by the Bussgang decomposition technique, we first develop the\nBussgang-aided Kalman filter by assuming perfectly known models. The proposed\nmethod suitably captures quantization distortion into the state estimation\nprocess. In addition, we propose a computationally efficient variant, referred\nto as the reduced Bussgang-aided Kalman filter and, building upon it, introduce\na deep learning-based approach for handling partially known models, termed the\nBussgang-aided KalmanNet. In particular, the Bussgang-aided KalmanNet jointly\nuses a dithering technique and a gated recurrent unit (GRU) architecture to\neffectively mitigate the effects of 1-bit quantization and model mismatch.\nThrough simulations on the Lorenz-Attractor model and the Michigan NCLT\ndataset, we demonstrate that our proposed methods achieve accurate state\nestimation performance even under highly nonlinear, mismatched models and 1-bit\nobservations.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf91\u6bd4\u7279\u91cf\u5316\u73af\u5883\u4e0b\u7684\u72b6\u6001\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eBussgang\u5206\u89e3\u6280\u672f\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u53ca\u5176\u6df1\u5ea6\u5b66\u4e60\u53d8\u4f53\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u91cf\u5316\u5931\u771f\u548c\u4fe1\u606f\u4e22\u5931\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\u5047\u8bbe\u4e0d\u5b58\u5728\u91cf\u5316\u5931\u771f\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d1\u6bd4\u7279\u91cf\u5316\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u91cf\u5316\u5931\u771f\u548c\u4fe1\u606f\u4e22\u5931\uff0c\u4f7f\u5f97\u4f20\u7edf\u65b9\u6cd5\u4e0d\u518d\u9002\u7528\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u8fd9\u79cd\u4e25\u91cd\u91cf\u5316\u5f71\u54cd\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eBussgang\u5206\u89e3\u6280\u672f\u5f00\u53d1\u4e86Bussgang\u8f85\u52a9\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u63d0\u51fa\u4e86\u8ba1\u7b97\u9ad8\u6548\u7684\u7b80\u5316\u7248\u672c\uff0c\u5e76\u7ed3\u5408\u6296\u52a8\u6280\u672f\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143(GRU)\u67b6\u6784\uff0c\u6784\u5efa\u4e86\u80fd\u5904\u7406\u90e8\u5206\u5df2\u77e5\u6a21\u578b\u7684Bussgang\u8f85\u52a9KalmanNet\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5728Lorenz-Attractor\u6a21\u578b\u548cMichigan NCLT\u6570\u636e\u96c6\u4e0a\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5373\u4f7f\u5728\u9ad8\u5ea6\u975e\u7ebf\u6027\u3001\u6a21\u578b\u5931\u914d\u548c1\u6bd4\u7279\u89c2\u6d4b\u6761\u4ef6\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u51c6\u786e\u7684\u72b6\u6001\u4f30\u8ba1\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684Bussgang\u8f85\u52a9\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5c06\u91cf\u5316\u5931\u771f\u7eb3\u5165\u72b6\u6001\u4f30\u8ba1\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u548c\u4e13\u95e8\u7684\u67b6\u6784\u8bbe\u8ba1\uff0c\u6210\u529f\u89e3\u51b3\u4e861\u6bd4\u7279\u91cf\u5316\u73af\u5883\u4e0b\u7684\u72b6\u6001\u4f30\u8ba1\u6311\u6218\u3002"}}
{"id": "2507.17686", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17686", "abs": "https://arxiv.org/abs/2507.17686", "authors": ["Takashi Hayakawa", "Satoshi Asai"], "title": "Debiased maximum-likelihood estimators for hazard ratios under machine-learning adjustment", "comment": null, "summary": "Previous studies have shown that hazard ratios between treatment groups\nestimated with the Cox model are uninterpretable because the indefinite\nbaseline hazard of the model fails to identify temporal change in the risk set\ncomposition due to treatment assignment and unobserved factors among multiple,\ncontradictory scenarios. To alleviate this problem, especially in studies based\non observational data with uncontrolled dynamic treatment and real-time\nmeasurement of many covariates, we propose abandoning the baseline hazard and\nusing machine learning to explicitly model the change in the risk set with or\nwithout latent variables. For this framework, we clarify the context in which\nhazard ratios can be causally interpreted, and then develop a method based on\nNeyman orthogonality to compute debiased maximum-likelihood estimators of\nhazard ratios. Computing the constructed estimators is more efficient than\ncomputing those based on weighted regression with marginal structural Cox\nmodels. Numerical simulations confirm that the proposed method identifies the\nground truth with minimal bias. These results lay the foundation for developing\na useful, alternative method for causal inference with uncontrolled,\nobservational data in modern epidemiology.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6765\u89e3\u51b3Cox\u6a21\u578b\u4e2d\u98ce\u9669\u6bd4\u4f30\u8ba1\u7684\u56e0\u679c\u63a8\u65ad\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u89c2\u5bdf\u6027\u6570\u636e\u4e2d\u5904\u7406\u52a8\u6001\u6cbb\u7597\u548c\u5b9e\u65f6\u534f\u53d8\u91cf\u6d4b\u91cf\u7684\u60c5\u51b5", "motivation": "\u4f20\u7edfCox\u6a21\u578b\u4e2d\u7684\u98ce\u9669\u6bd4\u4f30\u8ba1\u5b58\u5728\u4e0d\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u6a21\u578b\u7684\u4e0d\u5b9a\u57fa\u7ebf\u98ce\u9669\u65e0\u6cd5\u8bc6\u522b\u7531\u6cbb\u7597\u5206\u914d\u548c\u672a\u89c2\u5bdf\u56e0\u7d20\u5bfc\u81f4\u7684\u98ce\u9669\u96c6\u5408\u7ec4\u6210\u7684\u65f6\u95f4\u53d8\u5316\uff0c\u7279\u522b\u662f\u5728\u57fa\u4e8e\u89c2\u5bdf\u6027\u6570\u636e\u7684\u7814\u7a76\u4e2d\u5b58\u5728\u672a\u63a7\u5236\u7684\u52a8\u6001\u6cbb\u7597\u548c\u591a\u4e2a\u534f\u53d8\u91cf\u5b9e\u65f6\u6d4b\u91cf\u7684\u590d\u6742\u60c5\u51b5", "method": "\u63d0\u51fa\u653e\u5f03\u57fa\u7ebf\u98ce\u9669\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u663e\u5f0f\u5efa\u6a21\u98ce\u9669\u96c6\u5408\u7684\u53d8\u5316\uff08\u5305\u542b\u6216\u4e0d\u5305\u542b\u6f5c\u5728\u53d8\u91cf\uff09\uff1b\u57fa\u4e8eNeyman\u6b63\u4ea4\u6027\u5f00\u53d1\u65b9\u6cd5\u6765\u8ba1\u7b97\u98ce\u9669\u6bd4\u7684\u53bb\u504f\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\uff1b\u8be5\u6846\u67b6\u6bd4\u57fa\u4e8e\u8fb9\u9645\u7ed3\u6784Cox\u6a21\u578b\u7684\u52a0\u6743\u56de\u5f52\u8ba1\u7b97\u66f4\u9ad8\u6548", "result": "\u6570\u503c\u6a21\u62df\u8bc1\u5b9e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4ee5\u6700\u5c0f\u504f\u5dee\u8bc6\u522b\u771f\u5b9e\u503c\uff1b\u8be5\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u52a0\u6743\u56de\u5f52\u7684\u8fb9\u9645\u7ed3\u6784Cox\u6a21\u578b\uff1b\u4e3a\u98ce\u9669\u6bd4\u7684\u56e0\u679c\u89e3\u91ca\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u9002\u7528\u6761\u4ef6", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u73b0\u4ee3\u6d41\u884c\u75c5\u5b66\u4e2d\u4f7f\u7528\u672a\u63a7\u5236\u89c2\u5bdf\u6027\u6570\u636e\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u7528\u7684\u66ff\u4ee3\u65b9\u6cd5\u6765\u89e3\u51b3\u4f20\u7edfCox\u6a21\u578b\u5728\u89c2\u5bdf\u6027\u7814\u7a76\u4e2d\u7684\u5c40\u9650\u6027"}}
{"id": "2507.16933", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.16933", "abs": "https://arxiv.org/abs/2507.16933", "authors": ["Steven K. Esser", "Jeffrey L. McKinstry", "Deepika Bablani", "Rathinakumar Appuswamy", "Dharmendra S. Modha"], "title": "SiLQ: Simple Large Language Model Quantization-Aware Training", "comment": "12 pages, 3 figures", "summary": "Large language models can be quantized to reduce inference time latency,\nmodel size, and energy consumption, thereby delivering a better user experience\nat lower cost. A challenge exists to deliver quantized models with minimal loss\nof accuracy in reasonable time, and in particular to do so without requiring\nmechanisms incompatible with specialized inference accelerators. Here, we\ndemonstrate a simple, end-to-end quantization-aware training approach that,\nwith an increase in total model training budget of less than 0.1%, outperforms\nthe leading published quantization methods by large margins on several modern\nbenchmarks, with both base and instruct model variants. The approach easily\ngeneralizes across different model architectures, can be applied to\nactivations, cache, and weights, and requires the introduction of no additional\noperations to the model other than the quantization itself.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4ec5\u589e\u52a0\u4e0d\u52300.1%\u7684\u8bad\u7ec3\u6210\u672c\u5c31\u80fd\u5728\u591a\u4e2a\u73b0\u4ee3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\uff0c\u540c\u65f6\u4e0e\u63a8\u7406\u52a0\u901f\u5668\u517c\u5bb9\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u65b9\u6cd5\u5b58\u5728\u51c6\u786e\u6027\u635f\u5931\u5927\u3001\u8bad\u7ec3\u65f6\u95f4\u957f\u3001\u4e0e\u4e13\u7528\u63a8\u7406\u52a0\u901f\u5668\u4e0d\u517c\u5bb9\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u4e14\u517c\u5bb9\u6027\u597d\u7684\u91cf\u5316\u65b9\u6cd5\u6765\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3001\u6a21\u578b\u5927\u5c0f\u548c\u80fd\u8017\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7b80\u5355\u6613\u7528\uff0c\u53ef\u6cdb\u5316\u5230\u4e0d\u540c\u6a21\u578b\u67b6\u6784\uff0c\u9002\u7528\u4e8e\u6fc0\u6d3b\u503c\u3001\u7f13\u5b58\u548c\u6743\u91cd\u7684\u91cf\u5316\uff0c\u9664\u91cf\u5316\u64cd\u4f5c\u672c\u8eab\u5916\u4e0d\u5f15\u5165\u989d\u5916\u64cd\u4f5c\u3002", "result": "\u5728\u591a\u4e2a\u73b0\u4ee3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u57fa\u7840\u6a21\u578b\u548c\u6307\u4ee4\u6a21\u578b\u53d8\u4f53\u4e0a\u90fd\u5927\u5e45\u8d85\u8d8a\u4e86\u73b0\u6709\u9886\u5148\u7684\u91cf\u5316\u65b9\u6cd5\uff0c\u540c\u65f6\u8bad\u7ec3\u6210\u672c\u589e\u52a0\u4e0d\u52300.1%\u3002", "conclusion": "\u8be5\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u6781\u4f4e\u989d\u5916\u8bad\u7ec3\u6210\u672c\u4e0b\u663e\u8457\u63d0\u5347\u91cf\u5316\u6a21\u578b\u6027\u80fd\u7684\u76ee\u6807\uff0c\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17292", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17292", "abs": "https://arxiv.org/abs/2507.17292", "authors": ["Yu Zhang", "Qin Yi", "Leila Musavian", "Tongyang Xu", "Zilong Liu"], "title": "Non-Orthogonal AFDM: A Promising Spectrum-Efficient Waveform for 6G High-Mobility Communications", "comment": "This work has been accepted by IEEE PIMRC 2025", "summary": "This paper proposes a spectrum-efficient nonorthogonal affine frequency\ndivision multiplexing (AFDM) waveform for reliable high-mobility communications\nin the upcoming sixth-generation (6G) mobile systems. Our core idea is to\nintroduce a compression factor to enable controllable subcarrier overlapping in\nchirp-based AFDM modulation. To mitigate intercarrier interference (ICI), we\nintroduce linear precoding at the transmitter and an iterative detection scheme\nat the receiver. Simulation results demonstrate that these techniques can\neffectively reduce interference and maintain robust bit error rate (BER)\nperformance even under aggressive compression factors and high-mobility channel\nconditions. The proposed non-orthogonal AFDM waveform offers a promising\nsolution for next-generation wireless networks, balancing spectrum efficiency\nand Doppler resilience in highly dynamic environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9891\u8c31\u9ad8\u6548\u7684\u975e\u6b63\u4ea4\u4eff\u5c04\u9891\u5206\u590d\u7528(AFDM)\u6ce2\u5f62\uff0c\u901a\u8fc7\u5f15\u5165\u538b\u7f29\u56e0\u5b50\u5b9e\u73b0\u53ef\u63a7\u7684\u5b50\u8f7d\u6ce2\u91cd\u53e0\uff0c\u5e76\u91c7\u7528\u7ebf\u6027\u9884\u7f16\u7801\u548c\u8fed\u4ee3\u68c0\u6d4b\u6765\u51cf\u5c11\u8f7d\u6ce2\u95f4\u5e72\u6270\uff0c\u4e3a6G\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u9488\u5bf96G\u79fb\u52a8\u7cfb\u7edf\u4e2d\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u573a\u666f\uff0c\u9700\u8981\u5728\u9891\u8c31\u6548\u7387\u548c\u591a\u666e\u52d2\u6297\u6027\u4e4b\u95f4\u627e\u5230\u5e73\u8861\uff0c\u73b0\u6709\u6b63\u4ea4\u6ce2\u5f62\u5728\u9ad8\u52a8\u6001\u73af\u5883\u4e0b\u6027\u80fd\u53d7\u9650\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u65b0\u7684\u975e\u6b63\u4ea4\u6ce2\u5f62\u6765\u63d0\u5347\u9891\u8c31\u6548\u7387\u540c\u65f6\u4fdd\u6301\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u975e\u6b63\u4ea4AFDM\u6ce2\u5f62\u8bbe\u8ba1\u65b9\u6cd5\uff1a1\uff09\u5f15\u5165\u538b\u7f29\u56e0\u5b50\u5b9e\u73b0chirp\u57faAFDM\u8c03\u5236\u4e2d\u7684\u53ef\u63a7\u5b50\u8f7d\u6ce2\u91cd\u53e0\uff1b2\uff09\u5728\u53d1\u5c04\u7aef\u91c7\u7528\u7ebf\u6027\u9884\u7f16\u7801\u6280\u672f\uff1b3\uff09\u5728\u63a5\u6536\u7aef\u8bbe\u8ba1\u8fed\u4ee3\u68c0\u6d4b\u65b9\u6848\u6765\u51cf\u8f7b\u8f7d\u6ce2\u95f4\u5e72\u6270(ICI)\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6280\u672f\u80fd\u591f\u6709\u6548\u51cf\u5c11\u5e72\u6270\uff0c\u5373\u4f7f\u5728\u6fc0\u8fdb\u538b\u7f29\u56e0\u5b50\u548c\u9ad8\u79fb\u52a8\u6027\u4fe1\u9053\u6761\u4ef6\u4e0b\u4ecd\u80fd\u4fdd\u6301\u7a33\u5065\u7684\u8bef\u7801\u7387(BER)\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u975e\u6b63\u4ea4AFDM\u6ce2\u5f62\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u9ad8\u52a8\u6001\u73af\u5883\u4e2d\u5e73\u8861\u9891\u8c31\u6548\u7387\u548c\u591a\u666e\u52d2\u6297\u6027\uff0c\u9002\u7528\u4e8e6G\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u573a\u666f\u3002"}}
{"id": "2507.17713", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17713", "abs": "https://arxiv.org/abs/2507.17713", "authors": ["Hongji Wang", "Hongqiao Wang", "Jinyong Ying", "Qingping Zhou"], "title": "Sequential Bayesian Design for Efficient Surrogate Construction in the Inversion of Darcy Flows", "comment": "21 pages, 15 figures", "summary": "Inverse problems governed by partial differential equations (PDEs) play a\ncrucial role in various fields, including computational science, image\nprocessing, and engineering. Particularly, Darcy flow equation is a fundamental\nequation in fluid mechanics, which plays a crucial role in understanding fluid\nflow through porous media. Bayesian methods provide an effective approach for\nsolving PDEs inverse problems, while their numerical implementation requires\nnumerous evaluations of computationally expensive forward solvers. Therefore,\nthe adoption of surrogate models with lower computational costs is essential.\nHowever, constructing a globally accurate surrogate model for high-dimensional\ncomplex problems demands high model capacity and large amounts of data. To\naddress this challenge, this study proposes an efficient locally accurate\nsurrogate that focuses on the high-probability regions of the true likelihood\nin inverse problems, with relatively low model complexity and few training data\nrequirements. Additionally, we introduce a sequential Bayesian design strategy\nto acquire the proposed surrogate since the high-probability region of the\nlikelihood is unknown. The strategy treats the posterior evolution process of\nsequential Bayesian design as a Gaussian process, enabling algorithmic\nacceleration through one-step ahead prior. The complete algorithmic framework\nis referred to as Sequential Bayesian design for locally accurate surrogate\n(SBD-LAS). Finally, three experiments based the Darcy flow equation demonstrate\nthe advantages of the proposed method in terms of both inversion accuracy and\ncomputational speed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u504f\u5fae\u5206\u65b9\u7a0b\u53cd\u95ee\u9898\u7684\u5e8f\u5217\u8d1d\u53f6\u65af\u8bbe\u8ba1\u5c40\u90e8\u7cbe\u786e\u4ee3\u7406\u6a21\u578b\u65b9\u6cd5(SBD-LAS)\uff0c\u901a\u8fc7\u805a\u7126\u9ad8\u6982\u7387\u4f3c\u7136\u533a\u57df\u6765\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u5728\u8fbe\u897f\u6d41\u65b9\u7a0b\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5728\u53cd\u6f14\u7cbe\u5ea6\u548c\u8ba1\u7b97\u901f\u5ea6\u65b9\u9762\u7684\u4f18\u52bf\u3002", "motivation": "\u504f\u5fae\u5206\u65b9\u7a0b\u53cd\u95ee\u9898\u7684\u8d1d\u53f6\u65af\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u6602\u8d35\u7684\u6b63\u5411\u6c42\u89e3\u5668\u8bc4\u4f30\uff0c\u800c\u6784\u5efa\u5168\u5c40\u7cbe\u786e\u7684\u4ee3\u7406\u6a21\u578b\u5bf9\u4e8e\u9ad8\u7ef4\u590d\u6742\u95ee\u9898\u9700\u8981\u9ad8\u6a21\u578b\u5bb9\u91cf\u548c\u5927\u91cf\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u4f46\u4ecd\u80fd\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u5c40\u90e8\u7cbe\u786e\u4ee3\u7406\u6a21\u578b\uff0c\u4e13\u6ce8\u4e8e\u53cd\u95ee\u9898\u4e2d\u771f\u5b9e\u4f3c\u7136\u7684\u9ad8\u6982\u7387\u533a\u57df\uff0c\u5177\u6709\u76f8\u5bf9\u8f83\u4f4e\u7684\u6a21\u578b\u590d\u6742\u5ea6\u548c\u8f83\u5c11\u7684\u8bad\u7ec3\u6570\u636e\u9700\u6c42\uff1b\u5f15\u5165\u5e8f\u5217\u8d1d\u53f6\u65af\u8bbe\u8ba1\u7b56\u7565\u6765\u83b7\u53d6\u6240\u63d0\u51fa\u7684\u4ee3\u7406\u6a21\u578b\uff1b\u5c06\u5e8f\u5217\u8d1d\u53f6\u65af\u8bbe\u8ba1\u7684\u540e\u9a8c\u6f14\u5316\u8fc7\u7a0b\u89c6\u4e3a\u9ad8\u65af\u8fc7\u7a0b\uff0c\u901a\u8fc7\u4e00\u6b65\u9884\u6d4b\u5148\u9a8c\u5b9e\u73b0\u7b97\u6cd5\u52a0\u901f\u3002", "result": "\u5728\u57fa\u4e8e\u8fbe\u897f\u6d41\u65b9\u7a0b\u7684\u4e09\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u6240\u63d0\u51fa\u7684SBD-LAS\u65b9\u6cd5\u5728\u53cd\u6f14\u7cbe\u5ea6\u548c\u8ba1\u7b97\u901f\u5ea6\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u4f18\u52bf\u3002", "conclusion": "SBD-LAS\u65b9\u6cd5\u901a\u8fc7\u6784\u5efa\u5c40\u90e8\u7cbe\u786e\u7684\u4ee3\u7406\u6a21\u578b\u548c\u5e8f\u5217\u8d1d\u53f6\u65af\u8bbe\u8ba1\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u504f\u5fae\u5206\u65b9\u7a0b\u53cd\u95ee\u9898\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u7cbe\u5ea6\u8981\u6c42\u7684\u77db\u76fe\uff0c\u4e3a\u6b64\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16983", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16983", "abs": "https://arxiv.org/abs/2507.16983", "authors": ["Sonny T. Jones", "Grange M. Simpson", "Patrick M. Pilarski", "Ashley N. Dalrymple"], "title": "Hierarchical Reinforcement Learning Framework for Adaptive Walking Control Using General Value Functions of Lower-Limb Sensor Signals", "comment": "5 pages, 3 figures, accepted at the 6th Multi-disciplinary Conference\n  on Reinforcement Learning and Decision Making (RLDM2025), June 11-14, 2025", "summary": "Rehabilitation technology is a natural setting to study the shared learning\nand decision-making of human and machine agents. In this work, we explore the\nuse of Hierarchical Reinforcement Learning (HRL) to develop adaptive control\nstrategies for lower-limb exoskeletons, aiming to enhance mobility and autonomy\nfor individuals with motor impairments. Inspired by prominent models of\nbiological sensorimotor processing, our investigated HRL approach breaks down\nthe complex task of exoskeleton control adaptation into a higher-level\nframework for terrain strategy adaptation and a lower-level framework for\nproviding predictive information; this latter element is implemented via the\ncontinual learning of general value functions (GVFs). GVFs generated temporal\nabstractions of future signal values from multiple wearable lower-limb sensors,\nincluding electromyography, pressure insoles, and goniometers. We investigated\ntwo methods for incorporating actual and predicted sensor signals into a policy\nnetwork with the intent to improve the decision-making capacity of the control\nsystem of a lower-limb exoskeleton during ambulation across varied terrains. As\na key result, we found that the addition of predictions made from GVFs\nincreased overall network accuracy. Terrain-specific performance increases were\nseen while walking on even ground, uneven ground, up and down ramps, and turns,\nterrains that are often misclassified without predictive information. This\nsuggests that predictive information can aid decision-making during\nuncertainty, e.g., on terrains that have a high chance of being misclassified.\nThis work, therefore, contributes new insights into the nuances of HRL and the\nfuture development of exoskeletons to facilitate safe transitioning and\ntraversing across different walking environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u91c7\u7528\u5206\u5c42\u5f3a\u5316\u5b66\u4e60(HRL)\u5f00\u53d1\u4e0b\u80a2\u5916\u9aa8\u9abc\u7684\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u7ed3\u5408\u751f\u7269\u4f20\u611f\u5668\u6570\u636e\u548c\u9884\u6d4b\u4fe1\u606f\uff0c\u63d0\u9ad8\u4e86\u5916\u9aa8\u9abc\u5728\u4e0d\u540c\u5730\u5f62\u4e0a\u7684\u884c\u8d70\u51b3\u7b56\u51c6\u786e\u6027\u3002", "motivation": "\u5eb7\u590d\u6280\u672f\u4e3a\u7814\u7a76\u4eba\u673a\u534f\u4f5c\u5b66\u4e60\u548c\u51b3\u7b56\u63d0\u4f9b\u4e86\u81ea\u7136\u73af\u5883\u3002\u73b0\u6709\u4e0b\u80a2\u5916\u9aa8\u9abc\u63a7\u5236\u7cfb\u7edf\u5728\u590d\u6742\u5730\u5f62\u9002\u5e94\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u589e\u5f3a\u8fd0\u52a8\u969c\u788d\u60a3\u8005\u79fb\u52a8\u6027\u548c\u81ea\u4e3b\u6027\u7684\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\u3002", "method": "\u91c7\u7528\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u5916\u9aa8\u9abc\u63a7\u5236\u9002\u5e94\u4efb\u52a1\u5206\u89e3\u4e3a\u9ad8\u5c42\u5730\u5f62\u7b56\u7565\u9002\u5e94\u6846\u67b6\u548c\u4f4e\u5c42\u9884\u6d4b\u4fe1\u606f\u63d0\u4f9b\u6846\u67b6\u3002\u901a\u8fc7\u6301\u7eed\u5b66\u4e60\u4e00\u822c\u4ef7\u503c\u51fd\u6570(GVFs)\u5b9e\u73b0\u9884\u6d4b\u529f\u80fd\uff0c\u5229\u7528\u808c\u7535\u56fe\u3001\u538b\u529b\u978b\u57ab\u548c\u89d2\u5ea6\u8ba1\u7b49\u591a\u79cd\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6570\u636e\uff0c\u7814\u7a76\u4e86\u4e24\u79cd\u5c06\u5b9e\u9645\u548c\u9884\u6d4b\u4f20\u611f\u5668\u4fe1\u53f7\u878d\u5165\u7b56\u7565\u7f51\u7edc\u7684\u65b9\u6cd5\u3002", "result": "\u6dfb\u52a0GVFs\u9884\u6d4b\u4fe1\u606f\u663e\u8457\u63d0\u9ad8\u4e86\u7f51\u7edc\u6574\u4f53\u51c6\u786e\u6027\u3002\u5728\u5e73\u5730\u3001\u4e0d\u5e73\u5730\u9762\u3001\u4e0a\u4e0b\u5761\u9053\u548c\u8f6c\u5f2f\u7b49\u5730\u5f62\u4e0a\u90fd\u89c2\u5bdf\u5230\u4e86\u7279\u5b9a\u5730\u5f62\u6027\u80fd\u7684\u63d0\u5347\uff0c\u8fd9\u4e9b\u5730\u5f62\u5728\u6ca1\u6709\u9884\u6d4b\u4fe1\u606f\u65f6\u7ecf\u5e38\u88ab\u8bef\u5206\u7c7b\u3002\u9884\u6d4b\u4fe1\u606f\u5728\u4e0d\u786e\u5b9a\u6027\u60c5\u51b5\u4e0b\u80fd\u591f\u8f85\u52a9\u51b3\u7b56\u5236\u5b9a\u3002", "conclusion": "\u9884\u6d4b\u4fe1\u606f\u80fd\u591f\u5728\u5730\u5f62\u8bef\u5206\u7c7b\u6982\u7387\u8f83\u9ad8\u7684\u4e0d\u786e\u5b9a\u60c5\u51b5\u4e0b\u8f85\u52a9\u51b3\u7b56\u5236\u5b9a\u3002\u8be5\u7814\u7a76\u4e3a\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7684\u7ec6\u8282\u7406\u89e3\u548c\u672a\u6765\u5916\u9aa8\u9abc\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u5728\u4e0d\u540c\u884c\u8d70\u73af\u5883\u4e2d\u7684\u5b89\u5168\u8fc7\u6e21\u548c\u7a7f\u8d8a\u3002"}}
{"id": "2507.17352", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17352", "abs": "https://arxiv.org/abs/2507.17352", "authors": ["Chunmei Xu", "Siqi Zhang", "Yi Ma", "Rahim Tafazolli"], "title": "LightCom: A Generative AI-Augmented Framework for QoE-Oriented Communications", "comment": null, "summary": "Data-intensive and immersive applications, such as virtual reality, impose\nstringent quality of experience (QoE) requirements that challenge traditional\nquality of service (QoS)-driven communication systems. This paper presents\nLightCom, a lightweight encoding and generative AI (GenAI)-augmented decoding\nframework, designed for QoE-oriented communications under low signal-to-noise\nratio (SNR) conditions. LightCom simplifies transmitter design by applying\nbasic low-pass filtering for source coding and minimal channel coding,\nsignificantly reducing processing complexity and energy consumption. At the\nreceiver, GenAI models reconstruct high-fidelity content from highly compressed\nand degraded signals by leveraging generative priors to infer semantic and\nstructural information beyond traditional decoding capabilities. The key design\nprinciples are analyzed, along with the sufficiency and error-resilience of the\nsource representation. We also develop importance-aware power allocation\nstrategies to enhance QoE and extend perceived coverage. Simulation results\ndemonstrate that LightCom achieves up to a $14$ dB improvement in robustness\nand a $9$ dB gain in perceived coverage, outperforming traditional QoS-driven\nsystems relying on sophisticated source and channel coding. This paradigm shift\nmoves communication systems towards human-centric QoE metrics rather than\nbit-level fidelity, paving the way for more efficient and resilient wireless\nnetworks.", "AI": {"tldr": "LightCom\u662f\u4e00\u4e2a\u9762\u5411QoE\u7684\u8f7b\u91cf\u7ea7\u7f16\u7801\u548c\u751f\u6210AI\u589e\u5f3a\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u7b80\u5316\u53d1\u5c04\u7aef\u8bbe\u8ba1\u548c\u5229\u7528\u751f\u6210AI\u5728\u63a5\u6536\u7aef\u91cd\u5efa\u9ad8\u4fdd\u771f\u5185\u5bb9\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u9c81\u68d2\u6027\u548c\u8986\u76d6\u8303\u56f4\u6539\u8fdb\u3002", "motivation": "\u6570\u636e\u5bc6\u96c6\u578b\u548c\u6c89\u6d78\u5f0f\u5e94\u7528\uff08\u5982\u865a\u62df\u73b0\u5b9e\uff09\u5bf9\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\uff08QoE\uff09\u63d0\u51fa\u4e86\u4e25\u683c\u8981\u6c42\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u4ee5\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u4e3a\u9a71\u52a8\u7684\u901a\u4fe1\u7cfb\u7edf\u3002\u9700\u8981\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9762\u5411QoE\u7684\u901a\u4fe1\u3002", "method": "\u63d0\u51faLightCom\u6846\u67b6\uff1a1\uff09\u53d1\u5c04\u7aef\u91c7\u7528\u57fa\u7840\u4f4e\u901a\u6ee4\u6ce2\u8fdb\u884c\u4fe1\u6e90\u7f16\u7801\u548c\u6700\u5c0f\u4fe1\u9053\u7f16\u7801\uff0c\u7b80\u5316\u8bbe\u8ba1\u5e76\u964d\u4f4e\u590d\u6742\u5ea6\uff1b2\uff09\u63a5\u6536\u7aef\u4f7f\u7528\u751f\u6210AI\u6a21\u578b\u4ece\u9ad8\u5ea6\u538b\u7f29\u548c\u9000\u5316\u7684\u4fe1\u53f7\u4e2d\u91cd\u5efa\u9ad8\u4fdd\u771f\u5185\u5bb9\uff0c\u5229\u7528\u751f\u6210\u5148\u9a8c\u63a8\u65ad\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u606f\uff1b3\uff09\u5f00\u53d1\u91cd\u8981\u6027\u611f\u77e5\u529f\u7387\u5206\u914d\u7b56\u7565\u6765\u589e\u5f3aQoE\u548c\u6269\u5c55\u611f\u77e5\u8986\u76d6\u8303\u56f4\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793aLightCom\u5728\u9c81\u68d2\u6027\u65b9\u9762\u5b9e\u73b0\u4e86\u9ad8\u8fbe14 dB\u7684\u6539\u8fdb\uff0c\u5728\u611f\u77e5\u8986\u76d6\u8303\u56f4\u65b9\u9762\u83b7\u5f97\u4e869 dB\u7684\u589e\u76ca\uff0c\u6027\u80fd\u4f18\u4e8e\u4f9d\u8d56\u590d\u6742\u4fe1\u6e90\u548c\u4fe1\u9053\u7f16\u7801\u7684\u4f20\u7edfQoS\u9a71\u52a8\u7cfb\u7edf\u3002", "conclusion": "\u8fd9\u79cd\u8303\u5f0f\u8f6c\u53d8\u5c06\u901a\u4fe1\u7cfb\u7edf\u4ece\u6bd4\u7279\u7ea7\u4fdd\u771f\u5ea6\u8f6c\u5411\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684QoE\u6307\u6807\uff0c\u4e3a\u6784\u5efa\u66f4\u9ad8\u6548\u548c\u66f4\u5177\u5f39\u6027\u7684\u65e0\u7ebf\u7f51\u7edc\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.17066", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.17066", "abs": "https://arxiv.org/abs/2507.17066", "authors": ["Jessup Byun", "Xiaofeng Lin", "Joshua Ward", "Guang Cheng"], "title": "Risk In Context: Benchmarking Privacy Leakage of Foundation Models in Synthetic Tabular Data Generation", "comment": "Accepted by Agentic & GenAI Evaluation KDD2025, poster presentation", "summary": "Synthetic tabular data is essential for machine learning workflows,\nespecially for expanding small or imbalanced datasets and enabling\nprivacy-preserving data sharing. However, state-of-the-art generative models\n(GANs, VAEs, diffusion models) rely on large datasets with thousands of\nexamples. In low-data settings, often the primary motivation for synthetic\ndata, these models can overfit, leak sensitive records, and require frequent\nretraining. Recent work uses large pre-trained transformers to generate rows\nvia in-context learning (ICL), which needs only a few seed examples and no\nparameter updates, avoiding retraining. But ICL repeats seed rows verbatim,\nintroducing a new privacy risk that has only been studied in text. The severity\nof this risk in tabular synthesis-where a single row may identify a\nperson-remains unclear. We address this gap with the first benchmark of three\nfoundation models (GPT-4o-mini, LLaMA 3.3 70B, TabPFN v2) against four\nbaselines on 35 real-world tables from health, finance, and policy. We evaluate\nstatistical fidelity, downstream utility, and membership inference leakage.\nResults show foundation models consistently have the highest privacy risk.\nLLaMA 3.3 70B reaches up to 54 percentage points higher true-positive rate at\n1% FPR than the safest baseline. GPT-4o-mini and TabPFN are also highly\nvulnerable. We plot the privacy-utility frontier and show that CTGAN and\nGPT-4o-mini offer better tradeoffs. A factorial study finds that three\nzero-cost prompt tweaks-small batch size, low temperature, and using summary\nstatistics-can reduce worst-case AUC by 14 points and rare-class leakage by up\nto 39 points while maintaining over 90% fidelity. Our benchmark offers a\npractical guide for safer low-data synthesis with foundation models.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u57fa\u7840\u6a21\u578b\u5728\u4f4e\u6570\u636e\u91cf\u8868\u683c\u5408\u6210\u4e2d\u7684\u9690\u79c1\u98ce\u9669\uff0c\u53d1\u73b0\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u96f6\u6210\u672c\u7684\u63d0\u793a\u4f18\u5316\u7b56\u7565\u6765\u6539\u5584\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u5bb9\u6613\u8fc7\u62df\u5408\u548c\u6cc4\u9732\u654f\u611f\u4fe1\u606f\uff0c\u800c\u65b0\u5174\u7684\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u8fdb\u884c\u8868\u683c\u5408\u6210\u65f6\u4f1a\u9010\u5b57\u91cd\u590d\u79cd\u5b50\u884c\uff0c\u5728\u8868\u683c\u6570\u636e\u4e2d\u5f15\u5165\u65b0\u7684\u9690\u79c1\u98ce\u9669\uff0c\u4f46\u8fd9\u79cd\u98ce\u9669\u7684\u4e25\u91cd\u7a0b\u5ea6\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u6784\u5efa\u9996\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u75283\u4e2a\u57fa\u7840\u6a21\u578b\uff08GPT-4o-mini\u3001LLaMA 3.3 70B\u3001TabPFN v2\uff09\u4e0e4\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u572835\u4e2a\u6765\u81ea\u5065\u5eb7\u3001\u91d1\u878d\u548c\u653f\u7b56\u9886\u57df\u7684\u771f\u5b9e\u8868\u683c\u4e0a\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc4\u4f30\u7edf\u8ba1\u4fdd\u771f\u5ea6\u3001\u4e0b\u6e38\u6548\u7528\u548c\u6210\u5458\u63a8\u7406\u6cc4\u9732\u98ce\u9669\uff0c\u5e76\u901a\u8fc7\u56e0\u5b50\u7814\u7a76\u63a2\u7d22\u96f6\u6210\u672c\u63d0\u793a\u4f18\u5316\u7b56\u7565\u3002", "result": "\u57fa\u7840\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u6700\u9ad8\uff0cLLaMA 3.3 70B\u57281%\u5047\u9633\u6027\u7387\u4e0b\u7684\u771f\u9633\u6027\u7387\u6bd4\u6700\u5b89\u5168\u57fa\u7ebf\u9ad8\u51fa54\u4e2a\u767e\u5206\u70b9\uff1bCTGAN\u548cGPT-4o-mini\u63d0\u4f9b\u66f4\u597d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\uff1b\u4e09\u79cd\u96f6\u6210\u672c\u63d0\u793a\u8c03\u6574\uff08\u5c0f\u6279\u91cf\u3001\u4f4e\u6e29\u5ea6\u3001\u4f7f\u7528\u6c47\u603b\u7edf\u8ba1\uff09\u53ef\u5c06\u6700\u574f\u60c5\u51b5AUC\u964d\u4f4e14\u4e2a\u70b9\uff0c\u7a00\u6709\u7c7b\u6cc4\u9732\u964d\u4f4e39\u4e2a\u70b9\uff0c\u540c\u65f6\u4fdd\u630190%\u4ee5\u4e0a\u7684\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u5728\u8868\u683c\u5408\u6210\u4e2d\u5b58\u5728\u663e\u8457\u9690\u79c1\u98ce\u9669\uff0c\u4f46\u901a\u8fc7\u9002\u5f53\u7684\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u53ef\u4ee5\u5728\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u6709\u6548\u964d\u4f4e\u9690\u79c1\u6cc4\u9732\uff0c\u4e3a\u4f4e\u6570\u636e\u91cf\u573a\u666f\u4e0b\u7684\u5b89\u5168\u8868\u683c\u5408\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2507.16991", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16991", "abs": "https://arxiv.org/abs/2507.16991", "authors": ["Matthias Fey", "Jinu Sunil", "Akihiro Nitta", "Rishi Puri", "Manan Shah", "Bla\u017e Stojanovi\u010d", "Ramona Bendias", "Alexandria Barghi", "Vid Kocijan", "Zecheng Zhang", "Xinwei He", "Jan Eric Lenssen", "Jure Leskovec"], "title": "PyG 2.0: Scalable Learning on Real World Graphs", "comment": null, "summary": "PyG (PyTorch Geometric) has evolved significantly since its initial release,\nestablishing itself as a leading framework for Graph Neural Networks. In this\npaper, we present Pyg 2.0 (and its subsequent minor versions), a comprehensive\nupdate that introduces substantial improvements in scalability and real-world\napplication capabilities. We detail the framework's enhanced architecture,\nincluding support for heterogeneous and temporal graphs, scalable feature/graph\nstores, and various optimizations, enabling researchers and practitioners to\ntackle large-scale graph learning problems efficiently. Over the recent years,\nPyG has been supporting graph learning in a large variety of application areas,\nwhich we will summarize, while providing a deep dive into the important areas\nof relational deep learning and large language modeling.", "AI": {"tldr": "PyG 2.0\u662fPyTorch Geometric\u7684\u91cd\u5927\u66f4\u65b0\u7248\u672c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5e94\u7528\u80fd\u529b\uff0c\u652f\u6301\u5f02\u8d28\u56fe\u3001\u65f6\u5e8f\u56fe\u7b49\u590d\u6742\u573a\u666f\uff0c\u5e76\u5728\u5173\u7cfb\u6df1\u5ea6\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7b49\u9886\u57df\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u56fe\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u7684\u4e0d\u65ad\u6269\u5c55\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u5f3a\u5927\u3001\u66f4\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u5904\u7406\u5927\u89c4\u6a21\u56fe\u5b66\u4e60\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5f02\u8d28\u56fe\u3001\u65f6\u5e8f\u56fe\u4ee5\u53ca\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u7684\u590d\u6742\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u67b6\u6784\u589e\u5f3a\u5b9e\u73b0PyG 2.0\u7684\u5168\u9762\u5347\u7ea7\uff0c\u5305\u62ec\uff1a\u652f\u6301\u5f02\u8d28\u56fe\u548c\u65f6\u5e8f\u56fe\u3001\u53ef\u6269\u5c55\u7684\u7279\u5f81/\u56fe\u5b58\u50a8\u7cfb\u7edf\u3001\u5404\u79cd\u6027\u80fd\u4f18\u5316\u6280\u672f\uff0c\u4ee5\u53ca\u9488\u5bf9\u5173\u7cfb\u6df1\u5ea6\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e13\u95e8\u652f\u6301\u3002", "result": "PyG 2.0\u6210\u529f\u652f\u6301\u4e86\u5927\u89c4\u6a21\u56fe\u5b66\u4e60\u95ee\u9898\u7684\u9ad8\u6548\u5904\u7406\uff0c\u5728\u591a\u4e2a\u5e94\u7528\u9886\u57df\u5f97\u5230\u9a8c\u8bc1\uff0c\u7279\u522b\u662f\u5728\u5173\u7cfb\u6df1\u5ea6\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u9886\u57df\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5e94\u7528\u80fd\u529b\u3002", "conclusion": "PyG 2.0\u901a\u8fc7\u5168\u9762\u7684\u67b6\u6784\u6539\u8fdb\u548c\u529f\u80fd\u6269\u5c55\uff0c\u5de9\u56fa\u4e86\u5176\u4f5c\u4e3a\u9886\u5148\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u7684\u5730\u4f4d\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5904\u7406\u590d\u6742\u3001\u5927\u89c4\u6a21\u56fe\u5b66\u4e60\u4efb\u52a1\u7684\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2507.17393", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17393", "abs": "https://arxiv.org/abs/2507.17393", "authors": ["Omar Osman", "Abdullah Qayyum", "Maziar Nekovee"], "title": "Partially Reflected Surface (PRS)-Loaded Graphene-Based Patch Antenna for 6G", "comment": null, "summary": "This work investigates a slotted patch antenna integrated with a partially\nreflected surface (PRS) to operate in the TeraHertz (THz) frequency range for\n6G. The antenna is based on graphene material, on a Rogers RT Duroid 6010\nsubstrate. The proposed antenna achieves a bandwidth of 70 GHz (750 GHz to 820\nGHz). The PRS sheet consists of 5x4 unit cells, which are optimised to enhance\nthe overall realized gain of the antenna. The overall realized gain has\nincreased by 1.07 dBi. Also, the PRS enhanced the antenna radiation pattern,\nshowing stable properties over the operating bandwidth. The improved antenna\nperformance is validated via simulations.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u96c6\u6210\u90e8\u5206\u53cd\u5c04\u8868\u9762(PRS)\u7684\u5f00\u69fd\u8d34\u7247\u5929\u7ebf\uff0c\u5de5\u4f5c\u5728\u592a\u8d6b\u5179\u9891\u6bb5\uff0c\u7528\u4e8e6G\u901a\u4fe1\u3002\u8be5\u5929\u7ebf\u57fa\u4e8e\u77f3\u58a8\u70ef\u6750\u6599\uff0c\u5728Rogers RT Duroid 6010\u57fa\u677f\u4e0a\u5b9e\u73b0\uff0c\u5e26\u5bbd\u8fbe70 GHz\uff0c\u589e\u76ca\u63d0\u53471.07 dBi\u3002", "motivation": "\u4e3a6G\u901a\u4fe1\u7cfb\u7edf\u5f00\u53d1\u5de5\u4f5c\u5728\u592a\u8d6b\u5179\u9891\u6bb5\u7684\u9ad8\u6027\u80fd\u5929\u7ebf\uff0c\u9700\u8981\u89e3\u51b3\u592a\u8d6b\u5179\u9891\u6bb5\u5929\u7ebf\u589e\u76ca\u4f4e\u3001\u8f90\u5c04\u65b9\u5411\u56fe\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u77f3\u58a8\u70ef\u6750\u6599\u7684\u5f00\u69fd\u8d34\u7247\u5929\u7ebf\uff0c\u96c6\u62105x4\u5355\u5143\u683c\u7684\u90e8\u5206\u53cd\u5c04\u8868\u9762(PRS)\uff0c\u4f7f\u7528Rogers RT Duroid 6010\u4f5c\u4e3a\u57fa\u677f\u6750\u6599\uff0c\u901a\u8fc7\u4f18\u5316PRS\u5355\u5143\u683c\u6765\u589e\u5f3a\u5929\u7ebf\u6574\u4f53\u6027\u80fd\u3002", "result": "\u5929\u7ebf\u5b9e\u73b0\u4e8670 GHz\u7684\u5e26\u5bbd(750-820 GHz)\uff0c\u6574\u4f53\u5b9e\u73b0\u589e\u76ca\u63d0\u5347\u4e861.07 dBi\uff0cPRS\u589e\u5f3a\u4e86\u5929\u7ebf\u8f90\u5c04\u65b9\u5411\u56fe\uff0c\u5728\u5de5\u4f5c\u5e26\u5bbd\u5185\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u7279\u6027\u3002", "conclusion": "\u96c6\u6210PRS\u7684\u77f3\u58a8\u70ef\u5f00\u69fd\u8d34\u7247\u5929\u7ebf\u6210\u529f\u63d0\u5347\u4e86\u592a\u8d6b\u5179\u9891\u6bb5\u7684\u5929\u7ebf\u6027\u80fd\uff0c\u5305\u62ec\u589e\u76ca\u548c\u8f90\u5c04\u65b9\u5411\u56fe\u7a33\u5b9a\u6027\uff0c\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u6539\u8fdb\u540e\u5929\u7ebf\u7684\u6709\u6548\u6027\uff0c\u4e3a6G\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5929\u7ebf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17534", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.17534", "abs": "https://arxiv.org/abs/2507.17534", "authors": ["Aymeric Dieuleveut", "Gersende Fort", "Mahmoud Hegazy", "Hoi-To Wai"], "title": "Federated Majorize-Minimization: Beyond Parameter Aggregation", "comment": null, "summary": "This paper proposes a unified approach for designing stochastic optimization\nalgorithms that robustly scale to the federated learning setting. Our work\nstudies a class of Majorize-Minimization (MM) problems, which possesses a\nlinearly parameterized family of majorizing surrogate functions. This framework\nencompasses (proximal) gradient-based algorithms for (regularized) smooth\nobjectives, the Expectation Maximization algorithm, and many problems seen as\nvariational surrogate MM. We show that our framework motivates a unifying\nalgorithm called Stochastic Approximation Stochastic Surrogate MM (\\SSMM),\nwhich includes previous stochastic MM procedures as special instances. We then\nextend \\SSMM\\ to the federated setting, while taking into consideration common\nbottlenecks such as data heterogeneity, partial participation, and\ncommunication constraints; this yields \\QSMM. The originality of \\QSMM\\ is to\nlearn locally and then aggregate information characterizing the\n\\textit{surrogate majorizing function}, contrary to classical algorithms which\nlearn and aggregate the \\textit{original parameter}. Finally, to showcase the\nflexibility of this methodology beyond our theoretical setting, we use it to\ndesign an algorithm for computing optimal transport maps in the federated\nsetting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u968f\u673a\u4f18\u5316\u7b97\u6cd5\u6846\u67b6\uff0c\u901a\u8fc7Majorize-Minimization\u65b9\u6cd5\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff0c\u8bbe\u8ba1\u4e86SSMM\u548cQSMM\u7b97\u6cd5\u6765\u5904\u7406\u6570\u636e\u5f02\u6784\u6027\u3001\u90e8\u5206\u53c2\u4e0e\u548c\u901a\u4fe1\u7ea6\u675f\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u5728\u9762\u5bf9\u6570\u636e\u5f02\u6784\u6027\u3001\u90e8\u5206\u53c2\u4e0e\u548c\u901a\u4fe1\u7ea6\u675f\u7b49\u74f6\u9888\u65f6\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9c81\u68d2\u6269\u5c55\u5230\u8054\u90a6\u5b66\u4e60\u73af\u5883\u7684\u968f\u673a\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u7c7b\u5177\u6709\u7ebf\u6027\u53c2\u6570\u5316majorizing\u4ee3\u7406\u51fd\u6570\u65cf\u7684Majorize-Minimization\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7b97\u6cd5SSMM\uff08\u968f\u673a\u8fd1\u4f3c\u968f\u673a\u4ee3\u7406MM\uff09\uff0c\u7136\u540e\u5c06\u5176\u6269\u5c55\u5230\u8054\u90a6\u8bbe\u7f6e\u4e2d\u5f62\u6210QSMM\u7b97\u6cd5\u3002QSMM\u7684\u521b\u65b0\u5728\u4e8e\u5b66\u4e60\u5e76\u805a\u5408\u8868\u5f81\u4ee3\u7406majorizing\u51fd\u6570\u7684\u4fe1\u606f\uff0c\u800c\u975e\u4f20\u7edf\u7684\u539f\u59cb\u53c2\u6570\u805a\u5408\u3002", "result": "\u6846\u67b6\u6db5\u76d6\u4e86\u591a\u79cd\u7b97\u6cd5\u5305\u62ec\u68af\u5ea6\u7b97\u6cd5\u3001\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u7b49\uff0cSSMM\u7b97\u6cd5\u5305\u542b\u4e86\u4e4b\u524d\u7684\u968f\u673aMM\u8fc7\u7a0b\u4f5c\u4e3a\u7279\u4f8b\uff0c\u6210\u529f\u6269\u5c55\u5230\u8054\u90a6\u5b66\u4e60\u73af\u5883\u5e76\u89e3\u51b3\u4e86\u5e38\u89c1\u74f6\u9888\u95ee\u9898\uff0c\u8fd8\u5c55\u793a\u4e86\u5728\u8054\u90a6\u73af\u5883\u4e0b\u8ba1\u7b97\u6700\u4f18\u4f20\u8f93\u6620\u5c04\u7684\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bbe\u8ba1\u9002\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\u7684\u968f\u673a\u4f18\u5316\u7b97\u6cd5\uff0cQSMM\u7b97\u6cd5\u901a\u8fc7\u805a\u5408\u4ee3\u7406\u51fd\u6570\u4fe1\u606f\u800c\u975e\u539f\u59cb\u53c2\u6570\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u5c55\u73b0\u4e86\u8d85\u8d8a\u7406\u8bba\u8bbe\u7f6e\u7684\u5e94\u7528\u7075\u6d3b\u6027\u3002"}}
{"id": "2507.17001", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17001", "abs": "https://arxiv.org/abs/2507.17001", "authors": ["Yan Li", "Guangyi Chen", "Yunlong Deng", "Zijian Li", "Zeyu Tang", "Anpeng Wu", "Kun Zhang"], "title": "Should Bias Always be Eliminated? A Principled Framework to Use Data Bias for OOD Generation", "comment": null, "summary": "Most existing methods for adapting models to out-of-distribution (OOD)\ndomains rely on invariant representation learning to eliminate the influence of\nbiased features. However, should bias always be eliminated -- and if not, when\nshould it be retained, and how can it be leveraged? To address these questions,\nwe first present a theoretical analysis that explores the conditions under\nwhich biased features can be identified and effectively utilized. Building on\nthis theoretical foundation, we introduce a novel framework that strategically\nleverages bias to complement invariant representations during inference. The\nframework comprises two key components that leverage bias in both direct and\nindirect ways: (1) using invariance as guidance to extract predictive\ningredients from bias, and (2) exploiting identified bias to estimate the\nenvironmental condition and then use it to explore appropriate bias-aware\npredictors to alleviate environment gaps. We validate our approach through\nexperiments on both synthetic datasets and standard domain generalization\nbenchmarks. Results consistently demonstrate that our method outperforms\nexisting approaches, underscoring its robustness and adaptability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6218\u7565\u6027\u5730\u5229\u7528\u504f\u5dee\u6765\u8865\u5145\u4e0d\u53d8\u8868\u793a\uff0c\u5728\u57df\u5916\u5206\u5e03\u9002\u5e94\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57df\u5916\u5206\u5e03\u9002\u5e94\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e0d\u53d8\u8868\u793a\u5b66\u4e60\u6765\u6d88\u9664\u504f\u5dee\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u4f46\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\uff1a\u504f\u5dee\u662f\u5426\u603b\u662f\u5e94\u8be5\u88ab\u6d88\u9664\uff1f\u5982\u679c\u4e0d\u662f\uff0c\u4f55\u65f6\u5e94\u8be5\u4fdd\u7559\u504f\u5dee\uff0c\u4ee5\u53ca\u5982\u4f55\u6709\u6548\u5229\u7528\u504f\u5dee\uff1f", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u6765\u76f4\u63a5\u548c\u95f4\u63a5\u5730\u5229\u7528\u504f\u5dee\uff1a(1)\u4f7f\u7528\u4e0d\u53d8\u6027\u4f5c\u4e3a\u6307\u5bfc\u4ece\u504f\u5dee\u4e2d\u63d0\u53d6\u9884\u6d4b\u6210\u5206\uff1b(2)\u5229\u7528\u8bc6\u522b\u51fa\u7684\u504f\u5dee\u6765\u4f30\u8ba1\u73af\u5883\u6761\u4ef6\uff0c\u7136\u540e\u4f7f\u7528\u5b83\u6765\u63a2\u7d22\u5408\u9002\u7684\u504f\u5dee\u611f\u77e5\u9884\u6d4b\u5668\u4ee5\u7f13\u89e3\u73af\u5883\u5dee\u8ddd\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u6807\u51c6\u57df\u6cdb\u5316\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u73b0\u4e86\u5176\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u504f\u5dee\u7279\u5f81\u53ef\u4ee5\u88ab\u8bc6\u522b\u548c\u6709\u6548\u5229\u7528\uff0c\u6218\u7565\u6027\u5730\u5229\u7528\u504f\u5dee\u6765\u8865\u5145\u4e0d\u53d8\u8868\u793a\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u57df\u5916\u5206\u5e03\u9002\u5e94\u7684\u6027\u80fd\u3002"}}
{"id": "2507.17396", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17396", "abs": "https://arxiv.org/abs/2507.17396", "authors": ["Junlang Huang", "Hao Chen", "Zhong Guan"], "title": "Learning from Scratch: Structurally-masked Transformer for Next Generation Lib-free Simulation", "comment": null, "summary": "This paper proposes a neural framework for power and timing prediction of\nmulti-stage data path, distinguishing itself from traditional lib-based\nanalytical methods dependent on driver characterization and load\nsimplifications. To the best of our knowledge, this is the first\nlanguage-based, netlist-aware neural network designed explicitly for standard\ncells. Our approach employs two pre-trained neural models of waveform\nprediction and delay estimation that directly infer transient waveforms and\npropagation delays from SPICE netlists, conditioned on critical physical\nparameters such as load capacitance, input slew, and gate size. This method\naccurately captures both intrinsic and coupling-induced delay effects without\nrequiring simplification or interpolation. For multi-stage timing prediction,\nwe implement a recursive propagation strategy where predicted waveforms from\neach stage feed into subsequent stages, cumulatively capturing delays across\nthe logic chain. This approach ensures precise timing alignment and complete\nwaveform visibility throughout complex signal pathways. The waveform prediction\nutilizes a hybrid CNN-Transformer architecture with netlist-aware node-level\nencoding, addressing traditional Transformers' fixed input dimensionality\nconstraints. Additionally, specialized subnetworks separately handle primary\ndelay estimation and crosstalk correction. Experimental results demonstrate\nSPICE-level accuracy, consistently achieving RMSE below 0.0098 across diverse\nindustrial circuits. The proposed framework provides a scalable, structurally\nadaptable neural alternative to conventional power and timing engines,\ndemonstrating high fidelity to physical circuit behaviors.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u7ea7\u6570\u636e\u8def\u5f84\u529f\u8017\u548c\u65f6\u5e8f\u9884\u6d4b\u6846\u67b6\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6ce2\u5f62\u9884\u6d4b\u548c\u5ef6\u8fdf\u4f30\u8ba1\u6a21\u578b\u76f4\u63a5\u4eceSPICE\u7f51\u8868\u63a8\u65ad\u77ac\u6001\u6ce2\u5f62\u548c\u4f20\u64ad\u5ef6\u8fdf\uff0c\u5728\u5de5\u4e1a\u7535\u8def\u4e0a\u8fbe\u5230SPICE\u7ea7\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5e93\u7684\u5206\u6790\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9a71\u52a8\u5668\u7279\u6027\u63cf\u8ff0\u548c\u8d1f\u8f7d\u7b80\u5316\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u51c6\u786e\u6355\u83b7\u5185\u5728\u548c\u8026\u5408\u8bf1\u5bfc\u5ef6\u8fdf\u6548\u5e94\u7684\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u7b80\u5316\u6216\u63d2\u503c\uff0c\u540c\u65f6\u80fd\u591f\u5904\u7406\u590d\u6742\u4fe1\u53f7\u8def\u5f84\u4e2d\u7684\u5b8c\u6574\u6ce2\u5f62\u53ef\u89c1\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408CNN-Transformer\u67b6\u6784\u548c\u7f51\u8868\u611f\u77e5\u7684\u8282\u70b9\u7ea7\u7f16\u7801\uff0c\u6784\u5efa\u4e24\u4e2a\u9884\u8bad\u7ec3\u795e\u7ecf\u6a21\u578b\uff1a\u6ce2\u5f62\u9884\u6d4b\u548c\u5ef6\u8fdf\u4f30\u8ba1\u3002\u4f7f\u7528\u9012\u5f52\u4f20\u64ad\u7b56\u7565\u8fdb\u884c\u591a\u7ea7\u65f6\u5e8f\u9884\u6d4b\uff0c\u5176\u4e2d\u6bcf\u7ea7\u7684\u9884\u6d4b\u6ce2\u5f62\u8f93\u5165\u5230\u540e\u7eed\u7ea7\u3002\u4e13\u95e8\u7684\u5b50\u7f51\u7edc\u5206\u522b\u5904\u7406\u4e3b\u8981\u5ef6\u8fdf\u4f30\u8ba1\u548c\u4e32\u6270\u6821\u6b63\u3002", "result": "\u5728\u591a\u6837\u5316\u5de5\u4e1a\u7535\u8def\u4e0a\u5b9e\u73b0SPICE\u7ea7\u7cbe\u5ea6\uff0cRMSE\u59cb\u7ec8\u4f4e\u4e8e0.0098\u3002\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u7ed3\u6784\u81ea\u9002\u5e94\u7684\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u65b9\u6848\uff0c\u5bf9\u7269\u7406\u7535\u8def\u884c\u4e3a\u8868\u73b0\u51fa\u9ad8\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u795e\u7ecf\u6846\u67b6\u6210\u529f\u66ff\u4ee3\u4e86\u4f20\u7edf\u7684\u529f\u8017\u548c\u65f6\u5e8f\u5f15\u64ce\uff0c\u901a\u8fc7\u76f4\u63a5\u4eceSPICE\u7f51\u8868\u63a8\u65ad\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u4e3a\u6807\u51c6\u5355\u5143\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9996\u4e2a\u57fa\u4e8e\u8bed\u8a00\u7684\u3001\u7f51\u8868\u611f\u77e5\u7684\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17684", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.17684", "abs": "https://arxiv.org/abs/2507.17684", "authors": ["Penukonda Naga Chandana", "Tejas Srivastava", "Gowtham R. Kurri", "V. Lalitha"], "title": "Generalized Dual Discriminator GANs", "comment": "8 pages, 2 figures, extended version of a paper accepted for\n  presentation at ITW 2025", "summary": "Dual discriminator generative adversarial networks (D2 GANs) were introduced\nto mitigate the problem of mode collapse in generative adversarial networks. In\nD2 GANs, two discriminators are employed alongside a generator: one\ndiscriminator rewards high scores for samples from the true data distribution,\nwhile the other favors samples from the generator. In this work, we first\nintroduce dual discriminator $\\alpha$-GANs (D2 $\\alpha$-GANs), which combines\nthe strengths of dual discriminators with the flexibility of a tunable loss\nfunction, $\\alpha$-loss. We further generalize this approach to arbitrary\nfunctions defined on positive reals, leading to a broader class of models we\nrefer to as generalized dual discriminator generative adversarial networks. For\neach of these proposed models, we provide theoretical analysis and show that\nthe associated min-max optimization reduces to the minimization of a linear\ncombination of an $f$-divergence and a reverse $f$-divergence. This generalizes\nthe known simplification for D2-GANs, where the objective reduces to a linear\ncombination of the KL-divergence and the reverse KL-divergence. Finally, we\nperform experiments on 2D synthetic data and use multiple performance metrics\nto capture various advantages of our GANs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53cc\u5224\u522b\u5668\u03b1-GANs(D2\u03b1-GANs)\u548c\u5e7f\u4e49\u53cc\u5224\u522b\u5668GANs\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u8c03\u8282\u7684\u03b1\u635f\u5931\u51fd\u6570\u548c\u4efb\u610f\u6b63\u5b9e\u6570\u51fd\u6570\u6765\u6539\u8fdb\u4f20\u7edf\u53cc\u5224\u522b\u5668GANs\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u4f18\u5316\u76ee\u6807\u53ef\u7b80\u5316\u4e3af-\u6563\u5ea6\u548c\u9006f-\u6563\u5ea6\u7684\u7ebf\u6027\u7ec4\u5408", "motivation": "\u4f20\u7edfGANs\u5b58\u5728\u6a21\u5f0f\u5d29\u584c\u95ee\u9898\uff0c\u867d\u7136\u53cc\u5224\u522b\u5668GANs(D2-GANs)\u80fd\u591f\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u4ecd\u9700\u8981\u66f4\u7075\u6d3b\u7684\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u548c\u66f4\u5e7f\u6cdb\u7684\u7406\u8bba\u6846\u67b6\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u7684\u6027\u80fd", "method": "\u63d0\u51fa\u53cc\u5224\u522b\u5668\u03b1-GANs\uff0c\u7ed3\u5408\u53cc\u5224\u522b\u5668\u7ed3\u6784\u4e0e\u53ef\u8c03\u8282\u7684\u03b1\u635f\u5931\u51fd\u6570\uff1b\u8fdb\u4e00\u6b65\u63a8\u5e7f\u5230\u57fa\u4e8e\u6b63\u5b9e\u6570\u4e0a\u4efb\u610f\u51fd\u6570\u7684\u5e7f\u4e49\u53cc\u5224\u522b\u5668GANs\uff1b\u4f7f\u7528\u4e24\u4e2a\u5224\u522b\u5668\uff1a\u4e00\u4e2a\u5956\u52b1\u771f\u5b9e\u6570\u636e\u5206\u5e03\u7684\u6837\u672c\uff0c\u53e6\u4e00\u4e2a\u504f\u5411\u751f\u6210\u5668\u6837\u672c", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u6240\u63d0\u51fa\u6a21\u578b\u7684min-max\u4f18\u5316\u53ef\u7b80\u5316\u4e3af-\u6563\u5ea6\u548c\u9006f-\u6563\u5ea6\u7684\u7ebf\u6027\u7ec4\u5408\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u63a8\u5e7f\u4e86D2-GANs\u4e2dKL\u6563\u5ea6\u548c\u9006KL\u6563\u5ea6\u7ebf\u6027\u7ec4\u5408\u7684\u5df2\u77e5\u7b80\u5316\uff1b\u57282D\u5408\u6210\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u591a\u91cd\u4f18\u52bf", "conclusion": "\u53cc\u5224\u522b\u5668\u03b1-GANs\u548c\u5e7f\u4e49\u53cc\u5224\u522b\u5668GANs\u6210\u529f\u7ed3\u5408\u4e86\u53cc\u5224\u522b\u5668\u7684\u4f18\u52bf\u4e0e\u635f\u5931\u51fd\u6570\u7684\u7075\u6d3b\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u7406\u8bba\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u7f13\u89e3\u6a21\u5f0f\u5d29\u584c\u95ee\u9898\u5e76\u5728\u591a\u4e2a\u6027\u80fd\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u4f18\u52bf"}}
{"id": "2507.17013", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17013", "abs": "https://arxiv.org/abs/2507.17013", "authors": ["Tobias Weber", "B\u00e1lint Mucs\u00e1nyi", "Lenard Rommel", "Thomas Christie", "Lars Kas\u00fcschke", "Marvin Pf\u00f6rtner", "Philipp Hennig"], "title": "laplax -- Laplace Approximations with JAX", "comment": "Submission to the ICML 2025 Workshop on Championing Open-source\n  Development in Machine Learning (CODEML '25)", "summary": "The Laplace approximation provides a scalable and efficient means of\nquantifying weight-space uncertainty in deep neural networks, enabling the\napplication of Bayesian tools such as predictive uncertainty and model\nselection via Occam's razor. In this work, we introduce laplax, a new\nopen-source Python package for performing Laplace approximations with jax.\nDesigned with a modular and purely functional architecture and minimal external\ndependencies, laplax offers a flexible and researcher-friendly framework for\nrapid prototyping and experimentation. Its goal is to facilitate research on\nBayesian neural networks, uncertainty quantification for deep learning, and the\ndevelopment of improved Laplace approximation techniques.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86laplax\uff0c\u4e00\u4e2a\u57fa\u4e8eJAX\u7684\u5f00\u6e90Python\u5305\uff0c\u7528\u4e8e\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u6267\u884c\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\uff0c\u4ee5\u5b9e\u73b0\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u6a21\u578b\u9009\u62e9\u3002", "motivation": "\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6743\u91cd\u7a7a\u95f4\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5e94\u7528\u8d1d\u53f6\u65af\u5de5\u5177\u8fdb\u884c\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u548c\u6a21\u578b\u9009\u62e9\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u529f\u80fd\u7eaf\u7cb9\u4e14\u7814\u7a76\u53cb\u597d\u7684\u5b9e\u73b0\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86laplax\u8fd9\u4e00\u5f00\u6e90Python\u5305\uff0c\u91c7\u7528\u6a21\u5757\u5316\u548c\u7eaf\u51fd\u6570\u5f0f\u67b6\u6784\u8bbe\u8ba1\uff0c\u57fa\u4e8eJAX\u6846\u67b6\u5b9e\u73b0\uff0c\u5177\u6709\u6700\u5c0f\u7684\u5916\u90e8\u4f9d\u8d56\uff0c\u4e3a\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u63d0\u4f9b\u7075\u6d3b\u7684\u5b9e\u73b0\u6846\u67b6\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u7814\u7a76\u53cb\u597d\u7684\u6846\u67b6\uff0c\u652f\u6301\u5feb\u901f\u539f\u578b\u5f00\u53d1\u548c\u5b9e\u9a8c\uff0c\u80fd\u591f\u6709\u6548\u4fc3\u8fdb\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u3001\u6df1\u5ea6\u5b66\u4e60\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4ee5\u53ca\u6539\u8fdb\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u6280\u672f\u7684\u7814\u7a76\u3002", "conclusion": "laplax\u4e3a\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u6280\u672f\u7684\u53d1\u5c55\u548c\u5e94\u7528\u3002"}}
{"id": "2507.17419", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17419", "abs": "https://arxiv.org/abs/2507.17419", "authors": ["Abdullah Qayyum", "Maziar Nekovee"], "title": "Power Allocation and RIS Elements Optimisation for Reconfigurable Intelligent Surfaces assisted RSMA", "comment": null, "summary": "This paper proposes power allocation and the number of reconfigurable\nintelligent surfaces (RIS) elements optimisation in a RIS-assisted rate\nsplitting multiple access (RSMA) system. The optimised RIS-RSMA (ORIS-RSMA)\nmethod determines the optimal number of RIS elements and the power allocation\nfactors for both common and private parts of a message. Additionally, it\nmaximises the sum rate while ensuring that a target common rate is satisfied.\nThe performance of the proposed ORIS-RSMA is compared to that of the\nconventional RIS-RSMA and RSMA. Simulation results show that ORIS-RSMA achieves\na higher sum rate.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u53ef\u91cd\u914d\u7f6e\u667a\u80fd\u8868\u9762\u8f85\u52a9\u901f\u7387\u5206\u5272\u591a\u5740\u63a5\u5165\u7cfb\u7edf(ORIS-RSMA)\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316RIS\u5143\u7d20\u6570\u91cf\u548c\u529f\u7387\u5206\u914d\u6765\u6700\u5927\u5316\u7cfb\u7edf\u548c\u901f\u7387\u3002", "motivation": "\u5728RIS\u8f85\u52a9\u7684RSMA\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u4f18\u5316RIS\u5143\u7d20\u6570\u91cf\u548c\u529f\u7387\u5206\u914d\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u5e76\u6ee1\u8db3\u76ee\u6807\u516c\u5171\u901f\u7387\u8981\u6c42\u3002", "method": "\u63d0\u51faORIS-RSMA\u65b9\u6cd5\uff0c\u8054\u5408\u4f18\u5316RIS\u5143\u7d20\u6570\u91cf\u548c\u6d88\u606f\u516c\u5171\u90e8\u5206\u3001\u79c1\u6709\u90e8\u5206\u7684\u529f\u7387\u5206\u914d\u56e0\u5b50\uff0c\u5728\u4fdd\u8bc1\u76ee\u6807\u516c\u5171\u901f\u7387\u7684\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u7cfb\u7edf\u548c\u901f\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684RIS-RSMA\u548cRSMA\u65b9\u6848\uff0cORIS-RSMA\u80fd\u591f\u5b9e\u73b0\u66f4\u9ad8\u7684\u7cfb\u7edf\u548c\u901f\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684ORIS-RSMA\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316RIS\u5143\u7d20\u6570\u91cf\u548c\u529f\u7387\u5206\u914d\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347RIS\u8f85\u52a9RSMA\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u66f4\u9ad8\u7684\u548c\u901f\u7387\u3002"}}
{"id": "2507.17725", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.17725", "abs": "https://arxiv.org/abs/2507.17725", "authors": ["Melih Barsbey", "Ant\u00f4nio H. Ribeiro", "Umut \u015eim\u015fekli", "Tolga Birdal"], "title": "On the Interaction of Compressibility and Adversarial Robustness", "comment": null, "summary": "Modern neural networks are expected to simultaneously satisfy a host of\ndesirable properties: accurate fitting to training data, generalization to\nunseen inputs, parameter and computational efficiency, and robustness to\nadversarial perturbations. While compressibility and robustness have each been\nstudied extensively, a unified understanding of their interaction still remains\nelusive. In this work, we develop a principled framework to analyze how\ndifferent forms of compressibility - such as neuron-level sparsity and spectral\ncompressibility - affect adversarial robustness. We show that these forms of\ncompression can induce a small number of highly sensitive directions in the\nrepresentation space, which adversaries can exploit to construct effective\nperturbations. Our analysis yields a simple yet instructive robustness bound,\nrevealing how neuron and spectral compressibility impact $L_\\infty$ and $L_2$\nrobustness via their effects on the learned representations. Crucially, the\nvulnerabilities we identify arise irrespective of how compression is achieved -\nwhether via regularization, architectural bias, or implicit learning dynamics.\nThrough empirical evaluations across synthetic and realistic tasks, we confirm\nour theoretical predictions, and further demonstrate that these vulnerabilities\npersist under adversarial training and transfer learning, and contribute to the\nemergence of universal adversarial perturbations. Our findings show a\nfundamental tension between structured compressibility and robustness, and\nsuggest new pathways for designing models that are both efficient and secure.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u795e\u7ecf\u7f51\u7edc\u538b\u7f29\u6027\u4e0e\u5bf9\u6297\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u538b\u7f29\u4f1a\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u4ea7\u751f\u9ad8\u654f\u611f\u65b9\u5411\uff0c\u4f7f\u5f97\u5bf9\u6297\u653b\u51fb\u66f4\u5bb9\u6613\u6210\u529f\uff0c\u63ed\u793a\u4e86\u6548\u7387\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u6839\u672c\u6027\u77db\u76fe\u3002", "motivation": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u51c6\u786e\u6027\u3001\u6cdb\u5316\u6027\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u7b49\u591a\u79cd\u8981\u6c42\uff0c\u4f46\u538b\u7f29\u6027\u548c\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u79cd\u5173\u7cfb\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\u6765\u5206\u6790\u4e0d\u540c\u5f62\u5f0f\u7684\u538b\u7f29\u6027\uff08\u5982\u795e\u7ecf\u5143\u7ea7\u7a00\u758f\u6027\u548c\u8c31\u538b\u7f29\u6027\uff09\u5982\u4f55\u5f71\u54cd\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5f97\u51fa\u9c81\u68d2\u6027\u754c\u9650\uff0c\u5e76\u7ed3\u5408\u5408\u6210\u548c\u771f\u5b9e\u4efb\u52a1\u7684\u5b9e\u8bc1\u8bc4\u4f30\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u3002", "result": "\u53d1\u73b0\u538b\u7f29\u4f1a\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u8bf1\u5bfc\u5c11\u6570\u9ad8\u654f\u611f\u65b9\u5411\uff0c\u5bf9\u624b\u53ef\u4ee5\u5229\u7528\u8fd9\u4e9b\u65b9\u5411\u6784\u9020\u6709\u6548\u6270\u52a8\uff1b\u5f97\u51fa\u4e86\u63ed\u793a\u795e\u7ecf\u5143\u548c\u8c31\u538b\u7f29\u6027\u5982\u4f55\u901a\u8fc7\u5b66\u4e60\u8868\u793a\u5f71\u54cdL\u221e\u548cL2\u9c81\u68d2\u6027\u7684\u7b80\u5355\u9c81\u68d2\u6027\u754c\u9650\uff1b\u8bc1\u5b9e\u4e86\u8fd9\u4e9b\u8106\u5f31\u6027\u5728\u5bf9\u6297\u8bad\u7ec3\u548c\u8fc1\u79fb\u5b66\u4e60\u4e0b\u4ecd\u7136\u5b58\u5728\u3002", "conclusion": "\u7ed3\u6784\u5316\u538b\u7f29\u6027\u4e0e\u9c81\u68d2\u6027\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u77db\u76fe\uff0c\u65e0\u8bba\u901a\u8fc7\u4f55\u79cd\u65b9\u5f0f\u5b9e\u73b0\u538b\u7f29\u90fd\u4f1a\u4ea7\u751f\u8106\u5f31\u6027\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u65e2\u9ad8\u6548\u53c8\u5b89\u5168\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u65b9\u5411\u3002"}}
{"id": "2507.17016", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17016", "abs": "https://arxiv.org/abs/2507.17016", "authors": ["Omid Orang", "Patricia O. Lucas", "Gabriel I. F. Paiva", "Petronio C. L. Silva", "Felipe Augusto Rocha da Silva", "Adriano Alonso Veloso", "Frederico Gadelha Guimaraes"], "title": "Causal Graph Fuzzy LLMs: A First Introduction and Applications in Time Series Forecasting", "comment": "Accepted for publication at the Brazilian Congress of Artificial\n  Intelligence (CBIC)", "summary": "In recent years, the application of Large Language Models (LLMs) to time\nseries forecasting (TSF) has garnered significant attention among researchers.\nThis study presents a new frame of LLMs named CGF-LLM using GPT-2 combined with\nfuzzy time series (FTS) and causal graph to predict multivariate time series,\nmarking the first such architecture in the literature. The key objective is to\nconvert numerical time series into interpretable forms through the parallel\napplication of fuzzification and causal analysis, enabling both semantic\nunderstanding and structural insight as input for the pretrained GPT-2 model.\nThe resulting textual representation offers a more interpretable view of the\ncomplex dynamics underlying the original time series. The reported results\nconfirm the effectiveness of our proposed LLM-based time series forecasting\nmodel, as demonstrated across four different multivariate time series datasets.\nThis initiative paves promising future directions in the domain of TSF using\nLLMs based on FTS.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86CGF-LLM\u6846\u67b6\uff0c\u9996\u6b21\u5c06GPT-2\u4e0e\u6a21\u7cca\u65f6\u95f4\u5e8f\u5217\u548c\u56e0\u679c\u56fe\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u901a\u8fc7\u6a21\u7cca\u5316\u548c\u56e0\u679c\u5206\u6790\u5c06\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7684\u6587\u672c\u8868\u793a\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9886\u57df\u7684\u5e94\u7528\u5f15\u8d77\u4e86\u7814\u7a76\u8005\u7684\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5c06\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u8bed\u8a00\u6a21\u578b\u53ef\u7406\u89e3\u7684\u5f62\u5f0f\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u63d0\u9ad8\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51faCGF-LLM\u6846\u67b6\uff0c\u7ed3\u5408GPT-2\u3001\u6a21\u7cca\u65f6\u95f4\u5e8f\u5217(FTS)\u548c\u56e0\u679c\u56fe\u6280\u672f\u3002\u901a\u8fc7\u5e76\u884c\u5e94\u7528\u6a21\u7cca\u5316\u548c\u56e0\u679c\u5206\u6790\uff0c\u5c06\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7684\u6587\u672c\u8868\u793a\uff0c\u4f7f\u9884\u8bad\u7ec3\u7684GPT-2\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u6d1e\u5bdf\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u751f\u6210\u7684\u6587\u672c\u8868\u793a\u80fd\u591f\u66f4\u597d\u5730\u5c55\u73b0\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u590d\u6742\u52a8\u6001\u7684\u53ef\u89e3\u91ca\u89c6\u56fe\u3002", "conclusion": "CGF-LLM\u662f\u9996\u4e2a\u5c06GPT-2\u4e0e\u6a21\u7cca\u65f6\u95f4\u5e8f\u5217\u548c\u56e0\u679c\u56fe\u7ed3\u5408\u7684\u67b6\u6784\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u4e3a\u57fa\u4e8e\u6a21\u7cca\u65f6\u95f4\u5e8f\u5217\u7684\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9886\u57df\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2507.17441", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17441", "abs": "https://arxiv.org/abs/2507.17441", "authors": ["Zinat Behdad", "Ozlem Tugfe Demir", "Ki Won Sung", "Cicek Cavdar"], "title": "Detecting Multiple Targets with Distributed Sensing and Communication in Cell-Free Massive MIMO", "comment": "6 pages", "summary": "This paper investigates multi-target detection in an integrated sensing and\ncommunication (ISAC) system within a cell-free massive MIMO (CF-mMIMO)\nframework. We adopt a user-centric approach for communication user equipments\n(UEs) and a distributed sensing approach for multi-target detection. A\nheuristic access point (AP) mode selection algorithm and a channel-aware\ndistributed sensing scheme are proposed, where local measurements at receive\nAPs (RX-APs) are weighted based on the received signals signal-to-interference\nratio (SIR). A maximum a posteriori ratio test (MAPRT) detector is applied\nunder two awareness levels at RX-APs. To balance the communication-sensing\ntrade-off, we develop a power allocation algorithm to jointly maximize the\nminimum detection probability and communication\nsignal-to-interference-plus-noise ratio (SINR) while satisfying power\nconstraints. The proposed scheme outperforms non-weighted methods. Adding test\nstatistics from more RX-APs can degrade sensing performance due to weaker\nchannels, but this effect can be mitigated by optimizing the weighting\nexponent. Additionally, assigning more sensing RX-APs to a sensing area results\nin approximately 10 dB loss in minimum communication SINR due to limited\ncommunication resources.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u6846\u67b6\u4e0b\u7684\u96c6\u6210\u611f\u77e5\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u591a\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7528\u6237\u4e2d\u5fc3\u7684\u901a\u4fe1\u65b9\u6cd5\u548c\u5206\u5e03\u5f0f\u611f\u77e5\u65b9\u6cd5\uff0c\u901a\u8fc7\u542f\u53d1\u5f0f\u63a5\u5165\u70b9\u6a21\u5f0f\u9009\u62e9\u7b97\u6cd5\u548c\u4fe1\u9053\u611f\u77e5\u7684\u5206\u5e03\u5f0f\u611f\u77e5\u65b9\u6848\u6765\u5e73\u8861\u901a\u4fe1-\u611f\u77e5\u6743\u8861\u3002", "motivation": "\u5728\u96c6\u6210\u611f\u77e5\u901a\u4fe1(ISAC)\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u5728\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u6846\u67b6\u4e0b\u5b9e\u73b0\u6709\u6548\u7684\u591a\u76ee\u6807\u68c0\u6d4b\uff0c\u540c\u65f6\u4fdd\u8bc1\u901a\u4fe1\u6027\u80fd\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5e73\u8861\u901a\u4fe1\u4e0e\u611f\u77e5\u6027\u80fd\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u7b97\u6cd5\u6765\u4f18\u5316\u8fd9\u79cd\u6743\u8861\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u7528\u6237\u4e2d\u5fc3\u7684\u901a\u4fe1\u7528\u6237\u8bbe\u5907\u65b9\u6cd5\u548c\u5206\u5e03\u5f0f\u611f\u77e5\u7684\u591a\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u3002\u63d0\u51fa\u542f\u53d1\u5f0f\u63a5\u5165\u70b9\u6a21\u5f0f\u9009\u62e9\u7b97\u6cd5\u548c\u57fa\u4e8e\u4fe1\u53f7\u5e72\u6270\u6bd4\u52a0\u6743\u7684\u4fe1\u9053\u611f\u77e5\u5206\u5e03\u5f0f\u611f\u77e5\u65b9\u6848\u3002\u5728\u63a5\u6536\u63a5\u5165\u70b9\u5e94\u7528\u6700\u5927\u540e\u9a8c\u6bd4\u68c0\u9a8c\u68c0\u6d4b\u5668\uff0c\u5e76\u5f00\u53d1\u529f\u7387\u5206\u914d\u7b97\u6cd5\u6765\u8054\u5408\u6700\u5927\u5316\u6700\u5c0f\u68c0\u6d4b\u6982\u7387\u548c\u901a\u4fe1\u4fe1\u5e72\u566a\u6bd4\u3002", "result": "\u6240\u63d0\u65b9\u6848\u4f18\u4e8e\u975e\u52a0\u6743\u65b9\u6cd5\u3002\u589e\u52a0\u66f4\u591a\u63a5\u6536\u63a5\u5165\u70b9\u7684\u6d4b\u8bd5\u7edf\u8ba1\u91cf\u53ef\u80fd\u7531\u4e8e\u4fe1\u9053\u8f83\u5f31\u800c\u964d\u4f4e\u611f\u77e5\u6027\u80fd\uff0c\u4f46\u53ef\u901a\u8fc7\u4f18\u5316\u52a0\u6743\u6307\u6570\u6765\u7f13\u89e3\u3002\u4e3a\u611f\u77e5\u533a\u57df\u5206\u914d\u66f4\u591a\u611f\u77e5\u63a5\u6536\u63a5\u5165\u70b9\u4f1a\u5bfc\u81f4\u6700\u5c0f\u901a\u4fe1SINR\u635f\u5931\u7ea610dB\uff0c\u8fd9\u662f\u7531\u4e8e\u901a\u4fe1\u8d44\u6e90\u6709\u9650\u9020\u6210\u7684\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u5728ISAC\u7cfb\u7edf\u4e2d\u53ef\u4ee5\u901a\u8fc7\u4f18\u5316\u7684\u529f\u7387\u5206\u914d\u548c\u52a0\u6743\u65b9\u6848\u6709\u6548\u5e73\u8861\u901a\u4fe1\u4e0e\u611f\u77e5\u6027\u80fd\u3002\u867d\u7136\u589e\u52a0\u611f\u77e5\u8d44\u6e90\u4f1a\u5bf9\u901a\u4fe1\u6027\u80fd\u4ea7\u751f\u4e00\u5b9a\u5f71\u54cd\uff0c\u4f46\u901a\u8fc7\u5408\u7406\u7684\u53c2\u6570\u4f18\u5316\u53ef\u4ee5\u5b9e\u73b0\u8f83\u597d\u7684\u6027\u80fd\u6743\u8861\u3002"}}
{"id": "2507.17748", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.17748", "abs": "https://arxiv.org/abs/2507.17748", "authors": ["Melih Barsbey", "Lucas Prieto", "Stefanos Zafeiriou", "Tolga Birdal"], "title": "Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility", "comment": "Accepted at ICCV 2025, 23 pages", "summary": "Robustness and resource-efficiency are two highly desirable properties for\nmodern machine learning models. However, achieving them jointly remains a\nchallenge. In this paper, we position high learning rates as a facilitator for\nsimultaneously achieving robustness to spurious correlations and network\ncompressibility. We demonstrate that large learning rates also produce\ndesirable representation properties such as invariant feature utilization,\nclass separation, and activation sparsity. Importantly, our findings indicate\nthat large learning rates compare favorably to other hyperparameters and\nregularization methods, in consistently satisfying these properties in tandem.\nIn addition to demonstrating the positive effect of large learning rates across\ndiverse spurious correlation datasets, models, and optimizers, we also present\nstrong evidence that the previously documented success of large learning rates\nin standard classification tasks is likely due to its effect on addressing\nhidden/rare spurious correlations in the training dataset.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u5927\u5b66\u4e60\u7387\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u6a21\u578b\u5bf9\u865a\u5047\u76f8\u5173\u6027\u7684\u9c81\u68d2\u6027\u548c\u7f51\u7edc\u538b\u7f29\u6027\uff0c\u5e76\u53d1\u73b0\u5927\u5b66\u4e60\u7387\u80fd\u4ea7\u751f\u4e0d\u53d8\u7279\u5f81\u5229\u7528\u3001\u7c7b\u522b\u5206\u79bb\u548c\u6fc0\u6d3b\u7a00\u758f\u7b49\u7406\u60f3\u7684\u8868\u793a\u5c5e\u6027\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9700\u8981\u540c\u65f6\u5177\u5907\u9c81\u68d2\u6027\u548c\u8d44\u6e90\u6548\u7387\uff0c\u4f46\u540c\u65f6\u5b9e\u73b0\u8fd9\u4e24\u4e2a\u5c5e\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u7814\u7a76\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u540c\u65f6\u63d0\u5347\u6a21\u578b\u5bf9\u865a\u5047\u76f8\u5173\u6027\u7684\u9c81\u68d2\u6027\u548c\u7f51\u7edc\u7684\u53ef\u538b\u7f29\u6027\u3002", "method": "\u5c06\u5927\u5b66\u4e60\u7387\u4f5c\u4e3a\u540c\u65f6\u5b9e\u73b0\u9c81\u68d2\u6027\u548c\u53ef\u538b\u7f29\u6027\u7684\u4fc3\u8fdb\u56e0\u5b50\u3002\u901a\u8fc7\u5728\u591a\u79cd\u865a\u5047\u76f8\u5173\u6570\u636e\u96c6\u3001\u6a21\u578b\u548c\u4f18\u5316\u5668\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u5927\u5b66\u4e60\u7387\u5bf9\u8868\u793a\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u4e0d\u53d8\u7279\u5f81\u5229\u7528\u3001\u7c7b\u522b\u5206\u79bb\u548c\u6fc0\u6d3b\u7a00\u758f\u7b49\u5c5e\u6027\u7684\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5927\u5b66\u4e60\u7387\u80fd\u591f\u4ea7\u751f\u7406\u60f3\u7684\u8868\u793a\u5c5e\u6027\uff0c\u5305\u62ec\u4e0d\u53d8\u7279\u5f81\u5229\u7528\u3001\u7c7b\u522b\u5206\u79bb\u548c\u6fc0\u6d3b\u7a00\u758f\u3002\u4e0e\u5176\u4ed6\u8d85\u53c2\u6570\u548c\u6b63\u5219\u5316\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5927\u5b66\u4e60\u7387\u5728\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e9b\u5c5e\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u5728\u591a\u79cd\u865a\u5047\u76f8\u5173\u6570\u636e\u96c6\u4e0a\u90fd\u8bc1\u660e\u4e86\u5927\u5b66\u4e60\u7387\u7684\u79ef\u6781\u6548\u679c\u3002", "conclusion": "\u5927\u5b66\u4e60\u7387\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5de5\u5177\uff0c\u80fd\u591f\u540c\u65f6\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u8d44\u6e90\u6548\u7387\u3002\u4e4b\u524d\u6587\u732e\u4e2d\u5927\u5b66\u4e60\u7387\u5728\u6807\u51c6\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u5f88\u53ef\u80fd\u662f\u7531\u4e8e\u5176\u89e3\u51b3\u4e86\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u9690\u85cf\u6216\u7f55\u89c1\u7684\u865a\u5047\u76f8\u5173\u6027\u95ee\u9898\u3002\u8fd9\u4e3a\u7406\u89e3\u5927\u5b66\u4e60\u7387\u7684\u4f5c\u7528\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2507.17019", "categories": ["cs.LG", "65M32 65M32 65M32", "I.2.6; G.1.8"], "pdf": "https://arxiv.org/pdf/2507.17019", "abs": "https://arxiv.org/abs/2507.17019", "authors": ["Ray Zirui Zhang", "Christopher E. Miles", "Xiaohui Xie", "John S. Lowengrub"], "title": "BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part II: Efficient Uncertainty Quantification with Low-Rank Adaptation", "comment": null, "summary": "Uncertainty quantification and inverse problems governed by partial\ndifferential equations (PDEs) are central to a wide range of scientific and\nengineering applications. In this second part of a two part series, we extend\nBilevel Local Operator Learning (BiLO) for PDE-constrained optimization\nproblems developed in Part 1 to the Bayesian inference framework. At the lower\nlevel, we train a network to approximate the local solution operator by\nminimizing the local operator loss with respect to the weights of the neural\nnetwork. At the upper level, we sample the PDE parameters from the posterior\ndistribution. We achieve efficient sampling through gradient-based Markov Chain\nMonte Carlo (MCMC) methods and low-rank adaptation (LoRA). Compared with\nexisting methods based on Bayesian neural networks, our approach bypasses the\nchallenge of sampling in the high-dimensional space of neural network weights\nand does not require specifying a prior distribution on the neural network\nsolution. Instead, uncertainty propagates naturally from the data through the\nPDE constraints. By enforcing strong PDE constraints, the proposed method\nimproves the accuracy of both parameter inference and uncertainty\nquantification. We analyze the dynamic error of the gradient in the MCMC\nsampler and the static error in the posterior distribution due to inexact\nminimization of the lower level problem and demonstrate a direct link between\nthe tolerance for solving the lower level problem and the accuracy of the\nresulting uncertainty quantification. Through numerical experiments across a\nvariety of PDE models, we demonstrate that our method delivers accurate\ninference and quantification of uncertainties while maintaining high\ncomputational efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u5c42\u5c40\u90e8\u7b97\u5b50\u5b66\u4e60(BiLO)\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7ea6\u675f\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u9006\u95ee\u9898\uff0c\u901a\u8fc7\u68af\u5ea6MCMC\u65b9\u6cd5\u548c\u4f4e\u79e9\u9002\u5e94\u5b9e\u73b0\u9ad8\u6548\u91c7\u6837\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\u5728\u5904\u7406PDE\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u65f6\u9762\u4e34\u9ad8\u7ef4\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u7a7a\u95f4\u91c7\u6837\u56f0\u96be\u7684\u6311\u6218\uff0c\u4e14\u9700\u8981\u4e3a\u795e\u7ecf\u7f51\u7edc\u89e3\u6307\u5b9a\u5148\u9a8c\u5206\u5e03\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u5728\u53c2\u6570\u63a8\u7406\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u7cbe\u5ea6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5c06\u53cc\u5c42\u5c40\u90e8\u7b97\u5b50\u5b66\u4e60\u6269\u5c55\u5230\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6\uff1a\u4e0b\u5c42\u901a\u8fc7\u6700\u5c0f\u5316\u5c40\u90e8\u7b97\u5b50\u635f\u5931\u8bad\u7ec3\u7f51\u7edc\u8fd1\u4f3c\u5c40\u90e8\u89e3\u7b97\u5b50\uff1b\u4e0a\u5c42\u4ece\u540e\u9a8c\u5206\u5e03\u4e2d\u91c7\u6837PDE\u53c2\u6570\uff0c\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u9a6c\u5c14\u79d1\u592b\u94fe\u8499\u7279\u5361\u7f57(MCMC)\u65b9\u6cd5\u548c\u4f4e\u79e9\u9002\u5e94(LoRA)\u5b9e\u73b0\u9ad8\u6548\u91c7\u6837\uff0c\u901a\u8fc7\u5f3aPDE\u7ea6\u675f\u8ba9\u4e0d\u786e\u5b9a\u6027\u4ece\u6570\u636e\u81ea\u7136\u4f20\u64ad\u3002", "result": "\u65b9\u6cd5\u7ed5\u8fc7\u4e86\u9ad8\u7ef4\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u7a7a\u95f4\u7684\u91c7\u6837\u6311\u6218\uff0c\u65e0\u9700\u4e3a\u795e\u7ecf\u7f51\u7edc\u89e3\u6307\u5b9a\u5148\u9a8c\u5206\u5e03\uff0c\u63d0\u9ad8\u4e86\u53c2\u6570\u63a8\u7406\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u7cbe\u5ea6\u3002\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86MCMC\u91c7\u6837\u5668\u68af\u5ea6\u7684\u52a8\u6001\u8bef\u5dee\u548c\u4e0b\u5c42\u95ee\u9898\u6c42\u89e3\u5bb9\u5dee\u4e0e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7cbe\u5ea6\u7684\u76f4\u63a5\u8054\u7cfb\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728\u591a\u79cdPDE\u6a21\u578b\u4e0a\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eBiLO\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u80fd\u591f\u51c6\u786e\u5730\u8fdb\u884c\u63a8\u7406\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4e3aPDE\u7ea6\u675f\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u9006\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17505", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17505", "abs": "https://arxiv.org/abs/2507.17505", "authors": ["Jos\u00e9 P. Gonz\u00e1lez-Coma", "F. Javier L\u00f3pez-Mart\u00ednez"], "title": "Slow Fluid Antenna Multiple Access with Multiport Receivers", "comment": "5 pages, 3 figures. This work has been submitted to the IEEE for\n  publication", "summary": "We investigate whether equipping fluid-antenna (FA) receivers with multiple\n($L>1$) radiofrequency (RF) chains can improve the performance of the slow\nfluid-antenna multiple access (FAMA) technique, which enables open-loop\nconnectivity with channel state information (CSI) available only at the\nreceiver side. We analyze the case of slow-FAMA users equipped with multiport\nreceivers, so that $L$ ports of the FA are selected and combined to reduce\ninterference. We show that a joint design of the port selection matrix and the\ncombining vector at each receiver yields significant performance gains over\nreference schemes, demonstrating the potential of multiport reception in FA\nsystems with a limited number of RF chains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e3a\u6d41\u4f53\u5929\u7ebf\u63a5\u6536\u673a\u914d\u5907\u591a\u4e2a\u5c04\u9891\u94fe\u8def\u80fd\u5426\u63d0\u5347\u6162\u901f\u6d41\u4f53\u5929\u7ebf\u591a\u5740\u63a5\u5165\u6280\u672f\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u8054\u5408\u8bbe\u8ba1\u7aef\u53e3\u9009\u62e9\u77e9\u9635\u548c\u5408\u5e76\u5411\u91cf\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u63a2\u7d22\u5728\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u4e2d\u4f7f\u7528\u591a\u7aef\u53e3\u63a5\u6536\u673a\uff08\u914d\u5907\u591a\u4e2a\u5c04\u9891\u94fe\u8def\uff09\u662f\u5426\u80fd\u591f\u6539\u5584\u6162\u901f\u6d41\u4f53\u5929\u7ebf\u591a\u5740\u63a5\u5165\u6280\u672f\u7684\u6027\u80fd\uff0c\u8be5\u6280\u672f\u4ec5\u5728\u63a5\u6536\u7aef\u5177\u6709\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7684\u5f00\u73af\u8fde\u63a5\u573a\u666f\u4e0b\u5de5\u4f5c\u3002", "method": "\u5206\u6790\u914d\u5907\u591a\u7aef\u53e3\u63a5\u6536\u673a\u7684\u6162\u901fFAMA\u7528\u6237\uff0c\u9009\u62e9L\u4e2a\u6d41\u4f53\u5929\u7ebf\u7aef\u53e3\u5e76\u8fdb\u884c\u5408\u5e76\u4ee5\u51cf\u5c11\u5e72\u6270\u3002\u63d0\u51fa\u4e86\u7aef\u53e3\u9009\u62e9\u77e9\u9635\u548c\u5408\u5e76\u5411\u91cf\u7684\u8054\u5408\u8bbe\u8ba1\u65b9\u6cd5\u3002", "result": "\u8054\u5408\u8bbe\u8ba1\u65b9\u6848\u76f8\u6bd4\u53c2\u8003\u65b9\u6848\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5728\u5c04\u9891\u94fe\u8def\u6570\u91cf\u6709\u9650\u7684\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u4e2d\u591a\u7aef\u53e3\u63a5\u6536\u7684\u6f5c\u529b\u3002", "conclusion": "\u591a\u7aef\u53e3\u63a5\u6536\u6280\u672f\u80fd\u591f\u6709\u6548\u63d0\u5347\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u4f18\u5316\u7aef\u53e3\u9009\u62e9\u548c\u4fe1\u53f7\u5408\u5e76\u7b56\u7565\uff0c\u5373\u4f7f\u5728\u5c04\u9891\u94fe\u8def\u6570\u91cf\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u83b7\u5f97\u663e\u8457\u7684\u6027\u80fd\u6539\u5584\u3002"}}
{"id": "2507.17056", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17056", "abs": "https://arxiv.org/abs/2507.17056", "authors": ["Anton Matsson", "Yaochen Rao", "Heather J. Litman", "Fredrik D. Johansson"], "title": "Pragmatic Policy Development via Interpretable Behavior Cloning", "comment": null, "summary": "Offline reinforcement learning (RL) holds great promise for deriving optimal\npolicies from observational data, but challenges related to interpretability\nand evaluation limit its practical use in safety-critical domains.\nInterpretability is hindered by the black-box nature of unconstrained RL\npolicies, while evaluation -- typically performed off-policy -- is sensitive to\nlarge deviations from the data-collecting behavior policy, especially when\nusing methods based on importance sampling. To address these challenges, we\npropose a simple yet practical alternative: deriving treatment policies from\nthe most frequently chosen actions in each patient state, as estimated by an\ninterpretable model of the behavior policy. By using a tree-based model, which\nis specifically designed to exploit patterns in the data, we obtain a natural\ngrouping of states with respect to treatment. The tree structure ensures\ninterpretability by design, while varying the number of actions considered\ncontrols the degree of overlap with the behavior policy, enabling reliable\noff-policy evaluation. This pragmatic approach to policy development\nstandardizes frequent treatment patterns, capturing the collective clinical\njudgment embedded in the data. Using real-world examples in rheumatoid\narthritis and sepsis care, we demonstrate that policies derived under this\nframework can outperform current practice, offering interpretable alternatives\nto those obtained via offline RL.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6811\u7ed3\u6784\u7684\u53ef\u89e3\u91ca\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u6570\u636e\u4e2d\u6700\u9891\u7e41\u7684\u6cbb\u7597\u884c\u4e3a\u6765\u5236\u5b9a\u533b\u7597\u51b3\u7b56\u7b56\u7565\uff0c\u5728\u7c7b\u98ce\u6e7f\u5173\u8282\u708e\u548c\u8d25\u8840\u75c7\u6cbb\u7597\u4e2d\u5c55\u73b0\u51fa\u4f18\u4e8e\u5f53\u524d\u5b9e\u8df5\u7684\u6548\u679c\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff08\u5982\u533b\u7597\uff09\u7684\u5e94\u7528\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09\u9ed1\u76d2\u7b56\u7565\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff1b2\uff09\u79bb\u7b56\u7565\u8bc4\u4f30\u5bf9\u884c\u4e3a\u7b56\u7565\u504f\u5dee\u654f\u611f\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u91cd\u8981\u6027\u91c7\u6837\u7684\u65b9\u6cd5\u5b58\u5728\u8bc4\u4f30\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6811\u7ed3\u6784\u6a21\u578b\u7684\u6cbb\u7597\u7b56\u7565\u5236\u5b9a\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u53ef\u89e3\u91ca\u7684\u6811\u6a21\u578b\u4f30\u8ba1\u884c\u4e3a\u7b56\u7565\uff1b2\uff09\u4ece\u6bcf\u4e2a\u60a3\u8005\u72b6\u6001\u4e2d\u6700\u9891\u7e41\u9009\u62e9\u7684\u884c\u4e3a\u4e2d\u5bfc\u51fa\u6cbb\u7597\u7b56\u7565\uff1b3\uff09\u901a\u8fc7\u63a7\u5236\u8003\u8651\u7684\u884c\u4e3a\u6570\u91cf\u6765\u8c03\u8282\u4e0e\u884c\u4e3a\u7b56\u7565\u7684\u91cd\u53e0\u5ea6\uff0c\u786e\u4fdd\u53ef\u9760\u7684\u79bb\u7b56\u7565\u8bc4\u4f30\uff1b4\uff09\u5229\u7528\u6811\u7ed3\u6784\u7684\u5929\u7136\u5206\u7ec4\u7279\u6027\u5b9e\u73b0\u72b6\u6001-\u6cbb\u7597\u7684\u53ef\u89e3\u91ca\u6620\u5c04\u3002", "result": "\u5728\u7c7b\u98ce\u6e7f\u5173\u8282\u708e\u548c\u8d25\u8840\u75c7\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e2d\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5236\u5b9a\u7684\u7b56\u7565\u80fd\u591f\u8d85\u8d8a\u5f53\u524d\u4e34\u5e8a\u5b9e\u8df5\u7684\u8868\u73b0\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6807\u51c6\u5316\u9891\u7e41\u7684\u6cbb\u7597\u6a21\u5f0f\uff0c\u6355\u83b7\u4e86\u6570\u636e\u4e2d\u8574\u542b\u7684\u96c6\u4f53\u4e34\u5e8a\u5224\u65ad\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u57df\u7684\u51b3\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u533b\u7597\u5e94\u7528\u4e2d\u7684\u5173\u952e\u969c\u788d\u3002"}}
{"id": "2507.17506", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17506", "abs": "https://arxiv.org/abs/2507.17506", "authors": ["Imad Bouhou", "Stefano Fortunati", "Leila Gharsalli", "Alexandre Renaux"], "title": "Joint Multi-Target Detection-Tracking in Cognitive Massive MIMO Radar via POMCP", "comment": null, "summary": "This correspondence presents a power-aware cognitive radar framework for\njoint detection and tracking of multiple targets in a massive multiple-input\nmultiple-output (MIMO) radar environment. Building on a previous single-target\nalgorithm based on Partially Observable Monte Carlo Planning (POMCP), we extend\nit to the multi-target case by assigning each target an independent POMCP tree,\nenabling scalable and efficient planning.\n  Departing from uniform power allocation-which is often suboptimal with\nvarying signal-to-noise ratios (SNRs)-our approach predicts each target's\nfuture angular position and expected received power, based on its estimated\nrange and radar cross-section (RCS). These predictions guide adaptive waveform\ndesign via a constrained optimization problem that allocates transmit energy to\nenhance the detectability of weaker or distant targets, while ensuring\nsufficient power for high-SNR targets. The reward function in the underlying\npartially observable Markov decision process (POMDP) is also modified to\nprioritize accurate spatial and power estimation.\n  Simulations involving multiple targets with different SNRs confirm the\neffectiveness of our method. The proposed framework for the cognitive radar\nimproves detection probability for low-SNR targets and achieves more accurate\ntracking compared to approaches using uniform or orthogonal waveforms. These\nresults demonstrate the potential of the POMCP-based framework for adaptive,\nefficient multi-target radar systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePOMCP\u7684\u529f\u7387\u611f\u77e5\u8ba4\u77e5\u96f7\u8fbe\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21MIMO\u96f7\u8fbe\u73af\u5883\u4e2d\u591a\u76ee\u6807\u7684\u8054\u5408\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6ce2\u5f62\u8bbe\u8ba1\u548c\u529f\u7387\u5206\u914d\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u4fe1\u566a\u6bd4\u76ee\u6807\u7684\u68c0\u6d4b\u6982\u7387\u548c\u8ddf\u8e2a\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u96f7\u8fbe\u7cfb\u7edf\u91c7\u7528\u5747\u5300\u529f\u7387\u5206\u914d\u7b56\u7565\uff0c\u5728\u9762\u5bf9\u4e0d\u540c\u4fe1\u566a\u6bd4\u7684\u591a\u76ee\u6807\u573a\u666f\u65f6\u6548\u679c\u4e0d\u4f73\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6839\u636e\u76ee\u6807\u7279\u6027\u81ea\u9002\u5e94\u5206\u914d\u53d1\u5c04\u529f\u7387\u7684\u8ba4\u77e5\u96f7\u8fbe\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u5f31\u76ee\u6807\u6216\u8fdc\u8ddd\u79bb\u76ee\u6807\u7684\u53ef\u68c0\u6d4b\u6027\uff0c\u540c\u65f6\u786e\u4fdd\u9ad8\u4fe1\u566a\u6bd4\u76ee\u6807\u6709\u8db3\u591f\u7684\u529f\u7387\u652f\u6301\u3002", "method": "\u5c06\u5355\u76ee\u6807POMCP\u7b97\u6cd5\u6269\u5c55\u5230\u591a\u76ee\u6807\u573a\u666f\uff0c\u4e3a\u6bcf\u4e2a\u76ee\u6807\u5206\u914d\u72ec\u7acb\u7684POMCP\u6811\u5b9e\u73b0\u53ef\u6269\u5c55\u89c4\u5212\u3002\u57fa\u4e8e\u76ee\u6807\u7684\u4f30\u8ba1\u8ddd\u79bb\u548c\u96f7\u8fbe\u6563\u5c04\u622a\u9762\u9884\u6d4b\u5176\u672a\u6765\u89d2\u4f4d\u7f6e\u548c\u671f\u671b\u63a5\u6536\u529f\u7387\uff0c\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u6307\u5bfc\u81ea\u9002\u5e94\u6ce2\u5f62\u8bbe\u8ba1\uff0c\u5206\u914d\u53d1\u5c04\u80fd\u91cf\u4ee5\u589e\u5f3a\u5f31\u76ee\u6807\u68c0\u6d4b\u80fd\u529b\u3002\u540c\u65f6\u4fee\u6539POMDP\u4e2d\u7684\u5956\u52b1\u51fd\u6570\u4ee5\u4f18\u5148\u8003\u8651\u51c6\u786e\u7684\u7a7a\u95f4\u548c\u529f\u7387\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e0e\u4f7f\u7528\u5747\u5300\u6216\u6b63\u4ea4\u6ce2\u5f62\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u4f4e\u4fe1\u566a\u6bd4\u76ee\u6807\u7684\u68c0\u6d4b\u6982\u7387\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8ePOMCP\u7684\u529f\u7387\u611f\u77e5\u8ba4\u77e5\u96f7\u8fbe\u6846\u67b6\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u591a\u76ee\u6807\u7684\u81ea\u9002\u5e94\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\uff0c\u901a\u8fc7\u667a\u80fd\u7684\u529f\u7387\u5206\u914d\u7b56\u7565\u663e\u8457\u6539\u5584\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u5c55\u73b0\u4e86\u5728\u81ea\u9002\u5e94\u3001\u9ad8\u6548\u591a\u76ee\u6807\u96f7\u8fbe\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.17623", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17623", "abs": "https://arxiv.org/abs/2507.17623", "authors": ["Guangteng Liu", "Xiayue Liu", "Zhixiang Xu", "Yufeng Yuan", "Hui Zhao", "Yuxuan Liu", "Yufei Jiang"], "title": "SA-WiSense: A Blind-Spot-Free Respiration Sensing Framework for Single-Antenna Wi-Fi Devices", "comment": "12pages, 10figures", "summary": "Wi-Fi sensing offers a promising technique for contactless human respiration\nmonitoring. A key challenge, however, is the blind spot problem caused by\nrandom phase offsets that corrupt the complementarity of respiratory signals.\nTo address the challenge, we propose a single-antenna-Wi-Fi-sensing\n(SA-WiSense) framework to improve accuracy of human respiration monitoring,\nrobust against random phase offsets. The proposed SA-WiSense framework is\ncost-efficient, as only a single antenna is used rather than multiple antennas\nas in the previous works. Therefore, the proposed framework is applicable to\nInternet of Thing (IoT), where most of sensors are equipped with a single\nantenna. On one hand, we propose a cross-subcarrier channel state information\n(CSI) ratio (CSCR) based blind spot mitigation approach for IoT, where the\nratios of two values of CSI between subcarriers are leveraged to mitigate\nrandom phase offsets. We prove that the random phase offsets can be cancelled\nby the proposed CSCR approach, thereby restoring the inherent complementarity\nof signals for blind-spot-free sensing. On the other hand, we propose a genetic\nalgorithm (GA) based subcarrier selection (GASS) approach by formulating an\noptimization problem in terms of the sensing-signal-to-noise ratio (SSNR) of\nCSCR between subcarriers. GA is utilized to solve the formulated optimization\nproblem. We use commodity ESP32 microcontrollers to build an experiment test.\nThe proposed works are validated to achieve an detection rate of 91.2% for\nrespiration monitoring at distances up to 8.0 meters, substantially more\naccurate than the state-of-the-art methods with a single antenna.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5355\u5929\u7ebfWi-Fi\u611f\u77e5\u6846\u67b6(SA-WiSense)\uff0c\u901a\u8fc7\u8de8\u5b50\u8f7d\u6ce2CSI\u6bd4\u503c\u65b9\u6cd5\u548c\u9057\u4f20\u7b97\u6cd5\u5b50\u8f7d\u6ce2\u9009\u62e9\uff0c\u89e3\u51b3\u4e86Wi-Fi\u547c\u5438\u76d1\u6d4b\u4e2d\u7684\u968f\u673a\u76f8\u4f4d\u504f\u79fb\u76f2\u70b9\u95ee\u9898\uff0c\u57288\u7c73\u8ddd\u79bb\u5185\u5b9e\u73b091.2%\u7684\u68c0\u6d4b\u7387\u3002", "motivation": "Wi-Fi\u611f\u77e5\u6280\u672f\u5728\u975e\u63a5\u89e6\u5f0f\u4eba\u4f53\u547c\u5438\u76d1\u6d4b\u4e2d\u5177\u6709\u524d\u666f\uff0c\u4f46\u9762\u4e34\u968f\u673a\u76f8\u4f4d\u504f\u79fb\u5bfc\u81f4\u7684\u76f2\u70b9\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u4f1a\u7834\u574f\u547c\u5438\u4fe1\u53f7\u7684\u4e92\u8865\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u591a\u5929\u7ebf\uff0c\u6210\u672c\u9ad8\u4e14\u4e0d\u9002\u7528\u4e8e\u7269\u8054\u7f51\u5355\u5929\u7ebf\u8bbe\u5907\u3002", "method": "\u63d0\u51faSA-WiSense\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u65b9\u6cd5\uff1a1\uff09\u8de8\u5b50\u8f7d\u6ce2\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u6bd4\u503c(CSCR)\u65b9\u6cd5\uff0c\u5229\u7528\u5b50\u8f7d\u6ce2\u95f4CSI\u6bd4\u503c\u6765\u62b5\u6d88\u968f\u673a\u76f8\u4f4d\u504f\u79fb\uff1b2\uff09\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u5b50\u8f7d\u6ce2\u9009\u62e9(GASS)\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u611f\u77e5\u4fe1\u53f7\u566a\u58f0\u6bd4\u6765\u9009\u62e9\u6700\u4f18\u5b50\u8f7d\u6ce2\u7ec4\u5408\u3002", "result": "\u4f7f\u7528ESP32\u5fae\u63a7\u5236\u5668\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u57288.0\u7c73\u8ddd\u79bb\u5185\u5b9e\u73b0\u4e8691.2%\u7684\u547c\u5438\u68c0\u6d4b\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5355\u5929\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "SA-WiSense\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5355\u5929\u7ebfWi-Fi\u611f\u77e5\u4e2d\u7684\u76f2\u70b9\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u51c6\u786e\u7684\u975e\u63a5\u89e6\u5f0f\u547c\u5438\u76d1\u6d4b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7269\u8054\u7f51\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2507.17070", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17070", "abs": "https://arxiv.org/abs/2507.17070", "authors": ["Adithya Mohan", "Dominik R\u00f6\u00dfle", "Daniel Cremers", "Torsten Sch\u00f6n"], "title": "Advancing Robustness in Deep Reinforcement Learning with an Ensemble Defense Approach", "comment": "6 pages, 4 figures, 2 tables", "summary": "Recent advancements in Deep Reinforcement Learning (DRL) have demonstrated\nits applicability across various domains, including robotics, healthcare,\nenergy optimization, and autonomous driving. However, a critical question\nremains: How robust are DRL models when exposed to adversarial attacks? While\nexisting defense mechanisms such as adversarial training and distillation\nenhance the resilience of DRL models, there remains a significant research gap\nregarding the integration of multiple defenses in autonomous driving scenarios\nspecifically. This paper addresses this gap by proposing a novel ensemble-based\ndefense architecture to mitigate adversarial attacks in autonomous driving. Our\nevaluation demonstrates that the proposed architecture significantly enhances\nthe robustness of DRL models. Compared to the baseline under FGSM attacks, our\nensemble method improves the mean reward from 5.87 to 18.38 (over 213%\nincrease) and reduces the mean collision rate from 0.50 to 0.09 (an 82%\ndecrease) in the highway scenario and merge scenario, outperforming all\nstandalone defense strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u7684\u9632\u5fa1\u67b6\u6784\uff0c\u7528\u4e8e\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u5728FGSM\u653b\u51fb\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u5e73\u5747\u5956\u52b1\u5e76\u964d\u4f4e\u4e86\u78b0\u649e\u7387\u3002", "motivation": "\u867d\u7136\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u65f6\u7684\u9c81\u68d2\u6027\u4ecd\u5b58\u5728\u95ee\u9898\u3002\u73b0\u6709\u9632\u5fa1\u673a\u5236\u5982\u5bf9\u6297\u8bad\u7ec3\u548c\u84b8\u998f\u867d\u80fd\u589e\u5f3aDRL\u6a21\u578b\u7684\u97e7\u6027\uff0c\u4f46\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\u96c6\u6210\u591a\u79cd\u9632\u5fa1\u65b9\u6cd5\u4ecd\u5b58\u5728\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u96c6\u6210\u7684\u9632\u5fa1\u67b6\u6784\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u9632\u5fa1\u7b56\u7565\u6765\u7f13\u89e3\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u5bf9\u6297\u6027\u653b\u51fb\u3002", "result": "\u5728FGSM\u653b\u51fb\u4e0b\uff0c\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0c\u96c6\u6210\u65b9\u6cd5\u5c06\u5e73\u5747\u5956\u52b1\u4ece5.87\u63d0\u5347\u81f318.38\uff08\u589e\u957f\u8d85\u8fc7213%\uff09\uff0c\u5c06\u5e73\u5747\u78b0\u649e\u7387\u4ece0.50\u964d\u4f4e\u81f30.09\uff08\u964d\u4f4e82%\uff09\uff0c\u5728\u9ad8\u901f\u516c\u8def\u548c\u5408\u5e76\u573a\u666f\u4e2d\u5747\u4f18\u4e8e\u6240\u6709\u5355\u72ec\u7684\u9632\u5fa1\u7b56\u7565\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u96c6\u6210\u9632\u5fa1\u67b6\u6784\u663e\u8457\u589e\u5f3a\u4e86DRL\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\u6709\u6548\u62b5\u5fa1\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u6027\u80fd\u4f18\u4e8e\u5355\u4e00\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2507.17645", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.17645", "abs": "https://arxiv.org/abs/2507.17645", "authors": ["Alessio Lukaj", "Keigo Masuoka", "Takumi Takahashi", "Giuseppe Thadeu Freitas de Abreu", "Hideki Ochiai"], "title": "Quaternion-Domain Super MDS for Robust 3D Localization", "comment": "12 pages, 8 figures", "summary": "This paper proposes a novel low-complexity three-dimensional (3D)\nlocalization algorithm for wireless sensor networks, termed quanternion-domain\nsuper multi-dimensional scaling (QD-SMDS). The algorithm is based on a\nreformulation of the SMDS, originally developed in the real domain, using\nquaternion algebra. By representing 3D coordinates as quaternions, the method\nconstructs a rank-1 Gram edge kernel (GEK) matrix that integrates both relative\ndistance and angular information between nodes, which enhances the noise\nreduction effect achieved through low-rank truncation employing singular value\ndecomposition (SVD), thereby improving robustness against information loss. To\nfurther reduce computational complexity, we also propose a variant of QD-SMDS\nthat eliminates the need for the computationally expensive SVD by leveraging\nthe inherent structure of the quaternion-domain GEK matrix. This alternative\ndirectly estimates node coordinates using only matrix multiplications within\nthe quaternion domain. Simulation results demonstrate that the proposed method\nsignificantly improves localization accuracy compared to the original SMDS\nalgorithm, especially in scenarios with substantial measurement errors. The\nproposed method also achieves comparable localization accuracy without\nrequiring SVD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56db\u5143\u6570\u4ee3\u6570\u7684\u4f4e\u590d\u6742\u5ea6\u4e09\u7ef4\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u5b9a\u4f4d\u7b97\u6cd5QD-SMDS\uff0c\u901a\u8fc7\u5c063D\u5750\u6807\u8868\u793a\u4e3a\u56db\u5143\u6570\u5e76\u6784\u5efa\u79e9-1 Gram\u8fb9\u6838\u77e9\u9635\u6765\u96c6\u6210\u76f8\u5bf9\u8ddd\u79bb\u548c\u89d2\u5ea6\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684SMDS\u7b97\u6cd5\u5728\u5b9e\u57df\u4e2d\u8fd0\u884c\uff0c\u5728\u9762\u5bf9\u6d4b\u91cf\u8bef\u5dee\u8f83\u5927\u7684\u573a\u666f\u65f6\u5b9a\u4f4d\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u9ad8\uff08\u9700\u8981SVD\u5206\u89e3\uff09\u3002\u4e3a\u4e86\u63d0\u9ad8\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u4e09\u7ef4\u5b9a\u4f4d\u7684\u9c81\u68d2\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u4f4e\u590d\u6742\u5ea6\u5b9a\u4f4d\u7b97\u6cd5\u3002", "method": "\u5c06\u539f\u672c\u5728\u5b9e\u57df\u4e2d\u7684SMDS\u7b97\u6cd5\u91cd\u65b0\u8868\u8ff0\u5230\u56db\u5143\u6570\u57df\u4e2d\uff0c\u901a\u8fc7\u56db\u5143\u6570\u8868\u793a3D\u5750\u6807\uff0c\u6784\u5efa\u79e9-1\u7684Gram\u8fb9\u6838(GEK)\u77e9\u9635\u6765\u540c\u65f6\u96c6\u6210\u8282\u70b9\u95f4\u7684\u76f8\u5bf9\u8ddd\u79bb\u548c\u89d2\u5ea6\u4fe1\u606f\u3002\u5229\u7528\u5947\u5f02\u503c\u5206\u89e3(SVD)\u7684\u4f4e\u79e9\u622a\u65ad\u6765\u589e\u5f3a\u964d\u566a\u6548\u679c\u3002\u6b64\u5916\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2aQD-SMDS\u53d8\u4f53\uff0c\u901a\u8fc7\u5229\u7528\u56db\u5143\u6570\u57dfGEK\u77e9\u9635\u7684\u56fa\u6709\u7ed3\u6784\u7279\u6027\uff0c\u4ec5\u4f7f\u7528\u77e9\u9635\u4e58\u6cd5\u76f4\u63a5\u4f30\u8ba1\u8282\u70b9\u5750\u6807\uff0c\u4ece\u800c\u907f\u514d\u4e86\u8ba1\u7b97\u6602\u8d35\u7684SVD\u64cd\u4f5c\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u539f\u59cbSMDS\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u6d4b\u91cf\u8bef\u5dee\u8f83\u5927\u7684\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u4f73\u3002\u540c\u65f6\uff0c\u4e0d\u9700\u8981SVD\u7684\u53d8\u4f53\u7b97\u6cd5\u4e5f\u80fd\u8fbe\u5230\u53ef\u6bd4\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5927\u5927\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "QD-SMDS\u7b97\u6cd5\u901a\u8fc7\u56db\u5143\u6570\u57df\u7684\u91cd\u65b0\u8868\u8ff0\u548cGEK\u77e9\u9635\u7684\u6784\u5efa\uff0c\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u4e09\u7ef4\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u5b9a\u4f4d\u7684\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u8be5\u65b9\u6cd5\u4e3a\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u7684\u9ad8\u7cbe\u5ea6\u4f4e\u590d\u6742\u5ea6\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17107", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17107", "abs": "https://arxiv.org/abs/2507.17107", "authors": ["Andrii Balashov"], "title": "Reinforcement Learning Fine-Tunes a Sparse Subnetwork in Large Language Models", "comment": "16 pages, 6 figures", "summary": "Reinforcement learning (RL) is a key post-pretraining step for aligning large\nlanguage models (LLMs) with complex tasks and human preferences. While it is\noften assumed that RL fine-tuning requires updating most of a model's\nparameters, we challenge this assumption with a surprising finding: RL\nfine-tuning consistently modifies only a small subnetwork (typically 5-30% of\nweights), leaving most parameters unchanged. We call this phenomenon RL-induced\nparameter update sparsity. It arises naturally, without any sparsity\nconstraints or parameter-efficient tuning, and appears across multiple RL\nalgorithms (e.g., PPO, DPO, SimPO, PRIME) and model families (e.g., OpenAI,\nMeta, and open-source LLMs). Moreover, the subnetworks updated by RL show\nsubstantial overlap across different seeds, datasets, and algorithms-far\nexceeding chance-suggesting a partially transferable structure in the\npretrained model. We show that fine-tuning only this sparse subnetwork recovers\nfull model performance and yields parameters nearly identical to the fully\nfine-tuned model. Our analysis suggests this sparsity emerges because RL\noperates near the model's original distribution, requiring only targeted\nchanges. KL penalties, gradient clipping, and on-policy dynamics have limited\neffect on the sparsity pattern. These findings shed new light on how RL adapts\nmodels: not by shifting all weights, but by focusing training on a small,\nconsistently updated subnetwork. This insight enables more efficient RL methods\nand reframes sparsity through the lens of the lottery ticket hypothesis.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u53ea\u4f1a\u4fee\u6539\u5c11\u91cf\u53c2\u6570\u5b50\u7f51\u7edc\uff08\u901a\u5e385-30%\uff09\uff0c\u800c\u975e\u6240\u6709\u53c2\u6570\uff0c\u8fd9\u79cd\u7a00\u758f\u6027\u73b0\u8c61\u5728\u591a\u79cdRL\u7b97\u6cd5\u548c\u6a21\u578b\u4e2d\u666e\u904d\u5b58\u5728", "motivation": "\u6311\u6218\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u9700\u8981\u66f4\u65b0\u6a21\u578b\u5927\u90e8\u5206\u53c2\u6570\u7684\u4f20\u7edf\u5047\u8bbe\uff0c\u63a2\u7d22RL\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u53c2\u6570\u66f4\u65b0\u7684\u771f\u5b9e\u6a21\u5f0f", "method": "\u5206\u6790\u591a\u79cdRL\u7b97\u6cd5\uff08PPO\u3001DPO\u3001SimPO\u3001PRIME\uff09\u5728\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\uff08OpenAI\u3001Meta\u7b49\uff09\u4e0a\u7684\u53c2\u6570\u66f4\u65b0\u6a21\u5f0f\uff0c\u7814\u7a76\u66f4\u65b0\u5b50\u7f51\u7edc\u7684\u91cd\u53e0\u6027\u548c\u53ef\u8f6c\u79fb\u6027", "result": "\u53d1\u73b0RL\u5fae\u8c03\u81ea\u7136\u4ea7\u751f\u53c2\u6570\u66f4\u65b0\u7a00\u758f\u6027\uff0c\u66f4\u65b0\u7684\u5b50\u7f51\u7edc\u5728\u4e0d\u540c\u79cd\u5b50\u3001\u6570\u636e\u96c6\u548c\u7b97\u6cd5\u95f4\u663e\u793a\u51fa\u663e\u8457\u91cd\u53e0\uff1b\u4ec5\u5fae\u8c03\u7a00\u758f\u5b50\u7f51\u7edc\u5c31\u80fd\u6062\u590d\u5b8c\u6574\u6a21\u578b\u6027\u80fd", "conclusion": "RL\u901a\u8fc7\u4e13\u6ce8\u8bad\u7ec3\u5c0f\u800c\u4e00\u81f4\u7684\u5b50\u7f51\u7edc\u6765\u9002\u5e94\u6a21\u578b\uff0c\u800c\u975e\u6539\u53d8\u6240\u6709\u6743\u91cd\uff1b\u8fd9\u79cd\u7a00\u758f\u6027\u6e90\u4e8eRL\u5728\u6a21\u578b\u539f\u59cb\u5206\u5e03\u9644\u8fd1\u64cd\u4f5c\uff0c\u4e3a\u66f4\u9ad8\u6548\u7684RL\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3"}}
{"id": "2507.17116", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17116", "abs": "https://arxiv.org/abs/2507.17116", "authors": ["Jacqueline Maasch", "Willie Neiswanger", "Stefano Ermon", "Volodymyr Kuleshov"], "title": "Probabilistic Graphical Models: A Concise Tutorial", "comment": "Under review", "summary": "Probabilistic graphical modeling is a branch of machine learning that uses\nprobability distributions to describe the world, make predictions, and support\ndecision-making under uncertainty. Underlying this modeling framework is an\nelegant body of theory that bridges two mathematical traditions: probability\nand graph theory. This framework provides compact yet expressive\nrepresentations of joint probability distributions, yielding powerful\ngenerative models for probabilistic reasoning.\n  This tutorial provides a concise introduction to the formalisms, methods, and\napplications of this modeling framework. After a review of basic probability\nand graph theory, we explore three dominant themes: (1) the representation of\nmultivariate distributions in the intuitive visual language of graphs, (2)\nalgorithms for learning model parameters and graphical structures from data,\nand (3) algorithms for inference, both exact and approximate.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u7bc7\u5173\u4e8e\u6982\u7387\u56fe\u6a21\u578b\u7684\u6559\u7a0b\u8bba\u6587\uff0c\u4ecb\u7ecd\u4e86\u8fd9\u4e00\u673a\u5668\u5b66\u4e60\u5206\u652f\u7684\u7406\u8bba\u57fa\u7840\u3001\u65b9\u6cd5\u548c\u5e94\u7528\uff0c\u6db5\u76d6\u4e86\u56fe\u8868\u793a\u3001\u5b66\u4e60\u7b97\u6cd5\u548c\u63a8\u7406\u7b97\u6cd5\u4e09\u4e2a\u6838\u5fc3\u4e3b\u9898\u3002", "motivation": "\u6982\u7387\u56fe\u6a21\u578b\u4f5c\u4e3a\u673a\u5668\u5b66\u4e60\u7684\u91cd\u8981\u5206\u652f\uff0c\u9700\u8981\u4e00\u4e2a\u7b80\u6d01\u800c\u5168\u9762\u7684\u5165\u95e8\u6559\u7a0b\u6765\u5e2e\u52a9\u8bfb\u8005\u7406\u89e3\u5176\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9645\u5e94\u7528\u3002\u8be5\u9886\u57df\u7ed3\u5408\u4e86\u6982\u7387\u8bba\u548c\u56fe\u8bba\u4e24\u5927\u6570\u5b66\u4f20\u7edf\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u4ecb\u7ecd\u6765\u5c55\u793a\u5176\u5728\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u51b3\u7b56\u652f\u6301\u65b9\u9762\u7684\u5f3a\u5927\u80fd\u529b\u3002", "method": "\u672c\u6559\u7a0b\u91c7\u7528\u6e10\u8fdb\u5f0f\u6559\u5b66\u65b9\u6cd5\uff0c\u9996\u5148\u56de\u987e\u57fa\u7840\u7684\u6982\u7387\u8bba\u548c\u56fe\u8bba\u77e5\u8bc6\uff0c\u7136\u540e\u56f4\u7ed5\u4e09\u4e2a\u6838\u5fc3\u4e3b\u9898\u5c55\u5f00\uff1a(1) \u4f7f\u7528\u76f4\u89c2\u7684\u56fe\u5f62\u8bed\u8a00\u8868\u793a\u591a\u5143\u5206\u5e03\uff1b(2) \u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u6a21\u578b\u53c2\u6570\u548c\u56fe\u7ed3\u6784\u7684\u7b97\u6cd5\uff1b(3) \u7cbe\u786e\u548c\u8fd1\u4f3c\u63a8\u7406\u7b97\u6cd5\u3002", "result": "\u8be5\u6559\u7a0b\u63d0\u4f9b\u4e86\u6982\u7387\u56fe\u6a21\u578b\u6846\u67b6\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u3001\u7b97\u6cd5\u548c\u5e94\u7528\u7684\u7b80\u6d01\u4ecb\u7ecd\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u7528\u56fe\u5f62\u5316\u65b9\u5f0f\u7d27\u51d1\u800c\u5bcc\u6709\u8868\u73b0\u529b\u5730\u8868\u793a\u8054\u5408\u6982\u7387\u5206\u5e03\uff0c\u5f62\u6210\u5f3a\u5927\u7684\u6982\u7387\u63a8\u7406\u751f\u6210\u6a21\u578b\u3002", "conclusion": "\u6982\u7387\u56fe\u6a21\u578b\u4e3a\u5728\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u8fdb\u884c\u9884\u6d4b\u548c\u51b3\u7b56\u63d0\u4f9b\u4e86\u4f18\u96c5\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u6982\u7387\u8bba\u548c\u56fe\u8bba\uff0c\u80fd\u591f\u6709\u6548\u5730\u8868\u793a\u590d\u6742\u7684\u591a\u5143\u6982\u7387\u5206\u5e03\u5e76\u652f\u6301\u5404\u79cd\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2507.17123", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17123", "abs": "https://arxiv.org/abs/2507.17123", "authors": ["Jacob M. Delgado-L\u00f3pez", "Ricardo A. Morell-Rodriguez", "Sebasti\u00e1n O. Espinosa-Del Rosario", "Wilfredo E. Lugo-Beauchamp"], "title": "Computer Vision for Real-Time Monkeypox Diagnosis on Embedded Systems", "comment": null, "summary": "The rapid diagnosis of infectious diseases, such as monkeypox, is crucial for\neffective containment and treatment, particularly in resource-constrained\nenvironments. This study presents an AI-driven diagnostic tool developed for\ndeployment on the NVIDIA Jetson Orin Nano, leveraging the pre-trained\nMobileNetV2 architecture for binary classification. The model was trained on\nthe open-source Monkeypox Skin Lesion Dataset, achieving a 93.07% F1-Score,\nwhich reflects a well-balanced performance in precision and recall. To optimize\nthe model, the TensorRT framework was used to accelerate inference for FP32 and\nto perform post-training quantization for FP16 and INT8 formats. TensorRT's\nmixed-precision capabilities enabled these optimizations, which reduced the\nmodel size, increased inference speed, and lowered power consumption by\napproximately a factor of two, all while maintaining the original accuracy.\nPower consumption analysis confirmed that the optimized models used\nsignificantly less energy during inference, reinforcing their suitability for\ndeployment in resource-constrained environments. The system was deployed with a\nWi-Fi Access Point (AP) hotspot and a web-based interface, enabling users to\nupload and analyze images directly through connected devices such as mobile\nphones. This setup ensures simple access and seamless connectivity, making the\ntool practical for real-world applications. These advancements position the\ndiagnostic tool as an efficient, scalable, and energy-conscious solution to\naddress diagnosis challenges in underserved regions, paving the way for broader\nadoption in low-resource healthcare settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eAI\u7684\u7334\u75d8\u8bca\u65ad\u5de5\u5177\uff0c\u90e8\u7f72\u5728NVIDIA Jetson Orin Nano\u4e0a\uff0c\u4f7f\u7528MobileNetV2\u67b6\u6784\u5b9e\u73b093.07%\u7684F1\u5206\u6570\uff0c\u901a\u8fc7TensorRT\u4f18\u5316\u5c06\u529f\u8017\u964d\u4f4e\u7ea6\u4e00\u534a\uff0c\u5e76\u914d\u5907Wi-Fi\u70ed\u70b9\u548c\u7f51\u9875\u754c\u9762\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u4f20\u67d3\u75c5\u5feb\u901f\u8bca\u65ad\u3002", "motivation": "\u4f20\u67d3\u75c5\uff08\u5982\u7334\u75d8\uff09\u7684\u5feb\u901f\u8bca\u65ad\u5bf9\u4e8e\u6709\u6548\u63a7\u5236\u548c\u6cbb\u7597\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u3002\u73b0\u6709\u8bca\u65ad\u65b9\u6cd5\u5728\u6b20\u53d1\u8fbe\u5730\u533a\u9762\u4e34\u6280\u672f\u548c\u8d44\u6e90\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u8282\u80fd\u7684\u8bca\u65ad\u89e3\u51b3\u65b9\u6848\u6765\u89e3\u51b3\u670d\u52a1\u4e0d\u8db3\u5730\u533a\u7684\u8bca\u65ad\u6311\u6218\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684MobileNetV2\u67b6\u6784\u8fdb\u884c\u4e8c\u5206\u7c7b\uff0c\u5728\u5f00\u6e90\u7334\u75d8\u76ae\u80a4\u75c5\u53d8\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\u3002\u91c7\u7528TensorRT\u6846\u67b6\u5bf9FP32\u8fdb\u884c\u63a8\u7406\u52a0\u901f\uff0c\u5e76\u5bf9FP16\u548cINT8\u683c\u5f0f\u6267\u884c\u8bad\u7ec3\u540e\u91cf\u5316\u3002\u901a\u8fc7\u6df7\u5408\u7cbe\u5ea6\u4f18\u5316\u51cf\u5c0f\u6a21\u578b\u5927\u5c0f\u3001\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\u5e76\u964d\u4f4e\u529f\u8017\u3002\u7cfb\u7edf\u914d\u5907Wi-Fi\u63a5\u5165\u70b9\u70ed\u70b9\u548c\u57fa\u4e8e\u7f51\u9875\u7684\u754c\u9762\uff0c\u652f\u6301\u7528\u6237\u901a\u8fc7\u79fb\u52a8\u8bbe\u5907\u4e0a\u4f20\u548c\u5206\u6790\u56fe\u50cf\u3002", "result": "\u6a21\u578b\u5728\u7334\u75d8\u76ae\u80a4\u75c5\u53d8\u6570\u636e\u96c6\u4e0a\u53d6\u5f9793.07%\u7684F1\u5206\u6570\uff0c\u5728\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u65b9\u9762\u8868\u73b0\u5747\u8861\u3002TensorRT\u4f18\u5316\u5c06\u6a21\u578b\u5927\u5c0f\u3001\u63a8\u7406\u901f\u5ea6\u548c\u529f\u8017\u90fd\u6539\u5584\u4e86\u7ea6\u4e00\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u7cbe\u5ea6\u3002\u529f\u8017\u5206\u6790\u8bc1\u5b9e\u4f18\u5316\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\u3002\u7cfb\u7edf\u6210\u529f\u90e8\u7f72\u4e86Wi-Fi\u70ed\u70b9\u548c\u7f51\u9875\u754c\u9762\uff0c\u5b9e\u73b0\u4e86\u7b80\u5355\u8bbf\u95ee\u548c\u65e0\u7f1d\u8fde\u63a5\u3002", "conclusion": "\u8be5\u8bca\u65ad\u5de5\u5177\u4f5c\u4e3a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u8282\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u670d\u52a1\u4e0d\u8db3\u5730\u533a\u7684\u8bca\u65ad\u6311\u6218\uff0c\u4e3a\u5728\u4f4e\u8d44\u6e90\u533b\u7597\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\u3002\u4f18\u5316\u540e\u7684\u6a21\u578b\u5728\u4fdd\u6301\u8bca\u65ad\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8d44\u6e90\u9700\u6c42\uff0c\u4f7f\u5176\u9002\u5408\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u548c\u4f7f\u7528\u3002"}}
{"id": "2507.17125", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17125", "abs": "https://arxiv.org/abs/2507.17125", "authors": ["Jacob M. Delgado-L\u00f3pez", "Andrea P. Seda-Hernandez", "Juan D. Guadalupe-Rosado", "Luis E. Fernandez Ramirez", "Miguel Giboyeaux-Camilo", "Wilfredo E. Lugo-Beauchamp"], "title": "Model Compression Engine for Wearable Devices Skin Cancer Diagnosis", "comment": null, "summary": "Skin cancer is one of the most prevalent and preventable types of cancer, yet\nits early detection remains a challenge, particularly in resource-limited\nsettings where access to specialized healthcare is scarce. This study proposes\nan AI-driven diagnostic tool optimized for embedded systems to address this\ngap. Using transfer learning with the MobileNetV2 architecture, the model was\nadapted for binary classification of skin lesions into \"Skin Cancer\" and\n\"Other.\" The TensorRT framework was employed to compress and optimize the model\nfor deployment on the NVIDIA Jetson Orin Nano, balancing performance with\nenergy efficiency. Comprehensive evaluations were conducted across multiple\nbenchmarks, including model size, inference speed, throughput, and power\nconsumption. The optimized models maintained their performance, achieving an\nF1-Score of 87.18% with a precision of 93.18% and recall of 81.91%.\nPost-compression results showed reductions in model size of up to 0.41, along\nwith improvements in inference speed and throughput, and a decrease in energy\nconsumption of up to 0.93 in INT8 precision. These findings validate the\nfeasibility of deploying high-performing, energy-efficient diagnostic tools on\nresource-constrained edge devices. Beyond skin cancer detection, the\nmethodologies applied in this research have broader applications in other\nmedical diagnostics and domains requiring accessible, efficient AI solutions.\nThis study underscores the potential of optimized AI systems to revolutionize\nhealthcare diagnostics, thereby bridging the divide between advanced technology\nand underserved regions.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eMobileNetV2\u548cTensorRT\u4f18\u5316\u7684AI\u76ae\u80a4\u764c\u8bca\u65ad\u5de5\u5177\uff0c\u53ef\u5728NVIDIA Jetson Orin Nano\u7b49\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u90e8\u7f72\uff0c\u5b9e\u73b0\u4e8687.18%\u7684F1\u5206\u6570\u548c\u663e\u8457\u7684\u6a21\u578b\u538b\u7f29\u4e0e\u80fd\u8017\u964d\u4f4e\u3002", "motivation": "\u76ae\u80a4\u764c\u662f\u6700\u5e38\u89c1\u4e14\u53ef\u9884\u9632\u7684\u764c\u75c7\u7c7b\u578b\u4e4b\u4e00\uff0c\u4f46\u5176\u65e9\u671f\u68c0\u6d4b\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u7f3a\u4e4f\u4e13\u4e1a\u533b\u7597\u8d44\u6e90\u7684\u5730\u533a\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u9488\u5bf9\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4f18\u5316\u7684AI\u8bca\u65ad\u5de5\u5177\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528MobileNetV2\u67b6\u6784\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff0c\u5c06\u6a21\u578b\u9002\u914d\u4e3a\u76ae\u80a4\u75c5\u53d8\u7684\u4e8c\u5206\u7c7b\u4efb\u52a1\uff08\"\u76ae\u80a4\u764c\"\u548c\"\u5176\u4ed6\"\uff09\u3002\u91c7\u7528TensorRT\u6846\u67b6\u5bf9\u6a21\u578b\u8fdb\u884c\u538b\u7f29\u548c\u4f18\u5316\uff0c\u4ee5\u4fbf\u5728NVIDIA Jetson Orin Nano\u4e0a\u90e8\u7f72\uff0c\u5e73\u8861\u6027\u80fd\u4e0e\u80fd\u6548\u3002", "result": "\u4f18\u5316\u540e\u7684\u6a21\u578b\u4fdd\u6301\u4e86\u826f\u597d\u6027\u80fd\uff0cF1\u5206\u6570\u8fbe\u523087.18%\uff0c\u7cbe\u786e\u738793.18%\uff0c\u53ec\u56de\u738781.91%\u3002\u538b\u7f29\u540e\u6a21\u578b\u5927\u5c0f\u51cf\u5c11\u81f30.41\uff0c\u63a8\u7406\u901f\u5ea6\u548c\u541e\u5410\u91cf\u5f97\u5230\u6539\u5584\uff0cINT8\u7cbe\u5ea6\u4e0b\u80fd\u8017\u964d\u4f4e\u81f30.93\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u9ad8\u6027\u80fd\u3001\u9ad8\u80fd\u6548\u8bca\u65ad\u5de5\u5177\u7684\u53ef\u884c\u6027\u3002\u7814\u7a76\u65b9\u6cd5\u5728\u5176\u4ed6\u533b\u7597\u8bca\u65ad\u548c\u9700\u8981\u53ef\u8bbf\u95ee\u3001\u9ad8\u6548AI\u89e3\u51b3\u65b9\u6848\u7684\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\uff0c\u5c55\u73b0\u4e86\u4f18\u5316AI\u7cfb\u7edf\u5728\u9769\u547d\u6027\u6539\u53d8\u533b\u7597\u8bca\u65ad\u3001\u7f29\u5c0f\u5148\u8fdb\u6280\u672f\u4e0e\u670d\u52a1\u4e0d\u8db3\u5730\u533a\u5dee\u8ddd\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.17131", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17131", "abs": "https://arxiv.org/abs/2507.17131", "authors": ["Yufei He", "Ruoyu Li", "Alex Chen", "Yue Liu", "Yulin Chen", "Yuan Sui", "Cheng Chen", "Yi Zhu", "Luca Luo", "Frank Yang", "Bryan Hooi"], "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "comment": null, "summary": "Large language model (LLM) agents often struggle in environments where rules\nand required domain knowledge frequently change, such as regulatory compliance\nand user risk screening. Current approaches, like offline fine-tuning and\nstandard prompting, are insufficient because they cannot effectively adapt to\nnew knowledge during actual operation. To address this limitation, we propose\nthe Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework\ndesigned specifically to continuously learn updated domain knowledge at test\ntime. ARIA assesses its own uncertainty through structured self-dialogue,\nproactively identifying knowledge gaps and requesting targeted explanations or\ncorrections from human experts. It then systematically updates an internal,\ntimestamped knowledge repository with provided human guidance, detecting and\nresolving conflicting or outdated knowledge through comparisons and\nclarification queries. We evaluate ARIA on the realistic customer due diligence\nname screening task on TikTok Pay, alongside publicly available dynamic\nknowledge tasks. Results demonstrate significant improvements in adaptability\nand accuracy compared to baselines using standard offline fine-tuning and\nexisting self-improving agents. ARIA is deployed within TikTok Pay serving over\n150 million monthly active users, confirming its practicality and effectiveness\nfor operational use in rapidly evolving environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86ARIA\u6846\u67b6\uff0c\u4e00\u4e2a\u80fd\u591f\u5728\u6d4b\u8bd5\u65f6\u6301\u7eed\u5b66\u4e60\u66f4\u65b0\u9886\u57df\u77e5\u8bc6\u7684LLM\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u81ea\u6211\u5bf9\u8bdd\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3b\u52a8\u8bc6\u522b\u77e5\u8bc6\u7f3a\u53e3\u5e76\u5411\u4eba\u7c7b\u4e13\u5bb6\u8bf7\u6c42\u6307\u5bfc\uff0c\u7cfb\u7edf\u6027\u5730\u66f4\u65b0\u5185\u90e8\u77e5\u8bc6\u5e93\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u5728\u89c4\u5219\u548c\u9886\u57df\u77e5\u8bc6\u9891\u7e41\u53d8\u5316\u7684\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5982\u76d1\u7ba1\u5408\u89c4\u548c\u7528\u6237\u98ce\u9669\u7b5b\u67e5\u3002\u79bb\u7ebf\u5fae\u8c03\u548c\u6807\u51c6\u63d0\u793a\u7b49\u65b9\u6cd5\u65e0\u6cd5\u5728\u5b9e\u9645\u64cd\u4f5c\u4e2d\u6709\u6548\u9002\u5e94\u65b0\u77e5\u8bc6\u3002", "method": "\u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u53cd\u601d\u4ea4\u4e92\u667a\u80fd\u4f53(ARIA)\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u81ea\u6211\u5bf9\u8bdd\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3b\u52a8\u8bc6\u522b\u77e5\u8bc6\u7f3a\u53e3\u5e76\u8bf7\u6c42\u4eba\u7c7b\u4e13\u5bb6\u7684\u9488\u5bf9\u6027\u89e3\u91ca\u6216\u7ea0\u6b63\uff0c\u7cfb\u7edf\u6027\u5730\u66f4\u65b0\u5e26\u65f6\u95f4\u6233\u7684\u5185\u90e8\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u6bd4\u8f83\u548c\u6f84\u6e05\u67e5\u8be2\u68c0\u6d4b\u5e76\u89e3\u51b3\u51b2\u7a81\u6216\u8fc7\u65f6\u7684\u77e5\u8bc6\u3002", "result": "\u5728TikTok Pay\u7684\u5ba2\u6237\u5c3d\u804c\u8c03\u67e5\u59d3\u540d\u7b5b\u67e5\u4efb\u52a1\u548c\u516c\u5f00\u7684\u52a8\u6001\u77e5\u8bc6\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f7f\u7528\u6807\u51c6\u79bb\u7ebf\u5fae\u8c03\u548c\u73b0\u6709\u81ea\u6211\u6539\u8fdb\u667a\u80fd\u4f53\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9002\u5e94\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "ARIA\u5df2\u90e8\u7f72\u5728TikTok Pay\u4e2d\u4e3a\u8d85\u8fc71.5\u4ebf\u6708\u6d3b\u7528\u6237\u63d0\u4f9b\u670d\u52a1\uff0c\u8bc1\u5b9e\u4e86\u5176\u5728\u5feb\u901f\u53d8\u5316\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002\u8be5\u6846\u67b6\u4e3aLLM\u667a\u80fd\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17135", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.17135", "abs": "https://arxiv.org/abs/2507.17135", "authors": ["Ting Jiang", "Yixiao Wang", "Hancheng Ye", "Zishan Shao", "Jingwei Sun", "Jingyang Zhang", "Zekai Chen", "Jianyi Zhang", "Yiran Chen", "Hai Li"], "title": "SADA: Stability-guided Adaptive Diffusion Acceleration", "comment": "Accepted and published by ICML 2025. Code is available at:\n  https://github.com/Ting-Justin-Jiang/sada-icml", "summary": "Diffusion models have achieved remarkable success in generative tasks but\nsuffer from high computational costs due to their iterative sampling process\nand quadratic attention costs. Existing training-free acceleration strategies\nthat reduce per-step computation cost, while effectively reducing sampling\ntime, demonstrate low faithfulness compared to the original baseline. We\nhypothesize that this fidelity gap arises because (a) different prompts\ncorrespond to varying denoising trajectory, and (b) such methods do not\nconsider the underlying ODE formulation and its numerical solution. In this\npaper, we propose Stability-guided Adaptive Diffusion Acceleration (SADA), a\nnovel paradigm that unifies step-wise and token-wise sparsity decisions via a\nsingle stability criterion to accelerate sampling of ODE-based generative\nmodels (Diffusion and Flow-matching). For (a), SADA adaptively allocates\nsparsity based on the sampling trajectory. For (b), SADA introduces principled\napproximation schemes that leverage the precise gradient information from the\nnumerical ODE solver. Comprehensive evaluations on SD-2, SDXL, and Flux using\nboth EDM and DPM++ solvers reveal consistent $\\ge 1.8\\times$ speedups with\nminimal fidelity degradation (LPIPS $\\leq 0.10$ and FID $\\leq 4.5$) compared to\nunmodified baselines, significantly outperforming prior methods. Moreover, SADA\nadapts seamlessly to other pipelines and modalities: It accelerates ControlNet\nwithout any modifications and speeds up MusicLDM by $1.8\\times$ with $\\sim\n0.01$ spectrogram LPIPS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SADA\uff08\u7a33\u5b9a\u6027\u5f15\u5bfc\u7684\u81ea\u9002\u5e94\u6269\u6563\u52a0\u901f\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u7a33\u5b9a\u6027\u51c6\u5219\u540c\u65f6\u8fdb\u884c\u6b65\u9aa4\u7ea7\u548ctoken\u7ea7\u7684\u7a00\u758f\u5316\u51b3\u7b56\uff0c\u5b9e\u73b0\u4e86\u6269\u6563\u6a21\u578b\u5728\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u83b7\u5f971.8\u500d\u4ee5\u4e0a\u7684\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u867d\u7136\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u8fed\u4ee3\u91c7\u6837\u8fc7\u7a0b\u548c\u4e8c\u6b21\u6ce8\u610f\u529b\u6210\u672c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u9ad8\u6602\u3002\u73b0\u6709\u7684\u65e0\u8bad\u7ec3\u52a0\u901f\u7b56\u7565\u867d\u80fd\u51cf\u5c11\u91c7\u6837\u65f6\u95f4\uff0c\u4f46\u76f8\u6bd4\u539f\u59cb\u57fa\u7ebf\u4fdd\u771f\u5ea6\u8f83\u4f4e\u3002\u4f5c\u8005\u5047\u8bbe\u8fd9\u79cd\u4fdd\u771f\u5ea6\u5dee\u8ddd\u6e90\u4e8e\uff1a(a)\u4e0d\u540c\u63d0\u793a\u5bf9\u5e94\u4e0d\u540c\u7684\u53bb\u566a\u8f68\u8ff9\uff0c(b)\u8fd9\u4e9b\u65b9\u6cd5\u672a\u8003\u8651\u5e95\u5c42ODE\u516c\u5f0f\u53ca\u5176\u6570\u503c\u89e3\u3002", "method": "\u63d0\u51faSADA\uff08\u7a33\u5b9a\u6027\u5f15\u5bfc\u7684\u81ea\u9002\u5e94\u6269\u6563\u52a0\u901f\uff09\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u8303\u5f0f\uff0c\u901a\u8fc7\u5355\u4e00\u7a33\u5b9a\u6027\u51c6\u5219\u7edf\u4e00\u6b65\u9aa4\u7ea7\u548ctoken\u7ea7\u7a00\u758f\u5316\u51b3\u7b56\uff0c\u52a0\u901f\u57fa\u4e8eODE\u7684\u751f\u6210\u6a21\u578b\uff08\u6269\u6563\u548c\u6d41\u5339\u914d\uff09\u7684\u91c7\u6837\u3002\u9488\u5bf9\u95ee\u9898(a)\uff0cSADA\u57fa\u4e8e\u91c7\u6837\u8f68\u8ff9\u81ea\u9002\u5e94\u5206\u914d\u7a00\u758f\u6027\uff1b\u9488\u5bf9\u95ee\u9898(b)\uff0cSADA\u5f15\u5165\u539f\u7406\u6027\u8fd1\u4f3c\u65b9\u6848\uff0c\u5229\u7528\u6570\u503cODE\u6c42\u89e3\u5668\u7684\u7cbe\u786e\u68af\u5ea6\u4fe1\u606f\u3002", "result": "\u5728SD-2\u3001SDXL\u548cFlux\u4e0a\u4f7f\u7528EDM\u548cDPM++\u6c42\u89e3\u5668\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0c\u76f8\u6bd4\u672a\u4fee\u6539\u7684\u57fa\u7ebf\uff0cSADA\u5b9e\u73b0\u4e86\u4e00\u81f4\u7684\u22651.8\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5c0f\u7684\u4fdd\u771f\u5ea6\u964d\u4f4e\uff08LPIPS\u22640.10\uff0cFID\u22644.5\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002\u6b64\u5916\uff0cSADA\u65e0\u7f1d\u9002\u5e94\u5176\u4ed6\u7ba1\u9053\u548c\u6a21\u6001\uff1a\u65e0\u9700\u4efb\u4f55\u4fee\u6539\u5373\u53ef\u52a0\u901fControlNet\uff0c\u5e76\u4ee5\u7ea60.01\u7684\u9891\u8c31\u56feLPIPS\u5c06MusicLDM\u52a0\u901f1.8\u500d\u3002", "conclusion": "SADA\u901a\u8fc7\u7edf\u4e00\u7684\u7a33\u5b9a\u6027\u51c6\u5219\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6269\u6563\u6a21\u578b\u52a0\u901f\u65b9\u6cd5\u4e2d\u4fdd\u771f\u5ea6\u4e0e\u901f\u5ea6\u7684\u6743\u8861\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u90fd\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u52a0\u901f\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u8d28\u91cf\u7684\u751f\u6210\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2507.17151", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17151", "abs": "https://arxiv.org/abs/2507.17151", "authors": ["Anirudh Satheesh", "Anant Khandelwal", "Mucong Ding", "Radu Balan"], "title": "PICore: Physics-Informed Unsupervised Coreset Selection for Data Efficient Neural Operator Training", "comment": "Submitted to TMLR 2025", "summary": "Neural operators offer a powerful paradigm for solving partial differential\nequations (PDEs) that cannot be solved analytically by learning mappings\nbetween function spaces. However, there are two main bottlenecks in training\nneural operators: they require a significant amount of training data to learn\nthese mappings, and this data needs to be labeled, which can only be accessed\nvia expensive simulations with numerical solvers. To alleviate both of these\nissues simultaneously, we propose PICore, an unsupervised coreset selection\nframework that identifies the most informative training samples without\nrequiring access to ground-truth PDE solutions. PICore leverages a\nphysics-informed loss to select unlabeled inputs by their potential\ncontribution to operator learning. After selecting a compact subset of inputs,\nonly those samples are simulated using numerical solvers to generate labels,\nreducing annotation costs. We then train the neural operator on the reduced\nlabeled dataset, significantly decreasing training time as well. Across four\ndiverse PDE benchmarks and multiple coreset selection strategies, PICore\nachieves up to 78% average increase in training efficiency relative to\nsupervised coreset selection methods with minimal changes in accuracy. We\nprovide code at https://github.com/Asatheesh6561/PICore.", "AI": {"tldr": "PICore\u662f\u4e00\u4e2a\u65e0\u76d1\u7763\u6838\u5fc3\u96c6\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u635f\u5931\u8bc6\u522b\u6700\u6709\u4fe1\u606f\u91cf\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u65e0\u9700\u8bbf\u95ee\u771f\u5b9ePDE\u89e3\uff0c\u663e\u8457\u63d0\u9ad8\u795e\u7ecf\u7b97\u5b50\u8bad\u7ec3\u6548\u7387\u5e76\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u3002", "motivation": "\u795e\u7ecf\u7b97\u5b50\u8bad\u7ec3\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u74f6\u9888\uff1a\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u5b66\u4e60\u51fd\u6570\u7a7a\u95f4\u6620\u5c04\uff0c\u4e14\u6570\u636e\u9700\u8981\u6807\u6ce8\uff0c\u800c\u6807\u6ce8\u53ea\u80fd\u901a\u8fc7\u6602\u8d35\u7684\u6570\u503c\u6c42\u89e3\u5668\u4eff\u771f\u83b7\u5f97\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u540c\u65f6\u89e3\u51b3\u6570\u636e\u91cf\u5927\u548c\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faPICore\u65e0\u76d1\u7763\u6838\u5fc3\u96c6\u9009\u62e9\u6846\u67b6\uff0c\u5229\u7528\u7269\u7406\u4fe1\u606f\u635f\u5931\u6765\u9009\u62e9\u672a\u6807\u6ce8\u8f93\u5165\u6837\u672c\uff0c\u6839\u636e\u6837\u672c\u5bf9\u7b97\u5b50\u5b66\u4e60\u7684\u6f5c\u5728\u8d21\u732e\u8fdb\u884c\u8bc4\u4f30\u3002\u9009\u62e9\u51fa\u7d27\u51d1\u7684\u8f93\u5165\u5b50\u96c6\u540e\uff0c\u4ec5\u5bf9\u8fd9\u4e9b\u6837\u672c\u4f7f\u7528\u6570\u503c\u6c42\u89e3\u5668\u751f\u6210\u6807\u7b7e\uff0c\u7136\u540e\u5728\u7f29\u51cf\u7684\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u795e\u7ecf\u7b97\u5b50\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u7684PDE\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u79cd\u6838\u5fc3\u96c6\u9009\u62e9\u7b56\u7565\u4e0a\uff0cPICore\u76f8\u6bd4\u6709\u76d1\u7763\u6838\u5fc3\u96c6\u9009\u62e9\u65b9\u6cd5\u5e73\u5747\u63d0\u9ad8\u4e8678%\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u540c\u65f6\u51c6\u786e\u6027\u53d8\u5316\u6781\u5c0f\u3002\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u65f6\u95f4\u548c\u6807\u6ce8\u6210\u672c\u3002", "conclusion": "PICore\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u795e\u7ecf\u7b97\u5b50\u8bad\u7ec3\u4e2d\u7684\u6570\u636e\u9700\u6c42\u5927\u548c\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u53cc\u91cd\u95ee\u9898\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u7684\u65b9\u5f0f\u9009\u62e9\u6700\u6709\u4ef7\u503c\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u4e3aPDE\u6c42\u89e3\u7684\u795e\u7ecf\u7b97\u5b50\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17161", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17161", "abs": "https://arxiv.org/abs/2507.17161", "authors": ["Vinura Galwaduge", "Jagath Samarabandu"], "title": "Tabular Diffusion based Actionable Counterfactual Explanations for Network Intrusion Detection", "comment": null, "summary": "Modern network intrusion detection systems (NIDS) frequently utilize the\npredictive power of complex deep learning models. However, the \"black-box\"\nnature of such deep learning methods adds a layer of opaqueness that hinders\nthe proper understanding of detection decisions, trust in the decisions and\nprevent timely countermeasures against such attacks. Explainable AI (XAI)\nmethods provide a solution to this problem by providing insights into the\ncauses of the predictions. The majority of the existing XAI methods provide\nexplanations which are not convenient to convert into actionable\ncountermeasures. In this work, we propose a novel diffusion-based\ncounterfactual explanation framework that can provide actionable explanations\nfor network intrusion attacks. We evaluated our proposed algorithm against\nseveral other publicly available counterfactual explanation algorithms on 3\nmodern network intrusion datasets. To the best of our knowledge, this work also\npresents the first comparative analysis of existing counterfactual explanation\nalgorithms within the context of network intrusion detection systems. Our\nproposed method provide minimal, diverse counterfactual explanations out of the\ntested counterfactual explanation algorithms in a more efficient manner by\nreducing the time to generate explanations. We also demonstrate how\ncounterfactual explanations can provide actionable explanations by summarizing\nthem to create a set of global rules. These rules are actionable not only at\ninstance level but also at the global level for intrusion attacks. These global\ncounterfactual rules show the ability to effectively filter out incoming attack\nqueries which is crucial for efficient intrusion detection and defense\nmechanisms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6846\u67b6\uff0c\u7528\u4e8e\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u53ef\u89e3\u91caAI\uff0c\u80fd\u591f\u751f\u6210\u53ef\u64cd\u4f5c\u7684\u89e3\u91ca\u5e76\u8f6c\u5316\u4e3a\u5168\u5c40\u89c4\u5219\u4ee5\u6709\u6548\u8fc7\u6ee4\u653b\u51fb\u67e5\u8be2\u3002", "motivation": "\u73b0\u4ee3\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\"\u9ed1\u76d2\"\u7279\u6027\u5bfc\u81f4\u68c0\u6d4b\u51b3\u7b56\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u963b\u788d\u4e86\u5bf9\u51b3\u7b56\u7684\u7406\u89e3\u548c\u4fe1\u4efb\uff0c\u5e76\u5f71\u54cd\u53ca\u65f6\u91c7\u53d6\u5bf9\u6297\u63aa\u65bd\u3002\u73b0\u6709\u7684\u53ef\u89e3\u91caAI\u65b9\u6cd5\u63d0\u4f9b\u7684\u89e3\u91ca\u96be\u4ee5\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u5bf9\u6297\u63aa\u65bd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6846\u67b6\uff0c\u80fd\u591f\u4e3a\u7f51\u7edc\u5165\u4fb5\u653b\u51fb\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89e3\u91ca\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u6700\u5c0f\u5316\u3001\u591a\u6837\u5316\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e76\u5c06\u5176\u603b\u7ed3\u4e3a\u5168\u5c40\u89c4\u5219\u96c6\u3002", "result": "\u57283\u4e2a\u73b0\u4ee3\u7f51\u7edc\u5165\u4fb5\u6570\u636e\u96c6\u4e0a\u4e0e\u5176\u4ed6\u516c\u5f00\u53ef\u7528\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7b97\u6cd5\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6d4b\u8bd5\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7b97\u6cd5\u4e2d\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u63d0\u4f9b\u6700\u5c0f\u5316\u3001\u591a\u6837\u5316\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u51cf\u5c11\u4e86\u751f\u6210\u89e3\u91ca\u7684\u65f6\u95f4\u3002\u751f\u6210\u7684\u5168\u5c40\u53cd\u4e8b\u5b9e\u89c4\u5219\u80fd\u591f\u6709\u6548\u8fc7\u6ee4\u4f20\u5165\u7684\u653b\u51fb\u67e5\u8be2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u5b9e\u4f8b\u7ea7\u522b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89e3\u91ca\uff0c\u8fd8\u80fd\u5728\u5168\u5c40\u7ea7\u522b\u4e3a\u5165\u4fb5\u653b\u51fb\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89e3\u91ca\u3002\u5168\u5c40\u53cd\u4e8b\u5b9e\u89c4\u5219\u663e\u793a\u51fa\u6709\u6548\u8fc7\u6ee4\u4f20\u5165\u653b\u51fb\u67e5\u8be2\u7684\u80fd\u529b\uff0c\u8fd9\u5bf9\u9ad8\u6548\u7684\u5165\u4fb5\u68c0\u6d4b\u548c\u9632\u5fa1\u673a\u5236\u81f3\u5173\u91cd\u8981\u3002\u8fd9\u4e5f\u662f\u9996\u6b21\u5728\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u80cc\u666f\u4e0b\u5bf9\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7b97\u6cd5\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u7684\u5de5\u4f5c\u3002"}}
{"id": "2507.17189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17189", "abs": "https://arxiv.org/abs/2507.17189", "authors": ["Shaohan Li", "Hao Yang", "Min Chen", "Xiaolin Qin"], "title": "Met$^2$Net: A Decoupled Two-Stage Spatio-Temporal Forecasting Model for Complex Meteorological Systems", "comment": null, "summary": "The increasing frequency of extreme weather events due to global climate\nchange urges accurate weather prediction. Recently, great advances have been\nmade by the \\textbf{end-to-end methods}, thanks to deep learning techniques,\nbut they face limitations of \\textit{representation inconsistency} in\nmultivariable integration and struggle to effectively capture the dependency\nbetween variables, which is required in complex weather systems. Treating\ndifferent variables as distinct modalities and applying a \\textbf{two-stage\ntraining approach} from multimodal models can partially alleviate this issue,\nbut due to the inconformity in training tasks between the two stages, the\nresults are often suboptimal. To address these challenges, we propose an\nimplicit two-stage training method, configuring separate encoders and decoders\nfor each variable. In detailed, in the first stage, the Translator is frozen\nwhile the Encoders and Decoders learn a shared latent space, in the second\nstage, the Encoders and Decoders are frozen, and the Translator captures\ninter-variable interactions for prediction. Besides, by introducing a\nself-attention mechanism for multivariable fusion in the latent space, the\nperformance achieves further improvements. Empirically, extensive experiments\nshow the state-of-the-art performance of our method. Specifically, it reduces\nthe MSE for near-surface air temperature and relative humidity predictions by\n28.82\\% and 23.39\\%, respectively. The source code is available at\nhttps://github.com/ShremG/Met2Net.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Met2Net\uff0c\u4e00\u79cd\u9690\u5f0f\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\u7528\u4e8e\u5929\u6c14\u9884\u6d4b\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u53d8\u91cf\u914d\u7f6e\u72ec\u7acb\u7684\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff0c\u5e76\u5f15\u5165\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u591a\u53d8\u91cf\u878d\u5408\uff0c\u5728\u8fd1\u5730\u9762\u6c14\u6e29\u548c\u76f8\u5bf9\u6e7f\u5ea6\u9884\u6d4b\u4e0a\u5206\u522b\u964d\u4f4e\u4e8628.82%\u548c23.39%\u7684MSE", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u5929\u6c14\u9884\u6d4b\u65b9\u6cd5\u9762\u4e34\u591a\u53d8\u91cf\u96c6\u6210\u4e2d\u7684\u8868\u793a\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u96be\u4ee5\u6709\u6548\u6355\u83b7\u590d\u6742\u5929\u6c14\u7cfb\u7edf\u4e2d\u53d8\u91cf\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff1b\u73b0\u6709\u591a\u6a21\u6001\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\u7531\u4e8e\u4e24\u9636\u6bb5\u95f4\u8bad\u7ec3\u4efb\u52a1\u7684\u4e0d\u4e00\u81f4\u6027\u5bfc\u81f4\u7ed3\u679c\u6b21\u4f18", "method": "\u63d0\u51fa\u9690\u5f0f\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u51bb\u7ed3Translator\uff0c\u8ba9\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5b66\u4e60\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff1b\u7b2c\u4e8c\u9636\u6bb5\u51bb\u7ed3\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff0c\u8ba9Translator\u6355\u83b7\u53d8\u91cf\u95f4\u4ea4\u4e92\u8fdb\u884c\u9884\u6d4b\uff1b\u540c\u65f6\u5f15\u5165\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u591a\u53d8\u91cf\u878d\u5408", "result": "\u5728\u5929\u6c14\u9884\u6d4b\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8fd1\u5730\u9762\u6c14\u6e29\u9884\u6d4bMSE\u964d\u4f4e28.82%\uff0c\u76f8\u5bf9\u6e7f\u5ea6\u9884\u6d4bMSE\u964d\u4f4e23.39%", "conclusion": "\u6240\u63d0\u51fa\u7684Met2Net\u65b9\u6cd5\u901a\u8fc7\u9690\u5f0f\u4e24\u9636\u6bb5\u8bad\u7ec3\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u591a\u53d8\u91cf\u5929\u6c14\u9884\u6d4b\u4e2d\u7684\u8868\u793a\u4e0d\u4e00\u81f4\u548c\u53d8\u91cf\u4f9d\u8d56\u6355\u83b7\u95ee\u9898\uff0c\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347"}}
{"id": "2507.17204", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17204", "abs": "https://arxiv.org/abs/2507.17204", "authors": ["Zixuan Wang", "Jinghao Shi", "Hanzhong Liang", "Xiang Shen", "Vera Wen", "Zhiqian Chen", "Yifan Wu", "Zhixin Zhang", "Hongyu Xiong"], "title": "Filter-And-Refine: A MLLM Based Cascade System for Industrial-Scale Video Content Moderation", "comment": "Camera Ready for ACL 2025", "summary": "Effective content moderation is essential for video platforms to safeguard\nuser experience and uphold community standards. While traditional video\nclassification models effectively handle well-defined moderation tasks, they\nstruggle with complicated scenarios such as implicit harmful content and\ncontextual ambiguity. Multimodal large language models (MLLMs) offer a\npromising solution to these limitations with their superior cross-modal\nreasoning and contextual understanding. However, two key challenges hinder\ntheir industrial adoption. First, the high computational cost of MLLMs makes\nfull-scale deployment impractical. Second, adapting generative models for\ndiscriminative classification remains an open research problem. In this paper,\nwe first introduce an efficient method to transform a generative MLLM into a\nmultimodal classifier using minimal discriminative training data. To enable\nindustry-scale deployment, we then propose a router-ranking cascade system that\nintegrates MLLMs with a lightweight router model. Offline experiments\ndemonstrate that our MLLM-based approach improves F1 score by 66.50% over\ntraditional classifiers while requiring only 2% of the fine-tuning data. Online\nevaluations show that our system increases automatic content moderation volume\nby 41%, while the cascading deployment reduces computational cost to only 1.5%\nof direct full-scale deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLM)\u7684\u89c6\u9891\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\uff0c\u901a\u8fc7\u8def\u7531\u5668-\u6392\u5e8f\u7ea7\u8054\u67b6\u6784\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\uff0c\u76f8\u6bd4\u4f20\u7edf\u5206\u7c7b\u5668F1\u5206\u6570\u63d0\u534766.50%\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u4ec5\u4e3a\u76f4\u63a5\u90e8\u7f72\u76841.5%", "motivation": "\u4f20\u7edf\u89c6\u9891\u5206\u7c7b\u6a21\u578b\u5728\u5904\u7406\u9690\u5f0f\u6709\u5bb3\u5185\u5bb9\u548c\u4e0a\u4e0b\u6587\u6a21\u7cca\u6027\u7b49\u590d\u6742\u573a\u666f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5177\u6709\u4f18\u79c0\u7684\u8de8\u6a21\u6001\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u751f\u6210\u6a21\u578b\u9002\u914d\u5224\u522b\u5206\u7c7b\u4efb\u52a1\u56f0\u96be\u4e24\u5927\u6311\u6218\uff0c\u963b\u788d\u4e86\u5176\u5728\u5de5\u4e1a\u754c\u7684\u5e94\u7528", "method": "\u9996\u5148\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u4f7f\u7528\u6700\u5c11\u7684\u5224\u522b\u8bad\u7ec3\u6570\u636e\u5c06\u751f\u6210\u5f0fMLLM\u8f6c\u6362\u4e3a\u591a\u6a21\u6001\u5206\u7c7b\u5668\uff1b\u7136\u540e\u8bbe\u8ba1\u8def\u7531\u5668-\u6392\u5e8f\u7ea7\u8054\u7cfb\u7edf\uff0c\u5c06MLLM\u4e0e\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u6a21\u578b\u96c6\u6210\uff0c\u5b9e\u73b0\u5de5\u4e1a\u89c4\u6a21\u90e8\u7f72", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u663e\u793a\uff0c\u57fa\u4e8eMLLM\u7684\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u5206\u7c7b\u5668F1\u5206\u6570\u63d0\u534766.50%\uff0c\u4ec5\u9700\u89812%\u7684\u5fae\u8c03\u6570\u636e\uff1b\u5728\u7ebf\u8bc4\u4f30\u8868\u660e\u7cfb\u7edf\u5c06\u81ea\u52a8\u5185\u5bb9\u5ba1\u6838\u91cf\u63d0\u5347\u4e8641%\uff0c\u7ea7\u8054\u90e8\u7f72\u5c06\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u81f3\u76f4\u63a5\u5168\u89c4\u6a21\u90e8\u7f72\u76841.5%", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684\u9ad8\u6548\u8f6c\u6362\u65b9\u6cd5\u548c\u7ea7\u8054\u90e8\u7f72\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86MLLM\u5728\u89c6\u9891\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u8ba1\u7b97\u6210\u672c\u548c\u6a21\u578b\u9002\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u663e\u8457\u63d0\u5347\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u90e8\u7f72\u6210\u672c\uff0c\u4e3aMLLM\u5728\u5de5\u4e1a\u7ea7\u5185\u5bb9\u5ba1\u6838\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.17221", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.17221", "abs": "https://arxiv.org/abs/2507.17221", "authors": ["Youneng Bao", "Yiping Liu", "Zhuo Chen", "Yongsheng Liang", "Mu Li", "Kede Ma"], "title": "Dataset Distillation as Data Compression: A Rate-Utility Perspective", "comment": "Accepted by ICCV 2025", "summary": "Driven by the ``scale-is-everything'' paradigm, modern machine learning\nincreasingly demands ever-larger datasets and models, yielding prohibitive\ncomputational and storage requirements. Dataset distillation mitigates this by\ncompressing an original dataset into a small set of synthetic samples, while\npreserving its full utility. Yet, existing methods either maximize performance\nunder fixed storage budgets or pursue suitable synthetic data representations\nfor redundancy removal, without jointly optimizing both objectives. In this\nwork, we propose a joint rate-utility optimization method for dataset\ndistillation. We parameterize synthetic samples as optimizable latent codes\ndecoded by extremely lightweight networks. We estimate the Shannon entropy of\nquantized latents as the rate measure and plug any existing distillation loss\nas the utility measure, trading them off via a Lagrange multiplier. To enable\nfair, cross-method comparisons, we introduce bits per class (bpc), a precise\nstorage metric that accounts for sample, label, and decoder parameter costs. On\nCIFAR-10, CIFAR-100, and ImageNet-128, our method achieves up to $170\\times$\ngreater compression than standard distillation at comparable accuracy. Across\ndiverse bpc budgets, distillation losses, and backbone architectures, our\napproach consistently establishes better rate-utility trade-offs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u901f\u7387-\u6548\u7528\u4f18\u5316\u7684\u6570\u636e\u96c6\u84b8\u998f\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5408\u6210\u6837\u672c\u53c2\u6570\u5316\u4e3a\u53ef\u4f18\u5316\u7684\u6f5c\u5728\u7f16\u7801\u5e76\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7f51\u7edc\u89e3\u7801\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u8fbe170\u500d\u7684\u538b\u7f29\u7387", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u8ffd\u6c42\"\u89c4\u6a21\u5373\u4e00\u5207\"\u7684\u8303\u5f0f\uff0c\u9700\u8981\u8d8a\u6765\u8d8a\u5927\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u5bfc\u81f4\u8ba1\u7b97\u548c\u5b58\u50a8\u9700\u6c42\u8fc7\u9ad8\u3002\u73b0\u6709\u7684\u6570\u636e\u96c6\u84b8\u998f\u65b9\u6cd5\u8981\u4e48\u5728\u56fa\u5b9a\u5b58\u50a8\u9884\u7b97\u4e0b\u6700\u5927\u5316\u6027\u80fd\uff0c\u8981\u4e48\u8ffd\u6c42\u5408\u9002\u7684\u5408\u6210\u6570\u636e\u8868\u793a\u6765\u6d88\u9664\u5197\u4f59\uff0c\u4f46\u6ca1\u6709\u540c\u65f6\u4f18\u5316\u8fd9\u4e24\u4e2a\u76ee\u6807", "method": "\u5c06\u5408\u6210\u6837\u672c\u53c2\u6570\u5316\u4e3a\u53ef\u4f18\u5316\u7684\u6f5c\u5728\u7f16\u7801\uff0c\u901a\u8fc7\u6781\u8f7b\u91cf\u7ea7\u7f51\u7edc\u8fdb\u884c\u89e3\u7801\uff1b\u4f30\u8ba1\u91cf\u5316\u6f5c\u5728\u53d8\u91cf\u7684\u9999\u519c\u71b5\u4f5c\u4e3a\u901f\u7387\u5ea6\u91cf\uff0c\u4f7f\u7528\u73b0\u6709\u84b8\u998f\u635f\u5931\u4f5c\u4e3a\u6548\u7528\u5ea6\u91cf\uff0c\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u4e58\u6570\u8fdb\u884c\u6743\u8861\uff1b\u5f15\u5165\u6bcf\u7c7b\u6bd4\u7279\u6570(bpc)\u4f5c\u4e3a\u7cbe\u786e\u7684\u5b58\u50a8\u5ea6\u91cf\uff0c\u8003\u8651\u6837\u672c\u3001\u6807\u7b7e\u548c\u89e3\u7801\u5668\u53c2\u6570\u6210\u672c", "result": "\u5728CIFAR-10\u3001CIFAR-100\u548cImageNet-128\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u6bd4\u51c6\u786e\u6027\u4e0b\u5b9e\u73b0\u4e86\u6bd4\u6807\u51c6\u84b8\u998f\u9ad8\u8fbe170\u500d\u7684\u538b\u7f29\u7387\uff1b\u5728\u4e0d\u540c\u7684bpc\u9884\u7b97\u3001\u84b8\u998f\u635f\u5931\u548c\u9aa8\u5e72\u67b6\u6784\u4e0b\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u5efa\u7acb\u4e86\u66f4\u597d\u7684\u901f\u7387-\u6548\u7528\u6743\u8861", "conclusion": "\u63d0\u51fa\u7684\u8054\u5408\u901f\u7387-\u6548\u7528\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6570\u636e\u96c6\u84b8\u998f\u4e2d\u5b58\u50a8\u6548\u7387\u548c\u6027\u80fd\u4fdd\u6301\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u90fd\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u538b\u7f29\u6027\u80fd\u548c\u51c6\u786e\u6027\u4fdd\u6301\u80fd\u529b"}}
{"id": "2507.17228", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.17228", "abs": "https://arxiv.org/abs/2507.17228", "authors": ["Wei Fan", "JinYi Yoon", "Xiaochang Li", "Huajie Shao", "Bo Ji"], "title": "P3SL: Personalized Privacy-Preserving Split Learning on Heterogeneous Edge Devices", "comment": "Accepted as invited paper in The 34th International Conference on\n  Computer Communications and Networks (ICCCN 2025)", "summary": "Split Learning (SL) is an emerging privacy-preserving machine learning\ntechnique that enables resource constrained edge devices to participate in\nmodel training by partitioning a model into client-side and server-side\nsub-models. While SL reduces computational overhead on edge devices, it\nencounters significant challenges in heterogeneous environments where devices\nvary in computing resources, communication capabilities, environmental\nconditions, and privacy requirements. Although recent studies have explored\nheterogeneous SL frameworks that optimize split points for devices with varying\nresource constraints, they often neglect personalized privacy requirements and\nlocal model customization under varying environmental conditions. To address\nthese limitations, we propose P3SL, a Personalized Privacy-Preserving Split\nLearning framework designed for heterogeneous, resource-constrained edge device\nsystems. The key contributions of this work are twofold. First, we design a\npersonalized sequential split learning pipeline that allows each client to\nachieve customized privacy protection and maintain personalized local models\ntailored to their computational resources, environmental conditions, and\nprivacy needs. Second, we adopt a bi-level optimization technique that empowers\nclients to determine their own optimal personalized split points without\nsharing private sensitive information (i.e., computational resources,\nenvironmental conditions, privacy requirements) with the server. This approach\nbalances energy consumption and privacy leakage risks while maintaining high\nmodel accuracy. We implement and evaluate P3SL on a testbed consisting of 7\ndevices including 4 Jetson Nano P3450 devices, 2 Raspberry Pis, and 1 laptop,\nusing diverse model architectures and datasets under varying environmental\nconditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faP3SL\u6846\u67b6\uff0c\u4e00\u4e2a\u9762\u5411\u5f02\u6784\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u7684\u4e2a\u6027\u5316\u9690\u79c1\u4fdd\u62a4\u5206\u5272\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u6280\u672f\u8ba9\u5ba2\u6237\u7aef\u81ea\u4e3b\u786e\u5b9a\u6700\u4f18\u5206\u5272\u70b9\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u5e73\u8861\u80fd\u8017\u548c\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u5272\u5b66\u4e60\u65b9\u6cd5\u5728\u5f02\u6784\u73af\u5883\u4e0b\u5ffd\u7565\u4e86\u4e2a\u6027\u5316\u9690\u79c1\u9700\u6c42\u548c\u672c\u5730\u6a21\u578b\u5b9a\u5236\u5316\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u8bbe\u5907\u7684\u8ba1\u7b97\u8d44\u6e90\u3001\u901a\u4fe1\u80fd\u529b\u3001\u73af\u5883\u6761\u4ef6\u548c\u9690\u79c1\u8981\u6c42\u7684\u5dee\u5f02\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e2a\u6027\u5316\u5e8f\u5217\u5206\u5272\u5b66\u4e60\u6d41\u6c34\u7ebf\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u6280\u672f\u8ba9\u5ba2\u6237\u7aef\u5728\u4e0d\u5411\u670d\u52a1\u5668\u5171\u4eab\u654f\u611f\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u81ea\u4e3b\u786e\u5b9a\u6700\u4f18\u4e2a\u6027\u5316\u5206\u5272\u70b9\uff0c\u5b9e\u73b0\u5b9a\u5236\u5316\u9690\u79c1\u4fdd\u62a4\u548c\u672c\u5730\u6a21\u578b\u4e2a\u6027\u5316\u3002", "result": "\u5728\u5305\u542b4\u4e2aJetson Nano P3450\u8bbe\u5907\u30012\u4e2a\u6811\u8393\u6d3e\u548c1\u53f0\u7b14\u8bb0\u672c\u7535\u8111\u7684\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u4f7f\u7528\u591a\u79cd\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u96c6\u5728\u4e0d\u540c\u73af\u5883\u6761\u4ef6\u4e0b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "P3SL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5f02\u6784\u8fb9\u7f18\u8bbe\u5907\u73af\u5883\u4e0b\u7684\u4e2a\u6027\u5316\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u5728\u4e0d\u6cc4\u9732\u8bbe\u5907\u654f\u611f\u4fe1\u606f\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u80fd\u8017\u3001\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u548c\u6a21\u578b\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6709\u6548\u5e73\u8861\u3002"}}
{"id": "2507.17241", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.17241", "abs": "https://arxiv.org/abs/2507.17241", "authors": ["Mattia Sabella", "Monica Vitali"], "title": "Eco-Friendly AI: Unleashing Data Power for Green Federated Learning", "comment": null, "summary": "The widespread adoption of Artificial Intelligence (AI) and Machine Learning\n(ML) comes with a significant environmental impact, particularly in terms of\nenergy consumption and carbon emissions. This pressing issue highlights the\nneed for innovative solutions to mitigate AI's ecological footprint. One of the\nkey factors influencing the energy consumption of ML model training is the size\nof the training dataset. ML models are often trained on vast amounts of data\ncontinuously generated by sensors and devices distributed across multiple\nlocations. To reduce data transmission costs and enhance privacy, Federated\nLearning (FL) enables model training without the need to move or share raw\ndata. While FL offers these advantages, it also introduces challenges due to\nthe heterogeneity of data sources (related to volume and quality),\ncomputational node capabilities, and environmental impact.\n  This paper contributes to the advancement of Green AI by proposing a\ndata-centric approach to Green Federated Learning. Specifically, we focus on\nreducing FL's environmental impact by minimizing the volume of training data.\nOur methodology involves the analysis of the characteristics of federated\ndatasets, the selecting of an optimal subset of data based on quality metrics,\nand the choice of the federated nodes with the lowest environmental impact. We\ndevelop a comprehensive methodology that examines the influence of data-centric\nfactors, such as data quality and volume, on FL training performance and carbon\nemissions. Building on these insights, we introduce an interactive\nrecommendation system that optimizes FL configurations through data reduction,\nminimizing environmental impact during training. Applying this methodology to\ntime series classification has demonstrated promising results in reducing the\nenvironmental impact of FL tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u7eff\u8272\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u91cf\u548c\u9009\u62e9\u73af\u5883\u5f71\u54cd\u6700\u5c0f\u7684\u8282\u70b9\u6765\u964d\u4f4eAI/ML\u7684\u78b3\u6392\u653e\uff0c\u5e76\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u63a8\u8350\u7cfb\u7edf\u6765\u4f18\u5316\u8054\u90a6\u5b66\u4e60\u914d\u7f6e\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\u7684\u5e7f\u6cdb\u5e94\u7528\u5e26\u6765\u4e86\u663e\u8457\u7684\u73af\u5883\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u80fd\u8017\u548c\u78b3\u6392\u653e\u65b9\u9762\u3002\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5927\u5c0f\u662f\u5f71\u54cdML\u6a21\u578b\u8bad\u7ec3\u80fd\u8017\u7684\u5173\u952e\u56e0\u7d20\u4e4b\u4e00\u3002\u867d\u7136\u8054\u90a6\u5b66\u4e60\u80fd\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u6210\u672c\u5e76\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46\u4e5f\u56e0\u6570\u636e\u6e90\u5f02\u6784\u6027\u3001\u8ba1\u7b97\u8282\u70b9\u80fd\u529b\u5dee\u5f02\u548c\u73af\u5883\u5f71\u54cd\u800c\u5e26\u6765\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u7eff\u8272\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1\uff09\u5206\u6790\u8054\u90a6\u6570\u636e\u96c6\u7279\u5f81\uff1b2\uff09\u57fa\u4e8e\u8d28\u91cf\u6307\u6807\u9009\u62e9\u6700\u4f18\u6570\u636e\u5b50\u96c6\uff1b3\uff09\u9009\u62e9\u73af\u5883\u5f71\u54cd\u6700\u4f4e\u7684\u8054\u90a6\u8282\u70b9\uff1b4\uff09\u5f00\u53d1\u7efc\u5408\u65b9\u6cd5\u8bba\u6765\u7814\u7a76\u6570\u636e\u8d28\u91cf\u548c\u6570\u636e\u91cf\u7b49\u56e0\u7d20\u5bf9FL\u8bad\u7ec3\u6027\u80fd\u548c\u78b3\u6392\u653e\u7684\u5f71\u54cd\uff1b5\uff09\u6784\u5efa\u4ea4\u4e92\u5f0f\u63a8\u8350\u7cfb\u7edf\u4f18\u5316FL\u914d\u7f6e\u3002", "result": "\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\uff0c\u5728\u51cf\u5c11\u8054\u90a6\u5b66\u4e60\u4efb\u52a1\u73af\u5883\u5f71\u54cd\u65b9\u9762\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002\u901a\u8fc7\u6570\u636e\u51cf\u5c11\u5b9e\u73b0\u4e86FL\u914d\u7f6e\u7684\u4f18\u5316\uff0c\u6700\u5c0f\u5316\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u73af\u5883\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u6210\u529f\u63a8\u8fdb\u4e86\u7eff\u8272AI\u7684\u53d1\u5c55\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u4f18\u5316\u6570\u636e\u9009\u62e9\u548c\u8282\u70b9\u914d\u7f6e\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u8054\u90a6\u5b66\u4e60\u7684\u73af\u5883\u8db3\u8ff9\uff0c\u4e3a\u53ef\u6301\u7eed\u7684AI\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17245", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17245", "abs": "https://arxiv.org/abs/2507.17245", "authors": ["Haolin Jin", "Mengbai Xiao", "Yuan Yuan", "Xiao Zhang", "Dongxiao Yu", "Guanghui Zhang", "Haoliang Wang"], "title": "DistrAttention: An Efficient and Flexible Self-Attention Mechanism on Modern GPUs", "comment": null, "summary": "The Transformer architecture has revolutionized deep learning, delivering the\nstate-of-the-art performance in areas such as natural language processing,\ncomputer vision, and time series prediction. However, its core component,\nself-attention, has the quadratic time complexity relative to input sequence\nlength, which hinders the scalability of Transformers. The exsiting approaches\non optimizing self-attention either discard full-contextual information or lack\nof flexibility. In this work, we design DistrAttention, an effcient and\nflexible self-attention mechanism with the full context. DistrAttention\nachieves this by grouping data on the embedding dimensionality, usually\nreferred to as $d$. We realize DistrAttention with a lightweight sampling and\nfusion method that exploits locality-sensitive hashing to group similar data. A\nblock-wise grouping framework is further designed to limit the errors\nintroduced by locality sensitive hashing. By optimizing the selection of block\nsizes, DistrAttention could be easily integrated with FlashAttention-2, gaining\nhigh-performance on modern GPUs. We evaluate DistrAttention with extensive\nexperiments. The results show that our method is 37% faster than\nFlashAttention-2 on calculating self-attention. In ViT inference,\nDistrAttention is the fastest and the most accurate among approximate\nself-attention mechanisms. In Llama3-1B, DistrAttention still achieves the\nlowest inference time with only 1% accuray loss.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DistrAttention\uff0c\u4e00\u79cd\u9ad8\u6548\u7075\u6d3b\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u5728\u5d4c\u5165\u7ef4\u5ea6\u4e0a\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\u6765\u4fdd\u6301\u5b8c\u6574\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "Transformer\u67b6\u6784\u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5177\u6709\u76f8\u5bf9\u4e8e\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u7684\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u8fd9\u9650\u5236\u4e86Transformer\u7684\u53ef\u6269\u5c55\u6027\u3002\u73b0\u6709\u7684\u81ea\u6ce8\u610f\u529b\u4f18\u5316\u65b9\u6cd5\u8981\u4e48\u4e22\u5f03\u5b8c\u6574\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u8981\u4e48\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86DistrAttention\u673a\u5236\uff0c\u901a\u8fc7\u5728\u5d4c\u5165\u7ef4\u5ea6d\u4e0a\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\u6765\u5b9e\u73b0\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u81ea\u6ce8\u610f\u529b\u8ba1\u7b97\u3002\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7684\u91c7\u6837\u548c\u878d\u5408\u65b9\u6cd5\uff0c\u5229\u7528\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u6765\u5206\u7ec4\u76f8\u4f3c\u6570\u636e\u3002\u8fdb\u4e00\u6b65\u8bbe\u8ba1\u4e86\u5757\u72b6\u5206\u7ec4\u6846\u67b6\u6765\u9650\u5236\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u5f15\u5165\u7684\u8bef\u5dee\u3002\u901a\u8fc7\u4f18\u5316\u5757\u5927\u5c0f\u9009\u62e9\uff0cDistrAttention\u53ef\u4ee5\u8f7b\u677e\u4e0eFlashAttention-2\u96c6\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cDistrAttention\u5728\u8ba1\u7b97\u81ea\u6ce8\u610f\u529b\u65f6\u6bd4FlashAttention-2\u5feb37%\u3002\u5728ViT\u63a8\u7406\u4e2d\uff0cDistrAttention\u5728\u8fd1\u4f3c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u901f\u5ea6\u6700\u5feb\u4e14\u7cbe\u5ea6\u6700\u9ad8\u3002\u5728Llama3-1B\u6a21\u578b\u4e2d\uff0cDistrAttention\u5b9e\u73b0\u4e86\u6700\u4f4e\u7684\u63a8\u7406\u65f6\u95f4\uff0c\u51c6\u786e\u7387\u4ec5\u635f\u59311%\u3002", "conclusion": "DistrAttention\u6210\u529f\u89e3\u51b3\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5b8c\u6574\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u901f\u5ea6\uff0c\u4e3aTransformer\u67b6\u6784\u7684\u53ef\u6269\u5c55\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17255", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17255", "abs": "https://arxiv.org/abs/2507.17255", "authors": ["Songxuan Shi"], "title": "Rethinking VAE: From Continuous to Discrete Representations Without Probabilistic Assumptions", "comment": null, "summary": "This paper explores the generative capabilities of Autoencoders (AEs) and\nestablishes connections between Variational Autoencoders (VAEs) and Vector\nQuantized-Variational Autoencoders (VQ-VAEs) through a reformulated training\nframework. We demonstrate that AEs exhibit generative potential via latent\nspace interpolation and perturbation, albeit limited by undefined regions in\nthe encoding space. To address this, we propose a new VAE-like training method\nthat introduces clustering centers to enhance data compactness and ensure\nwell-defined latent spaces without relying on traditional KL divergence or\nreparameterization techniques. Experimental results on MNIST, CelebA, and\nFashionMNIST datasets show smooth interpolative transitions, though blurriness\npersists. Extending this approach to multiple learnable vectors, we observe a\nnatural progression toward a VQ-VAE-like model in continuous space. However,\nwhen the encoder outputs multiple vectors, the model degenerates into a\ndiscrete Autoencoder (VQ-AE), which combines image fragments without learning\nsemantic representations. Our findings highlight the critical role of encoding\nspace compactness and dispersion in generative modeling and provide insights\ninto the intrinsic connections between VAEs and VQ-VAEs, offering a new\nperspective on their design and limitations.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u81ea\u7f16\u7801\u5668\u7684\u751f\u6210\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684VAE\u8bad\u7ec3\u65b9\u6cd5\u6765\u89e3\u51b3\u7f16\u7801\u7a7a\u95f4\u672a\u5b9a\u4e49\u533a\u57df\u7684\u95ee\u9898\uff0c\u5e76\u5efa\u7acb\u4e86VAE\u548cVQ-VAE\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u53d1\u73b0\u7f16\u7801\u7a7a\u95f4\u7684\u7d27\u51d1\u6027\u548c\u5206\u6563\u6027\u5bf9\u751f\u6210\u5efa\u6a21\u81f3\u5173\u91cd\u8981", "motivation": "\u4f20\u7edf\u81ea\u7f16\u7801\u5668\u867d\u7136\u5177\u6709\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u63d2\u503c\u548c\u6270\u52a8\u8fdb\u884c\u751f\u6210\u7684\u6f5c\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u7f16\u7801\u7a7a\u95f4\u4e2d\u5b58\u5728\u672a\u5b9a\u4e49\u533a\u57df\u7684\u95ee\u9898\uff0c\u9700\u8981\u627e\u5230\u4e00\u79cd\u65b9\u6cd5\u6765\u786e\u4fdd\u6f5c\u5728\u7a7a\u95f4\u7684\u826f\u597d\u5b9a\u4e49\u5e76\u589e\u5f3a\u6570\u636e\u7d27\u51d1\u6027", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7c7bVAE\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5f15\u5165\u805a\u7c7b\u4e2d\u5fc3\u6765\u589e\u5f3a\u6570\u636e\u7d27\u51d1\u6027\u5e76\u786e\u4fdd\u6f5c\u5728\u7a7a\u95f4\u7684\u826f\u597d\u5b9a\u4e49\uff0c\u4e0d\u4f9d\u8d56\u4f20\u7edf\u7684KL\u6563\u5ea6\u6216\u91cd\u53c2\u6570\u5316\u6280\u672f\u3002\u5c06\u6b64\u65b9\u6cd5\u6269\u5c55\u5230\u591a\u4e2a\u53ef\u5b66\u4e60\u5411\u91cf\uff0c\u89c2\u5bdf\u5411VQ-VAE\u6a21\u578b\u7684\u81ea\u7136\u6f14\u8fdb", "result": "\u5728MNIST\u3001CelebA\u548cFashionMNIST\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e86\u5e73\u6ed1\u7684\u63d2\u503c\u8fc7\u6e21\uff0c\u4f46\u4ecd\u5b58\u5728\u6a21\u7cca\u6027\u95ee\u9898\u3002\u5f53\u7f16\u7801\u5668\u8f93\u51fa\u591a\u4e2a\u5411\u91cf\u65f6\uff0c\u6a21\u578b\u9000\u5316\u4e3a\u79bb\u6563\u81ea\u7f16\u7801\u5668(VQ-AE)\uff0c\u53ea\u80fd\u7ec4\u5408\u56fe\u50cf\u7247\u6bb5\u800c\u65e0\u6cd5\u5b66\u4e60\u8bed\u4e49\u8868\u793a", "conclusion": "\u7814\u7a76\u7a81\u51fa\u4e86\u7f16\u7801\u7a7a\u95f4\u7d27\u51d1\u6027\u548c\u5206\u6563\u6027\u5728\u751f\u6210\u5efa\u6a21\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u63d0\u4f9b\u4e86\u5bf9VAE\u548cVQ-VAE\u5185\u5728\u8054\u7cfb\u7684\u65b0\u89c1\u89e3\uff0c\u4e3a\u5b83\u4eec\u7684\u8bbe\u8ba1\u548c\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2"}}
{"id": "2507.17273", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17273", "abs": "https://arxiv.org/abs/2507.17273", "authors": ["Rishi Parekh", "Saisubramaniam Gopalakrishnan", "Zishan Ahmad", "Anirudh Deodhar"], "title": "Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational Bottlenecks for Warehouse Planning Assistance", "comment": "12 pages, 2 figures", "summary": "Analyzing large, complex output datasets from Discrete Event Simulations\n(DES) of warehouse operations to identify bottlenecks and inefficiencies is a\ncritical yet challenging task, often demanding significant manual effort or\nspecialized analytical tools. Our framework integrates Knowledge Graphs (KGs)\nand Large Language Model (LLM)-based agents to analyze complex Discrete Event\nSimulation (DES) output data from warehouse operations. It transforms raw DES\ndata into a semantically rich KG, capturing relationships between simulation\nevents and entities. An LLM-based agent uses iterative reasoning, generating\ninterdependent sub-questions. For each sub-question, it creates Cypher queries\nfor KG interaction, extracts information, and self-reflects to correct errors.\nThis adaptive, iterative, and self-correcting process identifies operational\nissues mimicking human analysis. Our DES approach for warehouse bottleneck\nidentification, tested with equipment breakdowns and process irregularities,\noutperforms baseline methods. For operational questions, it achieves\nnear-perfect pass rates in pinpointing inefficiencies. For complex\ninvestigative questions, we demonstrate its superior diagnostic ability to\nuncover subtle, interconnected issues. This work bridges simulation modeling\nand AI (KG+LLM), offering a more intuitive method for actionable insights,\nreducing time-to-insight, and enabling automated warehouse inefficiency\nevaluation and diagnosis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u4ed3\u5e93\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\u6570\u636e\uff0c\u81ea\u52a8\u8bc6\u522b\u74f6\u9888\u548c\u4f4e\u6548\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u6790\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5206\u6790\u4ed3\u5e93\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\u7684\u5927\u578b\u590d\u6742\u8f93\u51fa\u6570\u636e\u96c6\u4ee5\u8bc6\u522b\u74f6\u9888\u548c\u4f4e\u6548\u95ee\u9898\u662f\u4e00\u9879\u5173\u952e\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u901a\u5e38\u9700\u8981\u5927\u91cf\u624b\u5de5\u5de5\u4f5c\u6216\u4e13\u4e1a\u5206\u6790\u5de5\u5177\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u76f4\u89c2\u3001\u81ea\u52a8\u5316\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u96c6\u6210\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u6846\u67b6\uff1a1\uff09\u5c06\u539f\u59cbDES\u6570\u636e\u8f6c\u6362\u4e3a\u8bed\u4e49\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u6355\u83b7\u4eff\u771f\u4e8b\u4ef6\u548c\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\uff1b2\uff09LLM\u4ee3\u7406\u4f7f\u7528\u8fed\u4ee3\u63a8\u7406\u751f\u6210\u76f8\u4e92\u4f9d\u8d56\u7684\u5b50\u95ee\u9898\uff1b3\uff09\u4e3a\u6bcf\u4e2a\u5b50\u95ee\u9898\u521b\u5efaCypher\u67e5\u8be2\u4e0e\u77e5\u8bc6\u56fe\u8c31\u4ea4\u4e92\uff1b4\uff09\u63d0\u53d6\u4fe1\u606f\u5e76\u8fdb\u884c\u81ea\u6211\u53cd\u601d\u7ea0\u9519\uff0c\u5f62\u6210\u81ea\u9002\u5e94\u3001\u8fed\u4ee3\u548c\u81ea\u7ea0\u9519\u7684\u5206\u6790\u8fc7\u7a0b\u3002", "result": "\u5728\u8bbe\u5907\u6545\u969c\u548c\u6d41\u7a0b\u5f02\u5e38\u7684\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4ed3\u5e93\u74f6\u9888\u8bc6\u522b\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002\u5bf9\u4e8e\u64cd\u4f5c\u6027\u95ee\u9898\uff0c\u5728\u5b9a\u4f4d\u4f4e\u6548\u95ee\u9898\u65b9\u9762\u8fbe\u5230\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u901a\u8fc7\u7387\u3002\u5bf9\u4e8e\u590d\u6742\u7684\u8c03\u67e5\u6027\u95ee\u9898\uff0c\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u8bca\u65ad\u80fd\u529b\uff0c\u80fd\u591f\u53d1\u73b0\u5fae\u5999\u7684\u3001\u76f8\u4e92\u5173\u8054\u7684\u95ee\u9898\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c06\u4eff\u771f\u5efa\u6a21\u4e0e\u4eba\u5de5\u667a\u80fd\uff08\u77e5\u8bc6\u56fe\u8c31+\u5927\u8bed\u8a00\u6a21\u578b\uff09\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u76f4\u89c2\u7684\u65b9\u6cd5\u6765\u83b7\u5f97\u53ef\u884c\u7684\u6d1e\u5bdf\uff0c\u51cf\u5c11\u4e86\u6d1e\u5bdf\u65f6\u95f4\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u7684\u4ed3\u5e93\u4f4e\u6548\u8bc4\u4f30\u548c\u8bca\u65ad\u3002"}}
{"id": "2507.17285", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17285", "abs": "https://arxiv.org/abs/2507.17285", "authors": ["Aritz P\u00e9rez", "Carlos Echegoyen", "Guzm\u00e1n Santaf\u00e9"], "title": "Decentralized Federated Learning of Probabilistic Generative Classifiers", "comment": null, "summary": "Federated learning is a paradigm of increasing relevance in real world\napplications, aimed at building a global model across a network of\nheterogeneous users without requiring the sharing of private data. We focus on\nmodel learning over decentralized architectures, where users collaborate\ndirectly to update the global model without relying on a central server. In\nthis context, the current paper proposes a novel approach to collaboratively\nlearn probabilistic generative classifiers with a parametric form. The\nframework is composed by a communication network over a set of local nodes,\neach of one having its own local data, and a local updating rule. The proposal\ninvolves sharing local statistics with neighboring nodes, where each node\naggregates the neighbors' information and iteratively learns its own local\nclassifier, which progressively converges to a global model. Extensive\nexperiments demonstrate that the algorithm consistently converges to a globally\ncompetitive model across a wide range of network topologies, network sizes,\nlocal dataset sizes, and extreme non-i.i.d. data distributions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8282\u70b9\u95f4\u5171\u4eab\u5c40\u90e8\u7edf\u8ba1\u4fe1\u606f\u6765\u534f\u4f5c\u5b66\u4e60\u6982\u7387\u751f\u6210\u5206\u7c7b\u5668\uff0c\u65e0\u9700\u4e2d\u592e\u670d\u52a1\u5668\u5373\u53ef\u6536\u655b\u5230\u5168\u5c40\u7ade\u4e89\u6027\u6a21\u578b", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u4e3b\u8981\u4f9d\u8d56\u4e2d\u592e\u670d\u52a1\u5668\uff0c\u800c\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\u53ef\u4ee5\u8ba9\u7528\u6237\u76f4\u63a5\u534f\u4f5c\u66f4\u65b0\u5168\u5c40\u6a21\u578b\uff0c\u907f\u514d\u4e2d\u592e\u670d\u52a1\u5668\u4f9d\u8d56\uff0c\u540c\u65f6\u4fdd\u62a4\u79c1\u6709\u6570\u636e\u4e0d\u88ab\u5171\u4eab", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u901a\u4fe1\u7f51\u7edc\u6846\u67b6\uff0c\u5176\u4e2d\u6bcf\u4e2a\u672c\u5730\u8282\u70b9\u62e5\u6709\u81ea\u5df1\u7684\u6570\u636e\uff0c\u901a\u8fc7\u4e0e\u90bb\u5c45\u8282\u70b9\u5171\u4eab\u5c40\u90e8\u7edf\u8ba1\u4fe1\u606f\uff0c\u5404\u8282\u70b9\u805a\u5408\u90bb\u5c45\u4fe1\u606f\u5e76\u8fed\u4ee3\u5b66\u4e60\u81ea\u5df1\u7684\u5c40\u90e8\u5206\u7c7b\u5668\uff0c\u6700\u7ec8\u6536\u655b\u5230\u5168\u5c40\u6a21\u578b", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u5404\u79cd\u7f51\u7edc\u62d3\u6251\u3001\u7f51\u7edc\u89c4\u6a21\u3001\u672c\u5730\u6570\u636e\u96c6\u5927\u5c0f\u4ee5\u53ca\u6781\u7aef\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5206\u5e03\u4e0b\u90fd\u80fd\u4e00\u81f4\u6536\u655b\u5230\u5168\u5c40\u7ade\u4e89\u6027\u6a21\u578b", "conclusion": "\u63d0\u51fa\u7684\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5728\u5f02\u6784\u7528\u6237\u7f51\u7edc\u4e2d\u5b66\u4e60\u6982\u7387\u751f\u6210\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u5c40\u90e8\u7edf\u8ba1\u4fe1\u606f\u5171\u4eab\u5b9e\u73b0\u5168\u5c40\u6a21\u578b\u6536\u655b\uff0c\u5728\u591a\u79cd\u5b9e\u9a8c\u6761\u4ef6\u4e0b\u8868\u73b0\u7a33\u5b9a"}}
{"id": "2507.17307", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17307", "abs": "https://arxiv.org/abs/2507.17307", "authors": ["Zhuokun Chen", "Zeren Chen", "Jiahao He", "Mingkui Tan", "Jianfei Cai", "Bohan Zhuang"], "title": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning", "comment": null, "summary": "Chain-of-thought (CoT) reasoning enhances the problem-solving capabilities of\nlarge language models by encouraging step-by-step intermediate reasoning during\ninference. While effective, CoT introduces substantial computational overhead\ndue to its reliance on autoregressive decoding over long token sequences.\nExisting acceleration strategies either reduce sequence length through early\nstopping or compressive reward designs, or improve decoding speed via\nspeculative decoding with smaller models. However, speculative decoding suffers\nfrom limited speedup when the agreement between small and large models is low,\nand fails to exploit the potential advantages of small models in producing\nconcise intermediate reasoning. In this paper, we present R-Stitch, a\ntoken-level, confidence-based hybrid decoding framework that accelerates CoT\ninference by switching between a small language model (SLM) and a large\nlanguage model (LLM) along the reasoning trajectory. R-Stitch uses the SLM to\ngenerate tokens by default and delegates to the LLM only when the SLM's\nconfidence falls below a threshold. This design avoids full-sequence rollback\nand selectively invokes the LLM on uncertain steps, preserving both efficiency\nand answer quality. R-Stitch is model-agnostic, training-free, and compatible\nwith standard decoding pipelines. Experiments on math reasoning benchmarks\ndemonstrate that R-Stitch achieves up to 85\\% reduction in inference latency\nwith negligible accuracy drop, highlighting its practical effectiveness in\naccelerating CoT reasoning.", "AI": {"tldr": "R-Stitch\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u6df7\u5408\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u5c0f\u6a21\u578b\u548c\u5927\u6a21\u578b\u4e4b\u95f4\u667a\u80fd\u5207\u6362\u6765\u52a0\u901f\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0\u6700\u9ad885%\u7684\u63a8\u7406\u5ef6\u8fdf\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u601d\u7ef4\u94fe\u63a8\u7406\u867d\u7136\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4f46\u7531\u4e8e\u9700\u8981\u81ea\u56de\u5f52\u89e3\u7801\u957f\u5e8f\u5217\u800c\u5e26\u6765\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u73b0\u6709\u52a0\u901f\u7b56\u7565\u5b58\u5728\u5c40\u9650\u6027\uff1a\u63a8\u6d4b\u89e3\u7801\u5728\u5927\u5c0f\u6a21\u578b\u4e00\u81f4\u6027\u4f4e\u65f6\u52a0\u901f\u6709\u9650\uff0c\u4e14\u672a\u80fd\u5145\u5206\u5229\u7528\u5c0f\u6a21\u578b\u751f\u6210\u7b80\u6d01\u4e2d\u95f4\u63a8\u7406\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51faR-Stitch\uff0c\u4e00\u4e2atoken\u7ea7\u522b\u3001\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u6df7\u5408\u89e3\u7801\u6846\u67b6\u3002\u9ed8\u8ba4\u4f7f\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\u751f\u6210tokens\uff0c\u4ec5\u5f53\u5c0f\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4f4e\u4e8e\u9608\u503c\u65f6\u624d\u5207\u6362\u5230\u5927\u8bed\u8a00\u6a21\u578b\u3002\u8be5\u8bbe\u8ba1\u907f\u514d\u4e86\u5168\u5e8f\u5217\u56de\u6eda\uff0c\u9009\u62e9\u6027\u5730\u5728\u4e0d\u786e\u5b9a\u6b65\u9aa4\u8c03\u7528\u5927\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u6548\u7387\u548c\u7b54\u6848\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u4e0e\u6a21\u578b\u65e0\u5173\u3001\u65e0\u9700\u8bad\u7ec3\u3001\u517c\u5bb9\u6807\u51c6\u89e3\u7801\u7ba1\u9053\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cR-Stitch\u5b9e\u73b0\u4e86\u6700\u9ad885%\u7684\u63a8\u7406\u5ef6\u8fdf\u51cf\u5c11\uff0c\u540c\u65f6\u51c6\u786e\u6027\u4e0b\u964d\u5fae\u4e4e\u5176\u5fae\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u52a0\u901f\u601d\u7ef4\u94fe\u63a8\u7406\u65b9\u9762\u7684\u5b9e\u7528\u6709\u6548\u6027\u3002", "conclusion": "R-Stitch\u901a\u8fc7\u667a\u80fd\u7684\u5927\u5c0f\u6a21\u578b\u5207\u6362\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u63a8\u7406\u65f6\u95f4\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u52a0\u901f\u65b9\u6848\u3002"}}
{"id": "2507.17309", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17309", "abs": "https://arxiv.org/abs/2507.17309", "authors": ["Yan Zeng", "Shenglan Nie", "Feng Xie", "Libo Huang", "Peng Wu", "Zhi Geng"], "title": "Confounded Causal Imitation Learning with Instrumental Variables", "comment": "12 pages, 6 figures", "summary": "Imitation learning from demonstrations usually suffers from the confounding\neffects of unmeasured variables (i.e., unmeasured confounders) on the states\nand actions. If ignoring them, a biased estimation of the policy would be\nentailed. To break up this confounding gap, in this paper, we take the best of\nthe strong power of instrumental variables (IV) and propose a Confounded Causal\nImitation Learning (C2L) model. This model accommodates confounders that\ninfluence actions across multiple timesteps, rather than being restricted to\nimmediate temporal dependencies. We develop a two-stage imitation learning\nframework for valid IV identification and policy optimization. In particular,\nin the first stage, we construct a testing criterion based on the defined\npseudo-variable, with which we achieve identifying a valid IV for the C2L\nmodels. Such a criterion entails the sufficient and necessary identifiability\nconditions for IV validity. In the second stage, with the identified IV, we\npropose two candidate policy learning approaches: one is based on a simulator,\nwhile the other is offline. Extensive experiments verified the effectiveness of\nidentifying the valid IV as well as learning the policy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6df7\u6dc6\u56e0\u679c\u6a21\u4eff\u5b66\u4e60(C2L)\u6a21\u578b\uff0c\u901a\u8fc7\u5de5\u5177\u53d8\u91cf\u65b9\u6cd5\u89e3\u51b3\u6a21\u4eff\u5b66\u4e60\u4e2d\u672a\u6d4b\u91cf\u6df7\u6dc6\u53d8\u91cf\u5bfc\u81f4\u7684\u504f\u5dee\u95ee\u9898\uff0c\u5305\u542b\u4e24\u9636\u6bb5\u6846\u67b6\uff1aIV\u8bc6\u522b\u548c\u7b56\u7565\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u6a21\u4eff\u5b66\u4e60\u53d7\u5230\u672a\u6d4b\u91cf\u6df7\u6dc6\u53d8\u91cf\u7684\u5f71\u54cd\uff0c\u8fd9\u4e9b\u53d8\u91cf\u4f1a\u5bf9\u72b6\u6001\u548c\u52a8\u4f5c\u4ea7\u751f\u6df7\u6dc6\u6548\u5e94\uff0c\u5982\u679c\u5ffd\u7565\u5b83\u4eec\u4f1a\u5bfc\u81f4\u7b56\u7565\u4f30\u8ba1\u51fa\u73b0\u504f\u5dee\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8de8\u591a\u4e2a\u65f6\u95f4\u6b65\u5f71\u54cd\u52a8\u4f5c\u7684\u6df7\u6dc6\u56e0\u5b50\u3002", "method": "\u63d0\u51fa\u6df7\u6dc6\u56e0\u679c\u6a21\u4eff\u5b66\u4e60(C2L)\u6a21\u578b\uff0c\u7ed3\u5408\u5de5\u5177\u53d8\u91cf(IV)\u7684\u5f3a\u5927\u80fd\u529b\u3002\u5f00\u53d1\u4e86\u4e24\u9636\u6bb5\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u57fa\u4e8e\u5b9a\u4e49\u7684\u4f2a\u53d8\u91cf\u6784\u5efa\u6d4b\u8bd5\u51c6\u5219\u6765\u8bc6\u522b\u6709\u6548\u7684\u5de5\u5177\u53d8\u91cf\uff0c\u8be5\u51c6\u5219\u5305\u542bIV\u6709\u6548\u6027\u7684\u5145\u5206\u5fc5\u8981\u53ef\u8bc6\u522b\u6761\u4ef6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u8bc6\u522b\u51fa\u7684IV\u63d0\u51fa\u4e24\u79cd\u5019\u9009\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e00\u79cd\u57fa\u4e8e\u6a21\u62df\u5668\uff0c\u53e6\u4e00\u79cd\u662f\u79bb\u7ebf\u65b9\u6cd5\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bc6\u522b\u6709\u6548\u5de5\u5177\u53d8\u91cf\u4ee5\u53ca\u5b66\u4e60\u7b56\u7565\u7684\u6709\u6548\u6027\u3002C2L\u6a21\u578b\u80fd\u591f\u5904\u7406\u5f71\u54cd\u591a\u4e2a\u65f6\u95f4\u6b65\u52a8\u4f5c\u7684\u6df7\u6dc6\u56e0\u5b50\uff0c\u800c\u4e0d\u4ec5\u9650\u4e8e\u5373\u65f6\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u89e3\u51b3\u4e86\u6a21\u4eff\u5b66\u4e60\u4e2d\u672a\u6d4b\u91cf\u6df7\u6dc6\u53d8\u91cf\u5bfc\u81f4\u7684\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u5de5\u5177\u53d8\u91cf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u7b56\u7565\u5b66\u4e60\u3002\u4e24\u9636\u6bb5\u6846\u67b6\u4e3a\u5904\u7406\u590d\u6742\u65f6\u95f4\u4f9d\u8d56\u7684\u6df7\u6dc6\u56e0\u5b50\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17311", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2507.17311", "abs": "https://arxiv.org/abs/2507.17311", "authors": ["Zijie Guo", "Jiong Wang", "Xiaoyu Yue", "Wangxu Wei", "Zhe Jiang", "Wanghan Xu", "Ben Fei", "Wenlong Zhang", "Xinyu Gu", "Lijing Cheng", "Jing-Jia Luo", "Chao Li", "Yaqiang Wang", "Tao Chen", "Wanli Ouyang", "Fenghua Ling", "Lei Bai"], "title": "EarthLink: Interpreting Climate Signals with Self-Evolving AI Agents", "comment": null, "summary": "Modern Earth science is at an inflection point. The vast, fragmented, and\ncomplex nature of Earth system data, coupled with increasingly sophisticated\nanalytical demands, creates a significant bottleneck for rapid scientific\ndiscovery. Here we introduce EarthLink, the first AI agent designed as an\ninteractive copilot for Earth scientists. It automates the end-to-end research\nworkflow, from planning and code generation to multi-scenario analysis. Unlike\nstatic diagnostic tools, EarthLink can learn from user interaction,\ncontinuously refining its capabilities through a dynamic feedback loop. We\nvalidated its performance on a number of core scientific tasks of climate\nchange, ranging from model-observation comparisons to the diagnosis of complex\nphenomena. In a multi-expert evaluation, EarthLink produced scientifically\nsound analyses and demonstrated an analytical competency that was rated as\ncomparable to specific aspects of a human junior researcher's workflow.\nAdditionally, its transparent, auditable workflows and natural language\ninterface empower scientists to shift from laborious manual execution to\nstrategic oversight and hypothesis generation. EarthLink marks a pivotal step\ntowards an efficient, trustworthy, and collaborative paradigm for Earth system\nresearch in an era of accelerating global change.", "AI": {"tldr": "EarthLink\u662f\u9996\u4e2a\u4e13\u4e3a\u5730\u7403\u79d1\u5b66\u5bb6\u8bbe\u8ba1\u7684AI\u667a\u80fd\u52a9\u624b\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u5b8c\u6210\u4ece\u89c4\u5212\u5230\u5206\u6790\u7684\u7aef\u5230\u7aef\u7814\u7a76\u6d41\u7a0b\uff0c\u901a\u8fc7\u52a8\u6001\u53cd\u9988\u5faa\u73af\u6301\u7eed\u5b66\u4e60\uff0c\u5728\u6c14\u5019\u53d8\u5316\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e0e\u521d\u7ea7\u7814\u7a76\u5458\u76f8\u5f53\u7684\u5206\u6790\u80fd\u529b\u3002", "motivation": "\u73b0\u4ee3\u5730\u7403\u79d1\u5b66\u9762\u4e34\u74f6\u9888\uff1a\u5730\u7403\u7cfb\u7edf\u6570\u636e\u5e9e\u5927\u3001\u5206\u6563\u4e14\u590d\u6742\uff0c\u52a0\u4e0a\u65e5\u76ca\u590d\u6742\u7684\u5206\u6790\u9700\u6c42\uff0c\u4e25\u91cd\u963b\u788d\u4e86\u5feb\u901f\u79d1\u5b66\u53d1\u73b0\u7684\u8fdb\u7a0b\u3002", "method": "\u5f00\u53d1\u4e86EarthLink AI\u667a\u80fd\u4f53\uff0c\u4f5c\u4e3a\u5730\u7403\u79d1\u5b66\u5bb6\u7684\u4ea4\u4e92\u5f0f\u526f\u9a7e\u9a76\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u7aef\u5230\u7aef\u7814\u7a76\u5de5\u4f5c\u6d41\u7a0b\uff08\u5305\u62ec\u89c4\u5212\u3001\u4ee3\u7801\u751f\u6210\u3001\u591a\u573a\u666f\u5206\u6790\uff09\uff0c\u5177\u5907\u4ece\u7528\u6237\u4ea4\u4e92\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u52a8\u6001\u53cd\u9988\u5faa\u73af\u6301\u7eed\u6539\u8fdb\u3002", "result": "\u5728\u6c14\u5019\u53d8\u5316\u6838\u5fc3\u79d1\u5b66\u4efb\u52a1\uff08\u4ece\u6a21\u578b-\u89c2\u6d4b\u6bd4\u8f83\u5230\u590d\u6742\u73b0\u8c61\u8bca\u65ad\uff09\u4e0a\u9a8c\u8bc1\u4e86\u6027\u80fd\u3002\u591a\u4e13\u5bb6\u8bc4\u4f30\u663e\u793aEarthLink\u4ea7\u751f\u4e86\u79d1\u5b66\u5408\u7406\u7684\u5206\u6790\u7ed3\u679c\uff0c\u5206\u6790\u80fd\u529b\u5728\u7279\u5b9a\u65b9\u9762\u53ef\u4e0e\u4eba\u7c7b\u521d\u7ea7\u7814\u7a76\u5458\u7684\u5de5\u4f5c\u6d41\u7a0b\u76f8\u5ab2\u7f8e\u3002", "conclusion": "EarthLink\u6807\u5fd7\u7740\u5730\u7403\u7cfb\u7edf\u7814\u7a76\u5411\u9ad8\u6548\u3001\u53ef\u4fe1\u3001\u534f\u4f5c\u8303\u5f0f\u8fc8\u51fa\u7684\u5173\u952e\u4e00\u6b65\uff0c\u5176\u900f\u660e\u53ef\u5ba1\u8ba1\u7684\u5de5\u4f5c\u6d41\u7a0b\u548c\u81ea\u7136\u8bed\u8a00\u754c\u9762\u4f7f\u79d1\u5b66\u5bb6\u80fd\u591f\u4ece\u7e41\u91cd\u7684\u624b\u52a8\u6267\u884c\u8f6c\u5411\u6218\u7565\u76d1\u7763\u548c\u5047\u8bbe\u751f\u6210\uff0c\u9002\u5e94\u5168\u7403\u53d8\u5316\u52a0\u901f\u7684\u65f6\u4ee3\u9700\u6c42\u3002"}}
{"id": "2507.17328", "categories": ["cs.LG", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2507.17328", "abs": "https://arxiv.org/abs/2507.17328", "authors": ["Rui Wu", "Nikola Kovachki", "Burigede Liu"], "title": "A Learning-based Domain Decomposition Method", "comment": null, "summary": "Recent developments in mechanical, aerospace, and structural engineering have\ndriven a growing need for efficient ways to model and analyse structures at\nmuch larger and more complex scales than before. While established numerical\nmethods like the Finite Element Method remain reliable, they often struggle\nwith computational cost and scalability when dealing with large and\ngeometrically intricate problems. In recent years, neural network-based methods\nhave shown promise because of their ability to efficiently approximate\nnonlinear mappings. However, most existing neural approaches are still largely\nlimited to simple domains, which makes it difficult to apply to real-world PDEs\ninvolving complex geometries. In this paper, we propose a learning-based domain\ndecomposition method (L-DDM) that addresses this gap. Our approach uses a\nsingle, pre-trained neural operator-originally trained on simple domains-as a\nsurrogate model within a domain decomposition scheme, allowing us to tackle\nlarge and complicated domains efficiently. We provide a general theoretical\nresult on the existence of neural operator approximations in the context of\ndomain decomposition solution of abstract PDEs. We then demonstrate our method\nby accurately approximating solutions to elliptic PDEs with discontinuous\nmicrostructures in complex geometries, using a physics-pretrained neural\noperator (PPNO). Our results show that this approach not only outperforms\ncurrent state-of-the-art methods on these challenging problems, but also offers\nresolution-invariance and strong generalization to microstructural patterns\nunseen during training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u57df\u5206\u89e3\u65b9\u6cd5(L-DDM)\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u795e\u7ecf\u7b97\u5b50\u5728\u57df\u5206\u89e3\u6846\u67b6\u5185\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u590d\u6742\u51e0\u4f55\u5f62\u72b6\u7684\u5927\u89c4\u6a21PDE\u95ee\u9898\uff0c\u5728\u692d\u5706PDE\u6c42\u89e3\u4e2d\u5c55\u73b0\u51fa\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5982\u6709\u9650\u5143\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u590d\u6742\u51e0\u4f55\u95ee\u9898\u65f6\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u800c\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u7b80\u5355\u57df\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u6d89\u53ca\u590d\u6742\u51e0\u4f55\u7684\u5b9e\u9645PDE\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u57df\u5206\u89e3\u65b9\u6cd5(L-DDM)\uff0c\u5728\u57df\u5206\u89e3\u65b9\u6848\u4e2d\u4f7f\u7528\u5355\u4e2a\u9884\u8bad\u7ec3\u795e\u7ecf\u7b97\u5b50\uff08\u539f\u672c\u5728\u7b80\u5355\u57df\u4e0a\u8bad\u7ec3\uff09\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\uff0c\u7ed3\u5408\u7269\u7406\u9884\u8bad\u7ec3\u795e\u7ecf\u7b97\u5b50(PPNO)\u6765\u5904\u7406\u590d\u6742\u57df\u7684PDE\u6c42\u89e3\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5177\u6709\u4e0d\u8fde\u7eed\u5fae\u7ed3\u6784\u7684\u590d\u6742\u51e0\u4f55\u692d\u5706PDE\u95ee\u9898\u4e0a\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u5177\u6709\u5206\u8fa8\u7387\u4e0d\u53d8\u6027\u548c\u5bf9\u8bad\u7ec3\u65f6\u672a\u89c1\u5fae\u7ed3\u6784\u6a21\u5f0f\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "L-DDM\u65b9\u6cd5\u6210\u529f\u5f25\u5408\u4e86\u7b80\u5355\u57df\u8bad\u7ec3\u7684\u795e\u7ecf\u7b97\u5b50\u4e0e\u590d\u6742\u51e0\u4f55\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5927\u89c4\u6a21\u590d\u6742PDE\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17346", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17346", "abs": "https://arxiv.org/abs/2507.17346", "authors": ["Rongwei Lu", "Jingyan Jiang", "Chunyang Li", "Haotian Dong", "Xingguang Wei", "Delin Cai", "Zhi Wang"], "title": "DeCo-SGD: Joint Optimization of Delay Staleness and Gradient Compression Ratio for Distributed SGD", "comment": null, "summary": "Distributed machine learning in high end-to-end latency and low, varying\nbandwidth network environments undergoes severe throughput degradation. Due to\nits low communication requirements, distributed SGD (D-SGD) remains the\nmainstream optimizer in such challenging networks, but it still suffers from\nsignificant throughput reduction. To mitigate these limitations, existing\napproaches typically employ gradient compression and delayed aggregation to\nalleviate low bandwidth and high latency, respectively. To address both\nchallenges simultaneously, these strategies are often combined, introducing a\ncomplex three-way trade-off among compression ratio, staleness (delayed\nsynchronization steps), and model convergence rate. To achieve the balance\nunder varying bandwidth conditions, an adaptive policy is required to\ndynamically adjust these parameters. Unfortunately, existing works rely on\nstatic heuristic strategies due to the lack of theoretical guidance, which\nprevents them from achieving this goal. This study fills in this theoretical\ngap by introducing a new theoretical tool, decomposing the joint optimization\nproblem into a traditional convergence rate analysis with multiple analyzable\nnoise terms. We are the first to reveal that staleness exponentially amplifies\nthe negative impact of gradient compression on training performance, filling a\ncritical gap in understanding how compressed and delayed gradients affect\ntraining. Furthermore, by integrating the convergence rate with a network-aware\ntime minimization condition, we propose DeCo-SGD, which dynamically adjusts the\ncompression ratio and staleness based on the real-time network condition and\ntraining task. DeCo-SGD achieves up to 5.07 and 1.37 speed-ups over D-SGD and\nstatic strategy in high-latency and low, varying bandwidth networks,\nrespectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDeCo-SGD\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u68af\u5ea6\u538b\u7f29\u6bd4\u548c\u5ef6\u8fdf\u540c\u6b65\u6b65\u6570\u6765\u89e3\u51b3\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5728\u9ad8\u5ef6\u8fdf\u3001\u4f4e\u5e26\u5bbd\u7f51\u7edc\u73af\u5883\u4e0b\u7684\u541e\u5410\u91cf\u4e0b\u964d\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u9ad85.07\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5728\u9ad8\u5ef6\u8fdf\u3001\u4f4e\u53d8\u5316\u5e26\u5bbd\u7684\u7f51\u7edc\u73af\u5883\u4e2d\u9762\u4e34\u4e25\u91cd\u7684\u541e\u5410\u91cf\u4e0b\u964d\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u7ed3\u5408\u68af\u5ea6\u538b\u7f29\u548c\u5ef6\u8fdf\u805a\u5408\u6765\u89e3\u51b3\u4f4e\u5e26\u5bbd\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u4f46\u8fd9\u5f15\u5165\u4e86\u538b\u7f29\u6bd4\u3001\u5ef6\u8fdf\u6b65\u6570\u548c\u6a21\u578b\u6536\u655b\u7387\u4e4b\u95f4\u590d\u6742\u7684\u4e09\u65b9\u6743\u8861\u3002\u7531\u4e8e\u7f3a\u4e4f\u7406\u8bba\u6307\u5bfc\uff0c\u73b0\u6709\u5de5\u4f5c\u4f9d\u8d56\u9759\u6001\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u65e0\u6cd5\u5728\u53d8\u5316\u7684\u5e26\u5bbd\u6761\u4ef6\u4e0b\u5b9e\u73b0\u52a8\u6001\u5e73\u8861\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u7406\u8bba\u5de5\u5177\uff0c\u5c06\u8054\u5408\u4f18\u5316\u95ee\u9898\u5206\u89e3\u4e3a\u4f20\u7edf\u6536\u655b\u7387\u5206\u6790\u4e0e\u591a\u4e2a\u53ef\u5206\u6790\u566a\u58f0\u9879\u3002\u9996\u6b21\u63ed\u793a\u4e86\u5ef6\u8fdf\u4f1a\u6307\u6570\u7ea7\u653e\u5927\u68af\u5ea6\u538b\u7f29\u5bf9\u8bad\u7ec3\u6027\u80fd\u7684\u8d1f\u9762\u5f71\u54cd\u3002\u901a\u8fc7\u5c06\u6536\u655b\u7387\u4e0e\u7f51\u7edc\u611f\u77e5\u7684\u65f6\u95f4\u6700\u5c0f\u5316\u6761\u4ef6\u76f8\u7ed3\u5408\uff0c\u63d0\u51faDeCo-SGD\u7b97\u6cd5\uff0c\u6839\u636e\u5b9e\u65f6\u7f51\u7edc\u6761\u4ef6\u548c\u8bad\u7ec3\u4efb\u52a1\u52a8\u6001\u8c03\u6574\u538b\u7f29\u6bd4\u548c\u5ef6\u8fdf\u6b65\u6570\u3002", "result": "DeCo-SGD\u5728\u9ad8\u5ef6\u8fdf\u3001\u4f4e\u53d8\u5316\u5e26\u5bbd\u7f51\u7edc\u4e2d\u76f8\u6bd4\u5206\u5e03\u5f0fSGD\u5b9e\u73b0\u4e865.07\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u76f8\u6bd4\u9759\u6001\u7b56\u7565\u5b9e\u73b0\u4e861.37\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u53d8\u5316\u7684\u7f51\u7edc\u6761\u4ef6\u4e0b\u52a8\u6001\u9002\u5e94\u5e76\u4f18\u5316\u8bad\u7ec3\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86\u538b\u7f29\u548c\u5ef6\u8fdf\u68af\u5ea6\u5bf9\u8bad\u7ec3\u5f71\u54cd\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u9996\u6b21\u63ed\u793a\u4e86\u5ef6\u8fdf\u5bf9\u68af\u5ea6\u538b\u7f29\u8d1f\u9762\u5f71\u54cd\u7684\u6307\u6570\u7ea7\u653e\u5927\u6548\u5e94\u3002\u63d0\u51fa\u7684DeCo-SGD\u7b97\u6cd5\u901a\u8fc7\u7406\u8bba\u6307\u5bfc\u7684\u52a8\u6001\u53c2\u6570\u8c03\u6574\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5728\u6311\u6218\u6027\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17348", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17348", "abs": "https://arxiv.org/abs/2507.17348", "authors": ["Rafael Ayll\u00f3n-Gavil\u00e1n", "David Guijo-Rubio", "Antonio Manuel G\u00f3mez-Orellana", "David Guijo-Rubio", "Francisco B\u00e9rchez-Moreno", "V\u00edctor Manuel Vargas-Yun", "Pedro A. Guti\u00e9rrez"], "title": "TOC-UCO: a comprehensive repository of tabular ordinal classification datasets", "comment": "25 single column pages, 5 figures, 7 tables", "summary": "An ordinal classification (OC) problem corresponds to a special type of\nclassification characterised by the presence of a natural order relationship\namong the classes. This type of problem can be found in a number of real-world\napplications, motivating the design and development of many ordinal\nmethodologies over the last years. However, it is important to highlight that\nthe development of the OC field suffers from one main disadvantage: the lack of\na comprehensive set of datasets on which novel approaches to the literature\nhave to be benchmarked. In order to approach this objective, this manuscript\nfrom the University of C\\'ordoba (UCO), which have previous experience on the\nOC field, provides the literature with a publicly available repository of\ntabular data for a robust validation of novel OC approaches, namely TOC-UCO\n(Tabular Ordinal Classification repository of the UCO). Specifically, this\nrepository includes a set of $46$ tabular ordinal datasets, preprocessed under\na common framework and ensured to have a reasonable number of patterns and an\nappropriate class distribution. We also provide the sources and preprocessing\nsteps of each dataset, along with details on how to benchmark a novel approach\nusing the TOC-UCO repository. For this, indices for $30$ different randomised\ntrain-test partitions are provided to facilitate the reproducibility of the\nexperiments.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86TOC-UCO\u6570\u636e\u96c6\u5e93\uff0c\u8fd9\u662f\u4e00\u4e2a\u5305\u542b46\u4e2a\u8868\u683c\u5e8f\u6570\u5206\u7c7b\u6570\u636e\u96c6\u7684\u516c\u5f00\u53ef\u7528\u8d44\u6e90\u5e93\uff0c\u65e8\u5728\u4e3a\u5e8f\u6570\u5206\u7c7b\u65b9\u6cd5\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "\u5e8f\u6570\u5206\u7c7b\u9886\u57df\u7f3a\u4e4f\u4e00\u4e2a\u5168\u9762\u7684\u6570\u636e\u96c6\u96c6\u5408\u6765\u5bf9\u65b0\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002\u73b0\u6709\u7684\u5e8f\u6570\u5206\u7c7b\u65b9\u6cd5\u9700\u8981\u5728\u7edf\u4e00\u3001\u6807\u51c6\u5316\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u548c\u6bd4\u8f83\u3002", "method": "\u6784\u5efa\u4e86TOC-UCO\u6570\u636e\u96c6\u5e93\uff0c\u5305\u542b46\u4e2a\u8868\u683c\u5e8f\u6570\u5206\u7c7b\u6570\u636e\u96c6\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u8fdb\u884c\u9884\u5904\u7406\uff0c\u786e\u4fdd\u5408\u7406\u7684\u6837\u672c\u6570\u91cf\u548c\u9002\u5f53\u7684\u7c7b\u522b\u5206\u5e03\u3002\u63d0\u4f9b\u6570\u636e\u6e90\u3001\u9884\u5904\u7406\u6b65\u9aa4\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u4ee5\u53ca30\u4e2a\u4e0d\u540c\u968f\u673a\u8bad\u7ec3-\u6d4b\u8bd5\u5206\u5272\u7684\u7d22\u5f15\u4ee5\u4fc3\u8fdb\u5b9e\u9a8c\u7684\u53ef\u91cd\u590d\u6027\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u516c\u5f00\u53ef\u7528\u7684TOC-UCO\u6570\u636e\u96c6\u5e93\uff0c\u5305\u542b46\u4e2a\u7ecf\u8fc7\u9884\u5904\u7406\u7684\u8868\u683c\u5e8f\u6570\u5206\u7c7b\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6570\u636e\u96c6\u90fd\u5177\u6709\u5408\u7406\u7684\u6837\u672c\u6570\u91cf\u548c\u9002\u5f53\u7684\u7c7b\u522b\u5206\u5e03\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6570\u636e\u6e90\u548c\u9884\u5904\u7406\u4fe1\u606f\u3002", "conclusion": "TOC-UCO\u6570\u636e\u96c6\u5e93\u4e3a\u5e8f\u6570\u5206\u7c7b\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u65b0\u65b9\u6cd5\u7684\u9c81\u68d2\u9a8c\u8bc1\u548c\u6bd4\u8f83\uff0c\u63a8\u52a8\u5e8f\u6570\u5206\u7c7b\u9886\u57df\u7684\u53d1\u5c55\u3002\u901a\u8fc7\u63d0\u4f9b\u7edf\u4e00\u7684\u6570\u636e\u96c6\u548c\u5b9e\u9a8c\u8bbe\u7f6e\uff0c\u63d0\u9ad8\u4e86\u5b9e\u9a8c\u7684\u53ef\u91cd\u590d\u6027\u548c\u65b9\u6cd5\u6bd4\u8f83\u7684\u516c\u5e73\u6027\u3002"}}
{"id": "2507.17365", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17365", "abs": "https://arxiv.org/abs/2507.17365", "authors": ["Chuzhan Hao", "Wenfeng Feng", "Yuewei Zhang", "Hao Wang"], "title": "DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning", "comment": "10 pages, 2 figures", "summary": "Multi-step agentic retrieval systems based on large language models (LLMs)\nhave demonstrated remarkable performance in complex information search tasks.\nHowever, these systems still face significant challenges in practical\napplications, particularly in generating factually inconsistent intermediate\nqueries and inefficient search trajectories, which can lead to reasoning\ndeviations or redundant computations. To address these issues, we propose\nDynaSearcher, an innovative search agent enhanced by dynamic knowledge graphs\nand multi-reward reinforcement learning (RL). Specifically, our system\nleverages knowledge graphs as external structured knowledge to guide the search\nprocess by explicitly modeling entity relationships, thereby ensuring factual\nconsistency in intermediate queries and mitigating biases from irrelevant\ninformation. Furthermore, we employ a multi-reward RL framework for\nfine-grained control over training objectives such as retrieval accuracy,\nefficiency, and response quality. This framework promotes the generation of\nhigh-quality intermediate queries and comprehensive final answers, while\ndiscouraging unnecessary exploration and minimizing information omissions or\nredundancy. Experimental results demonstrate that our approach achieves\nstate-of-the-art answer accuracy on six multi-hop question answering datasets,\nmatching frontier LLMs while using only small-scale models and limited\ncomputational resources. Furthermore, our approach demonstrates strong\ngeneralization and robustness across diverse retrieval environments and\nlarger-scale models, highlighting its broad applicability.", "AI": {"tldr": "\u63d0\u51fa\u4e86DynaSearcher\uff0c\u4e00\u4e2a\u57fa\u4e8e\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\u548c\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u4ee3\u7406\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u548c\u641c\u7d22\u6548\u7387\u95ee\u9898", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u9aa4\u4ee3\u7406\u68c0\u7d22\u7cfb\u7edf\u5728\u590d\u6742\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u9762\u4e34\u751f\u6210\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u7684\u4e2d\u95f4\u67e5\u8be2\u548c\u4f4e\u6548\u641c\u7d22\u8f68\u8ff9\u7684\u6311\u6218\uff0c\u5bfc\u81f4\u63a8\u7406\u504f\u5dee\u6216\u5197\u4f59\u8ba1\u7b97", "method": "\u63d0\u51faDynaSearcher\u7cfb\u7edf\uff0c\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u5916\u90e8\u7ed3\u6784\u5316\u77e5\u8bc6\u6307\u5bfc\u641c\u7d22\u8fc7\u7a0b\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u5b9e\u4f53\u5173\u7cfb\u786e\u4fdd\u4e2d\u95f4\u67e5\u8be2\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\uff1b\u91c7\u7528\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u5bf9\u68c0\u7d22\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u54cd\u5e94\u8d28\u91cf\u7b49\u8bad\u7ec3\u76ee\u6807\u8fdb\u884c\u7ec6\u7c92\u5ea6\u63a7\u5236", "result": "\u5728\u516d\u4e2a\u591a\u8df3\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7b54\u6848\u51c6\u786e\u6027\uff0c\u4ec5\u4f7f\u7528\u5c0f\u89c4\u6a21\u6a21\u578b\u548c\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u5c31\u80fd\u5339\u914d\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff1b\u5728\u4e0d\u540c\u68c0\u7d22\u73af\u5883\u548c\u66f4\u5927\u89c4\u6a21\u6a21\u578b\u4e0a\u5c55\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027", "conclusion": "DynaSearcher\u901a\u8fc7\u7ed3\u5408\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\u548c\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6b65\u9aa4\u68c0\u7d22\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u9ad8\u6548\u7387\u7684\u4fe1\u606f\u68c0\u7d22\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027"}}
{"id": "2507.17368", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17368", "abs": "https://arxiv.org/abs/2507.17368", "authors": ["Hao Dai", "Chong Tang", "Jagmohan Chauhan"], "title": "ViRN: Variational Inference and Distribution Trilateration for Long-Tailed Continual Representation Learning", "comment": "6 pages, 2 figures", "summary": "Continual learning (CL) with long-tailed data distributions remains a\ncritical challenge for real-world AI systems, where models must sequentially\nadapt to new classes while retaining knowledge of old ones, despite severe\nclass imbalance. Existing methods struggle to balance stability and plasticity,\noften collapsing under extreme sample scarcity. To address this, we propose\nViRN, a novel CL framework that integrates variational inference (VI) with\ndistributional trilateration for robust long-tailed learning. First, we model\nclass-conditional distributions via a Variational Autoencoder to mitigate bias\ntoward head classes. Second, we reconstruct tail-class distributions via\nWasserstein distance-based neighborhood retrieval and geometric fusion,\nenabling sample-efficient alignment of tail-class representations. Evaluated on\nsix long-tailed classification benchmarks, including speech (e.g., rare\nacoustic events, accents) and image tasks, ViRN achieves a 10.24% average\naccuracy gain over state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86ViRN\u6846\u67b6\uff0c\u7ed3\u5408\u53d8\u5206\u63a8\u7406\u548c\u5206\u5e03\u4e09\u89d2\u6d4b\u91cf\u6280\u672f\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u957f\u5c3e\u6570\u636e\u5206\u5e03\u95ee\u9898\uff0c\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534710.24%", "motivation": "\u73b0\u5b9e\u4e16\u754cAI\u7cfb\u7edf\u9762\u4e34\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u957f\u5c3e\u6570\u636e\u5206\u5e03\u6311\u6218\uff0c\u6a21\u578b\u9700\u8981\u5728\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u4e0b\u987a\u5e8f\u9002\u5e94\u65b0\u7c7b\u522b\u540c\u65f6\u4fdd\u6301\u5bf9\u65e7\u7c7b\u522b\u7684\u77e5\u8bc6\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u7a33\u5b9a\u6027\u548c\u53ef\u5851\u6027\uff0c\u5728\u6781\u7aef\u6837\u672c\u7a00\u7f3a\u60c5\u51b5\u4e0b\u5bb9\u6613\u5d29\u6e83", "method": "\u63d0\u51faViRN\u6846\u67b6\uff0c\u96c6\u6210\u53d8\u5206\u63a8\u7406\u4e0e\u5206\u5e03\u4e09\u89d2\u6d4b\u91cf\uff1a1\uff09\u901a\u8fc7\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5efa\u6a21\u7c7b\u6761\u4ef6\u5206\u5e03\u4ee5\u51cf\u8f7b\u5bf9\u5934\u90e8\u7c7b\u522b\u7684\u504f\u89c1\uff1b2\uff09\u901a\u8fc7\u57fa\u4e8eWasserstein\u8ddd\u79bb\u7684\u90bb\u57df\u68c0\u7d22\u548c\u51e0\u4f55\u878d\u5408\u91cd\u6784\u5c3e\u90e8\u7c7b\u522b\u5206\u5e03\uff0c\u5b9e\u73b0\u5c3e\u90e8\u7c7b\u522b\u8868\u793a\u7684\u6837\u672c\u9ad8\u6548\u5bf9\u9f50", "result": "\u5728\u516d\u4e2a\u957f\u5c3e\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u8bed\u97f3\u4efb\u52a1\u5982\u7a00\u6709\u58f0\u5b66\u4e8b\u4ef6\u3001\u53e3\u97f3\u8bc6\u522b\u548c\u56fe\u50cf\u4efb\u52a1\uff09\u4e0a\u8bc4\u4f30\uff0cViRN\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534710.24%", "conclusion": "ViRN\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u53d8\u5206\u63a8\u7406\u548c\u5206\u5e03\u4e09\u89d2\u6d4b\u91cf\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u957f\u5c3e\u6570\u636e\u5206\u5e03\u7684\u6311\u6218\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e3a\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u6301\u7eed\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.17382", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17382", "abs": "https://arxiv.org/abs/2507.17382", "authors": ["Hao Dai", "Jagmohan Chauhan"], "title": "Continual Generalized Category Discovery: Learning and Forgetting from a Bayesian Perspective", "comment": "20 pages, 6 figures. Forty-second International Conference on Machine\n  Learning. 2025", "summary": "Continual Generalized Category Discovery (C-GCD) faces a critical challenge:\nincrementally learning new classes from unlabeled data streams while preserving\nknowledge of old classes. Existing methods struggle with catastrophic\nforgetting, especially when unlabeled data mixes known and novel categories. We\naddress this by analyzing C-GCD's forgetting dynamics through a Bayesian lens,\nrevealing that covariance misalignment between old and new classes drives\nperformance degradation. Building on this insight, we propose Variational Bayes\nC-GCD (VB-CGCD), a novel framework that integrates variational inference with\ncovariance-aware nearest-class-mean classification. VB-CGCD adaptively aligns\nclass distributions while suppressing pseudo-label noise via stochastic\nvariational updates. Experiments show VB-CGCD surpasses prior art by +15.21%\nwith the overall accuracy in the final session on standard benchmarks. We also\nintroduce a new challenging benchmark with only 10% labeled data and extended\nonline phases, VB-CGCD achieves a 67.86% final accuracy, significantly higher\nthan state-of-the-art (38.55%), demonstrating its robust applicability across\ndiverse scenarios. Code is available at: https://github.com/daihao42/VB-CGCD", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53d8\u5206\u8d1d\u53f6\u65af\u6301\u7eed\u5e7f\u4e49\u7c7b\u522b\u53d1\u73b0(VB-CGCD)\u65b9\u6cd5\uff0c\u901a\u8fc7\u534f\u65b9\u5dee\u611f\u77e5\u7684\u6700\u8fd1\u7c7b\u5747\u503c\u5206\u7c7b\u548c\u53d8\u5206\u63a8\u7406\u6765\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e8615.21%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u6301\u7eed\u5e7f\u4e49\u7c7b\u522b\u53d1\u73b0(C-GCD)\u65b9\u6cd5\u5728\u4ece\u65e0\u6807\u7b7e\u6570\u636e\u6d41\u4e2d\u589e\u91cf\u5b66\u4e60\u65b0\u7c7b\u522b\u65f6\u9762\u4e34\u707e\u96be\u6027\u9057\u5fd8\u7684\u4e25\u91cd\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u65e0\u6807\u7b7e\u6570\u636e\u6df7\u5408\u4e86\u5df2\u77e5\u548c\u65b0\u9896\u7c7b\u522b\u65f6\u3002\u9700\u8981\u5728\u5b66\u4e60\u65b0\u7c7b\u522b\u7684\u540c\u65f6\u4fdd\u6301\u5bf9\u65e7\u7c7b\u522b\u7684\u77e5\u8bc6\u3002", "method": "\u901a\u8fc7\u8d1d\u53f6\u65af\u89c6\u89d2\u5206\u6790C-GCD\u7684\u9057\u5fd8\u52a8\u6001\uff0c\u53d1\u73b0\u65b0\u65e7\u7c7b\u522b\u95f4\u7684\u534f\u65b9\u5dee\u4e0d\u5bf9\u9f50\u662f\u6027\u80fd\u4e0b\u964d\u7684\u4e3b\u8981\u539f\u56e0\u3002\u57fa\u4e8e\u6b64\u6d1e\u5bdf\uff0c\u63d0\u51fa\u4e86\u53d8\u5206\u8d1d\u53f6\u65afC-GCD(VB-CGCD)\u6846\u67b6\uff0c\u5c06\u53d8\u5206\u63a8\u7406\u4e0e\u534f\u65b9\u5dee\u611f\u77e5\u7684\u6700\u8fd1\u7c7b\u5747\u503c\u5206\u7c7b\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u968f\u673a\u53d8\u5206\u66f4\u65b0\u81ea\u9002\u5e94\u5bf9\u9f50\u7c7b\u522b\u5206\u5e03\u5e76\u6291\u5236\u4f2a\u6807\u7b7e\u566a\u58f0\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVB-CGCD\u5728\u6700\u7ec8\u4f1a\u8bdd\u7684\u6574\u4f53\u51c6\u786e\u7387\u4e0a\u8d85\u8d8a\u73b0\u6709\u6280\u672f15.21%\u3002\u5728\u65b0\u63d0\u51fa\u7684\u6311\u6218\u6027\u57fa\u51c6(\u4ec510%\u6807\u7b7e\u6570\u636e\u548c\u6269\u5c55\u5728\u7ebf\u9636\u6bb5)\u4e0a\uff0cVB-CGCD\u8fbe\u523067.86%\u7684\u6700\u7ec8\u51c6\u786e\u7387\uff0c\u663e\u8457\u9ad8\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u768438.55%\u3002", "conclusion": "VB-CGCD\u901a\u8fc7\u53d8\u5206\u63a8\u7406\u548c\u534f\u65b9\u5dee\u611f\u77e5\u5206\u7c7b\u6709\u6548\u89e3\u51b3\u4e86\u6301\u7eed\u5e7f\u4e49\u7c7b\u522b\u53d1\u73b0\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u591a\u79cd\u573a\u666f\u4e0b\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u9002\u7528\u6027\u548c\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u6301\u7eed\u5b66\u4e60\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17417", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17417", "abs": "https://arxiv.org/abs/2507.17417", "authors": ["Yutong Liu", "Cairong Zhao", "Guosheng Hu"], "title": "A Comprehensive Evaluation on Quantization Techniques for Large Language Models", "comment": null, "summary": "For large language models (LLMs), post-training quantization (PTQ) can\nsignificantly reduce memory footprint and computational overhead. Model\nquantization is a rapidly evolving research field. Though many papers have\nreported breakthrough performance, they may not conduct experiments on the same\nground since one quantization method usually contains multiple components. In\naddition, analyzing the theoretical connections among existing methods is\ncrucial for in-depth understanding. To bridge these gaps, we conduct an\nextensive review of state-of-the-art methods and perform comprehensive\nevaluations on the same ground to ensure fair comparisons. To our knowledge,\nthis fair and extensive investigation remains critically important yet\nunderexplored. To better understand the theoretical connections, we decouple\nthe published quantization methods into two steps: pre-quantization\ntransformation and quantization error mitigation. We define the former as a\npreprocessing step applied before quantization to reduce the impact of\noutliers, making the data distribution flatter and more suitable for\nquantization. Quantization error mitigation involves techniques that offset the\nerrors introduced during quantization, thereby enhancing model performance. We\nevaluate and analyze the impact of different components of quantization\nmethods. Additionally, we analyze and evaluate the latest MXFP4 data format and\nits performance. Our experimental results demonstrate that optimized rotation\nand scaling yield the best performance for pre-quantization transformation, and\ncombining low-rank compensation with GPTQ occasionally outperforms using GPTQ\nalone for quantization error mitigation. Furthermore, we explore the potential\nof the latest MXFP4 quantization and reveal that the optimal pre-quantization\ntransformation strategy for INT4 does not generalize well to MXFP4, inspiring\nfurther investigation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u540e\u91cf\u5316(PTQ)\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u548c\u7406\u8bba\u5206\u6790\uff0c\u5c06\u91cf\u5316\u65b9\u6cd5\u89e3\u8026\u4e3a\u9884\u91cf\u5316\u53d8\u6362\u548c\u91cf\u5316\u8bef\u5dee\u7f13\u89e3\u4e24\u4e2a\u6b65\u9aa4\uff0c\u5e76\u5728\u7edf\u4e00\u57fa\u51c6\u4e0b\u516c\u5e73\u6bd4\u8f83\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u65b9\u6cd5\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u4e0d\u540c\u8bba\u6587\u7684\u5b9e\u9a8c\u6761\u4ef6\u4e0d\u4e00\u81f4\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u73b0\u6709\u65b9\u6cd5\u7406\u8bba\u8054\u7cfb\u7684\u6df1\u5165\u5206\u6790\uff0c\u56e0\u6b64\u9700\u8981\u8fdb\u884c\u516c\u5e73\u5168\u9762\u7684\u6bd4\u8f83\u7814\u7a76\u3002", "method": "\u5c06\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u89e3\u8026\u4e3a\u4e24\u4e2a\u6b65\u9aa4\uff1a1)\u9884\u91cf\u5316\u53d8\u6362-\u5728\u91cf\u5316\u524d\u8fdb\u884c\u9884\u5904\u7406\u4ee5\u51cf\u5c11\u5f02\u5e38\u503c\u5f71\u54cd\uff0c\u4f7f\u6570\u636e\u5206\u5e03\u66f4\u5e73\u5766\uff1b2)\u91cf\u5316\u8bef\u5dee\u7f13\u89e3-\u91c7\u7528\u6280\u672f\u6765\u62b5\u6d88\u91cf\u5316\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7684\u8bef\u5dee\u3002\u5728\u7edf\u4e00\u57fa\u51c6\u4e0b\u8bc4\u4f30\u5404\u79cd\u7ec4\u4ef6\u7684\u5f71\u54cd\uff0c\u5e76\u5206\u6790\u6700\u65b0\u7684MXFP4\u6570\u636e\u683c\u5f0f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a1)\u4f18\u5316\u7684\u65cb\u8f6c\u548c\u7f29\u653e\u662f\u9884\u91cf\u5316\u53d8\u6362\u7684\u6700\u4f73\u65b9\u6cd5\uff1b2)\u4f4e\u79e9\u8865\u507f\u4e0eGPTQ\u7ed3\u5408\u6709\u65f6\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528GPTQ\u8fdb\u884c\u91cf\u5316\u8bef\u5dee\u7f13\u89e3\uff1b3)\u9488\u5bf9INT4\u7684\u6700\u4f18\u9884\u91cf\u5316\u53d8\u6362\u7b56\u7565\u4e0d\u80fd\u5f88\u597d\u5730\u63a8\u5e7f\u5230MXFP4\u683c\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u89e3\u8026\u5206\u6790\u548c\u516c\u5e73\u6bd4\u8f83\uff0c\u8be5\u7814\u7a76\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6df1\u5165\u7406\u89e3\uff0c\u53d1\u73b0\u4e86\u6700\u4f18\u7684\u7ec4\u4ef6\u7ec4\u5408\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u91cf\u5316\u683c\u5f0f\u4e4b\u95f4\u7b56\u7565\u7684\u5dee\u5f02\u6027\uff0c\u4e3a\u672a\u6765\u91cf\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2507.17450", "categories": ["cs.LG", "55N31"], "pdf": "https://arxiv.org/pdf/2507.17450", "abs": "https://arxiv.org/abs/2507.17450", "authors": ["Arsha Niksa", "Hooman Zare", "Ali Shahrabi", "Hanieh Hatami", "Mohammadreza Razvan"], "title": "Persistent Patterns in Eye Movements: A Topological Approach to Emotion Recognition", "comment": null, "summary": "We present a topological pipeline for automated multiclass emotion\nrecognition from eye-tracking data. Delay embeddings of gaze trajectories are\nanalyzed using persistent homology. From the resulting persistence diagrams, we\nextract shape-based features such as mean persistence, maximum persistence, and\nentropy. A random forest classifier trained on these features achieves up to\n$75.6\\%$ accuracy on four emotion classes, which are the quadrants the\nCircumplex Model of Affect. The results demonstrate that persistence diagram\ngeometry effectively encodes discriminative gaze dynamics, suggesting a\npromising topological approach for affective computing and human behavior\nanalysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u7684\u773c\u52a8\u8ffd\u8e2a\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6301\u7eed\u540c\u8c03\u5206\u6790\u6ce8\u89c6\u8f68\u8ff9\u7684\u5ef6\u8fdf\u5d4c\u5165\uff0c\u4ece\u6301\u7eed\u56fe\u4e2d\u63d0\u53d6\u5f62\u72b6\u7279\u5f81\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u5728\u56db\u7c7b\u60c5\u611f\u4e0a\u8fbe\u523075.6%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u773c\u52a8\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u6ce8\u89c6\u8f68\u8ff9\u7684\u590d\u6742\u51e0\u4f55\u7ed3\u6784\u548c\u52a8\u6001\u7279\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u7f16\u7801\u773c\u52a8\u6570\u636e\u4e2d\u7684\u5224\u522b\u6027\u4fe1\u606f\u7528\u4e8e\u60c5\u611f\u8bc6\u522b\u3002", "method": "\u91c7\u7528\u62d3\u6251\u7ba1\u9053\u8fdb\u884c\u81ea\u52a8\u5316\u591a\u7c7b\u60c5\u611f\u8bc6\u522b\uff1a1\uff09\u5bf9\u773c\u52a8\u8ffd\u8e2a\u6570\u636e\u7684\u6ce8\u89c6\u8f68\u8ff9\u8fdb\u884c\u5ef6\u8fdf\u5d4c\u5165\uff1b2\uff09\u4f7f\u7528\u6301\u7eed\u540c\u8c03\u5206\u6790\u5d4c\u5165\u540e\u7684\u6570\u636e\uff1b3\uff09\u4ece\u751f\u6210\u7684\u6301\u7eed\u56fe\u4e2d\u63d0\u53d6\u57fa\u4e8e\u5f62\u72b6\u7684\u7279\u5f81\uff0c\u5305\u62ec\u5e73\u5747\u6301\u7eed\u6027\u3001\u6700\u5927\u6301\u7eed\u6027\u548c\u71b5\uff1b4\uff09\u4f7f\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u5bf9\u63d0\u53d6\u7684\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3\u548c\u5206\u7c7b\u3002", "result": "\u5728\u57fa\u4e8e\u60c5\u611f\u73af\u6a21\u578b\u56db\u4e2a\u8c61\u9650\u7684\u56db\u7c7b\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e8675.6%\u7684\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u6301\u7eed\u56fe\u51e0\u4f55\u7ed3\u6784\u80fd\u591f\u6709\u6548\u7f16\u7801\u5177\u6709\u5224\u522b\u6027\u7684\u6ce8\u89c6\u52a8\u6001\u7279\u5f81\u3002", "conclusion": "\u6301\u7eed\u56fe\u51e0\u4f55\u7ed3\u6784\u80fd\u591f\u6709\u6548\u7f16\u7801\u773c\u52a8\u6570\u636e\u4e2d\u7684\u5224\u522b\u6027\u6ce8\u89c6\u52a8\u6001\u4fe1\u606f\uff0c\u8868\u660e\u62d3\u6251\u65b9\u6cd5\u5728\u60c5\u611f\u8ba1\u7b97\u548c\u4eba\u7c7b\u884c\u4e3a\u5206\u6790\u9886\u57df\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.17453", "categories": ["cs.LG", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.17453", "abs": "https://arxiv.org/abs/2507.17453", "authors": ["Guanqin Zhang", "Kota Fukuda", "Zhenya Zhang", "H. M. N. Dilum Bandara", "Shiping Chen", "Jianjun Zhao", "Yulei Sui"], "title": "Efficient Neural Network Verification via Order Leading Exploration of Branch-and-Bound Trees", "comment": "This is an extended version of the ECOOP 2025 paper, with a\n  comparison with DATE 2025 (Figure 7 of RQ1 in Section 5.2), as well as an\n  in-depth discussion of OOPSLA 2025 in the related work (Section 6)", "summary": "The vulnerability of neural networks to adversarial perturbations has\nnecessitated formal verification techniques that can rigorously certify the\nquality of neural networks. As the state-of-the-art, branch and bound (BaB) is\na \"divide-and-conquer\" strategy that applies off-the-shelf verifiers to\nsub-problems for which they perform better. While BaB can identify the\nsub-problems that are necessary to be split, it explores the space of these\nsub-problems in a naive \"first-come-first-serve\" manner, thereby suffering from\nan issue of inefficiency to reach a verification conclusion. To bridge this\ngap, we introduce an order over different sub-problems produced by BaB,\nconcerning with their different likelihoods of containing counterexamples.\nBased on this order, we propose a novel verification framework Oliva that\nexplores the sub-problem space by prioritizing those sub-problems that are more\nlikely to find counterexamples, in order to efficiently reach the conclusion of\nthe verification. Even if no counterexample can be found in any sub-problem, it\nonly changes the order of visiting different sub-problem and so will not lead\nto a performance degradation. Specifically, Oliva has two variants, including\n$Oliva^{GR}$, a greedy strategy that always prioritizes the sub-problems that\nare more likely to find counterexamples, and $Oliva^{SA}$, a balanced strategy\ninspired by simulated annealing that gradually shifts from exploration to\nexploitation to locate the globally optimal sub-problems. We experimentally\nevaluate the performance of Oliva on 690 verification problems spanning over 5\nmodels with datasets MNIST and CIFAR10. Compared to the state-of-the-art\napproaches, we demonstrate the speedup of Oliva for up to 25X in MNIST, and up\nto 80X in CIFAR10.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Oliva\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u5206\u652f\u5b9a\u754c(BaB)\u7b97\u6cd5\u4e2d\u5b50\u95ee\u9898\u7684\u63a2\u7d22\u987a\u5e8f\u6765\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u6548\u7387\uff0c\u5728MNIST\u548cCIFAR10\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad825\u500d\u548c80\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u652f\u5b9a\u754c\u9a8c\u8bc1\u65b9\u6cd5\u867d\u7136\u80fd\u8bc6\u522b\u9700\u8981\u5206\u5272\u7684\u5b50\u95ee\u9898\uff0c\u4f46\u91c7\u7528\"\u5148\u6765\u5148\u670d\u52a1\"\u7684\u7b80\u5355\u7b56\u7565\u63a2\u7d22\u5b50\u95ee\u9898\u7a7a\u95f4\uff0c\u5bfc\u81f4\u9a8c\u8bc1\u6548\u7387\u4f4e\u4e0b\uff0c\u96be\u4ee5\u5feb\u901f\u5f97\u51fa\u9a8c\u8bc1\u7ed3\u8bba\u3002", "method": "\u63d0\u51faOliva\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u5b50\u95ee\u9898\u5305\u542b\u53cd\u4f8b\u53ef\u80fd\u6027\u7684\u6392\u5e8f\u673a\u5236\uff0c\u4f18\u5148\u63a2\u7d22\u66f4\u53ef\u80fd\u627e\u5230\u53cd\u4f8b\u7684\u5b50\u95ee\u9898\u3002\u5305\u542b\u4e24\u4e2a\u53d8\u4f53\uff1aOliva^GR\uff08\u8d2a\u5fc3\u7b56\u7565\uff0c\u603b\u662f\u4f18\u5148\u5904\u7406\u6700\u53ef\u80fd\u627e\u5230\u53cd\u4f8b\u7684\u5b50\u95ee\u9898\uff09\u548cOliva^SA\uff08\u57fa\u4e8e\u6a21\u62df\u9000\u706b\u7684\u5e73\u8861\u7b56\u7565\uff0c\u4ece\u63a2\u7d22\u9010\u6e10\u8f6c\u5411\u5229\u7528\uff09\u3002", "result": "\u5728\u6db5\u76d65\u4e2a\u6a21\u578b\u3001690\u4e2a\u9a8c\u8bc1\u95ee\u9898\u7684MNIST\u548cCIFAR10\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0cOliva\u5728MNIST\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad825\u500d\u7684\u52a0\u901f\uff0c\u5728CIFAR10\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad880\u500d\u7684\u52a0\u901f\u3002", "conclusion": "Oliva\u6846\u67b6\u901a\u8fc7\u667a\u80fd\u7684\u5b50\u95ee\u9898\u4f18\u5148\u7ea7\u6392\u5e8f\u663e\u8457\u63d0\u9ad8\u4e86\u795e\u7ecf\u7f51\u7edc\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u6548\u7387\uff0c\u5373\u4f7f\u5728\u627e\u4e0d\u5230\u53cd\u4f8b\u7684\u60c5\u51b5\u4e0b\u4e5f\u4e0d\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17454", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17454", "abs": "https://arxiv.org/abs/2507.17454", "authors": ["Shusen Ma", "Yun-Bo Zhao", "Yu Kang"], "title": "C3RL: Rethinking the Combination of Channel-independence and Channel-mixing from Representation Learning", "comment": null, "summary": "Multivariate time series forecasting has drawn increasing attention due to\nits practical importance. Existing approaches typically adopt either\nchannel-mixing (CM) or channel-independence (CI) strategies. CM strategy can\ncapture inter-variable dependencies but fails to discern variable-specific\ntemporal patterns. CI strategy improves this aspect but fails to fully exploit\ncross-variable dependencies like CM. Hybrid strategies based on feature fusion\noffer limited generalization and interpretability. To address these issues, we\npropose C3RL, a novel representation learning framework that jointly models\nboth CM and CI strategies. Motivated by contrastive learning in computer\nvision, C3RL treats the inputs of the two strategies as transposed views and\nbuilds a siamese network architecture: one strategy serves as the backbone,\nwhile the other complements it. By jointly optimizing contrastive and\nprediction losses with adaptive weighting, C3RL balances representation and\nforecasting performance. Extensive experiments on seven models show that C3RL\nboosts the best-case performance rate to 81.4\\% for models based on CI strategy\nand to 76.3\\% for models based on CM strategy, demonstrating strong\ngeneralization and effectiveness. The code will be available once the paper is\naccepted.", "AI": {"tldr": "\u63d0\u51fa\u4e86C3RL\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8054\u5408\u5efa\u6a21\u901a\u9053\u6df7\u5408(CM)\u548c\u901a\u9053\u72ec\u7acb(CI)\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd", "motivation": "\u73b0\u6709\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1aCM\u7b56\u7565\u80fd\u6355\u83b7\u53d8\u91cf\u95f4\u4f9d\u8d56\u4f46\u65e0\u6cd5\u8bc6\u522b\u53d8\u91cf\u7279\u5b9a\u7684\u65f6\u95f4\u6a21\u5f0f\uff1bCI\u7b56\u7565\u6539\u5584\u4e86\u8fd9\u4e00\u70b9\u4f46\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8de8\u53d8\u91cf\u4f9d\u8d56\uff1b\u57fa\u4e8e\u7279\u5f81\u878d\u5408\u7684\u6df7\u5408\u7b56\u7565\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u6709\u9650", "method": "\u63d0\u51faC3RL\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u53d7\u8ba1\u7b97\u673a\u89c6\u89c9\u5bf9\u6bd4\u5b66\u4e60\u542f\u53d1\uff0c\u5c06CM\u548cCI\u7b56\u7565\u7684\u8f93\u5165\u89c6\u4e3a\u8f6c\u7f6e\u89c6\u56fe\uff0c\u6784\u5efa\u5b6a\u751f\u7f51\u7edc\u67b6\u6784\uff1a\u4e00\u79cd\u7b56\u7565\u4f5c\u4e3a\u4e3b\u5e72\uff0c\u53e6\u4e00\u79cd\u4f5c\u4e3a\u8865\u5145\u3002\u901a\u8fc7\u81ea\u9002\u5e94\u52a0\u6743\u8054\u5408\u4f18\u5316\u5bf9\u6bd4\u635f\u5931\u548c\u9884\u6d4b\u635f\u5931\u6765\u5e73\u8861\u8868\u793a\u548c\u9884\u6d4b\u6027\u80fd", "result": "\u5728\u4e03\u4e2a\u6a21\u578b\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cC3RL\u5c06\u57fa\u4e8eCI\u7b56\u7565\u7684\u6a21\u578b\u6700\u4f73\u6027\u80fd\u7387\u63d0\u5347\u81f381.4%\uff0c\u5c06\u57fa\u4e8eCM\u7b56\u7565\u7684\u6a21\u578b\u6700\u4f73\u6027\u80fd\u7387\u63d0\u5347\u81f376.3%\uff0c\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6709\u6548\u6027", "conclusion": "C3RL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21CM\u548cCI\u7b56\u7565\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.17472", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.17472", "abs": "https://arxiv.org/abs/2507.17472", "authors": ["Junhua Liu", "Roy Ka-Wei Lee", "Kwan Hui Lim"], "title": "BGM-HAN: A Hierarchical Attention Network for Accurate and Fair Decision Assessment on Semi-Structured Profiles", "comment": "Accepted at ASONAM 2025", "summary": "Human decision-making in high-stakes domains often relies on expertise and\nheuristics, but is vulnerable to hard-to-detect cognitive biases that threaten\nfairness and long-term outcomes. This work presents a novel approach to\nenhancing complex decision-making workflows through the integration of\nhierarchical learning alongside various enhancements. Focusing on university\nadmissions as a representative high-stakes domain, we propose BGM-HAN, an\nenhanced Byte-Pair Encoded, Gated Multi-head Hierarchical Attention Network,\ndesigned to effectively model semi-structured applicant data. BGM-HAN captures\nmulti-level representations that are crucial for nuanced assessment, improving\nboth interpretability and predictive performance. Experimental results on real\nadmissions data demonstrate that our proposed model significantly outperforms\nboth state-of-the-art baselines from traditional machine learning to large\nlanguage models, offering a promising framework for augmenting decision-making\nin domains where structure, context, and fairness matter. Source code is\navailable at: https://github.com/junhua/bgm-han.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBGM-HAN\u6a21\u578b\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u5b66\u4e60\u589e\u5f3a\u5927\u5b66\u62db\u751f\u7b49\u9ad8\u98ce\u9669\u51b3\u7b56\u573a\u666f\uff0c\u6709\u6548\u5904\u7406\u534a\u7ed3\u6784\u5316\u7533\u8bf7\u8005\u6570\u636e\uff0c\u5728\u771f\u5b9e\u62db\u751f\u6570\u636e\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u4eba\u7c7b\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u9886\u57df\u5bb9\u6613\u53d7\u5230\u8ba4\u77e5\u504f\u89c1\u5f71\u54cd\uff0c\u5a01\u80c1\u516c\u5e73\u6027\u548c\u957f\u671f\u7ed3\u679c\u3002\u9700\u8981\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u589e\u5f3a\u590d\u6742\u51b3\u7b56\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7279\u522b\u662f\u5728\u5927\u5b66\u62db\u751f\u8fd9\u7c7b\u4ee3\u8868\u6027\u9ad8\u98ce\u9669\u9886\u57df\u3002", "method": "\u63d0\u51faBGM-HAN\uff08\u589e\u5f3a\u578b\u5b57\u8282\u5bf9\u7f16\u7801\u95e8\u63a7\u591a\u5934\u5c42\u6b21\u6ce8\u610f\u529b\u7f51\u7edc\uff09\uff0c\u96c6\u6210\u5c42\u6b21\u5316\u5b66\u4e60\u548c\u591a\u79cd\u589e\u5f3a\u6280\u672f\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5efa\u6a21\u534a\u7ed3\u6784\u5316\u7533\u8bf7\u8005\u6570\u636e\uff0c\u6355\u83b7\u591a\u5c42\u6b21\u8868\u793a\u4ee5\u652f\u6301\u7ec6\u81f4\u8bc4\u4f30\u3002", "result": "\u5728\u771f\u5b9e\u62db\u751f\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4ece\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u5230\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5404\u79cd\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u53ef\u89e3\u91ca\u6027\u548c\u9884\u6d4b\u6027\u80fd\u65b9\u9762\u90fd\u6709\u63d0\u5347\u3002", "conclusion": "BGM-HAN\u4e3a\u7ed3\u6784\u5316\u3001\u4e0a\u4e0b\u6587\u548c\u516c\u5e73\u6027\u91cd\u8981\u7684\u51b3\u7b56\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u589e\u5f3a\u51b3\u7b56\u6846\u67b6\uff0c\u53ef\u6709\u6548\u8f85\u52a9\u9ad8\u98ce\u9669\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u4eba\u7c7b\u5224\u65ad\u3002"}}
{"id": "2507.17501", "categories": ["cs.LG", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.17501", "abs": "https://arxiv.org/abs/2507.17501", "authors": ["Xianbiao Qi", "Marco Chen", "Wenjie Xiao", "Jiaquan Ye", "Yelin He", "Chun-Guang Li", "Zhouchen Lin"], "title": "DNT: a Deeply Normalized Transformer that can be trained by Momentum SGD", "comment": "We have introduced a novel architecture, Deeply Normalized\n  Transformer (DNT), which enables efficient training with vanilla momentum\n  SGDW (mSGDW), achieving performance on par with AdamW-optimized Transformers", "summary": "Transformers have become the de facto backbone of modern deep learning, yet\ntheir training typically demands an advanced optimizer with adaptive learning\nrate like AdamW, rather than a momentum SGDW (mSGDW). Previous works show that\nit is mainly due to a heavy-tailed distribution of the gradients. In this\npaper, we introduce a Deeply Normalized Transformer (DNT), which is\nmeticulously engineered to overcome this limitation enabling seamless training\nwith vanilla mSGDW while yielding comparable performance to the Transformers\ntrained via AdamW. To be specific, in DNT, we strategically integrate\nnormalization techniques at proper positions in the Transformers to effectively\nmodulate the Jacobian matrices of each layer, balance the influence of weights,\nactivations, and their interactions, and thus enable the distributions of\ngradients concentrated. We provide both theoretical justifications of the\nnormalization technique used in our DNT and extensive empirical evaluation on\ntwo popular Transformer architectures to validate that: a) DNT outperforms its\ncounterparts (\\ie, ViT and GPT), and b) DNT can be effectively trained with\nvanilla mSGDW.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6df1\u5ea6\u5f52\u4e00\u5316Transformer(DNT)\uff0c\u901a\u8fc7\u5728\u5173\u952e\u4f4d\u7f6e\u96c6\u6210\u5f52\u4e00\u5316\u6280\u672f\uff0c\u4f7f\u5f97Transformer\u80fd\u591f\u7528\u4f20\u7edf\u7684\u52a8\u91cfSGD\u8bad\u7ec3\u800c\u4e0d\u9700\u8981AdamW\u7b49\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709Transformer\u8bad\u7ec3\u901a\u5e38\u9700\u8981AdamW\u7b49\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u4f18\u5316\u5668\uff0c\u800c\u65e0\u6cd5\u4f7f\u7528\u7b80\u5355\u7684\u52a8\u91cfSGD\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u68af\u5ea6\u5206\u5e03\u5448\u91cd\u5c3e\u5206\u5e03\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u4f7fTransformer\u80fd\u591f\u7528\u66f4\u7b80\u5355\u7684\u4f18\u5316\u5668\u8fdb\u884c\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u6df1\u5ea6\u5f52\u4e00\u5316Transformer(DNT)\uff0c\u5728Transformer\u7684\u9002\u5f53\u4f4d\u7f6e\u7b56\u7565\u6027\u5730\u96c6\u6210\u5f52\u4e00\u5316\u6280\u672f\uff0c\u6709\u6548\u8c03\u8282\u6bcf\u5c42\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u5e73\u8861\u6743\u91cd\u3001\u6fc0\u6d3b\u53ca\u5176\u4ea4\u4e92\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u4f7f\u68af\u5ea6\u5206\u5e03\u66f4\u52a0\u96c6\u4e2d\u3002", "result": "DNT\u5728\u4e24\u79cd\u6d41\u884c\u7684Transformer\u67b6\u6784(ViT\u548cGPT)\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a1) DNT\u6027\u80fd\u4f18\u4e8e\u5bf9\u5e94\u7684\u57fa\u7ebf\u6a21\u578b\uff1b2) DNT\u53ef\u4ee5\u6709\u6548\u5730\u4f7f\u7528\u4f20\u7edf\u7684\u52a8\u91cfSGD\u8fdb\u884c\u8bad\u7ec3\uff0c\u65e0\u9700\u81ea\u9002\u5e94\u4f18\u5316\u5668\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5f52\u4e00\u5316\u6280\u672f\uff0cDNT\u6210\u529f\u89e3\u51b3\u4e86Transformer\u8bad\u7ec3\u4e2d\u5bf9\u81ea\u9002\u5e94\u4f18\u5316\u5668\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7528\u7b80\u5355\u7684\u52a8\u91cfSGD\u8bad\u7ec3\u9ad8\u6027\u80fdTransformer\u7684\u76ee\u6807\uff0c\u4e3aTransformer\u7684\u8bad\u7ec3\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17513", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17513", "abs": "https://arxiv.org/abs/2507.17513", "authors": ["Nazar Buzun", "Daniil Shlenskii", "Maxim Bobrin", "Dmitry V. Dylov"], "title": "HOTA: Hamiltonian framework for Optimal Transport Advection", "comment": null, "summary": "Optimal transport (OT) has become a natural framework for guiding the\nprobability flows. Yet, the majority of recent generative models assume trivial\ngeometry (e.g., Euclidean) and rely on strong density-estimation assumptions,\nyielding trajectories that do not respect the true principles of optimality in\nthe underlying manifold. We present Hamiltonian Optimal Transport Advection\n(HOTA), a Hamilton-Jacobi-Bellman based method that tackles the dual dynamical\nOT problem explicitly through Kantorovich potentials, enabling efficient and\nscalable trajectory optimization. Our approach effectively evades the need for\nexplicit density modeling, performing even when the cost functionals are\nnon-smooth. Empirically, HOTA outperforms all baselines in standard benchmarks,\nas well as in custom datasets with non-differentiable costs, both in terms of\nfeasibility and optimality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HOTA\u65b9\u6cd5\uff0c\u901a\u8fc7Hamilton-Jacobi-Bellman\u65b9\u7a0b\u89e3\u51b3\u6700\u4f18\u4f20\u8f93\u95ee\u9898\uff0c\u907f\u514d\u4e86\u663e\u5f0f\u5bc6\u5ea6\u5efa\u6a21\uff0c\u5728\u6807\u51c6\u548c\u975e\u53ef\u5fae\u4ee3\u4ef7\u51fd\u6570\u6570\u636e\u96c6\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5927\u591a\u5047\u8bbe\u7b80\u5355\u51e0\u4f55\uff08\u5982\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff09\u5e76\u4f9d\u8d56\u5f3a\u5bc6\u5ea6\u4f30\u8ba1\u5047\u8bbe\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u8f68\u8ff9\u4e0d\u7b26\u5408\u5e95\u5c42\u6d41\u5f62\u7684\u771f\u6b63\u6700\u4f18\u6027\u539f\u5219\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u590d\u6742\u6d41\u5f62\u4e0a\u8fdb\u884c\u6709\u6548\u6700\u4f18\u4f20\u8f93\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u54c8\u5bc6\u987f\u6700\u4f18\u4f20\u8f93\u5e73\u6d41\uff08HOTA\uff09\u65b9\u6cd5\uff0c\u57fa\u4e8eHamilton-Jacobi-Bellman\u65b9\u7a0b\uff0c\u901a\u8fc7Kantorovich\u52bf\u51fd\u6570\u663e\u5f0f\u5904\u7406\u5bf9\u5076\u52a8\u529b\u5b66\u6700\u4f18\u4f20\u8f93\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u8f68\u8ff9\u4f18\u5316\u3002", "result": "HOTA\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u548c\u5177\u6709\u975e\u53ef\u5fae\u4ee3\u4ef7\u51fd\u6570\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\u90fd\u8d85\u8d8a\u4e86\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u53ef\u884c\u6027\u548c\u6700\u4f18\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u8be5\u65b9\u6cd5\u6709\u6548\u907f\u514d\u4e86\u663e\u5f0f\u5bc6\u5ea6\u5efa\u6a21\u7684\u9700\u6c42\uff0c\u5373\u4f7f\u5728\u4ee3\u4ef7\u51fd\u6570\u975e\u5149\u6ed1\u65f6\u4e5f\u80fd\u826f\u597d\u5de5\u4f5c\u3002", "conclusion": "HOTA\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u6700\u4f18\u4f20\u8f93\u65b9\u6cd5\u5728\u590d\u6742\u6d41\u5f62\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u907f\u514d\u5bc6\u5ea6\u5efa\u6a21\u548c\u5904\u7406\u975e\u5149\u6ed1\u4ee3\u4ef7\u51fd\u6570\uff0c\u4e3a\u6700\u4f18\u4f20\u8f93\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u52a0\u5b9e\u7528\u548c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17528", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17528", "abs": "https://arxiv.org/abs/2507.17528", "authors": ["Yao Wang", "Jiannan Li", "Yue Kang", "Shanxing Gao", "Zhenxin Xiao"], "title": "Generalized Low-Rank Matrix Contextual Bandits with Graph Information", "comment": null, "summary": "The matrix contextual bandit (CB), as an extension of the well-known\nmulti-armed bandit, is a powerful framework that has been widely applied in\nsequential decision-making scenarios involving low-rank structure. In many\nreal-world scenarios, such as online advertising and recommender systems,\nadditional graph information often exists beyond the low-rank structure, that\nis, the similar relationships among users/items can be naturally captured\nthrough the connectivity among nodes in the corresponding graphs. However,\nexisting matrix CB methods fail to explore such graph information, and thereby\nmaking them difficult to generate effective decision-making policies. To fill\nin this void, we propose in this paper a novel matrix CB algorithmic framework\nthat builds upon the classical upper confidence bound (UCB) framework. This new\nframework can effectively integrate both the low-rank structure and graph\ninformation in a unified manner. Specifically, it involves first solving a\njoint nuclear norm and matrix Laplacian regularization problem, followed by the\nimplementation of a graph-based generalized linear version of the UCB\nalgorithm. Rigorous theoretical analysis demonstrates that our procedure\noutperforms several popular alternatives in terms of cumulative regret bound,\nowing to the effective utilization of graph information. A series of synthetic\nand real-world data experiments are conducted to further illustrate the merits\nof our procedure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u77e9\u9635\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7b97\u6cd5\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u540c\u65f6\u5229\u7528\u4f4e\u79e9\u7ed3\u6784\u548c\u56fe\u4fe1\u606f\u6765\u6539\u8fdb\u5728\u7ebf\u51b3\u7b56\u5236\u5b9a\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5728\u7ebf\u5e7f\u544a\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u7684\u77e9\u9635\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u65b9\u6cd5\u867d\u7136\u80fd\u591f\u5904\u7406\u4f4e\u79e9\u7ed3\u6784\uff0c\u4f46\u5728\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\uff08\u5982\u5728\u7ebf\u5e7f\u544a\u548c\u63a8\u8350\u7cfb\u7edf\uff09\u4e2d\uff0c\u9664\u4e86\u4f4e\u79e9\u7ed3\u6784\u5916\u8fd8\u5b58\u5728\u989d\u5916\u7684\u56fe\u4fe1\u606f\uff08\u7528\u6237/\u7269\u54c1\u4e4b\u95f4\u7684\u76f8\u4f3c\u5173\u7cfb\uff09\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u56fe\u4fe1\u606f\uff0c\u5bfc\u81f4\u51b3\u7b56\u7b56\u7565\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178\u7684\u4e0a\u7f6e\u4fe1\u754c\uff08UCB\uff09\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u77e9\u9635\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7b97\u6cd5\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u6c42\u89e3\u4e00\u4e2a\u8054\u5408\u6838\u8303\u6570\u548c\u77e9\u9635\u62c9\u666e\u62c9\u65af\u6b63\u5219\u5316\u95ee\u9898\uff0c\u7136\u540e\u5b9e\u73b0\u57fa\u4e8e\u56fe\u7684\u5e7f\u4e49\u7ebf\u6027UCB\u7b97\u6cd5\uff0c\u4ece\u800c\u5728\u7edf\u4e00\u6846\u67b6\u5185\u6709\u6548\u6574\u5408\u4f4e\u79e9\u7ed3\u6784\u548c\u56fe\u4fe1\u606f\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u7531\u4e8e\u6709\u6548\u5229\u7528\u4e86\u56fe\u4fe1\u606f\uff0c\u8be5\u65b9\u6cd5\u5728\u7d2f\u79ef\u9057\u61be\u754c\u65b9\u9762\u4f18\u4e8e\u51e0\u79cd\u6d41\u884c\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u56fe\u4fe1\u606f\u4e0e\u4f4e\u79e9\u7ed3\u6784\u76f8\u7ed3\u5408\uff0c\u6240\u63d0\u51fa\u7684\u77e9\u9635\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u6846\u67b6\u80fd\u591f\u663e\u8457\u6539\u5584\u51b3\u7b56\u5236\u5b9a\u6027\u80fd\uff0c\u4e3a\u5728\u7ebf\u5e7f\u544a\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17530", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17530", "abs": "https://arxiv.org/abs/2507.17530", "authors": ["Shahil Shaik", "Jonathon M. Smereka", "Yue Wang"], "title": "Generalized Advantage Estimation for Distributional Policy Gradients", "comment": "6 pages, 3 figures, published at ACC 2025 Conference", "summary": "Generalized Advantage Estimation (GAE) has been used to mitigate the\ncomputational complexity of reinforcement learning (RL) by employing an\nexponentially weighted estimation of the advantage function to reduce the\nvariance in policy gradient estimates. Despite its effectiveness, GAE is not\ndesigned to handle value distributions integral to distributional RL, which can\ncapture the inherent stochasticity in systems and is hence more robust to\nsystem noises. To address this gap, we propose a novel approach that utilizes\nthe optimal transport theory to introduce a Wasserstein-like directional\nmetric, which measures both the distance and the directional discrepancies\nbetween probability distributions. Using the exponentially weighted estimation,\nwe leverage this Wasserstein-like directional metric to derive distributional\nGAE (DGAE). Similar to traditional GAE, our proposed DGAE provides a\nlow-variance advantage estimate with controlled bias, making it well-suited for\npolicy gradient algorithms that rely on advantage estimation for policy\nupdates. We integrated DGAE into three different policy gradient methods.\nAlgorithms were evaluated across various OpenAI Gym environments and compared\nwith the baselines with traditional GAE to assess the performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5206\u5e03\u5f0f\u5e7f\u4e49\u4f18\u52bf\u4f30\u8ba1(DGAE)\uff0c\u901a\u8fc7\u5f15\u5165\u7c7bWasserstein\u65b9\u5411\u6027\u5ea6\u91cf\u6765\u5904\u7406\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4ef7\u503c\u5206\u5e03\uff0c\u76f8\u6bd4\u4f20\u7edfGAE\u80fd\u66f4\u597d\u5730\u5904\u7406\u7cfb\u7edf\u968f\u673a\u6027\u548c\u566a\u58f0", "motivation": "\u4f20\u7edf\u7684\u5e7f\u4e49\u4f18\u52bf\u4f30\u8ba1(GAE)\u867d\u7136\u80fd\u964d\u4f4e\u7b56\u7565\u68af\u5ea6\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u4f46\u65e0\u6cd5\u5904\u7406\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4ef7\u503c\u5206\u5e03\u3002\u800c\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u80fd\u66f4\u597d\u5730\u6355\u6349\u7cfb\u7edf\u56fa\u6709\u7684\u968f\u673a\u6027\uff0c\u5bf9\u7cfb\u7edf\u566a\u58f0\u66f4\u52a0\u9c81\u68d2\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u4ef7\u503c\u5206\u5e03\u7684\u4f18\u52bf\u4f30\u8ba1\u65b9\u6cd5", "method": "\u5229\u7528\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u5f15\u5165\u7c7bWasserstein\u65b9\u5411\u6027\u5ea6\u91cf\uff0c\u8be5\u5ea6\u91cf\u80fd\u540c\u65f6\u8861\u91cf\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\u548c\u65b9\u5411\u5dee\u5f02\u3002\u7ed3\u5408\u6307\u6570\u52a0\u6743\u4f30\u8ba1\uff0c\u57fa\u4e8e\u8fd9\u4e2a\u65b9\u5411\u6027\u5ea6\u91cf\u63a8\u5bfc\u51fa\u5206\u5e03\u5f0fGAE(DGAE)\uff0c\u4e3a\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u63d0\u4f9b\u4f4e\u65b9\u5dee\u3001\u53ef\u63a7\u504f\u5dee\u7684\u4f18\u52bf\u4f30\u8ba1", "result": "\u5c06DGAE\u96c6\u6210\u5230\u4e09\u79cd\u4e0d\u540c\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u4e2d\uff0c\u5728\u591a\u4e2aOpenAI Gym\u73af\u5883\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0c\u4e0e\u4f7f\u7528\u4f20\u7edfGAE\u7684\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u9a8c\u8bc1\u4e86DGAE\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "\u63d0\u51fa\u7684DGAE\u65b9\u6cd5\u6210\u529f\u6269\u5c55\u4e86\u4f20\u7edfGAE\u5230\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u9886\u57df\uff0c\u901a\u8fc7\u7c7bWasserstein\u65b9\u5411\u6027\u5ea6\u91cf\u5b9e\u73b0\u4e86\u5bf9\u4ef7\u503c\u5206\u5e03\u7684\u6709\u6548\u5904\u7406\uff0c\u4e3a\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u4f18\u52bf\u4f30\u8ba1\u5de5\u5177"}}
{"id": "2507.17580", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.17580", "abs": "https://arxiv.org/abs/2507.17580", "authors": ["Amandeep Singh Bhatia", "Sabre Kais"], "title": "Enhancing Quantum Federated Learning with Fisher Information-Based Optimization", "comment": null, "summary": "Federated Learning (FL) has become increasingly popular across different\nsectors, offering a way for clients to work together to train a global model\nwithout sharing sensitive data. It involves multiple rounds of communication\nbetween the global model and participating clients, which introduces several\nchallenges like high communication costs, heterogeneous client data, prolonged\nprocessing times, and increased vulnerability to privacy threats. In recent\nyears, the convergence of federated learning and parameterized quantum circuits\nhas sparked significant research interest, with promising implications for\nfields such as healthcare and finance. By enabling decentralized training of\nquantum models, it allows clients or institutions to collaboratively enhance\nmodel performance and outcomes while preserving data privacy. Recognizing that\nFisher information can quantify the amount of information that a quantum state\ncarries under parameter changes, thereby providing insight into its geometric\nand statistical properties. We intend to leverage this property to address the\naforementioned challenges. In this work, we propose a Quantum Federated\nLearning (QFL) algorithm that makes use of the Fisher information computed on\nlocal client models, with data distributed across heterogeneous partitions.\nThis approach identifies the critical parameters that significantly influence\nthe quantum model's performance, ensuring they are preserved during the\naggregation process. Our research assessed the effectiveness and feasibility of\nQFL by comparing its performance against other variants, and exploring the\nbenefits of incorporating Fisher information in QFL settings. Experimental\nresults on ADNI and MNIST datasets demonstrate the effectiveness of our\napproach in achieving better performance and robustness against the quantum\nfederated averaging method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFisher\u4fe1\u606f\u7684\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u4fdd\u62a4\u5173\u952e\u53c2\u6570\u6765\u63d0\u5347\u5206\u5e03\u5f0f\u91cf\u5b50\u6a21\u578b\u8bad\u7ec3\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u901a\u4fe1\u6210\u672c\u9ad8\u3001\u5ba2\u6237\u7aef\u6570\u636e\u5f02\u6784\u3001\u5904\u7406\u65f6\u95f4\u957f\u548c\u9690\u79c1\u5a01\u80c1\u7b49\u6311\u6218\u3002\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u7684\u5174\u8d77\u4e3a\u533b\u7597\u548c\u91d1\u878d\u7b49\u9886\u57df\u5e26\u6765\u4e86\u65b0\u673a\u9047\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002Fisher\u4fe1\u606f\u80fd\u591f\u91cf\u5316\u91cf\u5b50\u6001\u5728\u53c2\u6570\u53d8\u5316\u4e0b\u643a\u5e26\u7684\u4fe1\u606f\u91cf\uff0c\u53ef\u7528\u4e8e\u6539\u5584\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u5229\u7528\u5728\u672c\u5730\u5ba2\u6237\u7aef\u6a21\u578b\u4e0a\u8ba1\u7b97\u7684Fisher\u4fe1\u606f\uff0c\u6570\u636e\u5206\u5e03\u5728\u5f02\u6784\u5206\u533a\u4e2d\u3002\u8be5\u65b9\u6cd5\u8bc6\u522b\u5bf9\u91cf\u5b50\u6a21\u578b\u6027\u80fd\u6709\u91cd\u5927\u5f71\u54cd\u7684\u5173\u952e\u53c2\u6570\uff0c\u5e76\u786e\u4fdd\u8fd9\u4e9b\u53c2\u6570\u5728\u805a\u5408\u8fc7\u7a0b\u4e2d\u5f97\u5230\u4fdd\u62a4\u3002", "result": "\u5728ADNI\u548cMNIST\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u91cf\u5b50\u8054\u90a6\u5e73\u5747\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5728\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u4e2d\u878d\u5165Fisher\u4fe1\u606f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8eFisher\u4fe1\u606f\u7684\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u4fdd\u62a4\u91cd\u8981\u53c2\u6570\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6a21\u578b\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17650", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17650", "abs": "https://arxiv.org/abs/2507.17650", "authors": ["Moncef Garouani", "Ayah Barhrhouj", "Olivier Teste"], "title": "XStacking: Explanation-Guided Stacked Ensemble Learning", "comment": null, "summary": "Ensemble Machine Learning (EML) techniques, especially stacking, have been\nshown to improve predictive performance by combining multiple base models.\nHowever, they are often criticized for their lack of interpretability. In this\npaper, we introduce XStacking, an effective and inherently explainable\nframework that addresses this limitation by integrating dynamic feature\ntransformation with model-agnostic Shapley additive explanations. This enables\nstacked models to retain their predictive accuracy while becoming inherently\nexplainable. We demonstrate the effectiveness of the framework on 29 datasets,\nachieving improvements in both the predictive effectiveness of the learning\nspace and the interpretability of the resulting models. XStacking offers a\npractical and scalable solution for responsible ML.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86XStacking\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u52a8\u6001\u7279\u5f81\u8f6c\u6362\u548cShapley\u53ef\u52a0\u6027\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u96c6\u6210\u673a\u5668\u5b66\u4e60(\u7279\u522b\u662f\u5806\u53e0\u65b9\u6cd5)\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6a21\u578b\u7684\u5185\u5728\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u96c6\u6210\u673a\u5668\u5b66\u4e60\u6280\u672f(\u5c24\u5176\u662f\u5806\u53e0\u65b9\u6cd5)\u867d\u7136\u80fd\u901a\u8fc7\u7ec4\u5408\u591a\u4e2a\u57fa\u7840\u6a21\u578b\u6765\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\uff0c\u4f46\u7ecf\u5e38\u56e0\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u800c\u53d7\u5230\u6279\u8bc4\u3002\u73b0\u6709\u7684\u5806\u53e0\u6a21\u578b\u96be\u4ee5\u89e3\u91ca\u5176\u9884\u6d4b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u9700\u8981\u53ef\u89e3\u91ca\u6027\u7684\u5e94\u7528\u573a\u666f\u4e2d\u7684\u4f7f\u7528\u3002", "method": "\u63d0\u51faXStacking\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u52a8\u6001\u7279\u5f81\u8f6c\u6362\u4e0e\u6a21\u578b\u65e0\u5173\u7684Shapley\u53ef\u52a0\u6027\u89e3\u91ca\u6765\u89e3\u51b3\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u4f7f\u5806\u53e0\u6a21\u578b\u80fd\u591f\u5728\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u83b7\u5f97\u5185\u5728\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u8d1f\u8d23\u4efb\u7684\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u572829\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u7ed3\u679c\u663e\u793aXStacking\u5728\u5b66\u4e60\u7a7a\u95f4\u7684\u9884\u6d4b\u6548\u679c\u548c\u7ed3\u679c\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4e24\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u6539\u8fdb\u3002\u8be5\u6846\u67b6\u6210\u529f\u5730\u5e73\u8861\u4e86\u9884\u6d4b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "XStacking\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u96c6\u6210\u5b66\u4e60\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3a\u8d1f\u8d23\u4efb\u7684\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u5728\u4e0d\u727a\u7272\u9884\u6d4b\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u662f\u53ef\u80fd\u7684\u3002"}}
{"id": "2507.17668", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17668", "abs": "https://arxiv.org/abs/2507.17668", "authors": ["Alexander David Goldie", "Zilin Wang", "Jakob Nicolaus Foerster", "Shimon Whiteson"], "title": "How Should We Meta-Learn Reinforcement Learning Algorithms?", "comment": "Accepted paper at Reinforcement Learning Conference (RLC) 2025", "summary": "The process of meta-learning algorithms from data, instead of relying on\nmanual design, is growing in popularity as a paradigm for improving the\nperformance of machine learning systems. Meta-learning shows particular promise\nfor reinforcement learning (RL), where algorithms are often adapted from\nsupervised or unsupervised learning despite their suboptimality for RL.\nHowever, until now there has been a severe lack of comparison between different\nmeta-learning algorithms, such as using evolution to optimise over black-box\nfunctions or LLMs to propose code. In this paper, we carry out this empirical\ncomparison of the different approaches when applied to a range of meta-learned\nalgorithms which target different parts of the RL pipeline. In addition to\nmeta-train and meta-test performance, we also investigate factors including the\ninterpretability, sample cost and train time for each meta-learning algorithm.\nBased on these findings, we propose several guidelines for meta-learning new RL\nalgorithms which will help ensure that future learned algorithms are as\nperformant as possible.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e0d\u540c\u5143\u5b66\u4e60\u7b97\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u8bc1\u6bd4\u8f83\uff0c\u5305\u62ec\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u9ed1\u76d2\u51fd\u6570\u548c\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7b49\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6837\u672c\u6210\u672c\u548c\u8bad\u7ec3\u65f6\u95f4\u7b49\u56e0\u7d20\u63d0\u51fa\u4e86\u5143\u5b66\u4e60\u65b0\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6307\u5bfc\u539f\u5219\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u901a\u5e38\u4ece\u76d1\u7763\u6216\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u6539\u7f16\u800c\u6765\uff0c\u5b58\u5728\u6b21\u4f18\u6027\u95ee\u9898\u3002\u867d\u7136\u5143\u5b66\u4e60\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4e0d\u540c\u5143\u5b66\u4e60\u7b97\u6cd5\u4e4b\u95f4\u7f3a\u4e4f\u5145\u5206\u7684\u6bd4\u8f83\u7814\u7a76\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u5404\u79cd\u65b9\u6cd5\u7684\u4f18\u52a3\u3002", "method": "\u5bf9\u591a\u79cd\u5143\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5b9e\u8bc1\u6bd4\u8f83\uff0c\u5305\u62ec\u4f7f\u7528\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u9ed1\u76d2\u51fd\u6570\u548c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7b49\u65b9\u6cd5\u3002\u8bc4\u4f30\u8fd9\u4e9b\u7b97\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\u7ba1\u9053\u4e0d\u540c\u90e8\u5206\u7684\u8868\u73b0\uff0c\u8003\u8651\u5143\u8bad\u7ec3\u548c\u5143\u6d4b\u8bd5\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6837\u672c\u6210\u672c\u548c\u8bad\u7ec3\u65f6\u95f4\u7b49\u591a\u4e2a\u7ef4\u5ea6\u3002", "result": "\u901a\u8fc7\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u5143\u5b66\u4e60\u7b97\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e2d\u7684\u76f8\u5bf9\u4f18\u52bf\u548c\u52a3\u52bf\uff0c\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u7b49\u65b9\u9762\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u6bd4\u8f83\u5206\u6790\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u8bc1\u7814\u7a76\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u5143\u5b66\u4e60\u65b0\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u82e5\u5e72\u6307\u5bfc\u539f\u5219\uff0c\u65e8\u5728\u5e2e\u52a9\u786e\u4fdd\u672a\u6765\u5b66\u4e60\u5230\u7684\u7b97\u6cd5\u80fd\u591f\u8fbe\u5230\u5c3d\u53ef\u80fd\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2507.17687", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17687", "abs": "https://arxiv.org/abs/2507.17687", "authors": ["Jiazhen Chen", "Zheng Ma", "Sichao Fu", "Mingbin Feng", "Tony S. Wirjanto", "Weihua Ou"], "title": "Towards Effective Open-set Graph Class-incremental Learning", "comment": "Accepted by 33rd ACM International Conference on Multimedia (MM 2025)", "summary": "Graph class-incremental learning (GCIL) allows graph neural networks (GNNs)\nto adapt to evolving graph analytical tasks by incrementally learning new class\nknowledge while retaining knowledge of old classes. Existing GCIL methods\nprimarily focus on a closed-set assumption, where all test samples are presumed\nto belong to previously known classes. Such an assumption restricts their\napplicability in real-world scenarios, where unknown classes naturally emerge\nduring inference, and are absent during training. In this paper, we explore a\nmore challenging open-set graph class-incremental learning scenario with two\nintertwined challenges: catastrophic forgetting of old classes, which impairs\nthe detection of unknown classes, and inadequate open-set recognition, which\ndestabilizes the retention of learned knowledge. To address the above problems,\na novel OGCIL framework is proposed, which utilizes pseudo-sample embedding\ngeneration to effectively mitigate catastrophic forgetting and enable robust\ndetection of unknown classes. To be specific, a prototypical conditional\nvariational autoencoder is designed to synthesize node embeddings for old\nclasses, enabling knowledge replay without storing raw graph data. To handle\nunknown classes, we employ a mixing-based strategy to generate\nout-of-distribution (OOD) samples from pseudo in-distribution and current node\nembeddings. A novel prototypical hypersphere classification loss is further\nproposed, which anchors in-distribution embeddings to their respective class\nprototypes, while repelling OOD embeddings away. Instead of assigning all\nunknown samples into one cluster, our proposed objective function explicitly\nmodels them as outliers through prototype-aware rejection regions, ensuring a\nrobust open-set recognition. Extensive experiments on five benchmarks\ndemonstrate the effectiveness of OGCIL over existing GCIL and open-set GNN\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e86OGCIL\u6846\u67b6\uff0c\u89e3\u51b3\u5f00\u653e\u96c6\u56fe\u7c7b\u589e\u91cf\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u539f\u578b\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u751f\u6210\u4f2a\u6837\u672c\u5d4c\u5165\u6765\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5e76\u4f7f\u7528\u6df7\u5408\u7b56\u7565\u548c\u539f\u578b\u8d85\u7403\u5206\u7c7b\u635f\u5931\u6765\u68c0\u6d4b\u672a\u77e5\u7c7b\u522b\u3002", "motivation": "\u73b0\u6709\u56fe\u7c7b\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\u5047\u8bbe\u6240\u6709\u6d4b\u8bd5\u6837\u672c\u90fd\u5c5e\u4e8e\u5df2\u77e5\u7c7b\u522b\uff08\u5c01\u95ed\u96c6\u5047\u8bbe\uff09\uff0c\u4f46\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u4f1a\u51fa\u73b0\u8bad\u7ec3\u65f6\u672a\u89c1\u8fc7\u7684\u672a\u77e5\u7c7b\u522b\u3002\u8fd9\u79cd\u5f00\u653e\u96c6\u573a\u666f\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a\u5bf9\u65e7\u7c7b\u522b\u7684\u707e\u96be\u6027\u9057\u5fd8\u4f1a\u5f71\u54cd\u672a\u77e5\u7c7b\u522b\u68c0\u6d4b\uff0c\u800c\u4e0d\u5145\u5206\u7684\u5f00\u653e\u96c6\u8bc6\u522b\u4f1a\u7834\u574f\u5df2\u5b66\u77e5\u8bc6\u7684\u4fdd\u6301\u3002", "method": "\u63d0\u51faOGCIL\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1\uff09\u539f\u578b\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5408\u6210\u65e7\u7c7b\u522b\u7684\u8282\u70b9\u5d4c\u5165\uff0c\u5b9e\u73b0\u77e5\u8bc6\u91cd\u653e\u800c\u65e0\u9700\u5b58\u50a8\u539f\u59cb\u56fe\u6570\u636e\uff1b2\uff09\u57fa\u4e8e\u6df7\u5408\u7684\u7b56\u7565\u4ece\u4f2a\u5206\u5e03\u5185\u6837\u672c\u548c\u5f53\u524d\u8282\u70b9\u5d4c\u5165\u751f\u6210\u5206\u5e03\u5916\uff08OOD\uff09\u6837\u672c\uff1b3\uff09\u539f\u578b\u8d85\u7403\u5206\u7c7b\u635f\u5931\uff0c\u5c06\u5206\u5e03\u5185\u5d4c\u5165\u951a\u5b9a\u5230\u5404\u81ea\u7684\u7c7b\u522b\u539f\u578b\uff0c\u540c\u65f6\u6392\u65a5OOD\u5d4c\u5165\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOGCIL\u5728\u73b0\u6709\u56fe\u7c7b\u589e\u91cf\u5b66\u4e60\u548c\u5f00\u653e\u96c6\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u96c6\u56fe\u7c7b\u589e\u91cf\u5b66\u4e60\u95ee\u9898\u3002", "conclusion": "OGCIL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5f00\u653e\u96c6\u56fe\u7c7b\u589e\u91cf\u5b66\u4e60\u7684\u6311\u6218\uff0c\u901a\u8fc7\u4f2a\u6837\u672c\u5d4c\u5165\u751f\u6210\u6709\u6548\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u901a\u8fc7\u539f\u578b\u611f\u77e5\u7684\u62d2\u7edd\u533a\u57df\u5b9e\u73b0\u9c81\u68d2\u7684\u5f00\u653e\u96c6\u8bc6\u522b\uff0c\u4e3a\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17692", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.17692", "abs": "https://arxiv.org/abs/2507.17692", "authors": ["Jialiang Wang", "Xianming Liu", "Xiong Zhou", "Gangfeng Hu", "Deming Zhai", "Junjun Jiang", "Xiangyang Ji"], "title": "Joint Asymmetric Loss for Learning with Noisy Labels", "comment": "Accepted by ICCV 2025", "summary": "Learning with noisy labels is a crucial task for training accurate deep\nneural networks. To mitigate label noise, prior studies have proposed various\nrobust loss functions, particularly symmetric losses. Nevertheless, symmetric\nlosses usually suffer from the underfitting issue due to the overly strict\nconstraint. To address this problem, the Active Passive Loss (APL) jointly\noptimizes an active and a passive loss to mutually enhance the overall fitting\nability. Within APL, symmetric losses have been successfully extended, yielding\nadvanced robust loss functions. Despite these advancements, emerging\ntheoretical analyses indicate that asymmetric losses, a new class of robust\nloss functions, possess superior properties compared to symmetric losses.\nHowever, existing asymmetric losses are not compatible with advanced\noptimization frameworks such as APL, limiting their potential and\napplicability. Motivated by this theoretical gap and the prospect of asymmetric\nlosses, we extend the asymmetric loss to the more complex passive loss scenario\nand propose the Asymetric Mean Square Error (AMSE), a novel asymmetric loss. We\nrigorously establish the necessary and sufficient condition under which AMSE\nsatisfies the asymmetric condition. By substituting the traditional symmetric\npassive loss in APL with our proposed AMSE, we introduce a novel robust loss\nframework termed Joint Asymmetric Loss (JAL). Extensive experiments demonstrate\nthe effectiveness of our method in mitigating label noise. Code available at:\nhttps://github.com/cswjl/joint-asymmetric-loss", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5e26\u566a\u58f0\u6807\u7b7e\u5b66\u4e60\u4e2d\u5bf9\u79f0\u635f\u5931\u51fd\u6570\u5b58\u5728\u6b20\u62df\u5408\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u975e\u5bf9\u79f0\u5747\u65b9\u8bef\u5dee(AMSE)\u635f\u5931\u51fd\u6570\uff0c\u5e76\u7ed3\u5408\u4e3b\u52a8\u88ab\u52a8\u635f\u5931\u6846\u67b6\u6784\u5efa\u4e86\u8054\u5408\u975e\u5bf9\u79f0\u635f\u5931(JAL)\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u4e86\u4f18\u5f02\u7684\u6297\u566a\u58f0\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u79f0\u635f\u5931\u51fd\u6570\u5728\u5904\u7406\u6807\u7b7e\u566a\u58f0\u65f6\u5b58\u5728\u8fc7\u5ea6\u4e25\u683c\u7ea6\u675f\u5bfc\u81f4\u7684\u6b20\u62df\u5408\u95ee\u9898\uff0c\u800c\u65b0\u5174\u7684\u975e\u5bf9\u79f0\u635f\u5931\u51fd\u6570\u867d\u7136\u7406\u8bba\u4e0a\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u4f46\u65e0\u6cd5\u4e0e\u5148\u8fdb\u7684\u4f18\u5316\u6846\u67b6(\u5982APL)\u517c\u5bb9\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u5c06\u975e\u5bf9\u79f0\u635f\u5931\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u88ab\u52a8\u635f\u5931\u573a\u666f\uff0c\u63d0\u51fa\u975e\u5bf9\u79f0\u5747\u65b9\u8bef\u5dee(AMSE)\u635f\u5931\u51fd\u6570\uff0c\u5e76\u4e25\u683c\u5efa\u7acb\u4e86AMSE\u6ee1\u8db3\u975e\u5bf9\u79f0\u6761\u4ef6\u7684\u5145\u8981\u6761\u4ef6\u3002\u901a\u8fc7\u7528AMSE\u66ff\u6362APL\u6846\u67b6\u4e2d\u7684\u4f20\u7edf\u5bf9\u79f0\u88ab\u52a8\u635f\u5931\uff0c\u6784\u5efa\u4e86\u8054\u5408\u975e\u5bf9\u79f0\u635f\u5931(JAL)\u6846\u67b6\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u7f13\u89e3\u6807\u7b7e\u566a\u58f0\u65b9\u9762\u7684\u6709\u6548\u6027\uff0cJAL\u6846\u67b6\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u5e26\u566a\u58f0\u6807\u7b7e\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u6210\u529f\u5c06\u975e\u5bf9\u79f0\u635f\u5931\u51fd\u6570\u6269\u5c55\u5230\u4e3b\u52a8\u88ab\u52a8\u635f\u5931\u4f18\u5316\u6846\u67b6\u4e2d\uff0c\u63d0\u51fa\u7684JAL\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u79f0\u635f\u5931\u51fd\u6570\u7684\u6b20\u62df\u5408\u95ee\u9898\uff0c\u4e3a\u5e26\u566a\u58f0\u6807\u7b7e\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u9c81\u68d2\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2507.17706", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17706", "abs": "https://arxiv.org/abs/2507.17706", "authors": ["Taha Ceritli", "Ondrej Bohdal", "Mete Ozay", "Jijoong Moon", "Kyeng-Hun Lee", "Hyeonmok Ko", "Umberto Michieli"], "title": "HydraOpt: Navigating the Efficiency-Performance Trade-off of Adapter Merging", "comment": null, "summary": "Large language models (LLMs) often leverage adapters, such as low-rank-based\nadapters, to achieve strong performance on downstream tasks. However, storing a\nseparate adapter for each task significantly increases memory requirements,\nposing a challenge for resource-constrained environments such as mobile\ndevices. Although model merging techniques can reduce storage costs, they\ntypically result in substantial performance degradation. In this work, we\nintroduce HydraOpt, a new model merging technique that capitalizes on the\ninherent similarities between the matrices of low-rank adapters. Unlike\nexisting methods that produce a fixed trade-off between storage size and\nperformance, HydraOpt allows us to navigate this spectrum of efficiency and\nperformance. Our experiments show that HydraOpt significantly reduces storage\nsize (48% reduction) compared to storing all adapters, while achieving\ncompetitive performance (0.2-1.8% drop). Furthermore, it outperforms existing\nmerging techniques in terms of performance at the same or slightly worse\nstorage efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HydraOpt\uff0c\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u5408\u5e76\u6280\u672f\uff0c\u901a\u8fc7\u5229\u7528\u4f4e\u79e9\u9002\u914d\u5668\u77e9\u9635\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u5728\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u9700\u6c42\uff0848%\u51cf\u5c11\uff09\u7684\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u80fd\uff08\u4ec50.2-1.8%\u6027\u80fd\u4e0b\u964d\uff09\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u9002\u914d\u5668\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u83b7\u5f97\u5f3a\u6027\u80fd\uff0c\u4f46\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u5b58\u50a8\u5355\u72ec\u7684\u9002\u914d\u5668\u4f1a\u663e\u8457\u589e\u52a0\u5185\u5b58\u9700\u6c42\uff0c\u5728\u79fb\u52a8\u8bbe\u5907\u7b49\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u6784\u6210\u6311\u6218\u3002\u73b0\u6709\u7684\u6a21\u578b\u5408\u5e76\u6280\u672f\u867d\u7136\u80fd\u51cf\u5c11\u5b58\u50a8\u6210\u672c\uff0c\u4f46\u901a\u5e38\u4f1a\u5bfc\u81f4\u5927\u5e45\u6027\u80fd\u4e0b\u964d\u3002", "method": "HydraOpt\u662f\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u5408\u5e76\u6280\u672f\uff0c\u901a\u8fc7\u5229\u7528\u4f4e\u79e9\u9002\u914d\u5668\u77e9\u9635\u4e4b\u95f4\u7684\u56fa\u6709\u76f8\u4f3c\u6027\u6765\u5de5\u4f5c\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u4ea7\u751f\u5b58\u50a8\u5927\u5c0f\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u56fa\u5b9a\u6743\u8861\u4e0d\u540c\uff0cHydraOpt\u5141\u8bb8\u5728\u6548\u7387\u548c\u6027\u80fd\u7684\u8c31\u7cfb\u4e2d\u8fdb\u884c\u5bfc\u822a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5b58\u50a8\u6240\u6709\u9002\u914d\u5668\u76f8\u6bd4\uff0cHydraOpt\u663e\u8457\u51cf\u5c11\u4e86\u5b58\u50a8\u5927\u5c0f\uff0848%\u51cf\u5c11\uff09\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u80fd\uff080.2-1.8%\u7684\u6027\u80fd\u4e0b\u964d\uff09\u3002\u5728\u76f8\u540c\u6216\u7565\u5dee\u7684\u5b58\u50a8\u6548\u7387\u4e0b\uff0c\u5b83\u5728\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u5408\u5e76\u6280\u672f\u3002", "conclusion": "HydraOpt\u6210\u529f\u89e3\u51b3\u4e86\u9002\u914d\u5668\u5b58\u50a8\u7684\u5185\u5b58\u6311\u6218\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5408\u5e76\u6280\u672f\u5b9e\u73b0\u4e86\u5b58\u50a8\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u7684\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.17731", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17731", "abs": "https://arxiv.org/abs/2507.17731", "authors": ["Zihao Li", "Zhichen Zeng", "Xiao Lin", "Feihao Fang", "Yanru Qu", "Zhe Xu", "Zhining Liu", "Xuying Ning", "Tianxin Wei", "Ge Liu", "Hanghang Tong", "Jingrui He"], "title": "Flow Matching Meets Biology and Life Science: A Survey", "comment": "Preprint, 27 pages", "summary": "Over the past decade, advances in generative modeling, such as generative\nadversarial networks, masked autoencoders, and diffusion models, have\nsignificantly transformed biological research and discovery, enabling\nbreakthroughs in molecule design, protein generation, drug discovery, and\nbeyond. At the same time, biological applications have served as valuable\ntestbeds for evaluating the capabilities of generative models. Recently, flow\nmatching has emerged as a powerful and efficient alternative to diffusion-based\ngenerative modeling, with growing interest in its application to problems in\nbiology and life sciences. This paper presents the first comprehensive survey\nof recent developments in flow matching and its applications in biological\ndomains. We begin by systematically reviewing the foundations and variants of\nflow matching, and then categorize its applications into three major areas:\nbiological sequence modeling, molecule generation and design, and peptide and\nprotein generation. For each, we provide an in-depth review of recent progress.\nWe also summarize commonly used datasets and software tools, and conclude with\na discussion of potential future directions. The corresponding curated\nresources are available at\nhttps://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology.", "AI": {"tldr": "\u8fd9\u662f\u7b2c\u4e00\u7bc7\u5168\u9762\u7efc\u8ff0\u6d41\u5339\u914d(flow matching)\u5728\u751f\u7269\u5b66\u9886\u57df\u5e94\u7528\u7684\u8bba\u6587\uff0c\u7cfb\u7edf\u6027\u5730\u56de\u987e\u4e86\u6d41\u5339\u914d\u7684\u57fa\u7840\u7406\u8bba\u53ca\u5176\u5728\u751f\u7269\u5e8f\u5217\u5efa\u6a21\u3001\u5206\u5b50\u751f\u6210\u8bbe\u8ba1\u3001\u80bd\u548c\u86cb\u767d\u8d28\u751f\u6210\u4e09\u4e2a\u4e3b\u8981\u751f\u7269\u5b66\u9886\u57df\u7684\u5e94\u7528\u8fdb\u5c55\u3002", "motivation": "\u8fd1\u5341\u5e74\u6765\uff0c\u751f\u6210\u5f0f\u5efa\u6a21(\u5982GAN\u3001\u63a9\u7801\u81ea\u7f16\u7801\u5668\u3001\u6269\u6563\u6a21\u578b)\u663e\u8457\u63a8\u52a8\u4e86\u751f\u7269\u5b66\u7814\u7a76\u548c\u53d1\u73b0\uff0c\u800c\u6d41\u5339\u914d\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5927\u4e14\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u751f\u7269\u5b66\u548c\u751f\u547d\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u7efc\u8ff0\u7814\u7a76\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff0c\u9996\u5148\u7cfb\u7edf\u6027\u56de\u987e\u6d41\u5339\u914d\u7684\u57fa\u7840\u7406\u8bba\u548c\u53d8\u4f53\uff0c\u7136\u540e\u5c06\u5176\u751f\u7269\u5b66\u5e94\u7528\u5206\u4e3a\u4e09\u4e2a\u4e3b\u8981\u9886\u57df\u8fdb\u884c\u5206\u7c7b\u6574\u7406\uff1a\u751f\u7269\u5e8f\u5217\u5efa\u6a21\u3001\u5206\u5b50\u751f\u6210\u4e0e\u8bbe\u8ba1\u3001\u80bd\u548c\u86cb\u767d\u8d28\u751f\u6210\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "result": "\u63d0\u4f9b\u4e86\u6d41\u5339\u914d\u5728\u751f\u7269\u5b66\u9886\u57df\u5e94\u7528\u7684\u5168\u9762\u6982\u89c8\uff0c\u603b\u7ed3\u4e86\u5e38\u7528\u7684\u6570\u636e\u96c6\u548c\u8f6f\u4ef6\u5de5\u5177\uff0c\u5e76\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u7b56\u5212\u8d44\u6e90\u5e93(https://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology)\u4f9b\u7814\u7a76\u8005\u4f7f\u7528\u3002", "conclusion": "\u6d41\u5339\u914d\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5174\u7684\u751f\u6210\u5efa\u6a21\u6280\u672f\uff0c\u5728\u751f\u7269\u5b66\u5404\u4e2a\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u8bba\u6587\u8ba8\u8bba\u4e86\u672a\u6765\u53ef\u80fd\u7684\u53d1\u5c55\u65b9\u5411\uff0c\u4e3a\u8be5\u4ea4\u53c9\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2507.17746", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.17746", "abs": "https://arxiv.org/abs/2507.17746", "authors": ["Anisha Gunjal", "Anthony Wang", "Elaine Lau", "Vaskar Nath", "Bing Liu", "Sean Hendryx"], "title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "comment": null, "summary": "Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world\ntasks often requires balancing objective and subjective evaluation criteria.\nHowever, many such tasks lack a single, unambiguous ground truth-making it\ndifficult to define reliable reward signals for post-training language models.\nWhile traditional preference-based methods offer a workaround, they rely on\nopaque reward functions that are difficult to interpret and prone to spurious\ncorrelations. We introduce $\\textbf{Rubrics as Rewards}$ (RaR), a framework\nthat uses structured, checklist-style rubrics as interpretable reward signals\nfor on-policy training with GRPO. Our best RaR method yields up to a $28\\%$\nrelative improvement on HealthBench-1k compared to simple Likert-based\napproaches, while matching or surpassing the performance of reward signals\nderived from expert-written references. By treating rubrics as structured\nreward signals, we show that RaR enables smaller-scale judge models to better\nalign with human preferences and sustain robust performance across model\nscales.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"Rubrics as Rewards\"(RaR)\u6846\u67b6\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u6e05\u5355\u5f0f\u8bc4\u5206\u6807\u51c6\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u5956\u52b1\u4fe1\u53f7\u6765\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u5728HealthBench-1k\u4e0a\u76f8\u6bd4\u7b80\u5355Likert\u65b9\u6cd5\u83b7\u5f97\u4e8628%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u5f80\u5f80\u7f3a\u4e4f\u660e\u786e\u7684\u771f\u5b9e\u6807\u51c6\uff0c\u96be\u4ee5\u4e3a\u8bad\u7ec3\u540e\u7684\u8bed\u8a00\u6a21\u578b\u5b9a\u4e49\u53ef\u9760\u7684\u5956\u52b1\u4fe1\u53f7\u3002\u4f20\u7edf\u57fa\u4e8e\u504f\u597d\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u900f\u660e\u4e14\u5bb9\u6613\u4ea7\u751f\u865a\u5047\u5173\u8054\u7684\u5956\u52b1\u51fd\u6570\uff0c\u9700\u8981\u66f4\u53ef\u89e3\u91ca\u548c\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\"Rubrics as Rewards\"(RaR)\u6846\u67b6\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u7684\u6e05\u5355\u5f0f\u8bc4\u5206\u6807\u51c6\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u7ed3\u5408GRPO\u8fdb\u884c\u5728\u7ebf\u7b56\u7565\u8bad\u7ec3\u3002\u5c06\u8bc4\u5206\u6807\u51c6\u89c6\u4e3a\u7ed3\u6784\u5316\u5956\u52b1\u4fe1\u53f7\uff0c\u4f7f\u5c0f\u89c4\u6a21\u5224\u65ad\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u3002", "result": "\u6700\u4f73RaR\u65b9\u6cd5\u5728HealthBench-1k\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u7b80\u5355Likert\u65b9\u6cd5\u83b7\u5f97\u4e86\u9ad8\u8fbe28%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u540c\u65f6\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u57fa\u4e8e\u4e13\u5bb6\u7f16\u5199\u53c2\u8003\u7b54\u6848\u7684\u5956\u52b1\u4fe1\u53f7\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u4fdd\u6301\u7a33\u5065\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "RaR\u6846\u67b6\u901a\u8fc7\u4f7f\u7528\u7ed3\u6784\u5316\u8bc4\u5206\u6807\u51c6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u5956\u52b1\u51fd\u6570\u4e0d\u900f\u660e\u548c\u96be\u4ee5\u89e3\u91ca\u7684\u95ee\u9898\uff0c\u4f7f\u5c0f\u89c4\u6a21\u5224\u65ad\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\u4e0a\u4fdd\u6301\u7a33\u5065\u6027\u80fd\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u5728\u73b0\u5b9e\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}

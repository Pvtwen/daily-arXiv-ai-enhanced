{"id": "2509.14039", "categories": ["stat.ML", "cs.LG", "math.OC", "60F05, 62L20, 93E35"], "pdf": "https://arxiv.org/pdf/2509.14039", "abs": "https://arxiv.org/abs/2509.14039", "authors": ["Marat Khusainov", "Marina Sheshukova", "Alain Durmus", "Sergey Samsonov"], "title": "On the Rate of Gaussian Approximation for Linear Regression Problems", "comment": null, "summary": "In this paper, we consider the problem of Gaussian approximation for the\nonline linear regression task. We derive the corresponding rates for the\nsetting of a constant learning rate and study the explicit dependence of the\nconvergence rate upon the problem dimension $d$ and quantities related to the\ndesign matrix. When the number of iterations $n$ is known in advance, our\nresults yield the rate of normal approximation of order $\\sqrt{\\log{n}/n}$,\nprovided that the sample size $n$ is large enough.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u7ebf\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u7684\u9ad8\u65af\u8fd1\u4f3c\u95ee\u9898\uff0c\u5206\u6790\u4e86\u6052\u5b9a\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e0b\u7684\u6536\u655b\u901f\u7387\u53ca\u5176\u4e0e\u95ee\u9898\u7ef4\u5ea6d\u548c\u8bbe\u8ba1\u77e9\u9635\u76f8\u5173\u91cf\u7684\u663e\u5f0f\u4f9d\u8d56\u5173\u7cfb", "motivation": "\u7814\u7a76\u5728\u7ebf\u7ebf\u6027\u56de\u5f52\u4e2d\u9ad8\u65af\u8fd1\u4f3c\u7684\u6536\u655b\u6027\u8d28\uff0c\u7279\u522b\u662f\u5728\u6052\u5b9a\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e0b\uff0c\u63a2\u7d22\u6536\u655b\u901f\u7387\u4e0e\u95ee\u9898\u7ef4\u5ea6\u3001\u8bbe\u8ba1\u77e9\u9635\u7279\u6027\u4e4b\u95f4\u7684\u6570\u5b66\u5173\u7cfb", "method": "\u63a8\u5bfc\u6052\u5b9a\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e0b\u7684\u9ad8\u65af\u8fd1\u4f3c\u7406\u8bba\uff0c\u5206\u6790\u6536\u655b\u901f\u7387\u5bf9\u7ef4\u5ea6d\u548c\u8bbe\u8ba1\u77e9\u9635\u76f8\u5173\u91cf\u7684\u663e\u5f0f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5efa\u7acb\u6570\u5b66\u7406\u8bba\u6846\u67b6", "result": "\u5f53\u8fed\u4ee3\u6b21\u6570n\u5df2\u77e5\u65f6\uff0c\u5728\u8db3\u591f\u5927\u7684\u6837\u672c\u91cfn\u4e0b\uff0c\u83b7\u5f97\u4e86\u9636\u6570\u4e3a\u221a(log n/n)\u7684\u6b63\u6001\u8fd1\u4f3c\u901f\u7387", "conclusion": "\u8bba\u6587\u4e3a\u5728\u7ebf\u7ebf\u6027\u56de\u5f52\u7684\u9ad8\u65af\u8fd1\u4f3c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u8bc1\u660e\u4e86\u5728\u9002\u5f53\u6761\u4ef6\u4e0b\u53ef\u4ee5\u83b7\u5f97\u5feb\u901f\u7684\u6b63\u6001\u6536\u655b\u901f\u7387\uff0c\u5bf9\u9ad8\u7ef4\u5728\u7ebf\u5b66\u4e60\u7406\u8bba\u6709\u91cd\u8981\u8d21\u732e"}}
{"id": "2509.13805", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.13805", "abs": "https://arxiv.org/abs/2509.13805", "authors": ["Florian Wiesner", "Matthias Wessling", "Stephen Baek"], "title": "Towards a Physics Foundation Model", "comment": null, "summary": "Foundation models have revolutionized natural language processing through a\n``train once, deploy anywhere'' paradigm, where a single pre-trained model\nadapts to countless downstream tasks without retraining. Access to a Physics\nFoundation Model (PFM) would be transformative -- democratizing access to\nhigh-fidelity simulations, accelerating scientific discovery, and eliminating\nthe need for specialized solver development. Yet current physics-aware machine\nlearning approaches remain fundamentally limited to single, narrow domains and\nrequire retraining for each new system. We present the General Physics\nTransformer (GPhyT), trained on 1.8 TB of diverse simulation data, that\ndemonstrates foundation model capabilities are achievable for physics. Our key\ninsight is that transformers can learn to infer governing dynamics from\ncontext, enabling a single model to simulate fluid-solid interactions, shock\nwaves, thermal convection, and multi-phase dynamics without being told the\nunderlying equations. GPhyT achieves three critical breakthroughs: (1) superior\nperformance across multiple physics domains, outperforming specialized\narchitectures by up to 29x, (2) zero-shot generalization to entirely unseen\nphysical systems through in-context learning, and (3) stable long-term\npredictions through 50-timestep rollouts. By establishing that a single model\ncan learn generalizable physical principles from data alone, this work opens\nthe path toward a universal PFM that could transform computational science and\nengineering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u901a\u7528\u7269\u7406\u53d8\u6362\u5668(GPhyT)\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u7269\u7406\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u591f\u5728\u591a\u4e2a\u7269\u7406\u9886\u57df\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u6a21\u62df\u5404\u79cd\u7269\u7406\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u7269\u7406\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5c40\u9650\u4e8e\u5355\u4e00\u72ed\u7a84\u9886\u57df\uff0c\u6bcf\u6b21\u9762\u5bf9\u65b0\u7cfb\u7edf\u90fd\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u3002\u7269\u7406\u57fa\u7840\u6a21\u578b(PFM)\u53ef\u4ee5\u5f7b\u5e95\u6539\u53d8\u8fd9\u4e00\u73b0\u72b6\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u4eff\u771f\u7684\u6c11\u4e3b\u5316\uff0c\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\uff0c\u5e76\u6d88\u9664\u5bf9\u4e13\u4e1a\u6c42\u89e3\u5668\u5f00\u53d1\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528Transformer\u67b6\u6784\uff0c\u57281.8TB\u7684\u591a\u6837\u5316\u4eff\u771f\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u5173\u952e\u6d1e\u5bdf\u662fTransformer\u53ef\u4ee5\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a8\u65ad\u63a7\u5236\u52a8\u529b\u5b66\uff0c\u4f7f\u5355\u4e2a\u6a21\u578b\u80fd\u591f\u6a21\u62df\u6d41\u4f53-\u56fa\u4f53\u76f8\u4e92\u4f5c\u7528\u3001\u51b2\u51fb\u6ce2\u3001\u70ed\u5bf9\u6d41\u548c\u591a\u76f8\u52a8\u529b\u5b66\uff0c\u800c\u65e0\u9700\u88ab\u544a\u77e5\u57fa\u7840\u65b9\u7a0b\u3002", "result": "GPhyT\u5b9e\u73b0\u4e86\u4e09\u4e2a\u5173\u952e\u7a81\u7834\uff1a(1)\u5728\u591a\u4e2a\u7269\u7406\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u6bd4\u4e13\u4e1a\u67b6\u6784\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe29\u500d\uff1b(2)\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u5230\u5b8c\u5168\u672a\u89c1\u8fc7\u7684\u7269\u7406\u7cfb\u7edf\uff1b(3)\u901a\u8fc750\u4e2a\u65f6\u95f4\u6b65\u957f\u7684\u6eda\u52a8\u9884\u6d4b\u5b9e\u73b0\u7a33\u5b9a\u7684\u957f\u671f\u9884\u6d4b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8bc1\u660e\u4e86\u5355\u4e2a\u6a21\u578b\u53ef\u4ee5\u4ec5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u53ef\u6cdb\u5316\u7684\u7269\u7406\u539f\u7406\uff0c\u4e3a\u901a\u5411\u53ef\u80fd\u6539\u53d8\u8ba1\u7b97\u79d1\u5b66\u4e0e\u5de5\u7a0b\u7684\u901a\u7528\u7269\u7406\u57fa\u7840\u6a21\u578b\u5f00\u8f9f\u4e86\u9053\u8def\u3002"}}
{"id": "2509.14225", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.14225", "abs": "https://arxiv.org/abs/2509.14225", "authors": ["Benjamin Sterling", "Yousef El-Laham", "M\u00f3nica F. Bugallo"], "title": "Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics", "comment": "5 pages, 2 figures, 1 table", "summary": "Recent advances in generative artificial intelligence applications have\nraised new data security concerns. This paper focuses on defending diffusion\nmodels against membership inference attacks. This type of attack occurs when\nthe attacker can determine if a certain data point was used to train the model.\nAlthough diffusion models are intrinsically more resistant to membership\ninference attacks than other generative models, they are still susceptible. The\ndefense proposed here utilizes critically-damped higher-order Langevin\ndynamics, which introduces several auxiliary variables and a joint diffusion\nprocess along these variables. The idea is that the presence of auxiliary\nvariables mixes external randomness that helps to corrupt sensitive input data\nearlier on in the diffusion process. This concept is theoretically investigated\nand validated on a toy dataset and a speech dataset using the Area Under the\nReceiver Operating Characteristic (AUROC) curves and the FID metric.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u4e34\u754c\u963b\u5c3c\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u9632\u5fa1\u6269\u6563\u6a21\u578b\u5bf9\u6297\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u53d8\u91cf\u548c\u8054\u5408\u6269\u6563\u8fc7\u7a0b\u6765\u6df7\u5408\u5916\u90e8\u968f\u673a\u6027\uff0c\u4ece\u800c\u5728\u6269\u6563\u8fc7\u7a0b\u65e9\u671f\u7834\u574f\u654f\u611f\u8f93\u5165\u6570\u636e\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5e94\u7528\u7684\u53d1\u5c55\u5e26\u6765\u4e86\u65b0\u7684\u6570\u636e\u5b89\u5168\u95ee\u9898\uff0c\u6269\u6563\u6a21\u578b\u867d\u7136\u6bd4\u5176\u4ed6\u751f\u6210\u6a21\u578b\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u66f4\u5177\u62b5\u6297\u529b\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u88ab\u653b\u51fb\u7684\u98ce\u9669\uff0c\u9700\u8981\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u91c7\u7528\u4e34\u754c\u963b\u5c3c\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\uff0c\u5f15\u5165\u591a\u4e2a\u8f85\u52a9\u53d8\u91cf\u548c\u8054\u5408\u6269\u6563\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8f85\u52a9\u53d8\u91cf\u6df7\u5408\u5916\u90e8\u968f\u673a\u6027\u6765\u5728\u6269\u6563\u8fc7\u7a0b\u65e9\u671f\u7834\u574f\u654f\u611f\u8f93\u5165\u6570\u636e\u3002", "result": "\u5728\u73a9\u5177\u6570\u636e\u96c6\u548c\u8bed\u97f3\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4f7f\u7528AUROC\u66f2\u7ebf\u548cFID\u6307\u6807\u8bc4\u4f30\u9632\u5fa1\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8bc1\u660e\u4e86\u5176\u53ef\u884c\u6027\u3002"}}
{"id": "2509.13328", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.13328", "abs": "https://arxiv.org/abs/2509.13328", "authors": ["Danish Rizvi", "David Boyle"], "title": "Dual Actor DDPG for Airborne STAR-RIS Assisted Communications", "comment": null, "summary": "This study departs from the prevailing assumption of independent Transmission\nand Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect\nReconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a\nnovel multi-user downlink communication system that leverages a UAV-mounted\nSTAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key\ncontributions include the joint optimization of UAV trajectory, active\nbeamforming vectors at the base station, and passive RIS TRCs to enhance\ncommunication efficiency, while considering UAV energy constraints. We design\nthe TRC as a combination of discrete and continuous actions, and propose a\nnovel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The\nalgorithm relies on two separate actor networks for high-dimensional hybrid\naction space. We also propose a novel harmonic mean index (HFI)-based reward\nfunction to ensure communication fairness amongst users. For comprehensive\nanalysis, we study the impact of RIS size on UAV aerodynamics showing that it\nincreases drag and energy demand. Simulation results demonstrate that the\nproposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based\nsolutions by 24% and 97%, respectively, in accumulated reward.\nThree-dimensional UAV trajectory optimization achieves 28% higher communication\nefficiency compared to two-dimensional and altitude optimization. The HFI based\nreward function provides 41% lower QoS denial rates as compared to other\nbenchmarks. The mobile Aerial-STAR system shows superior performance over fixed\ndeployed counterparts, with the coupled phase STAR-RIS outperforming dual\nTransmit/Reflect RIS and conventional RIS setups. These findings highlight the\npotential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG\napproach in optimizing their performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u642d\u8f7dSTAR-RIS\u7684\u7a7a\u4e2d\u667a\u80fd\u53cd\u5c04\u8868\u9762\u7cfb\u7edf\uff0c\u91c7\u7528\u8026\u5408TRC\u76f8\u4f4d\u504f\u79fb\u6a21\u578b\uff0c\u901a\u8fc7DA-DDPG\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u8f68\u8ff9\u3001\u6ce2\u675f\u6210\u5f62\u548cRIS\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u7528\u6237\u901a\u4fe1\u6548\u7387\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709STAR-RIS\u7814\u7a76\u901a\u5e38\u5047\u8bbe\u4f20\u8f93\u548c\u53cd\u5c04\u7cfb\u6570\u72ec\u7acb\uff0c\u4f46\u5b9e\u9645\u4e2d\u5b58\u5728\u8026\u5408\u5173\u7cfb\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u66f4\u771f\u5b9e\u7684\u8026\u5408TRC\u6a21\u578b\uff0c\u5e76\u89e3\u51b3\u65e0\u4eba\u673a\u80fd\u91cf\u7ea6\u675f\u4e0b\u7684\u591a\u7528\u6237\u901a\u4fe1\u4f18\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faDA-DDPG\u7b97\u6cd5\uff0c\u4f7f\u7528\u53ccactor\u7f51\u7edc\u5904\u7406\u9ad8\u7ef4\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\uff1b\u8bbe\u8ba1\u8c10\u6ce2\u5747\u503c\u6307\u6570\u5956\u52b1\u51fd\u6570\u4fdd\u8bc1\u7528\u6237\u516c\u5e73\u6027\uff1b\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u4e09\u7ef4\u8f68\u8ff9\u3001\u57fa\u7ad9\u6ce2\u675f\u6210\u5f62\u548c\u88ab\u52a8RIS TRC\u914d\u7f6e\u3002", "result": "DA-DDPG\u7b97\u6cd5\u6bd4\u4f20\u7edfDDPG\u548cDQN\u5206\u522b\u63d0\u534724%\u548c97%\u7684\u7d2f\u79ef\u5956\u52b1\uff1b\u4e09\u7ef4\u8f68\u8ff9\u4f18\u5316\u6bd4\u4e8c\u7ef4\u4f18\u5316\u63d0\u534728%\u901a\u4fe1\u6548\u7387\uff1bHFI\u5956\u52b1\u51fd\u6570\u964d\u4f4e41%QoS\u62d2\u7edd\u7387\uff1b\u8026\u5408\u76f8\u4f4dSTAR-RIS\u4f18\u4e8e\u4f20\u7edfRIS\u914d\u7f6e\u3002", "conclusion": "Aerial-STAR\u7cfb\u7edf\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u63d0\u51fa\u7684DA-DDPG\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\uff0c\u8026\u5408TRC\u6a21\u578b\u548c\u4e09\u7ef4\u8f68\u8ff9\u4f18\u5316\u5bf9\u63d0\u5347\u901a\u4fe1\u6548\u7387\u548c\u516c\u5e73\u6027\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2509.13559", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13559", "abs": "https://arxiv.org/abs/2509.13559", "authors": ["Yuan Liu", "Linlong Wu", "Xuesong Cai", "M. R. Bhavani Shankar"], "title": "Environment Reconstruction in Multi-Bounce Channels with Array Partial Blockage", "comment": "Presented in EUSIPCO2025", "summary": "Extremely-large antenna arrays (ELAA) are important in applications requiring\nhigh angular resolution. However, a prominent issue is the spatial\nnon-stationary (SNS) channels due to partial blockage to the ELAA. In this\npaper, we address the scatterer localization and subsequent environment\nreconstruction considering partially blocked SNS channels. Specifically, the\nSNS effects are parametrically modeled through spatial-varying amplitudes with\nsparsity. Based on the established signal model, the graph-based\ndictionary-aided multi-bounce space-alternating generalized\nexpectation-maximization (GM-SAGE) algorithm is applied to estimate the channel\nparameters and the channel sparsity is empirically detected along with\namplitude estimation. To validate the proposed approach, we generate\nmulti-bounce paths through ray tracing (RT) simulations, where the SNS channels\ncaused by partial blockage could be configured flexibly. The simulation results\ndemonstrate the robustness of the proposed approach in dealing with the SNS\nchannels.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u8d85\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217(ELAA)\u4e2d\u7684\u7a7a\u95f4\u975e\u5e73\u7a33(SNS)\u4fe1\u9053\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u56fe\u6a21\u578b\u7684\u591a\u8df3\u7a7a\u95f4\u4ea4\u66ff\u5e7f\u4e49\u671f\u671b\u6700\u5927\u5316(GM-SAGE)\u7b97\u6cd5\uff0c\u7528\u4e8e\u6563\u5c04\u4f53\u5b9a\u4f4d\u548c\u73af\u5883\u91cd\u5efa\u3002", "motivation": "\u8d85\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u5728\u9700\u8981\u9ad8\u89d2\u5ea6\u5206\u8fa8\u7387\u7684\u5e94\u7528\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u5b58\u5728\u7531\u4e8e\u90e8\u5206\u906e\u6321\u5bfc\u81f4\u7684\u7a7a\u95f4\u975e\u5e73\u7a33\u4fe1\u9053\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u6563\u5c04\u4f53\u5b9a\u4f4d\u548c\u73af\u5883\u91cd\u5efa\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u53c2\u6570\u5316\u5efa\u6a21\u7a7a\u95f4\u53d8\u5316\u7684\u5e45\u5ea6\u7a00\u758f\u6027\uff0c\u5e94\u7528\u56fe\u57fa\u5b57\u5178\u8f85\u52a9\u7684\u591a\u8df3\u7a7a\u95f4\u4ea4\u66ff\u5e7f\u4e49\u671f\u671b\u6700\u5927\u5316(GM-SAGE)\u7b97\u6cd5\u4f30\u8ba1\u4fe1\u9053\u53c2\u6570\uff0c\u5e76\u7ed3\u5408\u5e45\u5ea6\u4f30\u8ba1\u7ecf\u9a8c\u68c0\u6d4b\u4fe1\u9053\u7a00\u758f\u6027\u3002\u4f7f\u7528\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u751f\u6210\u591a\u8df3\u8def\u5f84\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5904\u7406\u7a7a\u95f4\u975e\u5e73\u7a33\u4fe1\u9053\u65b9\u9762\u8868\u73b0\u51fa\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u90e8\u5206\u906e\u6321\u5f15\u8d77\u7684\u7a7a\u95f4\u975e\u5e73\u7a33\u4fe1\u9053\u95ee\u9898\uff0c\u4e3a\u8d85\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6563\u5c04\u4f53\u5b9a\u4f4d\u548c\u73af\u5883\u91cd\u5efa\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14186", "categories": ["eess.SP", "cs.SY", "eess.SY", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2509.14186", "abs": "https://arxiv.org/abs/2509.14186", "authors": ["Patrick Vincent N. Lubenia", "Taposh Banerjee"], "title": "Quickest Change Detection with Cost-Constrained Experiment Design", "comment": null, "summary": "In the classical quickest change detection problem, an observer performs only\none experiment to monitor a stochastic process. This paper considers the case\nwhere, at each observation time, the decision-maker needs to choose between\nmultiple experiments with different information qualities and costs. The goal\nis to minimize the worst-case average detection delay subject to false alarm\nand cost constraints. An algorithm called the 2E-CUSUM Algorithm has been\ndeveloped to achieve this goal for the two-experiment case. Extensions to\nmultiple-experiment designs are also studied, and 2E-CUSUM is extended\naccordingly. Data efficiency, where the observer has the choice not to perform\nan experiment, is explored as well. The proposed algorithms are analyzed and\nshown to be asymptotically optimal.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u5b9e\u9a8c\u9009\u62e9\u7684\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\uff0c\u5f00\u53d1\u4e862E-CUSUM\u7b97\u6cd5\u6765\u6700\u5c0f\u5316\u6700\u574f\u60c5\u51b5\u5e73\u5747\u68c0\u6d4b\u5ef6\u8fdf\uff0c\u540c\u65f6\u6ee1\u8db3\u8bef\u62a5\u548c\u6210\u672c\u7ea6\u675f\u3002", "motivation": "\u4f20\u7edf\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\u4e2d\u89c2\u5bdf\u8005\u53ea\u80fd\u8fdb\u884c\u5355\u4e00\u5b9e\u9a8c\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u51b3\u7b56\u8005\u9700\u8981\u5728\u6bcf\u4e2a\u89c2\u6d4b\u65f6\u523b\u9009\u62e9\u4e0d\u540c\u4fe1\u606f\u8d28\u91cf\u548c\u6210\u672c\u7684\u591a\u91cd\u5b9e\u9a8c\u3002", "method": "\u9488\u5bf9\u4e24\u5b9e\u9a8c\u60c5\u51b5\u5f00\u53d1\u4e862E-CUSUM\u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u591a\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u540c\u65f6\u63a2\u7d22\u4e86\u6570\u636e\u6548\u7387\uff08\u53ef\u9009\u62e9\u4e0d\u8fdb\u884c\u5b9e\u9a8c\uff09\u7684\u60c5\u51b5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u7ecf\u8fc7\u5206\u6790\u88ab\u8bc1\u660e\u662f\u6e10\u8fd1\u6700\u4f18\u7684\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u5b9e\u9a8c\u9009\u62e9\u7684\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.13592", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13592", "abs": "https://arxiv.org/abs/2509.13592", "authors": ["Youval Klioui"], "title": "Fast Single-Snapshot Harmonic Recovery with 2D Sparse Arrays using BCCB Matrices", "comment": null, "summary": "We introduce an efficient implementation of sparse recovery methods for the\nproblem of harmonic estimation with 2D sparse arrays using a single snapshot.\nBy imposing a uniformity constraint on the harmonic grids of the\nsubdictionaries used in the sparse recovery problem, in addition to a mild\nconstraint on the array topology that consists in having the elements lie on a\ngrid specified in half-wavelength units, we show that the Gram matrices that\nappear in these sparse recovery methods exhibit a block-circulant with\ncirculant blocks (BCCB) structure. The BCCB structure is then exploited to\nreduce the computational complexity of the matrix-vector products that appear\nin these methods through the use of 2D fast Fourier transforms (FFT) from\nO((L1L2)^2) down to O(L1L2 log(L1L2)) operations per iterations, where L1, L2\nare the lengths of the subdictionaries used for estimating the harmonics in the\nfirst and second dimension, respectively. We experimentally verify the proposed\nimplementation using the iterative shrinkage thresholding algorithm (ISTA), the\nfast iterative shrinkage-thresholding algorithm (FISTA), and the alternating\ndirection method of multipliers (ADMM) where we observe improvements", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7a00\u758f\u6062\u590d\u65b9\u6cd5\u5b9e\u73b0\uff0c\u7528\u4e8e\u5355\u5feb\u71672D\u7a00\u758f\u9635\u5217\u8c10\u6ce2\u4f30\u8ba1\u95ee\u9898\uff0c\u901a\u8fc7\u5229\u7528BCCB\u77e9\u9635\u7ed3\u6784\u548c2D FFT\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO((L1L2)^2)\u964d\u4f4e\u5230O(L1L2 log(L1L2))", "motivation": "\u89e3\u51b32D\u7a00\u758f\u9635\u5217\u8c10\u6ce2\u4f30\u8ba1\u4e2dGram\u77e9\u9635\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981O((L1L2)^2)\u6b21\u64cd\u4f5c\uff0c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b", "method": "\u5bf9\u7a00\u758f\u6062\u590d\u95ee\u9898\u7684\u5b50\u5b57\u5178\u8c10\u6ce2\u7f51\u683c\u65bd\u52a0\u5747\u5300\u6027\u7ea6\u675f\uff0c\u5e76\u9650\u5236\u9635\u5217\u62d3\u6251\u7ed3\u6784\u4f7f\u9635\u5143\u4f4d\u4e8e\u534a\u6ce2\u957f\u5355\u4f4d\u7684\u7f51\u683c\u4e0a\uff0c\u4ece\u800c\u4f7fGram\u77e9\u9635\u5448\u73b0BCCB\u7ed3\u6784\uff0c\u5229\u75282D FFT\u52a0\u901f\u77e9\u9635-\u5411\u91cf\u4e58\u79ef\u8ba1\u7b97", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5728ISTA\u3001FISTA\u548cADMM\u7b97\u6cd5\u4e2d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u663e\u8457\u964d\u4f4e", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528BCCB\u77e9\u9635\u7ed3\u6784\u548cFFT\u6280\u672f\uff0c\u6709\u6548\u964d\u4f4e\u4e862D\u7a00\u758f\u9635\u5217\u8c10\u6ce2\u4f30\u8ba1\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u63d0\u9ad8\u4e86\u7b97\u6cd5\u6548\u7387"}}
{"id": "2509.14201", "categories": ["eess.SP", "cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.14201", "abs": "https://arxiv.org/abs/2509.14201", "authors": ["Guangjin Pan", "Liping Bai", "Zhuojun Tian", "Hui Chen", "Mehdi Bennis", "Henk Wymeersch"], "title": "Active Inference Framework for Closed-Loop Sensing, Communication, and Control in UAV Systems", "comment": "5 pages, 2 figures", "summary": "Integrated sensing and communication (ISAC) is a core technology for 6G, and\nits application to closed-loop sensing, communication, and control (SCC)\nenables various services. Existing SCC solutions often treat sensing and\ncontrol separately, leading to suboptimal performance and resource usage. In\nthis work, we introduce the active inference framework (AIF) into SCC-enabled\nunmanned aerial vehicle (UAV) systems for joint state estimation, control, and\nsensing resource allocation. By formulating a unified generative model, the\nproblem reduces to minimizing variational free energy for inference and\nexpected free energy for action planning. Simulation results show that both\ncontrol cost and sensing cost are reduced relative to baselines.", "AI": {"tldr": "\u5c06\u4e3b\u52a8\u63a8\u7406\u6846\u67b6(AIF)\u5f15\u5165\u652f\u6301SCC\u7684\u65e0\u4eba\u673a\u7cfb\u7edf\uff0c\u5b9e\u73b0\u8054\u5408\u72b6\u6001\u4f30\u8ba1\u3001\u63a7\u5236\u548c\u611f\u77e5\u8d44\u6e90\u5206\u914d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u964d\u4f4e\u4e86\u63a7\u5236\u548c\u611f\u77e5\u6210\u672c", "motivation": "\u73b0\u6709\u7684SCC\u89e3\u51b3\u65b9\u6848\u5f80\u5f80\u5c06\u611f\u77e5\u548c\u63a7\u5236\u5206\u5f00\u5904\u7406\uff0c\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\u548c\u8d44\u6e90\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u7edf\u4e00\u7684\u6846\u67b6\u6765\u4f18\u5316\u96c6\u6210\u611f\u77e5\u901a\u4fe1\u63a7\u5236", "method": "\u901a\u8fc7\u6784\u5efa\u7edf\u4e00\u7684\u751f\u6210\u6a21\u578b\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u6700\u5c0f\u5316\u53d8\u5206\u81ea\u7531\u80fd\u8fdb\u884c\u63a8\u7406\u548c\u6700\u5c0f\u5316\u671f\u671b\u81ea\u7531\u80fd\u8fdb\u884c\u52a8\u4f5c\u89c4\u5212", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63a7\u5236\u6210\u672c\u548c\u611f\u77e5\u6210\u672c\u90fd\u5f97\u5230\u4e86\u964d\u4f4e", "conclusion": "\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\u4e3a\u96c6\u6210\u611f\u77e5\u901a\u4fe1\u63a7\u5236\u7684\u65e0\u4eba\u673a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8054\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u6539\u5584\u72b6\u6001\u4f30\u8ba1\u3001\u63a7\u5236\u548c\u8d44\u6e90\u5206\u914d\u6027\u80fd"}}
{"id": "2509.13600", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13600", "abs": "https://arxiv.org/abs/2509.13600", "authors": ["Argyris Kriezis", "Yu-Hsuan Chen", "Dennis Akos", "Sherman Lo", "Todd Walter"], "title": "GNSS Jamming and Spoofing Monitoring Using Low-Cost COTS Receivers", "comment": "Submitted to ION NAVIGATION Journal", "summary": "The Global Navigation Satellite System (GNSS) is increasingly vulnerable to\nradio frequency interference (RFI), including jamming and spoofing, which\nthreaten the integrity of navigation and timing services. This paper presents a\nmethodology for detecting and classifying RFI events using low-cost commercial\noff-the-shelf (COTS) GNSS receivers. By combining carrier-to-noise ratio (C/N0)\nmeasurements with a calibrated received power metric, a two-dimensional\ndetection space is constructed to identify and distinguish nominal, jammed,\nspoofed, and blocked signal conditions. The method is validated through both\ncontrolled jamming tests in Norway and real-world deployments in Poland, and\nthe Southeast Mediterranean which have experienced such conditions. Results\ndemonstrate that COTS-based detection, when properly calibrated, offers a\nviable and effective approach for GNSS RFI monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u4f4e\u6210\u672c\u5546\u7528GNSS\u63a5\u6536\u673a\u68c0\u6d4b\u548c\u5206\u7c7b\u5c04\u9891\u5e72\u6270\u4e8b\u4ef6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u8f7d\u566a\u6bd4\u548c\u6821\u51c6\u63a5\u6536\u529f\u7387\u6784\u5efa\u4e8c\u7ef4\u68c0\u6d4b\u7a7a\u95f4\uff0c\u6709\u6548\u8bc6\u522b\u6b63\u5e38\u3001\u5e72\u6270\u3001\u6b3a\u9a97\u548c\u963b\u585e\u4fe1\u53f7\u72b6\u6001\u3002", "motivation": "\u5168\u7403\u5bfc\u822a\u536b\u661f\u7cfb\u7edf(GNSS)\u65e5\u76ca\u5bb9\u6613\u53d7\u5230\u5c04\u9891\u5e72\u6270(RFI)\uff0c\u5305\u62ec\u5e72\u6270\u548c\u6b3a\u9a97\uff0c\u8fd9\u4e9b\u5a01\u80c1\u5bfc\u822a\u548c\u6388\u65f6\u670d\u52a1\u7684\u5b8c\u6574\u6027\uff0c\u9700\u8981\u6709\u6548\u7684\u76d1\u6d4b\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u8f7d\u566a\u6bd4(C/N0)\u6d4b\u91cf\u548c\u6821\u51c6\u63a5\u6536\u529f\u7387\u6307\u6807\uff0c\u6784\u5efa\u4e8c\u7ef4\u68c0\u6d4b\u7a7a\u95f4\u6765\u8bc6\u522b\u548c\u533a\u5206\u6b63\u5e38\u3001\u5e72\u6270\u3001\u6b3a\u9a97\u548c\u963b\u585e\u4fe1\u53f7\u6761\u4ef6\u3002", "result": "\u901a\u8fc7\u5728\u632a\u5a01\u7684\u53d7\u63a7\u5e72\u6270\u6d4b\u8bd5\u4ee5\u53ca\u5728\u6ce2\u5170\u548c\u4e1c\u5357\u5730\u4e2d\u6d77\u7684\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u7ecf\u8fc7\u9002\u5f53\u6821\u51c6\u7684\u5546\u7528\u63a5\u6536\u673a\u68c0\u6d4b\u65b9\u6cd5\u5bf9GNSS RFI\u76d1\u6d4b\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002", "conclusion": "\u57fa\u4e8e\u5546\u7528\u63a5\u6536\u673a\u7684\u68c0\u6d4b\u65b9\u6cd5\u5728\u9002\u5f53\u6821\u51c6\u540e\uff0c\u4e3aGNSS\u5c04\u9891\u5e72\u6270\u76d1\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13745", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13745", "abs": "https://arxiv.org/abs/2509.13745", "authors": ["Hiroki Kuroda", "Renato Luis Garrido Cavalcante", "Masahiro Yukawa"], "title": "Theoretical Validation of the Latent Optimally Partitioned-$\\ell_2/\\ell_1$ Penalty with Application to Angular Power Spectrum Estimation", "comment": null, "summary": "This paper demonstrates that, in both theory and practice, the latent\noptimally partitioned (LOP)-$\\ell_2/\\ell_1$ penalty is effective for exploiting\nblock-sparsity without the knowledge of the concrete block structure. More\nprecisely, we first present a novel theoretical result showing that the\noptimized block partition in the LOP-$\\ell_2/\\ell_1$ penalty satisfy a\ncondition required for accurate recovery of block-sparse signals. Motivated by\nthis result, we present a new application of the LOP-$\\ell_2/\\ell_1$ penalty to\nestimation of angular power spectrum, which is block-sparse with unknown block\npartition, in MIMO communication systems. Numerical simulations show that the\nproposed use of block-sparsity with the LOP-$\\ell_2/\\ell_1$ penalty\nsignificantly improves the estimation accuracy of the angular power spectrum.", "AI": {"tldr": "LOP-\u2113\u2082/\u2113\u2081\u60e9\u7f5a\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u90fd\u80fd\u6709\u6548\u5229\u7528\u5757\u7a00\u758f\u6027\uff0c\u65e0\u9700\u5df2\u77e5\u5177\u4f53\u5757\u7ed3\u6784\u3002\u8be5\u60e9\u7f5a\u7684\u4f18\u5316\u5757\u5206\u533a\u6ee1\u8db3\u5757\u7a00\u758f\u4fe1\u53f7\u51c6\u786e\u6062\u590d\u7684\u6761\u4ef6\uff0c\u5e94\u7528\u4e8eMIMO\u7cfb\u7edf\u4e2d\u672a\u77e5\u5757\u5206\u533a\u7684\u89d2\u529f\u7387\u8c31\u4f30\u8ba1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u5728MIMO\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u89d2\u529f\u7387\u8c31\u5177\u6709\u5757\u7a00\u758f\u7279\u6027\u4f46\u5757\u5206\u533a\u672a\u77e5\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u5148\u9a8c\u5757\u7ed3\u6784\u77e5\u8bc6\u7684\u65b9\u6cd5\u6765\u6709\u6548\u5229\u7528\u8fd9\u79cd\u5757\u7a00\u758f\u6027\u3002", "method": "\u63d0\u51fa\u4f7f\u7528LOP-\u2113\u2082/\u2113\u2081\u60e9\u7f5a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u5757\u5206\u533a\u6765\u5229\u7528\u5757\u7a00\u758f\u6027\uff0c\u65e0\u9700\u5df2\u77e5\u5177\u4f53\u7684\u5757\u7ed3\u6784\u4fe1\u606f\u3002", "result": "\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u4f7f\u7528LOP-\u2113\u2082/\u2113\u2081\u60e9\u7f5a\u7684\u5757\u7a00\u758f\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u89d2\u529f\u7387\u8c31\u7684\u4f30\u8ba1\u7cbe\u5ea6\u3002", "conclusion": "LOP-\u2113\u2082/\u2113\u2081\u60e9\u7f5a\u662f\u4e00\u79cd\u6709\u6548\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5728\u4e0d\u77e5\u9053\u5177\u4f53\u5757\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u6210\u529f\u5229\u7528\u5757\u7a00\u758f\u6027\uff0c\u5728\u89d2\u529f\u7387\u8c31\u4f30\u8ba1\u7b49\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2509.13786", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13786", "abs": "https://arxiv.org/abs/2509.13786", "authors": ["SaiKrishna Saketh Yellapragada", "Esa Ollila", "Mario Costa"], "title": "Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization", "comment": "Submitted for 51st International Conference on Acoustics, Speech, and\n  Signal Processing, ICASSP 2026", "summary": "As wireless communication systems advance toward Sixth Generation (6G) Radio\nAccess Networks (RAN), Deep Learning (DL)-based neural receivers are emerging\nas transformative solutions for Physical Layer (PHY) processing, delivering\nsuperior Block Error Rate (BLER) performance compared to traditional\nmodel-based approaches. Practical deployment on resource-constrained hardware,\nhowever, requires efficient quantization to reduce latency, energy, and memory\nwithout sacrificing reliability. We extend Post-Training Quantization (PTQ)\nbaselines with Quantization-Aware Training (QAT), which incorporates\nlow-precision simulation during training for robustness at ultra-low bitwidths.\nOur study applies QAT/PTQ to a neural receiver architecture and evaluates\nacross 3GPP Clustered Delay Line (CDL)-B/D channels in LoS and NLoS\nenvironments at user velocities up to 40 m/s. Results show that 4-bit and 8-bit\nQAT models achieve BLERs similar to that of FP32 models at 10% target BLER. QAT\nmodels are also shown to outperform PTQ models by up to 3 dB, and yield 8x\ncompression. These results demonstrate that QAT is a key enabler of\nlow-complexity and latency-constrained inference at the PHY layer, facilitating\nreal-time processing in 6G edge devices", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57286G\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u91cf\u5316\u611f\u77e5\u8bad\u7ec3(QAT)\u6280\u672f\u5bf9\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u795e\u7ecf\u63a5\u6536\u673a\u8fdb\u884c\u4f4e\u6bd4\u7279\u91cf\u5316\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b08\u500d\u538b\u7f29\u548c3dB\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u77406G\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u795e\u7ecf\u63a5\u6536\u673a\u5728\u7269\u7406\u5c42\u5904\u7406\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4f46\u5728\u8d44\u6e90\u53d7\u9650\u7684\u786c\u4ef6\u4e0a\u90e8\u7f72\u65f6\u9700\u8981\u9ad8\u6548\u7684\u91cf\u5316\u6280\u672f\u6765\u964d\u4f4e\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u5185\u5b58\u5360\u7528\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u53ef\u9760\u6027\u3002", "method": "\u6269\u5c55\u4e86\u540e\u8bad\u7ec3\u91cf\u5316(PTQ)\u57fa\u7ebf\u65b9\u6cd5\uff0c\u91c7\u7528\u91cf\u5316\u611f\u77e5\u8bad\u7ec3(QAT)\u6280\u672f\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u878d\u5165\u4f4e\u7cbe\u5ea6\u6a21\u62df\uff0c\u4ee5\u63d0\u9ad8\u5728\u8d85\u4f4e\u6bd4\u7279\u5bbd\u5ea6\u4e0b\u7684\u9c81\u68d2\u6027\u3002\u7814\u7a76\u5c06QAT/PTQ\u5e94\u7528\u4e8e\u795e\u7ecf\u63a5\u6536\u673a\u67b6\u6784\uff0c\u5e76\u57283GPP CDL-B/D\u4fe1\u9053\u3001LoS/NLoS\u73af\u5883\u4ee5\u53ca\u6700\u9ad840m/s\u7528\u6237\u901f\u5ea6\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c4\u4f4d\u548c8\u4f4dQAT\u6a21\u578b\u572810%\u76ee\u6807BLER\u4e0b\u5b9e\u73b0\u4e86\u4e0eFP32\u6a21\u578b\u76f8\u4f3c\u7684\u6027\u80fd\u3002QAT\u6a21\u578b\u6bd4PTQ\u6a21\u578b\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe3dB\uff0c\u5e76\u5b9e\u73b0\u4e868\u500d\u538b\u7f29\u3002", "conclusion": "QAT\u662f\u5b9e\u73b0\u7269\u7406\u5c42\u4f4e\u590d\u6742\u5ea6\u3001\u4f4e\u5ef6\u8fdf\u63a8\u7406\u7684\u5173\u952e\u6280\u672f\uff0c\u80fd\u591f\u4fc3\u8fdb6G\u8fb9\u7f18\u8bbe\u5907\u7684\u5b9e\u65f6\u5904\u7406\u80fd\u529b\uff0c\u4e3a\u795e\u7ecf\u63a5\u6536\u673a\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2509.13807", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13807", "abs": "https://arxiv.org/abs/2509.13807", "authors": ["Ruiqi Kong", "He Chen"], "title": "Domino: Dominant Path-based Compensation for Hardware Impairments in Modern WiFi Sensing", "comment": "5 pages, 5 figures", "summary": "WiFi sensing faces a critical reliability challenge due to hardware-induced\nRF distortions, especially with modern, market-dominant WiFi cards supporting\n802.11ac/ax protocols. These cards employ sensitive automatic gain control and\nseparate RF chains, introducing complex and dynamic distortions that render\nexisting compensation methods ineffective. In this paper, we introduce Domino,\na new framework that transforms channel state information (CSI) into channel\nimpulse response (CIR) and leverages it for precise distortion compensation.\nDomino is built on the key insight that hardware-induced distortions impact all\nsignal paths uniformly, allowing the dominant static path to serve as a\nreliable reference for effective compensation through delay-domain processing.\nReal-world respiration monitoring experiments show that Domino achieves at\nleast 2x higher mean accuracy over existing methods, maintaining robust\nperformance with a median error below 0.24 bpm, even using a single antenna in\nboth direct line-of-sight and obstructed scenarios.", "AI": {"tldr": "Domino\u662f\u4e00\u4e2a\u65b0\u7684WiFi\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u8f6c\u6362\u4e3a\u4fe1\u9053\u8109\u51b2\u54cd\u5e94\uff0c\u5229\u7528\u5ef6\u8fdf\u57df\u5904\u7406\u6765\u7cbe\u786e\u8865\u507f\u786c\u4ef6\u5f15\u8d77\u7684\u5c04\u9891\u5931\u771f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u547c\u5438\u76d1\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u4ee3WiFi\u5361\uff08\u652f\u6301802.11ac/ax\u534f\u8bae\uff09\u7684\u81ea\u52a8\u589e\u76ca\u63a7\u5236\u548c\u72ec\u7acbRF\u94fe\u4f1a\u5f15\u5165\u590d\u6742\u7684\u52a8\u6001\u5931\u771f\uff0c\u5bfc\u81f4\u73b0\u6709\u8865\u507f\u65b9\u6cd5\u5931\u6548\uff0cWiFi\u611f\u77e5\u9762\u4e34\u53ef\u9760\u6027\u6311\u6218\u3002", "method": "\u5c06\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\u8f6c\u6362\u4e3a\u4fe1\u9053\u8109\u51b2\u54cd\u5e94\uff08CIR\uff09\uff0c\u5229\u7528\u4e3b\u5bfc\u9759\u6001\u8def\u5f84\u4f5c\u4e3a\u53c2\u8003\uff0c\u901a\u8fc7\u5ef6\u8fdf\u57df\u5904\u7406\u8fdb\u884c\u6709\u6548\u7684\u5931\u771f\u8865\u507f\u3002", "result": "\u5728\u5b9e\u9645\u547c\u5438\u76d1\u6d4b\u5b9e\u9a8c\u4e2d\uff0cDomino\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e86\u81f3\u5c112\u500d\u7684\u5e73\u5747\u7cbe\u5ea6\u63d0\u5347\uff0c\u4e2d\u4f4d\u8bef\u5dee\u4f4e\u4e8e0.24 bpm\uff0c\u5728\u76f4\u89c6\u548c\u975e\u76f4\u89c6\u573a\u666f\u4e0b\u5747\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "Domino\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u5ef6\u8fdf\u57df\u5904\u7406\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u4ee3WiFi\u786c\u4ef6\u5f15\u8d77\u7684\u5c04\u9891\u5931\u771f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86WiFi\u611f\u77e5\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2509.13822", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13822", "abs": "https://arxiv.org/abs/2509.13822", "authors": ["Hao Sun", "Shicong Liu", "Xianghao Yu", "Ying Sun"], "title": "Flow Matching-Based Active Learning for Radio Map Construction with Low-Altitude UAVs", "comment": null, "summary": "The employment of unmanned aerial vehicles (UAVs) in the lowaltitude economy\nnecessitates precise and real-time radio maps for reliable communication and\nsafe navigation. However, constructing such maps is hindered by the\ninfeasibility of exhaustive measurements due to UAVs' limited flight endurance.\nTo address this, we propose a novel active learning framework for low-altitude\nradio map construction based on limited measurements. First, a Plug-and-Play\n(PnP)-refined flow matching algorithm is introduced, which leverages flow\nmatching as a powerful generative prior within a PnP scheme to reconstruct\nhigh-fidelity radio maps. Second, the generative nature of flow matching is\nexploited to quantify uncertainty by generating an ensemble of radio maps and\ncomputing the location-wise variance. The resulting uncertainty map guides a\nmulti-objective candidate selection and then a trajectory is planned via\nutility-aware path search (UAPS), directing the UAV to the most informative\nlocations while taking travel costs into account. Simulation results\ndemonstrate that our method significantly outperforms the baselines, achieving\nmore than a 70% reduction in normalized mean squared error (NMSE).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7684\u65e0\u4eba\u673a\u4f4e\u7a7a\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\u6846\u67b6\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u751f\u6210\u5148\u9a8c\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u7ed3\u5408\u591a\u76ee\u6807\u5019\u9009\u9009\u62e9\u548c\u8def\u5f84\u89c4\u5212\uff0c\u663e\u8457\u964d\u4f4e\u91cd\u5efa\u8bef\u5dee\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u4f4e\u7a7a\u7ecf\u6d4e\u4e2d\u7684\u5e94\u7528\u9700\u8981\u7cbe\u786e\u5b9e\u65f6\u7684\u65e0\u7ebf\u7535\u5730\u56fe\uff0c\u4f46\u53d7\u9650\u4e8e\u98de\u884c\u7eed\u822a\u80fd\u529b\u65e0\u6cd5\u8fdb\u884c\u8be6\u5c3d\u6d4b\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u57fa\u4e8e\u6709\u9650\u6d4b\u91cf\u7684\u9ad8\u6548\u5730\u56fe\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u91c7\u7528Plug-and-Play\u7cbe\u70bc\u7684\u6d41\u5339\u914d\u7b97\u6cd5\u4f5c\u4e3a\u751f\u6210\u5148\u9a8c\uff0c\u5229\u7528\u6d41\u5339\u914d\u751f\u6210\u591a\u4e2a\u5730\u56fe\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u5019\u9009\u9009\u62e9\u548c\u6548\u7528\u611f\u77e5\u8def\u5f84\u641c\u7d22\u6307\u5bfc\u65e0\u4eba\u673a\u91c7\u96c6\u6700\u6709\u4ef7\u503c\u7684\u6570\u636e\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u964d\u4f4e\u8d85\u8fc770%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e3b\u52a8\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528\u6709\u9650\u6d4b\u91cf\u6570\u636e\u6784\u5efa\u9ad8\u4fdd\u771f\u5ea6\u7684\u4f4e\u7a7a\u65e0\u7ebf\u7535\u5730\u56fe\uff0c\u4e3a\u65e0\u4eba\u673a\u901a\u4fe1\u548c\u5bfc\u822a\u63d0\u4f9b\u53ef\u9760\u652f\u6301\u3002"}}
{"id": "2509.13851", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13851", "abs": "https://arxiv.org/abs/2509.13851", "authors": ["Hao Su", "Jiangtao Wang", "Yongchao Wang"], "title": "FFT-Free PAPR Reduction Methods for OFDM Signals", "comment": "6 page, 7 figures", "summary": "In this paper, we propose two low-complexity peak to average power\nratio(PAPR) reduction algorithms for orthogonal frequency division\nmultiplexing(OFDM) signals. The main content is as follows: First, a non-convex\noptimization model is established by minimizing the signal distortion power.\nThen, a customized alternating direction method of multipliers(ADMM) algorithm\nis proposed to solve the problem, named time domain ADMM(T-ADMM) along with an\nimproved version called T-ADMM with constrain update(TCU-ADMM). In the\nalgorithms, all subproblems can be solved analytically, and each iteration has\nlinear computational complexity. These algorithms circumvents the challenges\nposed by repeated fast Fourier transform(FFT) and inverse FFT(IFFT) operations\nin traditional PAPR reduction algorithms. Additionally, we prove that the\nT-ADMM algorithm is theoretically guaranteed convergent if proper parameter is\nchosen. Finally, simulation results demonstrate the effectiveness of the\nproposed methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u4f4e\u590d\u6742\u5ea6\u7684OFDM\u4fe1\u53f7\u5cf0\u5747\u529f\u7387\u6bd4(PAPR)\u964d\u4f4e\u7b97\u6cd5\uff1aT-ADMM\u548cTCU-ADMM\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4fe1\u53f7\u5931\u771f\u529f\u7387\u5efa\u7acb\u975e\u51f8\u4f18\u5316\u6a21\u578b\uff0c\u91c7\u7528\u5b9a\u5236\u5316\u7684ADMM\u7b97\u6cd5\u6c42\u89e3\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u91cd\u590dFFT/IFFT\u64cd\u4f5c\u7684\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edfOFDM\u4fe1\u53f7PAPR\u964d\u4f4e\u7b97\u6cd5\u9700\u8981\u91cd\u590d\u8fdb\u884cFFT\u548cIFFT\u64cd\u4f5c\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5efa\u7acb\u6700\u5c0f\u5316\u4fe1\u53f7\u5931\u771f\u529f\u7387\u7684\u975e\u51f8\u4f18\u5316\u6a21\u578b\uff0c\u63d0\u51fa\u5b9a\u5236\u5316\u7684\u4ea4\u66ff\u65b9\u5411\u4e58\u5b50\u6cd5(T-ADMM)\u53ca\u5176\u6539\u8fdb\u7248\u672cTCU-ADMM\uff0c\u6240\u6709\u5b50\u95ee\u9898\u53ef\u89e3\u6790\u6c42\u89e3\uff0c\u6bcf\u6b21\u8fed\u4ee3\u5177\u6709\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u7b97\u6cd5\u907f\u514d\u4e86\u91cd\u590dFFT/IFFT\u64cd\u4f5c\uff0cT-ADMM\u5728\u9002\u5f53\u53c2\u6570\u9009\u62e9\u4e0b\u5177\u6709\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\uff0c\u4eff\u771f\u7ed3\u679c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684T-ADMM\u548cTCU-ADMM\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u964d\u4f4eOFDM\u4fe1\u53f7\u7684PAPR\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13940", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.13940", "abs": "https://arxiv.org/abs/2509.13940", "authors": ["Weifeng Zhu", "Junyuan Gao", "Shuowen Zhang", "Liang Liu"], "title": "Reconfigurable Intelligent Surface-Assisted Multiuser Tracking and Signal Detection in ISAC", "comment": "6 pages, 6 figures, accepted by IEEE conference", "summary": "This paper investigates the multiuser tracking and signal detection problem\nin integrated sensing and communication (ISAC) systems with the assistance of\nreconfigurable intelligent surfaces (RISs). Due to the diverse and high user\nmobility, the tracking and signal detection performance can be significantly\ndeteriorated without choreographed user state (position and velocity) updating\nprinciple. To tackle this challenge, we manage to establish a comprehensive\nprobabilistic signal model to characterize the interdependencies among user\nstates, transmit signals, and received signals during the tracking procedure.\nBased on the Bayesian problem formulation, we further propose a novel hybrid\nvariational message passing algorithm for the online estimation of user states,\nwhich can iteratively update the posterior probabilities of user states during\neach tracking frame with computational efficiency. Numerical results are\nprovided to demonstrate that the proposed algorithm can significantly improve\nboth of the tracking and signal detection performance over the representative\nBayesian estimation counterparts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u6d88\u606f\u4f20\u9012\u7684\u6df7\u5408\u7b97\u6cd5\uff0c\u7528\u4e8eRIS\u8f85\u52a9ISAC\u7cfb\u7edf\u4e2d\u7684\u591a\u7528\u6237\u8ddf\u8e2a\u548c\u4fe1\u53f7\u68c0\u6d4b\uff0c\u901a\u8fc7\u6982\u7387\u4fe1\u53f7\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u8ddf\u8e2a\u548c\u68c0\u6d4b\u6027\u80fd", "motivation": "\u89e3\u51b3\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7531\u4e8e\u7528\u6237\u9ad8\u79fb\u52a8\u6027\u5bfc\u81f4\u7684\u8ddf\u8e2a\u548c\u4fe1\u53f7\u68c0\u6d4b\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u9700\u8981\u5efa\u7acb\u6709\u6548\u7684\u72b6\u6001\u66f4\u65b0\u673a\u5236", "method": "\u5efa\u7acb\u6982\u7387\u4fe1\u53f7\u6a21\u578b\u63cf\u8ff0\u7528\u6237\u72b6\u6001\u3001\u53d1\u5c04\u4fe1\u53f7\u548c\u63a5\u6536\u4fe1\u53f7\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u63d0\u51fa\u6df7\u5408\u53d8\u5206\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\u8fdb\u884c\u5728\u7ebf\u7528\u6237\u72b6\u6001\u4f30\u8ba1", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u5728\u8ddf\u8e2a\u548c\u4fe1\u53f7\u68c0\u6d4b\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u4ee3\u8868\u6027\u8d1d\u53f6\u65af\u4f30\u8ba1\u7b97\u6cd5", "conclusion": "\u8be5\u6df7\u5408\u53d8\u5206\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\u80fd\u591f\u4ee5\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u5f0f\u8fed\u4ee3\u66f4\u65b0\u7528\u6237\u72b6\u6001\u540e\u9a8c\u6982\u7387\uff0c\u6709\u6548\u63d0\u5347RIS\u8f85\u52a9ISAC\u7cfb\u7edf\u7684\u591a\u7528\u6237\u8ddf\u8e2a\u548c\u4fe1\u53f7\u68c0\u6d4b\u6027\u80fd"}}
{"id": "2509.13961", "categories": ["eess.SP", "92C55, 68T10, 93C85", "I.5.4; J.3; H.1.2"], "pdf": "https://arxiv.org/pdf/2509.13961", "abs": "https://arxiv.org/abs/2509.13961", "authors": ["Lorenza Angelini", "Dimitar Stanev", "Marta P\u0142onka", "Rafa\u0142 Klimas", "Natan Napi\u00f3rkowski", "Gabriela Gonz\u00e1lez Chan", "Lisa Bunn", "Paul S Glazier", "Richard Hosking", "Jenny Freeman", "Jeremy Hobart", "Jonathan Marsden", "Licinio Craveiro", "Mike D Rinderknecht", "Mattia Zanon"], "title": "Adaptive and robust smartphone-based step detection in multiple sclerosis", "comment": "66 pages total, 6 figures, 1 table, 23 supplementary appendix pages,\n  2 supplementary figures, 6 supplementary tables", "summary": "Background: Many attempts to validate gait pipelines that process sensor data\nto detect gait events have focused on the detection of initial contacts only in\nsupervised settings using a single sensor. Objective: To evaluate the\nperformance of a gait pipeline in detecting initial/final contacts using a step\ndetection algorithm adaptive to different test settings, smartphone wear\nlocations, and gait impairment levels. Methods: In GaitLab (ISRCTN15993728),\nhealthy controls (HC) and people with multiple sclerosis (PwMS; Expanded\nDisability Status Scale 0.0-6.5) performed supervised Two-Minute Walk Test\n[2MWT] (structured in-lab overground and treadmill 2MWT) during two on-site\nvisits carrying six smartphones and unsupervised walking activities (structured\nand unstructured real-world walking) daily for 10-14 days using a single\nsmartphone. Reference gait data were collected with a motion capture system or\nGait Up sensors. The pipeline's performance in detecting initial/final contacts\nwas evaluated through F1 scores and absolute temporal error with respect to\nreference measurement systems. Results: We studied 35 HC and 93 PwMS.\nInitial/final contacts were accurately detected across all smartphone wear\nlocations. Median F1 scores for initial/final contacts on in-lab 2MWT were\n>=98.2%/96.5% in HC and >=98.5%/97.7% in PwMS. F1 scores remained high on\nstructured (HC: 100% [0.3%]/100% [0.2%]; PwMS: 99.5% [1.9%]/99.4% [2.5%]) and\nunstructured real-world walking (HC: 97.8% [2.6%]/97.8% [2.8%]; PwMS: 94.4%\n[6.2%]/94.0% [6.5%]). Median temporal errors were <=0.08 s. Neither age, sex,\ndisease severity, walking aid use, nor setting (outdoor/indoor) impacted\npipeline performance (all p>0.05). Conclusion: This gait pipeline accurately\nand consistently detects initial and final contacts in PwMS across different\nsmartphone locations and environments, highlighting its potential for\nreal-world gait assessment.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u6b65\u6001\u68c0\u6d4b\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u6d4b\u8bd5\u8bbe\u7f6e\u3001\u667a\u80fd\u624b\u673a\u4f69\u6234\u4f4d\u7f6e\u548c\u6b65\u6001\u969c\u788d\u6c34\u5e73\u4e0b\u51c6\u786e\u68c0\u6d4b\u521d\u59cb/\u6700\u7ec8\u63a5\u89e6\u70b9\uff0c\u5728\u5b9e\u9a8c\u5ba4\u548c\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u90fd\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u6b65\u6001\u5904\u7406\u7ba1\u9053\u4e3b\u8981\u5173\u6ce8\u5728\u76d1\u7763\u8bbe\u7f6e\u4e0b\u4f7f\u7528\u5355\u4e2a\u4f20\u611f\u5668\u68c0\u6d4b\u521d\u59cb\u63a5\u89e6\u70b9\uff0c\u9700\u8981\u9a8c\u8bc1\u7b97\u6cd5\u5728\u4e0d\u540c\u6d4b\u8bd5\u73af\u5883\u3001\u591a\u79cd\u624b\u673a\u4f69\u6234\u4f4d\u7f6e\u548c\u4e0d\u540c\u6b65\u6001\u969c\u788d\u7a0b\u5ea6\u4e0b\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7GaitLab\u7814\u7a76\uff0c\u8ba9\u5065\u5eb7\u5bf9\u7167\u7ec4\u548c\u591a\u53d1\u6027\u786c\u5316\u75c7\u60a3\u8005\u5728\u5b9e\u9a8c\u5ba4\u8fdb\u884c\u76d1\u7763\u5f0f\u4e24\u5206\u949f\u6b65\u884c\u6d4b\u8bd5\uff08\u4f7f\u75286\u90e8\u624b\u673a\uff09\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u8fdb\u884c10-14\u5929\u7684\u65e0\u76d1\u7763\u6b65\u884c\u6d3b\u52a8\uff08\u4f7f\u7528\u5355\u90e8\u624b\u673a\uff09\uff0c\u4f7f\u7528\u8fd0\u52a8\u6355\u6349\u7cfb\u7edf\u6216Gait Up\u4f20\u611f\u5668\u4f5c\u4e3a\u53c2\u8003\u6570\u636e\u3002", "result": "\u7814\u7a7635\u540d\u5065\u5eb7\u4eba\u548c93\u540d\u591a\u53d1\u6027\u786c\u5316\u75c7\u60a3\u8005\uff0c\u5728\u6240\u6709\u624b\u673a\u4f69\u6234\u4f4d\u7f6e\u90fd\u80fd\u51c6\u786e\u68c0\u6d4b\u521d\u59cb/\u6700\u7ec8\u63a5\u89e6\u70b9\uff0cF1\u5206\u6570\u5728\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u4e2d\u226598.2%/96.5%\uff08\u5065\u5eb7\u4eba\uff09\u548c\u226598.5%/97.7%\uff08\u60a3\u8005\uff09\uff0c\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2dF1\u5206\u6570\u4fdd\u6301\u572894.4%-100%\uff0c\u65f6\u95f4\u8bef\u5dee\u22640.08\u79d2\u3002", "conclusion": "\u8be5\u6b65\u6001\u7ba1\u9053\u80fd\u591f\u5728\u4e0d\u540c\u667a\u80fd\u624b\u673a\u4f4d\u7f6e\u548c\u73af\u5883\u4e2d\u51c6\u786e\u4e00\u81f4\u5730\u68c0\u6d4b\u521d\u59cb\u548c\u6700\u7ec8\u63a5\u89e6\u70b9\uff0c\u5c55\u793a\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u6b65\u6001\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13975", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13975", "abs": "https://arxiv.org/abs/2509.13975", "authors": ["Ilker Bayram"], "title": "Classification Filtering", "comment": null, "summary": "We consider a streaming signal in which each sample is linked to a latent\nclass. We assume that multiple classifiers are available, each providing class\nprobabilities with varying degrees of accuracy. These classifiers are employed\nfollowing a straightforward and fixed policy. In this setting, we consider the\nproblem of fusing the output of the classifiers while incorporating the\ntemporal aspect to improve classification accuracy. We propose a state-space\nmodel and develop a filter tailored for realtime execution. We demonstrate the\neffectiveness of the proposed filter in an activity classification application\nbased on inertial measurement unit (IMU) data from a wearable device.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u6d41\u5f0f\u4fe1\u53f7\u5206\u7c7b\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u5b9e\u65f6\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u878d\u5408\u591a\u4e2a\u5206\u7c7b\u5668\u7684\u8f93\u51fa\u5e76\u5229\u7528\u65f6\u95f4\u4fe1\u606f\u6765\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u7387", "motivation": "\u5728\u6d41\u5f0f\u4fe1\u53f7\u5904\u7406\u4e2d\uff0c\u591a\u4e2a\u5206\u7c7b\u5668\u4ee5\u56fa\u5b9a\u7b56\u7565\u8fd0\u884c\uff0c\u4f46\u5b83\u4eec\u7684\u51c6\u786e\u7387\u5404\u4e0d\u76f8\u540c\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u878d\u5408\u8fd9\u4e9b\u5206\u7c7b\u5668\u7684\u8f93\u51fa\uff0c\u540c\u65f6\u5229\u7528\u65f6\u5e8f\u4fe1\u606f\u6765\u63d0\u5347\u5206\u7c7b\u6027\u80fd", "method": "\u8bbe\u8ba1\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5e76\u5f00\u53d1\u4e13\u95e8\u7528\u4e8e\u5b9e\u65f6\u6267\u884c\u7684\u6ee4\u6ce2\u5668\uff0c\u5c06\u591a\u4e2a\u5206\u7c7b\u5668\u7684\u6982\u7387\u8f93\u51fa\u8fdb\u884c\u65f6\u5e8f\u878d\u5408", "result": "\u5728\u57fa\u4e8e\u53ef\u7a7f\u6234\u8bbe\u5907IMU\u6570\u636e\u7684\u6d3b\u52a8\u5206\u7c7b\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u6ee4\u6ce2\u5668\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u5b9e\u65f6\u6ee4\u6ce2\u5668\u80fd\u591f\u6709\u6548\u878d\u5408\u591a\u4e2a\u5206\u7c7b\u5668\u7684\u8f93\u51fa\uff0c\u5229\u7528\u65f6\u5e8f\u4fe1\u606f\u663e\u8457\u63d0\u5347\u6d41\u5f0f\u4fe1\u53f7\u7684\u5206\u7c7b\u51c6\u786e\u7387"}}
{"id": "2509.13425", "categories": ["cs.LG", "physics.app-ph", "92D25, 35K57, 68T07", "I.2.6; J.3; G.1.8"], "pdf": "https://arxiv.org/pdf/2509.13425", "abs": "https://arxiv.org/abs/2509.13425", "authors": ["Julian Evan Chrisnanto", "Yulison Herry Chrisnanto", "Ferry Faizal"], "title": "Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics", "comment": "20 pages, 11 figures. A preprint on using a unified physics-informed\n  neural network framework to model predator-prey dynamics", "summary": "Ecological systems exhibit complex multi-scale dynamics that challenge\ntraditional modeling. New methods must capture temporal oscillations and\nemergent spatiotemporal patterns while adhering to conservation principles. We\npresent the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,\na deep learning architecture integrating physics-informed neural networks\n(PINNs) and conservation laws to model predator-prey dynamics across\ndimensional scales. The framework provides a unified solution for both ordinary\n(ODE) and partial (PDE) differential equation systems, describing temporal\ncycles and reaction-diffusion patterns within a single neural network\narchitecture. Our methodology uses automatic differentiation to enforce physics\nconstraints and adaptive loss weighting to balance data fidelity with physical\nconsistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%\ncorrelation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures\ncomplex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).\nValidation confirms conservation law adherence within 0.5% and shows a 10-50x\ncomputational speedup for inference compared to numerical solvers. USPIL also\nenables mechanistic understanding through interpretable physics constraints,\nfacilitating parameter discovery and sensitivity analysis not possible with\npurely data-driven methods. Its ability to transition between dimensional\nformulations opens new avenues for multi-scale ecological modeling. These\ncapabilities make USPIL a transformative tool for ecological forecasting,\nconservation planning, and understanding ecosystem resilience, establishing\nphysics-informed deep learning as a powerful and scientifically rigorous\nparadigm.", "AI": {"tldr": "USPIL\u6846\u67b6\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u548c\u5b88\u6052\u5b9a\u5f8b\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u6210\u529f\u5efa\u6a21\u4e86\u6355\u98df\u8005-\u730e\u7269\u7cfb\u7edf\u7684\u591a\u5c3a\u5ea6\u65f6\u7a7a\u52a8\u529b\u5b66\uff0c\u5728\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u751f\u6001\u7cfb\u7edf\u7684\u590d\u6742\u591a\u5c3a\u5ea6\u52a8\u529b\u5b66\u7279\u6027\u5bf9\u4f20\u7edf\u5efa\u6a21\u65b9\u6cd5\u6784\u6210\u6311\u6218\uff0c\u9700\u8981\u80fd\u591f\u540c\u65f6\u6355\u6349\u65f6\u95f4\u632f\u8361\u548c\u6d8c\u73b0\u65f6\u7a7a\u6a21\u5f0f\u7684\u65b0\u65b9\u6cd5\uff0c\u540c\u65f6\u5fc5\u987b\u9075\u5b88\u5b88\u6052\u5b9a\u5f8b\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u65f6\u7a7a\u7269\u7406\u4fe1\u606f\u5b66\u4e60(USPIL)\u6846\u67b6\uff0c\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINNs)\u548c\u5b88\u6052\u5b9a\u5f8b\uff0c\u4f7f\u7528\u81ea\u52a8\u5fae\u5206\u5b9e\u65bd\u7269\u7406\u7ea6\u675f\u548c\u81ea\u9002\u5e94\u635f\u5931\u52a0\u6743\u6765\u5e73\u8861\u6570\u636e\u4fdd\u771f\u5ea6\u4e0e\u7269\u7406\u4e00\u81f4\u6027\u3002", "result": "\u5728Lotka-Volterra\u7cfb\u7edf\u4e2d\uff0cUSPIL\u5b9e\u73b0\u4e861D\u65f6\u95f4\u52a8\u529b\u5b6698.9%\u7684\u76f8\u5173\u6027(\u635f\u5931:0.0219\uff0cMAE:0.0184)\uff0c\u57282D\u7cfb\u7edf\u4e2d\u6355\u6349\u5230\u590d\u6742\u87ba\u65cb\u6ce2(\u635f\u5931:4.7656\uff0c\u6a21\u5f0f\u76f8\u5173\u6027:0.94)\uff0c\u9a8c\u8bc1\u663e\u793a\u5b88\u6052\u5b9a\u5f8b\u9075\u5b88\u57280.5%\u4ee5\u5185\uff0c\u63a8\u7406\u8ba1\u7b97\u901f\u5ea6\u6bd4\u6570\u503c\u6c42\u89e3\u5668\u5feb10-50\u500d\u3002", "conclusion": "USPIL\u5efa\u7acb\u4e86\u7269\u7406\u4fe1\u606f\u6df1\u5ea6\u5b66\u4e60\u4f5c\u4e3a\u5f3a\u5927\u4e14\u79d1\u5b66\u4e25\u8c28\u7684\u8303\u5f0f\uff0c\u4e3a\u751f\u6001\u9884\u6d4b\u3001\u4fdd\u62a4\u89c4\u5212\u548c\u751f\u6001\u7cfb\u7edf\u97e7\u6027\u7406\u89e3\u63d0\u4f9b\u4e86\u53d8\u9769\u6027\u5de5\u5177\uff0c\u5176\u5728\u4e0d\u540c\u7ef4\u5ea6\u8868\u8ff0\u95f4\u8f6c\u6362\u7684\u80fd\u529b\u4e3a\u591a\u5c3a\u5ea6\u751f\u6001\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.13984", "categories": ["eess.SP", "physics.optics"], "pdf": "https://arxiv.org/pdf/2509.13984", "abs": "https://arxiv.org/abs/2509.13984", "authors": ["Drake Silbernagel", "Yu Rong", "Isabella Lenz", "Prithvi Hemanth", "Carl Morgenstern", "Owen Ma", "Nolan Matthews", "Nader Zaki", "Kyle W. Martin", "John D. Elgin", "Jacob Holtom", "Daniel W. Bliss", "Kimberly Frey"], "title": "Distributed Coherent Beamforming at 60 GHz Enabled by Optically-Established Coherence", "comment": null, "summary": "We implement and experimentally demonstrate a 60 GHz distributed system\nleveraging an optical time synchronization system that provides precise time\nand frequency alignment between independent elements of the distributed mesh.\nUtilizing such accurate coherence, we perform receive beamforming with\ninterference rejection and transmit nulling. In these configurations, the\nsystem achieves a coherent gain over an incoherent network of N nodes,\nsignificantly improving the relevant signal power ratios. Our system\ndemonstrates extended array phase coherence times, enabling advanced\ntechniques. Results from over-the-air experiments demonstrate a 14.3 dB\nsignal-to-interference-plus-noise improvement in interference-laden scenarios\nwith a contributing 13.5 dB null towards interference in receive beamforming.\nIn transmit nulling, a signal-to-noise ratio (SNR) gain of 7.9 dB is measured\ntowards an intended receiver while maintaining an SNR reduction of 8.9 dB at\nanother receiver. These findings represent the use of distributed coherence in\nthe V band without the use of GPS timing.", "AI": {"tldr": "\u901a\u8fc7\u5149\u5b66\u65f6\u95f4\u540c\u6b65\u7cfb\u7edf\u5b9e\u73b0\u4e8660 GHz\u5206\u5e03\u5f0f\u7f51\u7edc\u7684\u7cbe\u786e\u540c\u6b65\uff0c\u5728\u63a5\u6536\u7aef\u5b9e\u73b0\u653e\u5927\u548c\u5e72\u6270\u62d2\u6b62\uff0c\u5728\u53d1\u5c04\u7aef\u5b9e\u73b0\u4fe1\u53f7\u7a7a\u95f4\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u53f7\u8d28\u91cf\u548c\u5e72\u6270\u62d2\u6b62\u80fd\u529b", "motivation": "\u4f7f\u7528\u5206\u5e03\u5f0f\u7cfb\u7edf\u83b7\u5f97\u76f8\u4f4d\u540c\u6b65\u80fd\u529b\uff0c\u5728V\u6ce2\u6bb5\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u6536\u53d1\u7a7a\u95f4\u5904\u7406\u6280\u672f\uff0c\u800c\u65e0\u9700GPS\u5b9a\u65f6", "method": "\u91c7\u7528\u5149\u5b66\u65f6\u95f4\u540c\u6b65\u7cfb\u7edf\uff0c\u4e3a\u5206\u5e03\u5f0f\u7f51\u7edc\u5143\u7d20\u63d0\u4f9b\u7cbe\u786e\u65f6\u95f4\u548c\u9891\u7387\u5bf9\u9f50\uff0c\u5e76\u8fdb\u884c\u63a5\u6536\u7aef\u653f\u5f62\u5904\u7406\u548c\u53d1\u5c04\u7aef\u7a7a\u95f4\u63a7\u5236", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u63a5\u6536\u7aef\u5e72\u6270\u60c5\u51b5\u4e0bSINR\u63d0\u534714.3dB\uff0c\u5bf9\u5e72\u6270\u5f62\u621013.5dB\u7684\u7a7a\u95f4\u62d2\u6b62\uff1b\u53d1\u5c04\u7aef\u5728\u76ee\u6807\u6536\u6536\u673a\u5904SNR\u63d0\u53477.9dB\uff0c\u540c\u65f6\u5728\u5176\u4ed6\u6536\u6536\u673a\u5904SNR\u964d\u4f4e8.9dB", "conclusion": "\u8fd9\u4e00\u65b9\u6cd5\u6210\u529f\u5728V\u6ce2\u6bb5\u5b9e\u73b0\u4e86\u5206\u5e03\u5f0f\u540c\u6b65\u6280\u672f\uff0c\u4e3a\u9ad8\u9891\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7684\u7a7a\u95f4\u5904\u7406\u80fd\u529b"}}
{"id": "2509.13516", "categories": ["cs.LG", "68T05 (Primary) 90C30, 68W40 (Secondary)"], "pdf": "https://arxiv.org/pdf/2509.13516", "abs": "https://arxiv.org/abs/2509.13516", "authors": ["Tom Almog"], "title": "An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training", "comment": "7 pages. 3 figures", "summary": "As machine learning models grow increasingly complex and computationally\ndemanding, understanding the environmental impact of training decisions becomes\ncritical for sustainable AI development. This paper presents a comprehensive\nempirical study investigating the relationship between optimizer choice and\nenergy efficiency in neural network training. We conducted 360 controlled\nexperiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using\neight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,\nNAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking\non Apple M1 Pro hardware, we measured training duration, peak memory usage,\ncarbon dioxide emissions, and final model performance. Our findings reveal\nsubstantial trade-offs between training speed, accuracy, and environmental\nimpact that vary across datasets and model complexity. We identify AdamW and\nNAdam as consistently efficient choices, while SGD demonstrates superior\nperformance on complex datasets despite higher emissions. These results provide\nactionable insights for practitioners seeking to balance performance and\nsustainability in machine learning workflows.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7360\u6b21\u5b9e\u9a8c\u5bf9\u6bd48\u79cd\u4f18\u5316\u5668\u7684\u80fd\u8017\u6548\u7387\uff0c\u53d1\u73b0AdamW\u548cNAdam\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u5747\u8861\uff0cSGD\u5728\u590d\u6742\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u5f02\u4f46\u78b3\u6392\u653e\u8f83\u9ad8\uff0c\u4e3a\u5e73\u8861AI\u6027\u80fd\u4e0e\u53ef\u6301\u7eed\u6027\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65e5\u76ca\u590d\u6742\u548c\u8ba1\u7b97\u9700\u6c42\u589e\u957f\uff0c\u7406\u89e3\u8bad\u7ec3\u51b3\u7b56\u5bf9\u73af\u5883\u7684\u5f71\u54cd\u5bf9\u53ef\u6301\u7eedAI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u7814\u7a76\u4e0d\u540c\u4f18\u5316\u5668\u9009\u62e9\u4e0e\u80fd\u6e90\u6548\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6(MNIST\u3001CIFAR-10\u3001CIFAR-100)\u4e0a\u4f7f\u75288\u79cd\u6d41\u884c\u4f18\u5316\u5668\u8fdb\u884c360\u6b21\u53d7\u63a7\u5b9e\u9a8c\uff0c\u6bcf\u4e2a\u4f18\u5316\u5668\u4f7f\u752815\u4e2a\u968f\u673a\u79cd\u5b50\uff0c\u901a\u8fc7CodeCarbon\u5728Apple M1 Pro\u786c\u4ef6\u4e0a\u7cbe\u786e\u8ffd\u8e2a\u80fd\u8017\u6307\u6807\u3002", "result": "\u53d1\u73b0\u8bad\u7ec3\u901f\u5ea6\u3001\u51c6\u786e\u6027\u548c\u73af\u5883\u5f71\u54cd\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6743\u8861\uff0c\u4e14\u968f\u6570\u636e\u96c6\u548c\u6a21\u578b\u590d\u6742\u5ea6\u53d8\u5316\u3002AdamW\u548cNAdam\u8868\u73b0\u4e00\u81f4\u9ad8\u6548\uff0cSGD\u5728\u590d\u6742\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u8d8a\u4f46\u6392\u653e\u66f4\u9ad8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4ece\u4e1a\u8005\u5728\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u4e2d\u5e73\u8861\u6027\u80fd\u4e0e\u53ef\u6301\u7eed\u6027\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u4f18\u5316\u5668\u9009\u62e9\u5bf9\u73af\u5883\u5f71\u54cd\u7684\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.14062", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.14062", "abs": "https://arxiv.org/abs/2509.14062", "authors": ["Saifur Rahman", "Syed Luqman Shah", "Salman Khan", "Jalal Khan", "Muhammad Irfan", "Maaz Shafi", "Said Muhammad", "Fazal Muhammad", "Mohammad Shahed Akond"], "title": "Distributed Deep Learning with RIS Grouping for Accurate Cascaded Channel Estimation", "comment": "Submitted for Publication", "summary": "Reconfigurable Intelligent Surface (RIS) panels are envisioned as a key\ntechnology for sixth-generation (6G) wireless networks, providing a\ncost-effective means to enhance coverage and spectral efficiency. A critical\nchallenge is the estimation of the cascaded base station (BS)-RIS-user channel,\nsince the passive nature of RIS elements prevents direct channel acquisition,\nincurring prohibitive pilot overhead, computational complexity, and energy\nconsumption. To address this, we propose a deep learning (DL)-based channel\nestimation framework that reduces pilot overhead by grouping RIS elements and\nreconstructing the cascaded channel from partial pilot observations.\nFurthermore, conventional DL models trained under single-user settings suffer\nfrom poor generalization across new user locations and propagation scenarios.\nWe develop a distributed machine learning (DML) strategy in which the BS and\nusers collaboratively train a shared neural network using diverse channel\ndatasets collected across the network, thereby achieving robust generalization.\nBuilding on this foundation, we design a hierarchical DML neural architecture\nthat first classifies propagation conditions and then employs scenario-specific\nfeature extraction to further improve estimation accuracy. Simulation results\nconfirm that the proposed framework substantially reduces pilot overhead and\ncomplexity while outperforming conventional methods and single-user models in\nchannel estimation accuracy. These results demonstrate the practicality and\neffectiveness of the proposed approach for 6G RIS-assisted systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684RIS\u4fe1\u9053\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7RIS\u5143\u7d20\u5206\u7ec4\u548c\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u964d\u4f4e\u5bfc\u9891\u5f00\u9500\u5e76\u63d0\u5347\u8de8\u7528\u6237\u4f4d\u7f6e\u548c\u4f20\u64ad\u573a\u666f\u7684\u6cdb\u5316\u80fd\u529b", "motivation": "\u89e3\u51b3RIS\u8f85\u52a96G\u7cfb\u7edf\u4e2d\u7ea7\u8054\u4fe1\u9053\u4f30\u8ba1\u7684\u9ad8\u5bfc\u9891\u5f00\u9500\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u80fd\u8017\u95ee\u9898\uff0c\u4ee5\u53ca\u4f20\u7edf\u5355\u7528\u6237DL\u6a21\u578b\u5728\u65b0\u573a\u666f\u4e0b\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898", "method": "\u91c7\u7528RIS\u5143\u7d20\u5206\u7ec4\u51cf\u5c11\u5bfc\u9891\u89c2\u6d4b\uff0c\u5f00\u53d1\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u7b56\u7565\u8ba9\u57fa\u7ad9\u548c\u7528\u6237\u534f\u4f5c\u8bad\u7ec3\u5171\u4eab\u795e\u7ecf\u7f51\u7edc\uff0c\u8bbe\u8ba1\u5206\u5c42DML\u67b6\u6784\u5148\u5206\u7c7b\u4f20\u64ad\u6761\u4ef6\u518d\u8fdb\u884c\u573a\u666f\u7279\u5b9a\u7279\u5f81\u63d0\u53d6", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u5927\u5e45\u964d\u4f4e\u5bfc\u9891\u5f00\u9500\u548c\u590d\u6742\u5ea6\uff0c\u5728\u4fe1\u9053\u4f30\u8ba1\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u5355\u7528\u6237\u6a21\u578b", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a6G RIS\u8f85\u52a9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6709\u6548\u7684\u4fe1\u9053\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.13520", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13520", "abs": "https://arxiv.org/abs/2509.13520", "authors": ["Varun Kumar", "Jing Bi", "Cyril Ngo Ngoc", "Victor Oancea", "George Em Karniadakis"], "title": "Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework", "comment": null, "summary": "Neural surrogates and operator networks for solving partial differential\nequation (PDE) problems have attracted significant research interest in recent\nyears. However, most existing approaches are limited in their ability to\ngeneralize solutions across varying non-parametric geometric domains. In this\nwork, we address this challenge in the context of Polyethylene Terephthalate\n(PET) bottle buckling analysis, a representative packaging design problem\nconventionally solved using computationally expensive finite element analysis\n(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously\npredicts nodal displacement fields and the time evolution of reaction forces\nduring top load compression. Our methodology is evaluated on two families of\nbottle geometries parameterized by two and four design variables. Training data\nis generated using nonlinear FEA simulations in Abaqus for 254 unique designs\nper family. The proposed framework achieves mean relative $L^{2}$ errors of\n2.5-13% for displacement fields and approximately 2.4% for time-dependent\nreaction forces for the four-parameter bottle family. Point-wise error analyses\nfurther show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,\nwith the largest discrepancies confined to localized geometric regions.\nImportantly, the model accurately captures key physical phenomena, such as\nbuckling behavior, across diverse bottle geometries. These results highlight\nthe potential of our framework as a scalable and computationally efficient\nsurrogate, particularly for multi-task predictions in computational mechanics\nand applications requiring rapid design evaluation.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408DeepONet-Transolver\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3PET\u74f6\u5b50\u5c48\u66f2\u5206\u6790\u95ee\u9898\uff0c\u80fd\u591f\u540c\u65f6\u9884\u6d4b\u8282\u70b9\u4f4d\u79fb\u573a\u548c\u65f6\u95f4\u76f8\u5173\u7684\u53cd\u4f5c\u7528\u529b\uff0c\u5728\u51e0\u4f55\u53c2\u6570\u5316\u8bbe\u8ba1\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u5728\u5904\u7406\u975e\u53c2\u6570\u5316\u51e0\u4f55\u57df\u53d8\u5316\u7684PDE\u95ee\u9898\u65f6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u800c\u4f20\u7edf\u7684\u6709\u9650\u5143\u5206\u6790\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u8ba1\u7b97\u66ff\u4ee3\u6a21\u578b\u3002", "method": "\u91c7\u7528\u6df7\u5408DeepONet-Transolver\u6846\u67b6\uff0c\u7ed3\u5408\u6df1\u5ea6\u7b97\u5b50\u7f51\u7edc\u548c\u53d8\u6362\u6c42\u89e3\u5668\uff0c\u5bf9\u4e24\u4e2a\u53c2\u6570\u5316\u74f6\u5b50\u51e0\u4f55\u5bb6\u65cf\uff082\u53c2\u6570\u548c4\u53c2\u6570\uff09\u8fdb\u884c\u975e\u7ebf\u6027\u6709\u9650\u5143\u5206\u6790\u6570\u636e\u8bad\u7ec3\u3002", "result": "\u57284\u53c2\u6570\u74f6\u5b50\u5bb6\u65cf\u4e0a\uff0c\u4f4d\u79fb\u573a\u7684\u5e73\u5747\u76f8\u5bf9L2\u8bef\u5dee\u4e3a2.5-13%\uff0c\u65f6\u95f4\u76f8\u5173\u53cd\u4f5c\u7528\u529b\u8bef\u5dee\u7ea62.4%\uff0c\u7edd\u5bf9\u4f4d\u79fb\u8bef\u5dee\u572810^-4-10^-3\u91cf\u7ea7\uff0c\u80fd\u591f\u51c6\u786e\u6355\u6349\u5c48\u66f2\u7b49\u5173\u952e\u7269\u7406\u73b0\u8c61\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u8ba1\u7b97\u9ad8\u6548\u66ff\u4ee3\u6a21\u578b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8ba1\u7b97\u529b\u5b66\u4e2d\u7684\u591a\u4efb\u52a1\u9884\u6d4b\u548c\u9700\u8981\u5feb\u901f\u8bbe\u8ba1\u8bc4\u4f30\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2509.14072", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.14072", "abs": "https://arxiv.org/abs/2509.14072", "authors": ["Vincent Lauinger", "Lennart Schmitz", "Patrick Matalla", "Andrej Rode", "Sebastian Randel", "Laurent Schmalen"], "title": "Novel Phase-Noise-Tolerant Variational-Autoencoder-Based Equalization Suitable for Space-Division-Multiplexed Transmission", "comment": "Accepted and to be presented at the European Conference on Optical\n  Communication (ECOC) 2025", "summary": "We demonstrate the effectiveness of a novel phase-noise-tolerant,\nvariational-autoencoder-based equalization scheme for\nspace-division-multiplexed (SDM) transmission in an experiment over 150km of\nrandomly-coupled multi-core fibers.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u76f8\u4f4d\u566a\u58f0\u5bb9\u5fcd\u5747\u8861\u65b9\u6848\uff0c\u7528\u4e8e\u968f\u673a\u8026\u5408\u591a\u82af\u5149\u7ea4\u7684\u7a7a\u95f4\u5206\u590d\u7528\u4f20\u8f93\u5b9e\u9a8c", "motivation": "\u89e3\u51b3\u7a7a\u95f4\u5206\u590d\u7528\u4f20\u8f93\u4e2d\u76f8\u4f4d\u566a\u58f0\u5bf9\u4fe1\u53f7\u8d28\u91cf\u7684\u5f71\u54cd\u95ee\u9898\uff0c\u63d0\u9ad8\u591a\u82af\u5149\u7ea4\u4f20\u8f93\u7cfb\u7edf\u7684\u6027\u80fd", "method": "\u91c7\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\u67b6\u6784\u7684\u5747\u8861\u65b9\u6848\uff0c\u5177\u6709\u76f8\u4f4d\u566a\u58f0\u5bb9\u5fcd\u7279\u6027\uff0c\u5728150km\u968f\u673a\u8026\u5408\u591a\u82af\u5149\u7ea4\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6848\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5728\u957f\u8ddd\u79bb\u968f\u673a\u8026\u5408\u591a\u82af\u5149\u7ea4\u4f20\u8f93\u4e2d\u5b9e\u73b0\u826f\u597d\u7684\u5747\u8861\u6548\u679c", "conclusion": "\u57fa\u4e8eVAE\u7684\u5747\u8861\u65b9\u6848\u662f\u89e3\u51b3SDM\u4f20\u8f93\u4e2d\u76f8\u4f4d\u566a\u58f0\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4e3a\u591a\u82af\u5149\u7ea4\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u9014\u5f84"}}
{"id": "2509.13523", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13523", "abs": "https://arxiv.org/abs/2509.13523", "authors": ["V\u00e4in\u00f6 Hatanp\u00e4\u00e4", "Eugene Ku", "Jason Stock", "Murali Emani", "Sam Foreman", "Chunyong Jung", "Sandeep Madireddy", "Tung Nguyen", "Varuni Sastry", "Ray A. O. Sinurat", "Sam Wheeler", "Huihuo Zheng", "Troy Arcomano", "Venkatram Vishwanath", "Rao Kotamarthi"], "title": "AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions", "comment": "14 pages, 7 figures", "summary": "Generative machine learning offers new opportunities to better understand\ncomplex Earth system dynamics. Recent diffusion-based methods address spectral\nbiases and improve ensemble calibration in weather forecasting compared to\ndeterministic methods, yet have so far proven difficult to scale stably at high\nresolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin\ndiffusion transformer to address this gap, and SWiPe, a generalizable technique\nthat composes window parallelism with sequence and pipeline parallelism to\nshard window-based transformers without added communication cost or increased\nglobal batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS\n(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \\times 1$\npatch size on the 0.25{\\deg} ERA5 dataset, achieving 95.5% weak scaling\nefficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS\nand remains stable on seasonal scales to 90 days, highlighting the potential of\nbillion-parameter diffusion models for weather and climate prediction.", "AI": {"tldr": "AERIS\u662f\u4e00\u4e2a10-800\u4ebf\u53c2\u6570\u7684\u50cf\u7d20\u7ea7Swin\u6269\u6563\u53d8\u6362\u5668\uff0c\u901a\u8fc7SWiPe\u5e76\u884c\u5316\u6280\u672f\u5b9e\u73b0\u9ad8\u6548\u6269\u5c55\uff0c\u5728\u5929\u6c14\u9884\u6d4b\u4e2d\u8d85\u8d8aIFS ENS\u7cfb\u7edf\u5e76\u4fdd\u630190\u5929\u7684\u5b63\u8282\u5c3a\u5ea6\u7a33\u5b9a\u6027", "motivation": "\u89e3\u51b3\u6269\u6563\u6a21\u578b\u5728\u9ad8\u5206\u8fa8\u7387\u5929\u6c14\u9884\u6d4b\u4e2d\u96be\u4ee5\u7a33\u5b9a\u6269\u5c55\u7684\u95ee\u9898\uff0c\u5229\u7528\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u66f4\u597d\u5730\u7406\u89e3\u590d\u6742\u5730\u7403\u7cfb\u7edf\u52a8\u529b\u5b66", "method": "\u91c7\u7528\u50cf\u7d20\u7ea7Swin\u6269\u6563\u53d8\u6362\u5668\u67b6\u6784\uff0c\u7ed3\u5408SWiPe\u5e76\u884c\u5316\u6280\u672f\uff08\u7a97\u53e3\u5e76\u884c\u4e0e\u5e8f\u5217/\u6d41\u6c34\u7ebf\u5e76\u884c\u7ec4\u5408\uff09\uff0c\u5728Aurora\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97", "result": "\u57280.25\u5ea6ERA5\u6570\u636e\u96c6\u4e0a\u5b9e\u73b010.21 ExaFLOPS\u6301\u7eed\u6027\u80fd\u548c11.21 ExaFLOPS\u5cf0\u503c\u6027\u80fd\uff0c\u5f31\u6269\u5c55\u6548\u738795.5%\uff0c\u5f3a\u6269\u5c55\u6548\u738781.6%\uff0c\u6027\u80fd\u8d85\u8d8aIFS ENS\u7cfb\u7edf", "conclusion": "\u5341\u4ebf\u53c2\u6570\u7ea7\u522b\u7684\u6269\u6563\u6a21\u578b\u5728\u5929\u6c14\u548c\u6c14\u5019\u9884\u6d4b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u63d0\u4f9b\u6bd4\u786e\u5b9a\u6027\u65b9\u6cd5\u66f4\u597d\u7684\u96c6\u5408\u6821\u51c6\u548c\u5149\u8c31\u504f\u5dee\u5904\u7406"}}
{"id": "2509.14160", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.14160", "abs": "https://arxiv.org/abs/2509.14160", "authors": ["Adam Umra", "Aya Mostafa Ahmed", "Stefan Roth", "Aydin Sezgin"], "title": "Hardware-Efficient Cognitive Radar: Multi-Target Detection with RL-Driven Transmissive RIS", "comment": "5 pages, 3 figures, submitted to ICASSP 2026", "summary": "Cognitive radar has emerged as a key paradigm for next-generation sensing,\nenabling adaptive, intelligent operation in dynamic and complex environments.\nYet, conventional cognitive multiple-input multiple-output (MIMO) radars offer\nstrong detection performance but suffer from high hardware complexity and power\ndemands. To overcome these limitations, we develop a reinforcement learning\n(RL)-based framework that leverages a transmissive reconfigurable intelligent\nsurface (TRIS) for adaptive beamforming. A state-action-reward-state-action\n(SARSA) agent tunes TRIS phase shifts to improve multi-target detection in low\nsignal-to-noise ratio (SNR) conditions while operating with far fewer radio\nfrequency (RF) chains. Simulations confirm that the proposed TRIS-RL radar\nmatches or, for large number of elements, even surpasses MIMO performance with\nreduced cost and energy requirements.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u900f\u5c04\u5f0f\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u96f7\u8fbe\u6846\u67b6\uff0c\u5728\u51cf\u5c11\u5c04\u9891\u94fe\u6570\u91cf\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u591a\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u63d0\u5347", "motivation": "\u4f20\u7edf\u8ba4\u77e5MIMO\u96f7\u8fbe\u786c\u4ef6\u590d\u6742\u5ea6\u548c\u529f\u8017\u8fc7\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u6ce2\u675f\u6210\u5f62\u65b9\u6848", "method": "\u4f7f\u7528SARSA\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8c03\u6574TRIS\u76f8\u4f4d\u504f\u79fb\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u4f18\u5316\u591a\u76ee\u6807\u68c0\u6d4b\u6027\u80fd", "result": "\u4eff\u771f\u663e\u793aTRIS-RL\u96f7\u8fbe\u6027\u80fd\u5339\u914d\u751a\u81f3\u8d85\u8d8aMIMO\u96f7\u8fbe\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6210\u672c\u548c\u80fd\u8017", "conclusion": "TRIS-RL\u6846\u67b6\u4e3a\u4e0b\u4e00\u4ee3\u8ba4\u77e5\u96f7\u8fbe\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u5927\u89c4\u6a21\u9635\u5217\u5e94\u7528"}}
{"id": "2509.13527", "categories": ["cs.LG", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2509.13527", "abs": "https://arxiv.org/abs/2509.13527", "authors": ["Yulia Pimonova", "Michael G. Taylor", "Alice Allen", "Ping Yang", "Nicholas Lubbers"], "title": "Meta-Learning Linear Models for Molecular Property Prediction", "comment": "26 pages, 16 figures", "summary": "Chemists in search of structure-property relationships face great challenges\ndue to limited high quality, concordant datasets. Machine learning (ML) has\nsignificantly advanced predictive capabilities in chemical sciences, but these\nmodern data-driven approaches have increased the demand for data. In response\nto the growing demand for explainable AI (XAI) and to bridge the gap between\npredictive accuracy and human comprehensibility, we introduce LAMeL - a Linear\nAlgorithm for Meta-Learning that preserves interpretability while improving the\nprediction accuracy across multiple properties. While most approaches treat\neach chemical prediction task in isolation, LAMeL leverages a meta-learning\nframework to identify shared model parameters across related tasks, even if\nthose tasks do not share data, allowing it to learn a common functional\nmanifold that serves as a more informed starting point for new unseen tasks.\nOur method delivers performance improvements ranging from 1.1- to 25-fold over\nstandard ridge regression, depending on the domain of the dataset. While the\ndegree of performance enhancement varies across tasks, LAMeL consistently\noutperforms or matches traditional linear methods, making it a reliable tool\nfor chemical property prediction where both accuracy and interpretability are\ncritical.", "AI": {"tldr": "LAMeL\u662f\u4e00\u79cd\u7ebf\u6027\u5143\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u5728\u76f8\u5173\u4efb\u52a1\u95f4\u5171\u4eab\u6a21\u578b\u53c2\u6570\u6765\u63d0\u9ad8\u5316\u5b66\u6027\u8d28\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u6027\u80fd\u6bd4\u6807\u51c6\u5cad\u56de\u5f52\u63d0\u53471.1-25\u500d\u3002", "motivation": "\u5316\u5b66\u7814\u7a76\u4e2d\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u6709\u9650\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5bf9\u6570\u636e\u9700\u6c42\u589e\u52a0\uff0c\u9700\u8981\u5e73\u8861\u9884\u6d4b\u51c6\u786e\u6027\u548c\u4eba\u7c7b\u53ef\u7406\u89e3\u6027\uff0c\u56e0\u6b64\u5f00\u53d1\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684AI\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u8bc6\u522b\u76f8\u5173\u4efb\u52a1\u95f4\u7684\u5171\u4eab\u6a21\u578b\u53c2\u6570\uff0c\u5b66\u4e60\u5171\u540c\u51fd\u6570\u6d41\u5f62\u4f5c\u4e3a\u65b0\u4efb\u52a1\u7684\u66f4\u4f18\u8d77\u70b9\uff0c\u5373\u4f7f\u4efb\u52a1\u95f4\u4e0d\u5171\u4eab\u6570\u636e\u3002", "result": "\u6027\u80fd\u6bd4\u6807\u51c6\u5cad\u56de\u5f52\u63d0\u53471.1-25\u500d\uff0c\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u8868\u73b0\u7a33\u5b9a\uff0c\u59cb\u7ec8\u4f18\u4e8e\u6216\u5339\u914d\u4f20\u7edf\u7ebf\u6027\u65b9\u6cd5\u3002", "conclusion": "LAMeL\u662f\u5316\u5b66\u6027\u8d28\u9884\u6d4b\u4e2d\u53ef\u9760\u7684\u5de5\u5177\uff0c\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u90fd\u81f3\u5173\u91cd\u8981\u7684\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2509.13608", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13608", "abs": "https://arxiv.org/abs/2509.13608", "authors": ["Niruthiha Selvanayagam", "Ted Kurti"], "title": "Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection", "comment": null, "summary": "As Large Multimodal Models (LMMs) become integral to daily digital life,\nunderstanding their safety architectures is a critical problem for AI\nAlignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a\nglobally deployed model, on the difficult task of multimodal hate speech\ndetection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase\ninvestigation on 500 samples to probe the model's reasoning and failure modes.\nOur central finding is the experimental identification of a \"Unimodal\nBottleneck,\" an architectural flaw where the model's advanced multimodal\nreasoning is systematically preempted by context-blind safety filters. A\nquantitative validation of 144 content policy refusals reveals that these\noverrides are triggered in equal measure by unimodal visual 50% and textual 50%\ncontent. We further demonstrate that this safety system is brittle, blocking\nnot only high-risk imagery but also benign, common meme formats, leading to\npredictable false positives. These findings expose a fundamental tension\nbetween capability and safety in state-of-the-art LMMs, highlighting the need\nfor more integrated, context-aware alignment strategies to ensure AI systems\ncan be deployed both safely and effectively.", "AI": {"tldr": "GPT-4o mini\u5b58\u5728\"\u5355\u6a21\u6001\u74f6\u9888\"\u5b89\u5168\u67b6\u6784\u7f3a\u9677\uff0c\u5176\u5148\u8fdb\u7684\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u88ab\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\u7cfb\u7edf\u6027\u5730\u963b\u65ad\uff0c\u5bfc\u81f4\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4e2d\u51fa\u73b0\u53ef\u9884\u6d4b\u7684\u8bef\u62a5\u95ee\u9898", "motivation": "\u968f\u7740\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b(LMMs)\u6210\u4e3a\u65e5\u5e38\u751f\u6d3b\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u7406\u89e3\u5176\u5b89\u5168\u67b6\u6784\u5bf9\u4e8eAI\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u5168\u7403\u90e8\u7f72\u6a21\u578b\u7684\u5b89\u5168\u6027\u80fd", "method": "\u4f7f\u7528Hateful Memes Challenge\u6570\u636e\u96c6\uff0c\u5bf9500\u4e2a\u6837\u672c\u8fdb\u884c\u591a\u9636\u6bb5\u8c03\u67e5\uff0c\u5206\u6790\u6a21\u578b\u63a8\u7406\u548c\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u5bf9144\u4e2a\u5185\u5bb9\u7b56\u7565\u62d2\u7edd\u8fdb\u884c\u5b9a\u91cf\u9a8c\u8bc1", "result": "\u5b9e\u9a8c\u53d1\u73b050%\u7684\u62d2\u7edd\u7531\u5355\u6a21\u6001\u89c6\u89c9\u5185\u5bb9\u89e6\u53d1\uff0c50%\u7531\u6587\u672c\u5185\u5bb9\u89e6\u53d1\uff0c\u5b89\u5168\u7cfb\u7edf\u8106\u5f31\uff0c\u4e0d\u4ec5\u963b\u6b62\u9ad8\u98ce\u9669\u56fe\u50cf\uff0c\u8fd8\u963b\u6b62\u826f\u6027\u7684\u5e38\u89c1meme\u683c\u5f0f", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86\u6700\u5148\u8fdbLMMs\u4e2d\u80fd\u529b\u4e0e\u5b89\u5168\u4e4b\u95f4\u7684\u6839\u672c\u5f20\u529b\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u96c6\u6210\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5bf9\u9f50\u7b56\u7565\uff0c\u4ee5\u786e\u4fddAI\u7cfb\u7edf\u80fd\u591f\u5b89\u5168\u6709\u6548\u5730\u90e8\u7f72"}}
{"id": "2509.13621", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13621", "abs": "https://arxiv.org/abs/2509.13621", "authors": ["Antonin Sulc", "Thorsten Hellert", "Steven Hunt"], "title": "Unsupervised Anomaly Detection in ALS EPICS Event Logs", "comment": "6 pages, 5 figures, The 20th International Conference on Accelerator\n  and Large Experimental Physics Control Systems", "summary": "This paper introduces an automated fault analysis framework for the Advanced\nLight Source (ALS) that processes real-time event logs from its EPICS control\nsystem. By treating log entries as natural language, we transform them into\ncontextual vector representations using semantic embedding techniques. A\nsequence-aware neural network, trained on normal operational data, assigns a\nreal-time anomaly score to each event. This method flags deviations from\nbaseline behavior, enabling operators to rapidly identify the critical event\nsequences that precede complex system failures.", "AI": {"tldr": "\u57fa\u4e8e\u8bed\u4e49\u5d4c\u5165\u548c\u5e8f\u5217\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u52a8\u5316\u6545\u969c\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406ALS\u5149\u6e90\u7684\u5b9e\u65f6\u4e8b\u4ef6\u65e5\u5fd7\u5e76\u68c0\u6d4b\u5f02\u5e38", "motivation": "\u4e3a\u5148\u8fdb\u5149\u6e90(ALS)\u63a7\u5236\u7cfb\u7edf\u5f00\u53d1\u81ea\u52a8\u5316\u6545\u969c\u5206\u6790\u65b9\u6cd5\uff0c\u5e2e\u52a9\u64cd\u4f5c\u5458\u5feb\u901f\u8bc6\u522b\u5bfc\u81f4\u590d\u6742\u7cfb\u7edf\u6545\u969c\u7684\u5173\u952e\u4e8b\u4ef6\u5e8f\u5217", "method": "\u5c06EPICS\u63a7\u5236\u7cfb\u7edf\u7684\u65e5\u5fd7\u6761\u76ee\u89c6\u4e3a\u81ea\u7136\u8bed\u8a00\uff0c\u4f7f\u7528\u8bed\u4e49\u5d4c\u5165\u6280\u672f\u8f6c\u6362\u4e3a\u4e0a\u4e0b\u6587\u5411\u91cf\u8868\u793a\uff0c\u901a\u8fc7\u5e8f\u5217\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\u5bf9\u6b63\u5e38\u64cd\u4f5c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e3a\u6bcf\u4e2a\u4e8b\u4ef6\u5206\u914d\u5b9e\u65f6\u5f02\u5e38\u5206\u6570", "result": "\u80fd\u591f\u6807\u8bb0\u4e0e\u57fa\u7ebf\u884c\u4e3a\u7684\u504f\u5dee\uff0c\u6709\u6548\u68c0\u6d4b\u7cfb\u7edf\u6545\u969c\u524d\u7684\u5f02\u5e38\u4e8b\u4ef6\u5e8f\u5217", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u7cfb\u7edf\u6545\u969c\u7684\u81ea\u52a8\u5316\u5b9e\u65f6\u76d1\u6d4b\u548c\u9884\u8b66\uff0c\u63d0\u9ad8\u4e86\u6545\u969c\u8bca\u65ad\u6548\u7387"}}
{"id": "2509.14217", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.14217", "abs": "https://arxiv.org/abs/2509.14217", "authors": ["Andriy Enttsel", "Weichen Wang", "Mauro Mangia", "Riccardo Rovatti", "Deniz G\u00fcnd\u00fcz"], "title": "Goal-Oriented Joint Source-Channel Coding: Distortion-Classification-Power Trade-off", "comment": "13 pages, 3 figures", "summary": "Joint source-channel coding is a compelling paradigm when low-latency and\nlow-complexity communication is required. This work proposes a theoretical\nframework that integrates classification and anomaly detection within the\nconventional signal reconstruction objective. Assuming a Gaussian scalar source\nand constraining the encoder to piecewise linear mappings, we derive tractable\ndesign rules and explicitly characterize the trade-offs between distortion,\nclassification error, and transmission power.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\u96c6\u6210\u5230\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u4e2d\uff0c\u5728\u4fe1\u53f7\u91cd\u5efa\u76ee\u6807\u57fa\u7840\u4e0a\u589e\u52a0\u5206\u7c7b\u529f\u80fd", "motivation": "\u5728\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u590d\u6742\u5ea6\u901a\u4fe1\u9700\u6c42\u4e0b\uff0c\u9700\u8981\u5c06\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\u529f\u80fd\u6574\u5408\u5230\u4f20\u7edf\u7684\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u6846\u67b6\u4e2d", "method": "\u5047\u8bbe\u9ad8\u65af\u6807\u91cf\u6e90\uff0c\u7ea6\u675f\u7f16\u7801\u5668\u4e3a\u5206\u6bb5\u7ebf\u6027\u6620\u5c04\uff0c\u63a8\u5bfc\u53ef\u5904\u7406\u7684\u8bbe\u8ba1\u89c4\u5219\uff0c\u660e\u786e\u8868\u5f81\u5931\u771f\u3001\u5206\u7c7b\u9519\u8bef\u548c\u4f20\u8f93\u529f\u7387\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb", "result": "\u5efa\u7acb\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u4fe1\u53f7\u91cd\u5efa\u3001\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u63d0\u4f9b\u4e86\u96c6\u6210\u5206\u7c7b\u529f\u80fd\u7684\u7406\u8bba\u57fa\u7840\uff0c\u660e\u786e\u4e86\u4e0d\u540c\u6027\u80fd\u6307\u6807\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb"}}
{"id": "2509.13625", "categories": ["cs.LG", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13625", "abs": "https://arxiv.org/abs/2509.13625", "authors": ["Bishnu Bhusal", "Manoj Acharya", "Ramneet Kaur", "Colin Samplawski", "Anirban Roy", "Adam D. Cobb", "Rohit Chadha", "Susmit Jha"], "title": "Privacy-Aware In-Context Learning for Large Language Models", "comment": null, "summary": "Large language models (LLMs) have significantly transformed natural language\nunderstanding and generation, but they raise privacy concerns due to potential\nexposure of sensitive information. Studies have highlighted the risk of\ninformation leakage, where adversaries can extract sensitive information\nembedded in the prompts. In this work, we introduce a novel private prediction\nframework for generating high-quality synthetic text with strong privacy\nguarantees. Our approach leverages the Differential Privacy (DP) framework to\nensure worst-case theoretical bounds on information leakage without requiring\nany fine-tuning of the underlying models.The proposed method performs inference\non private records and aggregates the resulting per-token output distributions.\nThis enables the generation of longer and coherent synthetic text while\nmaintaining privacy guarantees. Additionally, we propose a simple blending\noperation that combines private and public inference to further enhance\nutility. Empirical evaluations demonstrate that our approach outperforms\nprevious state-of-the-art methods on in-context-learning (ICL) tasks, making it\na promising direction for privacy-preserving text generation while maintaining\nhigh utility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u6587\u672c\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u6bcf\u4e2atoken\u7684\u8f93\u51fa\u5206\u5e03\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6587\u672c\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u5b9e\u7528\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u4ece\u63d0\u793a\u4e2d\u63d0\u53d6\u654f\u611f\u4fe1\u606f\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u4fdd\u6301\u6587\u672c\u8d28\u91cf\u7684\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5dee\u5206\u9690\u79c1\u6846\u67b6\uff0c\u5bf9\u79c1\u6709\u8bb0\u5f55\u8fdb\u884c\u63a8\u7406\u5e76\u805a\u5408\u6bcf\u4e2atoken\u7684\u8f93\u51fa\u5206\u5e03\uff0c\u901a\u8fc7\u6df7\u5408\u79c1\u6709\u548c\u516c\u5171\u63a8\u7406\u7684\u7b80\u5355\u64cd\u4f5c\u6765\u63d0\u5347\u5b9e\u7528\u6027\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u957f\u4e14\u8fde\u8d2f\u7684\u5408\u6210\u6587\u672c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9690\u79c1\u4fdd\u62a4\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u5728\u4fdd\u6301\u9ad8\u5b9e\u7528\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u969c\u3002"}}
{"id": "2509.13974", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13974", "abs": "https://arxiv.org/abs/2509.13974", "authors": ["Amirhossein Shahbazinia", "Jonathan Dan", "Jose A. Miranda", "Giovanni Ansaloni", "David Atienza"], "title": "Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection", "comment": null, "summary": "Objective: Epilepsy, a prevalent neurological disease, demands careful\ndiagnosis and continuous care. Seizure detection remains challenging, as\ncurrent clinical practice relies on expert analysis of electroencephalography,\nwhich is a time-consuming process and requires specialized knowledge.\nAddressing this challenge, this paper explores automated epileptic seizure\ndetection using deep learning, focusing on personalized continual learning\nmodels that adapt to each patient's unique electroencephalography signal\nfeatures, which evolve over time. Methods: In this context, our approach\naddresses the challenge of integrating new data into existing models without\ncatastrophic forgetting, a common issue in static deep learning models. We\npropose EpiSMART, a continual learning framework for seizure detection that\nuses a size-constrained replay buffer and an informed sample selection strategy\nto incrementally adapt to patient-specific electroencephalography signals. By\nselectively retaining high-entropy and seizure-predicted samples, our method\npreserves critical past information while maintaining high performance with\nminimal memory and computational requirements. Results: Validation on the\nCHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score\nover a trained baseline without updates in all other patients. On average,\nEpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,\nmaking it suitable for real-time deployment in wearable systems.\nConclusion:EpiSMART enables robust and personalized seizure detection under\nrealistic and resource-constrained conditions by effectively integrating new\ndata into existing models without degrading past knowledge. Significance: This\nframework advances automated seizure detection by providing a continual\nlearning approach that supports patient-specific adaptation and practical\ndeployment in wearable healthcare systems.", "AI": {"tldr": "EpiSMART\u662f\u4e00\u4e2a\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u4fdd\u7559\u9ad8\u71b5\u548c\u9884\u6d4b\u4e3a\u53d1\u4f5c\u7684\u6837\u672c\uff0c\u5728\u6709\u9650\u5185\u5b58\u548c\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u4e2a\u6027\u5316\u9002\u5e94\uff0c\u5728CHB-MIT\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u63d0\u534721%\u3002", "motivation": "\u5f53\u524d\u766b\u75eb\u8bca\u65ad\u4f9d\u8d56\u4e13\u5bb6\u5206\u6790EEG\u4fe1\u53f7\uff0c\u8fc7\u7a0b\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u60a3\u8005\u7279\u5f02\u6027EEG\u4fe1\u53f7\u7279\u5f81\u968f\u65f6\u95f4\u53d8\u5316\u7684\u81ea\u52a8\u5316\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faEpiSMART\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u5c0f\u53d7\u9650\u7684\u91cd\u653e\u7f13\u51b2\u533a\u548c\u4fe1\u606f\u6837\u672c\u9009\u62e9\u7b56\u7565\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u4fdd\u7559\u9ad8\u71b5\u548c\u9884\u6d4b\u4e3a\u53d1\u4f5c\u7684\u6837\u672c\uff0c\u589e\u91cf\u5f0f\u9002\u5e94\u60a3\u8005\u7279\u5f02\u6027EEG\u4fe1\u53f7\u3002", "result": "\u5728CHB-MIT\u6570\u636e\u96c6\u9a8c\u8bc1\u4e2d\uff0cEpiSMART\u76f8\u6bd4\u65e0\u66f4\u65b0\u7684\u57fa\u7ebf\u6a21\u578bF1\u5206\u6570\u63d0\u534721%\uff0c\u5e73\u5747\u6bcf\u5929\u4ec5\u97006.46\u5206\u949f\u6807\u8bb0\u6570\u636e\u548c6.28\u6b21\u66f4\u65b0\uff0c\u9002\u5408\u53ef\u7a7f\u6234\u7cfb\u7edf\u5b9e\u65f6\u90e8\u7f72\u3002", "conclusion": "EpiSMART\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73b0\u5b9e\u6761\u4ef6\u4e0b\uff0c\u6709\u6548\u6574\u5408\u65b0\u6570\u636e\u800c\u4e0d\u635f\u5bb3\u8fc7\u53bb\u77e5\u8bc6\uff0c\u5b9e\u73b0\u9c81\u68d2\u7684\u4e2a\u6027\u5316\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\uff0c\u63a8\u52a8\u53ef\u7a7f\u6234\u533b\u7597\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2509.13633", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13633", "abs": "https://arxiv.org/abs/2509.13633", "authors": ["Jeremy Oon", "Rakhi Manohar Mepparambath", "Ling Feng"], "title": "DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis", "comment": null, "summary": "Despite the significant progress of deep learning models in multitude of\napplications, their adaption in planning and policy related areas remains\nchallenging due to the black-box nature of these models. In this work, we\ndevelop a set of DeepLogit models that follow a novel sequentially constrained\napproach in estimating deep learning models for transport policy analysis. In\nthe first step of the proposed approach, we estimate a convolutional neural\nnetwork (CNN) model with only linear terms, which is equivalent of a\nlinear-in-parameter multinomial logit model. We then estimate other deep\nlearning models by constraining the parameters that need interpretability at\nthe values obtained in the linear-in-parameter CNN model and including higher\norder terms or by introducing advanced deep learning architectures like\nTransformers. Our approach can retain the interpretability of the selected\nparameters, yet provides significantly improved model accuracy than the\ndiscrete choice model. We demonstrate our approach on a transit route choice\nexample using real-world transit smart card data from Singapore. This study\nshows the potential for a unifying approach, where theory-based discrete choice\nmodel (DCM) and data-driven AI models can leverage each other's strengths in\ninterpretability and predictive power. With the availability of larger datasets\nand more complex constructions, such approach can lead to more accurate models\nusing discrete choice models while maintaining its applicability in planning\nand policy-related areas. Our code is available on\nhttps://github.com/jeremyoon/route-choice/ .", "AI": {"tldr": "\u63d0\u51faDeepLogit\u6a21\u578b\uff0c\u901a\u8fc7\u5e8f\u5217\u7ea6\u675f\u65b9\u6cd5\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u79bb\u6563\u9009\u62e9\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u53c2\u6570\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u89c4\u5212\u548c\u653f\u7b56\u9886\u57df\u7684\u5e94\u7528\u53d7\u9650\u4e8e\u5176\u9ed1\u76d2\u7279\u6027\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u53c8\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u65b9\u6cd5", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u5148\u4f30\u8ba1\u7ebf\u6027\u53c2\u6570\u7684CNN\u6a21\u578b\uff08\u7b49\u4ef7\u4e8e\u591a\u9879Logit\u6a21\u578b\uff09\uff0c\u7136\u540e\u7ea6\u675f\u9700\u8981\u89e3\u91ca\u7684\u53c2\u6570\u503c\uff0c\u5f15\u5165\u9ad8\u9636\u9879\u6216Transformer\u7b49\u5148\u8fdb\u67b6\u6784", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u65b0\u52a0\u5761\u516c\u4ea4\u5237\u5361\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u5728\u4fdd\u6301\u9009\u5b9a\u53c2\u6570\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027", "conclusion": "\u5c55\u793a\u4e86\u7406\u8bba\u9a71\u52a8\u7684\u79bb\u6563\u9009\u62e9\u6a21\u578b\u4e0e\u6570\u636e\u9a71\u52a8\u7684AI\u6a21\u578b\u76f8\u7ed3\u5408\u7684\u7edf\u4e00\u65b9\u6cd5\u6f5c\u529b\uff0c\u53ef\u5728\u4fdd\u6301\u89c4\u5212\u653f\u7b56\u9002\u7528\u6027\u7684\u540c\u65f6\u83b7\u5f97\u66f4\u51c6\u786e\u6a21\u578b"}}
{"id": "2509.14029", "categories": ["cs.LG", "eess.SP", "physics.comp-ph", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2509.14029", "abs": "https://arxiv.org/abs/2509.14029", "authors": ["Samuel Tovey", "Julian Ho\u00dfbach", "Sandro Kuppel", "Tobias Ensslen", "Jan C. Behrends", "Christian Holm"], "title": "Deep Learning-Driven Peptide Classification in Biological Nanopores", "comment": "29 pages (incl. references) 7 figures", "summary": "A device capable of performing real time classification of proteins in a\nclinical setting would allow for inexpensive and rapid disease diagnosis. One\nsuch candidate for this technology are nanopore devices. These devices work by\nmeasuring a current signal that arises when a protein or peptide enters a\nnanometer-length-scale pore. Should this current be uniquely related to the\nstructure of the peptide and its interactions with the pore, the signals can be\nused to perform identification. While such a method would allow for real time\nidentification of peptides and proteins in a clinical setting, to date, the\ncomplexities of these signals limit their accuracy. In this work, we tackle the\nissue of classification by converting the current signals into scaleogram\nimages via wavelet transforms, capturing amplitude, frequency, and time\ninformation in a modality well-suited to machine learning algorithms. When\ntested on 42 peptides, our method achieved a classification accuracy of\n~$81\\,\\%$, setting a new state-of-the-art in the field and taking a step toward\npractical peptide/protein diagnostics at the point of care. In addition, we\ndemonstrate model transfer techniques that will be critical when deploying\nthese models into real hardware, paving the way to a new method for real-time\ndisease diagnosis.", "AI": {"tldr": "\u4f7f\u7528\u5c0f\u6ce2\u53d8\u6362\u5c06\u7eb3\u7c73\u5b54\u7535\u6d41\u4fe1\u53f7\u8f6c\u6362\u4e3a\u5c3a\u5ea6\u56fe\u56fe\u50cf\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u5b9e\u73b0\u86cb\u767d\u8d28\u5b9e\u65f6\u5206\u7c7b\uff0c\u51c6\u786e\u7387\u8fbe81%\uff0c\u521b\u4e0b\u65b0\u7eaa\u5f55", "motivation": "\u5f00\u53d1\u80fd\u591f\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u5b9e\u65f6\u5206\u7c7b\u86cb\u767d\u8d28\u7684\u8bbe\u5907\uff0c\u5b9e\u73b0\u5ec9\u4ef7\u5feb\u901f\u7684\u75be\u75c5\u8bca\u65ad\u3002\u7eb3\u7c73\u5b54\u6280\u672f\u867d\u7136\u6709\u671b\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u4f46\u5f53\u524d\u4fe1\u53f7\u590d\u6742\u6027\u9650\u5236\u4e86\u5206\u7c7b\u51c6\u786e\u6027", "method": "\u5c06\u7eb3\u7c73\u5b54\u7535\u6d41\u4fe1\u53f7\u901a\u8fc7\u5c0f\u6ce2\u53d8\u6362\u8f6c\u6362\u4e3a\u5c3a\u5ea6\u56fe\u56fe\u50cf\uff0c\u6355\u6349\u632f\u5e45\u3001\u9891\u7387\u548c\u65f6\u95f4\u4fe1\u606f\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5206\u7c7b", "result": "\u572842\u79cd\u80bd\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u7ea681%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u521b\u4e0b\u8be5\u9886\u57df\u65b0\u7eaa\u5f55\uff0c\u5e76\u5c55\u793a\u4e86\u6a21\u578b\u8fc1\u79fb\u6280\u672f", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u65f6\u75be\u75c5\u8bca\u65ad\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u5411\u4e34\u5e8a\u70b9\u62a4\u7406\u86cb\u767d\u8d28\u8bca\u65ad\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65"}}
{"id": "2509.13634", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13634", "abs": "https://arxiv.org/abs/2509.13634", "authors": ["Md Bokhtiar Al Zami", "Md Raihan Uddin", "Dinh C. Nguyen"], "title": "Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs", "comment": "15 pages, under revision at IEEE Internet of Things Journal", "summary": "Federated learning (FL) has gained popularity as a privacy-preserving method\nof training machine learning models on decentralized networks. However to\nensure reliable operation of UAV-assisted FL systems, issues like as excessive\nenergy consumption, communication inefficiencies, and security vulnerabilities\nmust be solved. This paper proposes an innovative framework that integrates\nDigital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to\ntackle these challenges. UAVs act as mobile base stations, allowing scattered\ndevices to train FL models locally and upload model updates for aggregation. By\nincorporating DT technology, our approach enables real-time system monitoring\nand predictive maintenance, improving UAV network efficiency. Additionally,\nZero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification\nwithout exposing sensitive data. To optimize energy efficiency and resource\nmanagement, we introduce a dynamic allocation strategy that adjusts UAV flight\npaths, transmission power, and processing rates based on network conditions.\nUsing block coordinate descent and convex optimization techniques, our method\nsignificantly reduces system energy consumption by up to 29.6% compared to\nconventional FL approaches. Simulation results demonstrate improved learning\nperformance, security, and scalability, positioning this framework as a\npromising solution for next-generation UAV-based intelligent networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6570\u5b57\u5b6a\u751f(DT)\u548c\u96f6\u77e5\u8bc6\u8054\u90a6\u5b66\u4e60(zkFed)\u7684\u521b\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u65e0\u4eba\u673a\u8f85\u52a9\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u80fd\u8017\u3001\u901a\u4fe1\u6548\u7387\u548c\u5b89\u5168\u6027\u95ee\u9898\u3002", "motivation": "\u65e0\u4eba\u673a\u8f85\u52a9\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u9762\u4e34\u80fd\u8017\u8fc7\u9ad8\u3001\u901a\u4fe1\u6548\u7387\u4f4e\u4e0b\u548c\u5b89\u5168\u6f0f\u6d1e\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u6765\u786e\u4fdd\u7cfb\u7edf\u53ef\u9760\u8fd0\u884c\u3002", "method": "\u91c7\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u5b9e\u73b0\u5b9e\u65f6\u7cfb\u7edf\u76d1\u63a7\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u7ed3\u5408\u96f6\u77e5\u8bc6\u8bc1\u660e\u6280\u672f\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u5206\u914d\u7b56\u7565\u4f18\u5316\u65e0\u4eba\u673a\u98de\u884c\u8def\u5f84\u3001\u4f20\u8f93\u529f\u7387\u548c\u5904\u7406\u901f\u7387\u3002\u4f7f\u7528\u5757\u5750\u6807\u4e0b\u964d\u548c\u51f8\u4f18\u5316\u6280\u672f\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7cfb\u7edf\u80fd\u8017\u964d\u4f4e\u9ad8\u8fbe29.6%\uff0c\u4eff\u771f\u7ed3\u679c\u663e\u793a\u5b66\u4e60\u6027\u80fd\u3001\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u4eba\u673a\u667a\u80fd\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u80fd\u8017\u4f18\u5316\u3001\u5b89\u5168\u589e\u5f3a\u548c\u7cfb\u7edf\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.13636", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13636", "abs": "https://arxiv.org/abs/2509.13636", "authors": ["Yasin Hasanpoor", "Bahram Tarvirdizadeh", "Khalil Alipour", "Mohammad Ghamari"], "title": "Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images", "comment": "14 pages 7 images 2 tables", "summary": "This study introduces a novel method that transforms multimodal physiological\nsignalsphotoplethysmography (PPG), galvanic skin response (GSR), and\nacceleration (ACC) into 2D image matrices to enhance stress detection using\nconvolutional neural networks (CNNs). Unlike traditional approaches that\nprocess these signals separately or rely on fixed encodings, our technique\nfuses them into structured image representations that enable CNNs to capture\ntemporal and cross signal dependencies more effectively. This image based\ntransformation not only improves interpretability but also serves as a robust\nform of data augmentation. To further enhance generalization and model\nrobustness, we systematically reorganize the fused signals into multiple\nformats, combining them in a multi stage training pipeline. This approach\nsignificantly boosts classification performance. While demonstrated here in the\ncontext of stress detection, the proposed method is broadly applicable to any\ndomain involving multimodal physiological signals, paving the way for more\naccurate, personalized, and real time health monitoring through wearable\ntechnologies.", "AI": {"tldr": "\u5c06\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\uff08PPG\u3001GSR\u3001ACC\uff09\u8f6c\u6362\u4e3a2D\u56fe\u50cf\u77e9\u9635\uff0c\u901a\u8fc7CNN\u63d0\u5347\u538b\u529b\u68c0\u6d4b\u6027\u80fd\u7684\u65b0\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5355\u72ec\u5904\u7406\u591a\u6a21\u6001\u4fe1\u53f7\u6216\u4f9d\u8d56\u56fa\u5b9a\u7f16\u7801\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349\u65f6\u5e8f\u548c\u8de8\u4fe1\u53f7\u4f9d\u8d56\u5173\u7cfb\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u878d\u5408\u8868\u793a\u65b9\u6cd5", "method": "\u5c06\u751f\u7406\u4fe1\u53f7\u878d\u5408\u4e3a\u7ed3\u6784\u5316\u56fe\u50cf\u8868\u793a\uff0c\u901a\u8fc7\u7cfb\u7edf\u91cd\u7ec4\u4e3a\u591a\u79cd\u683c\u5f0f\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5229\u7528CNN\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u5206\u7c7b", "result": "\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\uff0c\u6539\u5584\u4e86\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u538b\u529b\u68c0\u6d4b\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4efb\u4f55\u6d89\u53ca\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u7684\u9886\u57df\uff0c\u4e3a\u53ef\u7a7f\u6234\u6280\u672f\u5b9e\u73b0\u66f4\u51c6\u786e\u3001\u4e2a\u6027\u5316\u548c\u5b9e\u65f6\u7684\u5065\u5eb7\u76d1\u6d4b\u94fa\u5e73\u9053\u8def"}}
{"id": "2509.13642", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13642", "abs": "https://arxiv.org/abs/2509.13642", "authors": ["Zirun Guo", "Feng Zhang", "Kai Jia", "Tao Jin"], "title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "comment": null, "summary": "We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that\nreframes interleaved image-text generation as a tool-use problem. LLM-I is\ndesigned to overcome the \"one-tool\" bottleneck of current unified models, which\nare limited to synthetic imagery and struggle with tasks requiring factual\ngrounding or programmatic precision. Our framework empowers a central LLM or\nMLLM agent to intelligently orchestrate a diverse toolkit of specialized visual\ntools, including online image search, diffusion-based generation, code\nexecution, and image editing. The agent is trained to select and apply these\ntools proficiently via a Reinforcement Learning (RL) framework that features a\nhybrid reward system combining rule-based logic with judgments from LLM and\nMLLM evaluators. Trained on a diverse new dataset using four different model\nbackbones, LLM-I demonstrates state-of-the-art performance, outperforming\nexisting methods by a large margin across four benchmarks. We also introduce a\nnovel test-time scaling strategy that provides further performance gains.\nProject Page: https://github.com/ByteDance-BandAI/LLM-I.", "AI": {"tldr": "LLM-Interleaved\u662f\u4e00\u4e2a\u5c06\u56fe\u50cf-\u6587\u672c\u4ea4\u9519\u751f\u6210\u91cd\u6784\u4e3a\u5de5\u5177\u4f7f\u7528\u95ee\u9898\u7684\u52a8\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLM\u667a\u80fd\u8c03\u5ea6\u591a\u79cd\u89c6\u89c9\u5de5\u5177\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u7edf\u4e00\u6a21\u578b\u53ea\u80fd\u4f7f\u7528\u5355\u4e00\u5de5\u5177\u3001\u5c40\u9650\u4e8e\u5408\u6210\u56fe\u50cf\u3001\u96be\u4ee5\u5904\u7406\u9700\u8981\u4e8b\u5b9e\u57fa\u7840\u6216\u7a0b\u5e8f\u5316\u7cbe\u5ea6\u7684\u4efb\u52a1\u7684\u74f6\u9888\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\u4e2d\u592eLLM/MLLM\u4ee3\u7406\u667a\u80fd\u8c03\u5ea6\u4e13\u4e1a\u89c6\u89c9\u5de5\u5177\uff08\u5728\u7ebf\u56fe\u50cf\u641c\u7d22\u3001\u6269\u6563\u751f\u6210\u3001\u4ee3\u7801\u6267\u884c\u3001\u56fe\u50cf\u7f16\u8f91\uff09\uff0c\u91c7\u7528\u7ed3\u5408\u89c4\u5219\u903b\u8f91\u548cLLM/MLLM\u8bc4\u4f30\u7684\u6df7\u5408\u5956\u52b1\u7cfb\u7edf\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b56\u7565\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "LLM-Interleaved\u6846\u67b6\u901a\u8fc7\u5de5\u5177\u4f7f\u7528\u8303\u5f0f\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u50cf-\u6587\u672c\u4ea4\u9519\u751f\u6210\u7684\u6311\u6218\uff0c\u5c55\u793a\u4e86\u5728\u52a8\u6001\u5de5\u5177\u8c03\u5ea6\u65b9\u9762\u7684\u5f3a\u5927\u80fd\u529b\u3002"}}
{"id": "2509.13648", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.13648", "abs": "https://arxiv.org/abs/2509.13648", "authors": ["Geon Lee", "Bhuvesh Kumar", "Clark Mingxuan Ju", "Tong Zhao", "Kijung Shin", "Neil Shah", "Liam Collins"], "title": "Sequential Data Augmentation for Generative Recommendation", "comment": null, "summary": "Generative recommendation plays a crucial role in personalized systems,\npredicting users' future interactions from their historical behavior sequences.\nA critical yet underexplored factor in training these models is data\naugmentation, the process of constructing training data from user interaction\nhistories. By shaping the training distribution, data augmentation directly and\noften substantially affects model generalization and performance. Nevertheless,\nin much of the existing work, this process is simplified, applied\ninconsistently, or treated as a minor design choice, without a systematic and\nprincipled understanding of its effects.\n  Motivated by our empirical finding that different augmentation strategies can\nyield large performance disparities, we conduct an in-depth analysis of how\nthey reshape training distributions and influence alignment with future targets\nand generalization to unseen inputs. To systematize this design space, we\npropose GenPAS, a generalized and principled framework that models augmentation\nas a stochastic sampling process over input-target pairs with three\nbias-controlled steps: sequence sampling, target sampling, and input sampling.\nThis formulation unifies widely used strategies as special cases and enables\nflexible control of the resulting training distribution. Our extensive\nexperiments on benchmark and industrial datasets demonstrate that GenPAS yields\nsuperior accuracy, data efficiency, and parameter efficiency compared to\nexisting strategies, providing practical guidance for principled training data\nconstruction in generative recommendation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86GenPAS\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u5730\u5206\u6790\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u6570\u636e\u589e\u5f3a\u7b56\u7565\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u504f\u7f6e\u63a7\u5236\u6b65\u9aa4\u7edf\u4e00\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u4e2d\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\u5f80\u5f80\u88ab\u7b80\u5316\u5904\u7406\u6216\u5e94\u7528\u4e0d\u4e00\u81f4\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u548c\u539f\u5219\u6027\u7684\u7406\u89e3\uff0c\u800c\u4e0d\u540c\u7684\u589e\u5f3a\u7b56\u7565\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u63d0\u51faGenPAS\u6846\u67b6\uff0c\u5c06\u6570\u636e\u589e\u5f3a\u5efa\u6a21\u4e3a\u5305\u542b\u4e09\u4e2a\u504f\u7f6e\u63a7\u5236\u6b65\u9aa4\u7684\u968f\u673a\u91c7\u6837\u8fc7\u7a0b\uff1a\u5e8f\u5217\u91c7\u6837\u3001\u76ee\u6807\u91c7\u6837\u548c\u8f93\u5165\u91c7\u6837\uff0c\u7edf\u4e00\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684\u7b56\u7565\u4f5c\u4e3a\u7279\u4f8b\u3002", "result": "\u5728\u57fa\u51c6\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cGenPAS\u5728\u51c6\u786e\u6027\u3001\u6570\u636e\u6548\u7387\u548c\u53c2\u6570\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u7b56\u7565\u3002", "conclusion": "GenPAS\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6307\u5bfc\uff0c\u80fd\u591f\u7075\u6d3b\u63a7\u5236\u8bad\u7ec3\u5206\u5e03\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.13651", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13651", "abs": "https://arxiv.org/abs/2509.13651", "authors": ["Yongkang Du", "Jieyu Zhao", "Yijun Yang", "Tianyi Zhou"], "title": "Controllable Pareto Trade-off between Fairness and Accuracy", "comment": null, "summary": "The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work\nfocuses on finding a single \"optimal\" solution to balance the two objectives,\nwhich is limited considering the diverse solutions on the Pareto front. This\nwork intends to provide controllable trade-offs according to the user's\npreference of the two objectives, which is defined as a reference vector. To\nachieve this goal, we apply multi-objective optimization (MOO), which can find\nsolutions from various regions of the Pareto front. However, it is challenging\nto precisely control the trade-off due to the stochasticity of the training\nprocess and the high dimentional gradient vectors. Thus, we propose\nControllable Pareto Trade-off (CPT) that can effectively train models to\nperform different trade-offs according to users' preferences. CPT 1) stabilizes\nthe fairness update with a moving average of stochastic gradients to determine\nthe update direction, and 2) prunes the gradients by only keeping the gradients\nof the critical parameters. We evaluate CPT on hate speech detection and\noccupation classification tasks. Experiments show that CPT can achieve a\nhigher-quality set of solutions on the Pareto front than the baseline methods.\nIt also exhibits better controllability and can precisely follow the\nhuman-defined reference vectors.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCPT\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u5b9e\u73b0\u516c\u5e73\u6027\u4e0e\u51c6\u786e\u6027\u7684\u53ef\u63a7\u6743\u8861\uff0c\u4f7f\u7528\u79fb\u52a8\u5e73\u5747\u68af\u5ea6\u7a33\u5b9a\u6027\u548c\u5173\u952e\u53c2\u6570\u68af\u5ea6\u526a\u679d\u6280\u672f\uff0c\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u548c\u804c\u4e1a\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dNLP\u4efb\u52a1\u4e2d\u516c\u5e73\u6027\u4e0e\u51c6\u786e\u6027\u7684\u6743\u8861\u7814\u7a76\u901a\u5e38\u5bfb\u627e\u5355\u4e00\"\u6700\u4f18\"\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5e15\u7d2f\u6258\u524d\u6cbf\u5b58\u5728\u591a\u79cd\u53ef\u80fd\u89e3\u3002\u672c\u6587\u65e8\u5728\u6839\u636e\u7528\u6237\u504f\u597d\u63d0\u4f9b\u53ef\u63a7\u7684\u6743\u8861\u65b9\u6848\u3002", "method": "\u63d0\u51faControllable Pareto Trade-off (CPT)\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u968f\u673a\u68af\u5ea6\u7684\u79fb\u52a8\u5e73\u5747\u6765\u7a33\u5b9a\u516c\u5e73\u6027\u66f4\u65b0\u65b9\u5411\uff1b2) \u901a\u8fc7\u4ec5\u4fdd\u7559\u5173\u952e\u53c2\u6570\u7684\u68af\u5ea6\u8fdb\u884c\u68af\u5ea6\u526a\u679d\u3002", "result": "\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u548c\u804c\u4e1a\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCPT\u80fd\u591f\u5728\u5e15\u7d2f\u6258\u524d\u6cbf\u83b7\u5f97\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u96c6\u5408\uff0c\u5e76\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u53ef\u63a7\u6027\uff0c\u80fd\u591f\u7cbe\u786e\u9075\u5faa\u4eba\u5de5\u5b9a\u4e49\u7684\u53c2\u8003\u5411\u91cf\u3002", "conclusion": "CPT\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u516c\u5e73\u6027-\u51c6\u786e\u6027\u6743\u8861\u7684\u53ef\u63a7\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u6280\u672f\u5b9e\u73b0\u4e86\u6839\u636e\u7528\u6237\u504f\u597d\u7cbe\u786e\u8c03\u6574\u6a21\u578b\u6027\u80fd\u7684\u76ee\u6807\u3002"}}
{"id": "2509.13686", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13686", "abs": "https://arxiv.org/abs/2509.13686", "authors": ["Bingsheng Peng", "Shutao Zhang", "Xi Zheng", "Ye Xue", "Xinyu Qin", "Tsung-Hui Chang"], "title": "RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization", "comment": null, "summary": "Accurate localized wireless channel modeling is a cornerstone of cellular\nnetwork optimization, enabling reliable prediction of network performance\nduring parameter tuning. Localized statistical channel modeling (LSCM) is the\nstate-of-the-art channel modeling framework tailored for cellular network\noptimization. However, traditional LSCM methods, which infer the channel's\nAngular Power Spectrum (APS) from Reference Signal Received Power (RSRP)\nmeasurements, suffer from critical limitations: they are typically confined to\nsingle-cell, single-grid and single-carrier frequency analysis and fail to\ncapture complex cross-domain interactions. To overcome these challenges, we\npropose RF-LSCM, a novel framework that models the channel APS by jointly\nrepresenting large-scale signal attenuation and multipath components within a\nradiance field. RF-LSCM introduces a multi-domain LSCM formulation with a\nphysics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the\ncross frequency generalization as well as a point-cloud-aided environment\nenhanced method to enable multi-cell and multi-grid channel modeling.\nFurthermore, to address the computational inefficiency of typical neural\nradiance fields, RF-LSCM leverages a low-rank tensor representation,\ncomplemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.\nThis efficient design significantly reduces GPU memory requirements and\ntraining time while preserving fine-grained accuracy. Extensive experiments on\nreal-world multi-cell datasets demonstrate that RF-LSCM significantly\noutperforms state-of-the-art methods, achieving up to a 30% reduction in mean\nabsolute error (MAE) for coverage prediction and a 22% MAE improvement by\neffectively fusing multi-frequency data.", "AI": {"tldr": "RF-LSCM\u662f\u4e00\u4e2a\u57fa\u4e8e\u8f90\u5c04\u573a\u7684\u591a\u57df\u65e0\u7ebf\u4fe1\u9053\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u7269\u7406\u611f\u77e5\u7684\u9891\u7387\u76f8\u5173\u8870\u51cf\u6a21\u578b\u548c\u70b9\u4e91\u589e\u5f3a\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5355\u7ec6\u80de\u5355\u9891\u6bb5\u4fe1\u9053\u5efa\u6a21\u7684\u5c40\u9650\u6027\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7cbe\u5ea6\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u5c40\u90e8\u7edf\u8ba1\u4fe1\u9053\u5efa\u6a21\u65b9\u6cd5\u5c40\u9650\u4e8e\u5355\u7ec6\u80de\u3001\u5355\u7f51\u683c\u548c\u5355\u8f7d\u6ce2\u9891\u7387\u5206\u6790\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u7684\u8de8\u57df\u4ea4\u4e92\uff0c\u9700\u8981\u65b0\u7684\u6846\u67b6\u6765\u652f\u6301\u591a\u7ec6\u80de\u591a\u9891\u6bb5\u7684\u4fe1\u9053\u5efa\u6a21\u9700\u6c42\u3002", "method": "\u63d0\u51faRF-LSCM\u6846\u67b6\uff0c\u4f7f\u7528\u8f90\u5c04\u573a\u8054\u5408\u5efa\u6a21\u5927\u5c3a\u5ea6\u4fe1\u53f7\u8870\u51cf\u548c\u591a\u5f84\u5206\u91cf\uff1b\u5f15\u5165\u7269\u7406\u611f\u77e5\u7684\u9891\u7387\u76f8\u5173\u8870\u51cf\u6a21\u578b\u5b9e\u73b0\u8de8\u9891\u6bb5\u6cdb\u5316\uff1b\u91c7\u7528\u70b9\u4e91\u589e\u5f3a\u65b9\u6cd5\u652f\u6301\u591a\u7ec6\u80de\u591a\u7f51\u683c\u5efa\u6a21\uff1b\u5229\u7528\u4f4e\u79e9\u5f20\u91cf\u8868\u793a\u548c\u5206\u5c42\u5f20\u91cf\u89d2\u5ea6\u5efa\u6a21\u7b97\u6cd5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u771f\u5b9e\u591a\u7ec6\u80de\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRF-LSCM\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1a\u8986\u76d6\u9884\u6d4b\u7684MAE\u964d\u4f4e30%\uff0c\u901a\u8fc7\u591a\u9891\u6570\u636e\u878d\u5408\u5b9e\u73b022%\u7684MAE\u6539\u8fdb\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11GPU\u5185\u5b58\u9700\u6c42\u548c\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "RF-LSCM\u901a\u8fc7\u521b\u65b0\u7684\u8f90\u5c04\u573a\u5efa\u6a21\u548c\u9ad8\u6548\u8ba1\u7b97\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u4fe1\u9053\u5efa\u6a21\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8702\u7a9d\u7f51\u7edc\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u548c\u9ad8\u6548\u7684\u591a\u57df\u4fe1\u9053\u5efa\u6a21\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13717", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.13717", "abs": "https://arxiv.org/abs/2509.13717", "authors": ["Yifan Yu", "Cheuk Hin Ho", "Yangshuai Wang"], "title": "A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks", "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving PDEs, yet existing uncertainty quantification (UQ) approaches for\nPINNs generally lack rigorous statistical guarantees. In this work, we bridge\nthis gap by introducing a distribution-free conformal prediction (CP) framework\nfor UQ in PINNs. This framework calibrates prediction intervals by constructing\nnonconformity scores on a calibration set, thereby yielding distribution-free\nuncertainty estimates with rigorous finite-sample coverage guarantees for\nPINNs. To handle spatial heteroskedasticity, we further introduce local\nconformal quantile estimation, enabling spatially adaptive uncertainty bands\nwhile preserving theoretical guarantee. Through systematic evaluations on\ntypical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz\nequations) and comprehensive testing across multiple uncertainty metrics, our\nresults demonstrate that the proposed framework achieves reliable calibration\nand locally adaptive uncertainty intervals, consistently outperforming\nheuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work\nintroduces a general framework that not only enhances calibration and\nreliability, but also opens new avenues for uncertainty-aware modeling of\ncomplex PDE systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u65e0\u5206\u5e03\u5171\u5f62\u9884\u6d4b\u7684PINNs\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u6821\u51c6\u96c6\u6784\u5efa\u975e\u5171\u5f62\u5206\u6570\uff0c\u4e3aPINNs\u63d0\u4f9b\u5177\u6709\u4e25\u683c\u6709\u9650\u6837\u672c\u8986\u76d6\u4fdd\u8bc1\u7684\u5206\u5e03\u65e0\u5173\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "motivation": "\u73b0\u6709\u7684PINNs\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u7f3a\u4e4f\u4e25\u683c\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u7edf\u8ba1\u4fdd\u8bc1\u7684UQ\u6846\u67b6\u3002", "method": "\u5f15\u5165\u65e0\u5206\u5e03\u5171\u5f62\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6821\u51c6\u96c6\u6784\u5efa\u975e\u5171\u5f62\u5206\u6570\u6765\u6821\u51c6\u9884\u6d4b\u533a\u95f4\uff1b\u9488\u5bf9\u7a7a\u95f4\u5f02\u65b9\u5dee\u6027\uff0c\u63d0\u51fa\u5c40\u90e8\u5171\u5f62\u5206\u4f4d\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u7a7a\u95f4\u81ea\u9002\u5e94\u4e0d\u786e\u5b9a\u6027\u5e26\u3002", "result": "\u5728\u5178\u578bPDE\u7cfb\u7edf\uff08\u963b\u5c3c\u8c10\u632f\u5b50\u3001\u6cca\u677e\u3001Allen-Cahn\u548cHelmholtz\u65b9\u7a0b\uff09\u4e0a\u7684\u7cfb\u7edf\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u6821\u51c6\u548c\u5c40\u90e8\u81ea\u9002\u5e94\u4e0d\u786e\u5b9a\u6027\u533a\u95f4\uff0c\u4e00\u81f4\u4f18\u4e8e\u542f\u53d1\u5f0fUQ\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u5c06PINNs\u4e0e\u65e0\u5206\u5e03UQ\u76f8\u7ed3\u5408\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6821\u51c6\u6027\u548c\u53ef\u9760\u6027\uff0c\u8fd8\u4e3a\u590d\u6742PDE\u7cfb\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.13725", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13725", "abs": "https://arxiv.org/abs/2509.13725", "authors": ["Md Sabbir Ahmed", "Noah French", "Mark Rucker", "Zhiyuan Wang", "Taylor Myers-Brower", "Kaitlyn Petz", "Mehdi Boukhechba", "Bethany A. Teachman", "Laura E. Barnes"], "title": "WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data", "comment": null, "summary": "Social anxiety is a common mental health condition linked to significant\nchallenges in academic, social, and occupational functioning. A core feature is\nelevated momentary (state) anxiety in social situations, yet little prior work\nhas measured or predicted fluctuations in this anxiety throughout the day.\nCapturing these intra-day dynamics is critical for designing real-time,\npersonalized interventions such as Just-In-Time Adaptive Interventions\n(JITAIs). To address this gap, we conducted a study with socially anxious\ncollege students (N=91; 72 after exclusions) using our custom smartwatch-based\nsystem over an average of 9.03 days (SD = 2.95). Participants received seven\necological momentary assessments (EMAs) per day to report state anxiety. We\ndeveloped a base model on over 10,000 days of external heart rate data,\ntransferred its representations to our dataset, and fine-tuned it to generate\nprobabilistic predictions. These were combined with trait-level measures in a\nmeta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety\ndetection in our dataset. To evaluate generalizability, we applied the training\napproach to a separate hold-out set from the TILES-18 dataset-the same dataset\nused for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%\nbalanced accuracy, outperforming prior work by at least 7%.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u624b\u8868\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5fc3\u7387\u6570\u636e\u548c\u7279\u8d28\u6c34\u5e73\u6d4b\u91cf\u6765\u9884\u6d4b\u793e\u4ea4\u7126\u8651\u60a3\u8005\u7684\u77ac\u65f6\u7126\u8651\u6ce2\u52a8\uff0c\u5728\u5185\u90e8\u6570\u636e\u96c6\u4e0a\u8fbe\u523060.4%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u8fbe\u523059.1%\u7684\u51c6\u786e\u7387\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u81f3\u5c117%\u3002", "motivation": "\u793e\u4ea4\u7126\u8651\u662f\u4e00\u79cd\u5e38\u89c1\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u6d4b\u91cf\u548c\u9884\u6d4b\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u77ac\u65f6\u7126\u8651\u6ce2\u52a8\u3002\u6355\u6349\u8fd9\u4e9b\u65e5\u5185\u52a8\u6001\u5bf9\u4e8e\u8bbe\u8ba1\u5b9e\u65f6\u4e2a\u6027\u5316\u5e72\u9884\u63aa\u65bd\uff08\u5982JITAIs\uff09\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u5b9a\u5236\u667a\u80fd\u624b\u8868\u7cfb\u7edf\u6536\u96c691\u540d\u793e\u4ea4\u7126\u8651\u5927\u5b66\u751f\u7684\u6570\u636e\uff0c\u6bcf\u5929\u8fdb\u884c7\u6b21\u751f\u6001\u77ac\u65f6\u8bc4\u4f30\u3002\u57fa\u4e8e10,000\u591a\u5929\u5916\u90e8\u5fc3\u7387\u6570\u636e\u5f00\u53d1\u57fa\u7840\u6a21\u578b\uff0c\u8fc1\u79fb\u8868\u793a\u5230\u7814\u7a76\u6570\u636e\u96c6\u5e76\u8fdb\u884c\u5fae\u8c03\uff0c\u751f\u6210\u6982\u7387\u9884\u6d4b\uff0c\u518d\u4e0e\u7279\u8d28\u6c34\u5e73\u6d4b\u91cf\u7ed3\u5408\u4f7f\u7528\u5143\u5b66\u4e60\u5668\u3002", "result": "\u5728\u5185\u90e8\u6570\u636e\u96c6\u4e0a\u8fbe\u523060.4%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff1b\u5728TILES-18\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u8fbe\u523059.1%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u6bd4\u5148\u524d\u5de5\u4f5c\u81f3\u5c11\u63d0\u9ad87%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u9884\u6d4b\u793e\u4ea4\u7126\u8651\u60a3\u8005\u7684\u77ac\u65f6\u7126\u8651\u6ce2\u52a8\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u5b9e\u65f6\u4e2a\u6027\u5316\u5e72\u9884\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2509.13735", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13735", "abs": "https://arxiv.org/abs/2509.13735", "authors": ["Junzhi She", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "State Space Models over Directed Graphs", "comment": "currently undergoing review by IEEE Transactions on Big Data", "summary": "Directed graphs are ubiquitous across numerous domains, where the\ndirectionality of edges encodes critical causal dependencies. However, existing\nGNNs and graph Transformers tailored for directed graphs face two major\nchallenges: (1) effectively capturing long-range causal dependencies derived\nfrom directed edges; (2) balancing accuracy and training efficiency when\nprocessing large-scale graph datasets. In recent years, state space models\n(SSMs) have achieved substantial progress in causal sequence tasks, and their\nvariants designed for graphs have demonstrated state-of-the-art accuracy while\nmaintaining high efficiency across various graph learning benchmarks. However,\nexisting graph state space models are exclusively designed for undirected\ngraphs, which limits their performance in directed graph learning. To this end,\nwe propose an innovative approach DirEgo2Token which sequentializes directed\ngraphs via k-hop ego graphs. This marks the first systematic extension of state\nspace models to the field of directed graph learning. Building upon this, we\ndevelop DirGraphSSM, a novel directed graph neural network architecture that\nimplements state space models on directed graphs via the message-passing\nmechanism. Experimental results demonstrate that DirGraphSSM achieves\nstate-of-the-art performance on three representative directed graph learning\ntasks while attaining competitive performance on two additional tasks with\n1.5$\\times $ to 2$\\times $ training speed improvements compared to existing\nstate-of-the-art models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DirGraphSSM\uff0c\u9996\u4e2a\u5c06\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7cfb\u7edf\u6269\u5c55\u5230\u6709\u5411\u56fe\u5b66\u4e60\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7k-hop ego\u56fe\u5e8f\u5217\u5316\u6709\u5411\u56fe\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u8bad\u7ec3\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6709\u5411\u56fe\u795e\u7ecf\u7f51\u7edc\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u6709\u6548\u6355\u6349\u957f\u8ddd\u79bb\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ee5\u53ca\u5728\u5904\u7406\u5927\u89c4\u6a21\u56fe\u6570\u636e\u65f6\u5e73\u8861\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u6548\u7387\u3002\u73b0\u6709\u7684\u56fe\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4ec5\u9002\u7528\u4e8e\u65e0\u5411\u56fe\uff0c\u9650\u5236\u4e86\u5176\u6027\u80fd\u3002", "method": "\u63d0\u51faDirEgo2Token\u65b9\u6cd5\u901a\u8fc7k-hop ego\u56fe\u5e8f\u5217\u5316\u6709\u5411\u56fe\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5f00\u53d1DirGraphSSM\u67b6\u6784\uff0c\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u673a\u5236\u5728\u6709\u5411\u56fe\u4e0a\u5b9e\u73b0\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u6709\u5411\u56fe\u5b66\u4e60\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u53e6\u5916\u4e24\u4e2a\u4efb\u52a1\u4e0a\u83b7\u5f97\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u8bad\u7ec3\u901f\u5ea6\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u5feb1.5-2\u500d\u3002", "conclusion": "DirGraphSSM\u6210\u529f\u5c06\u6709\u5411\u56fe\u5b66\u4e60\u4e0e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u4e3a\u6709\u5411\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13739", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13739", "abs": "https://arxiv.org/abs/2509.13739", "authors": ["Zihou Wu", "Yuecheng Li", "Tianchi Liao", "Jian Lou", "Chuan Chen"], "title": "ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning", "comment": "8 pages, 1 figure", "summary": "Federated learning (FL) faces a critical dilemma: existing protection\nmechanisms like differential privacy (DP) and homomorphic encryption (HE)\nenforce a rigid trade-off, forcing a choice between model utility and\ncomputational efficiency. This lack of flexibility hinders the practical\nimplementation. To address this, we introduce ParaAegis, a parallel protection\nframework designed to give practitioners flexible control over the\nprivacy-utility-efficiency balance. Our core innovation is a strategic model\npartitioning scheme. By applying lightweight DP to the less critical, low norm\nportion of the model while protecting the remainder with HE, we create a\ntunable system. A distributed voting mechanism ensures consensus on this\npartitioning. Theoretical analysis confirms the adjustments between efficiency\nand utility with the same privacy. Crucially, the experimental results\ndemonstrate that by adjusting the hyperparameters, our method enables flexible\nprioritization between model accuracy and training time.", "AI": {"tldr": "ParaAegis\u662f\u4e00\u4e2a\u5e76\u884c\u4fdd\u62a4\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u5206\u5272\u7b56\u7565\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u5b9e\u73b0\u9690\u79c1-\u6548\u7528-\u6548\u7387\u7684\u7075\u6d3b\u5e73\u8861\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u4f4e\u91cd\u8981\u6027\u90e8\u5206\uff0c\u540c\u6001\u52a0\u5bc6\u4fdd\u62a4\u5173\u952e\u90e8\u5206\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u4fdd\u62a4\u673a\u5236\uff08\u5982\u5dee\u5206\u9690\u79c1\u548c\u540c\u6001\u52a0\u5bc6\uff09\u5b58\u5728\u521a\u6027\u6743\u8861\uff0c\u5fc5\u987b\u5728\u6a21\u578b\u6548\u7528\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u505a\u51fa\u9009\u62e9\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u963b\u788d\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u6218\u7565\u6a21\u578b\u5206\u5272\u65b9\u6848\uff1a\u5bf9\u6a21\u578b\u4f4e\u8303\u6570\u90e8\u5206\u5e94\u7528\u8f7b\u91cf\u7ea7\u5dee\u5206\u9690\u79c1\uff0c\u5176\u4f59\u90e8\u5206\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u4fdd\u62a4\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0f\u6295\u7968\u673a\u5236\u786e\u4fdd\u5206\u5272\u5171\u8bc6\u3002", "result": "\u7406\u8bba\u5206\u6790\u786e\u8ba4\u4e86\u5728\u76f8\u540c\u9690\u79c1\u4fdd\u62a4\u4e0b\u6548\u7387\u4e0e\u6548\u7528\u4e4b\u95f4\u7684\u53ef\u8c03\u8282\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u901a\u8fc7\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u53ef\u4ee5\u7075\u6d3b\u4f18\u5148\u8003\u8651\u6a21\u578b\u7cbe\u5ea6\u6216\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "ParaAegis\u6846\u67b6\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5bf9\u9690\u79c1-\u6548\u7528-\u6548\u7387\u5e73\u8861\u7684\u7075\u6d3b\u63a7\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4fdd\u62a4\u673a\u5236\u7684\u521a\u6027\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2509.13753", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13753", "abs": "https://arxiv.org/abs/2509.13753", "authors": ["Hyotaek Jeon", "Hyunwook Lee", "Juwon Kim", "Sungahn Ko"], "title": "ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting", "comment": "11 pages, 4 figures, Accepted to CIKM 2025. Code:\n  https://github.com/HyoTaek98/ST_LINK", "summary": "Traffic forecasting represents a crucial problem within intelligent\ntransportation systems. In recent research, Large Language Models (LLMs) have\nemerged as a promising method, but their intrinsic design, tailored primarily\nfor sequential token processing, introduces notable challenges in effectively\ncapturing spatial dependencies. Specifically, the inherent limitations of LLMs\nin modeling spatial relationships and their architectural incompatibility with\ngraph-structured spatial data remain largely unaddressed. To overcome these\nlimitations, we introduce ST-LINK, a novel framework that enhances the\ncapability of Large Language Models to capture spatio-temporal dependencies.\nIts key components are Spatially-Enhanced Attention (SE-Attention) and the\nMemory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary\nposition embeddings to integrate spatial correlations as direct rotational\ntransformations within the attention mechanism. This approach maximizes spatial\nlearning while preserving the LLM's inherent sequential processing structure.\nMeanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to\ncapture complex temporal dependencies and improve the stability of long-term\nforecasting. Comprehensive experiments on benchmark datasets demonstrate that\nST-LINK surpasses conventional deep learning and LLM approaches, and\neffectively captures both regular traffic patterns and abrupt changes.", "AI": {"tldr": "ST-LINK\u662f\u4e00\u4e2a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u7a7a\u4f9d\u8d56\u6355\u83b7\u80fd\u529b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u589e\u5f3a\u6ce8\u610f\u529b\u548c\u8bb0\u5fc6\u68c0\u7d22\u524d\u9988\u7f51\u7edc\u89e3\u51b3LLM\u5728\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u7a7a\u95f4\u5efa\u6a21\u9650\u5236", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u901a\u9884\u6d4b\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u4e3b\u8981\u4e3a\u5e8f\u5217\u6807\u8bb0\u5904\u7406\u8bbe\u8ba1\uff0c\u96be\u4ee5\u6709\u6548\u6355\u83b7\u7a7a\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u5efa\u6a21\u7a7a\u95f4\u5173\u7cfb\u548c\u56fe\u7ed3\u6784\u7a7a\u95f4\u6570\u636e\u65b9\u9762\u5b58\u5728\u67b6\u6784\u4e0d\u517c\u5bb9\u95ee\u9898", "method": "\u63d0\u51faST-LINK\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u7a7a\u95f4\u589e\u5f3a\u6ce8\u610f\u529b\uff08SE-Attention\uff09\u6269\u5c55\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\u6765\u6574\u5408\u7a7a\u95f4\u76f8\u5173\u6027\uff1b\u8bb0\u5fc6\u68c0\u7d22\u524d\u9988\u7f51\u7edc\uff08MRFFN\uff09\u52a8\u6001\u68c0\u7d22\u5386\u53f2\u6a21\u5f0f\u6765\u6355\u83b7\u590d\u6742\u65f6\u95f4\u4f9d\u8d56", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cST-LINK\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u6df1\u5ea6\u5b66\u4e60\u548cLLM\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u6355\u83b7\u5e38\u89c4\u4ea4\u901a\u6a21\u5f0f\u548c\u7a81\u53d8\u53d8\u5316", "conclusion": "ST-LINK\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u7a7a\u95f4\u5efa\u6a21\u6311\u6218\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\u548c\u8bb0\u5fc6\u68c0\u7d22\u7f51\u7edc\u663e\u8457\u63d0\u5347\u4e86\u65f6\u7a7a\u4f9d\u8d56\u7684\u6355\u83b7\u80fd\u529b"}}
{"id": "2509.13763", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13763", "abs": "https://arxiv.org/abs/2509.13763", "authors": ["Zongxin Shen", "Yanyong Huang", "Bin Wang", "Jinyuan Chang", "Shiyu Liu", "Tianrui Li"], "title": "Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning", "comment": null, "summary": "Multi-view unsupervised feature selection (MUFS) has recently received\nincreasing attention for its promising ability in dimensionality reduction on\nmulti-view unlabeled data. Existing MUFS methods typically select\ndiscriminative features by capturing correlations between features and\nclustering labels. However, an important yet underexplored question remains:\n\\textit{Are such correlations sufficiently reliable to guide feature\nselection?} In this paper, we analyze MUFS from a causal perspective by\nintroducing a novel structural causal model, which reveals that existing\nmethods may select irrelevant features because they overlook spurious\ncorrelations caused by confounders. Building on this causal perspective, we\npropose a novel MUFS method called CAusal multi-view Unsupervised feature\nSelection leArning (CAUSA). Specifically, we first employ a generalized\nunsupervised spectral regression model that identifies informative features by\ncapturing dependencies between features and consensus clustering labels. We\nthen introduce a causal regularization module that can adaptively separate\nconfounders from multi-view data and simultaneously learn view-shared sample\nweights to balance confounder distributions, thereby mitigating spurious\ncorrelations. Thereafter, integrating both into a unified learning framework\nenables CAUSA to select causally informative features. Comprehensive\nexperiments demonstrate that CAUSA outperforms several state-of-the-art\nmethods. To our knowledge, this is the first in-depth study of causal\nmulti-view feature selection in the unsupervised setting.", "AI": {"tldr": "\u672c\u6587\u4ece\u56e0\u679c\u89c6\u89d2\u5206\u6790\u591a\u89c6\u56fe\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\uff0c\u63d0\u51faCAUSA\u65b9\u6cd5\uff0c\u901a\u8fc7\u56e0\u679c\u6b63\u5219\u5316\u6a21\u5757\u6d88\u9664\u6df7\u6742\u56e0\u7d20\u5bfc\u81f4\u7684\u4f2a\u76f8\u5173\uff0c\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u7279\u5f81\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u591a\u89c6\u56fe\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u7279\u5f81\u4e0e\u805a\u7c7b\u6807\u7b7e\u7684\u76f8\u5173\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u6df7\u6742\u56e0\u7d20\u5bfc\u81f4\u7684\u4f2a\u76f8\u5173\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u9009\u62e9\u4e0d\u76f8\u5173\u7279\u5f81\u3002", "method": "\u63d0\u51faCAUSA\u65b9\u6cd5\uff1a1)\u4f7f\u7528\u5e7f\u4e49\u65e0\u76d1\u7763\u8c31\u56de\u5f52\u6a21\u578b\u6355\u6349\u7279\u5f81\u4e0e\u5171\u8bc6\u805a\u7c7b\u6807\u7b7e\u7684\u4f9d\u8d56\u5173\u7cfb\uff1b2)\u5f15\u5165\u56e0\u679c\u6b63\u5219\u5316\u6a21\u5757\u81ea\u9002\u5e94\u5206\u79bb\u6df7\u6742\u56e0\u7d20\u5e76\u5b66\u4e60\u89c6\u56fe\u5171\u4eab\u6837\u672c\u6743\u91cd\u6765\u5e73\u8861\u6df7\u6742\u5206\u5e03\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660eCAUSA\u4f18\u4e8e\u591a\u4e2a\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5728\u65e0\u76d1\u7763\u8bbe\u7f6e\u4e0b\u5bf9\u56e0\u679c\u591a\u89c6\u56fe\u7279\u5f81\u9009\u62e9\u7684\u6df1\u5165\u7814\u7a76\uff0cCAUSA\u80fd\u6709\u6548\u9009\u62e9\u56e0\u679c\u4fe1\u606f\u7279\u5f81\u3002"}}
{"id": "2509.13783", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13783", "abs": "https://arxiv.org/abs/2509.13783", "authors": ["Tianshuo Zhang", "Wenzhe Zhai", "Rui Yann", "Jia Gao", "He Cao", "Xianglei Xing"], "title": "Floating-Body Hydrodynamic Neural Networks", "comment": null, "summary": "Fluid-structure interaction is common in engineering and natural systems,\nwhere floating-body motion is governed by added mass, drag, and background\nflows. Modeling these dissipative dynamics is difficult: black-box neural\nmodels regress state derivatives with limited interpretability and unstable\nlong-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks\n(FHNN), a physics-structured framework that predicts interpretable hydrodynamic\nparameters such as directional added masses, drag coefficients, and a\nstreamfunction-based flow, and couples them with analytic equations of motion.\nThis design constrains the hypothesis space, enhances interpretability, and\nstabilizes integration. On synthetic vortex datasets, FHNN achieves up to an\norder-of-magnitude lower error than Neural ODEs, recovers physically consistent\nflow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN\nmore effectively handles dissipative dynamics while preserving\ninterpretability, which bridges the gap between black-box learning and\ntransparent system identification.", "AI": {"tldr": "\u63d0\u51fa\u4e86FHNN\u6846\u67b6\uff0c\u901a\u8fc7\u7269\u7406\u7ed3\u6784\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u53ef\u89e3\u91ca\u7684\u6c34\u52a8\u529b\u53c2\u6570\uff0c\u7ed3\u5408\u89e3\u6790\u8fd0\u52a8\u65b9\u7a0b\uff0c\u5728\u6da1\u6d41\u6570\u636e\u96c6\u4e0a\u6bd4Neural ODEs\u8bef\u5dee\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u6709\u6548\u5904\u7406\u8017\u6563\u52a8\u529b\u5b66\u5e76\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u9ed1\u76d2\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u6d41\u4f53-\u7ed3\u6784\u76f8\u4e92\u4f5c\u7528\u4e2d\u56de\u5f52\u72b6\u6001\u5bfc\u6570\u65f6\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u5dee\u548c\u957f\u671f\u9884\u6d4b\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\u53c8\u80fd\u5904\u7406\u8017\u6563\u52a8\u529b\u5b66\u7684\u900f\u660e\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7269\u7406\u7ed3\u6784\u5316\u7684Floating-Body Hydrodynamic Neural Networks (FHNN)\u6846\u67b6\uff0c\u9884\u6d4b\u53ef\u89e3\u91ca\u7684\u6c34\u52a8\u529b\u53c2\u6570\uff08\u5982\u65b9\u5411\u9644\u52a0\u8d28\u91cf\u3001\u963b\u529b\u7cfb\u6570\u548c\u57fa\u4e8e\u6d41\u51fd\u6570\u7684\u6d41\u52a8\uff09\uff0c\u5e76\u5c06\u5176\u4e0e\u89e3\u6790\u8fd0\u52a8\u65b9\u7a0b\u8026\u5408\u3002", "result": "\u5728\u5408\u6210\u6da1\u6d41\u6570\u636e\u96c6\u4e0a\uff0cFHNN\u6bd4Neural ODEs\u7684\u8bef\u5dee\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u591f\u6062\u590d\u7269\u7406\u4e00\u81f4\u7684\u6d41\u573a\uff0c\u76f8\u6bd4\u54c8\u5bc6\u987f\u548c\u62c9\u683c\u6717\u65e5\u795e\u7ecf\u7f51\u7edc\u66f4\u6709\u6548\u5730\u5904\u7406\u8017\u6563\u52a8\u529b\u5b66\u3002", "conclusion": "FHNN\u586b\u8865\u4e86\u9ed1\u76d2\u5b66\u4e60\u548c\u900f\u660e\u7cfb\u7edf\u8bc6\u522b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u7ea6\u675f\u5047\u8bbe\u7a7a\u95f4\u3001\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u548c\u7a33\u5b9a\u79ef\u5206\u8fc7\u7a0b\uff0c\u4e3a\u6d41\u4f53-\u7ed3\u6784\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7269\u7406\u7ed3\u6784\u5316\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2509.13818", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.13818", "abs": "https://arxiv.org/abs/2509.13818", "authors": ["Zheng-an Wang", "Yanbo J. Wang", "Jiachi Zhang", "Qi Xu", "Yilun Zhao", "Jintao Li", "Yipeng Zhang", "Bo Yang", "Xinkai Gao", "Xiaofeng Cao", "Kai Xu", "Pengpeng Hao", "Xuan Yang", "Heng Fan"], "title": "Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment", "comment": null, "summary": "Quantum Machine Learning (QML) offers a new paradigm for addressing complex\nfinancial problems intractable for classical methods. This work specifically\ntackles the challenge of few-shot credit risk assessment, a critical issue in\ninclusive finance where data scarcity and imbalance limit the effectiveness of\nconventional models. To address this, we design and implement a novel hybrid\nquantum-classical workflow. The methodology first employs an ensemble of\nclassical machine learning models (Logistic Regression, Random Forest, XGBoost)\nfor intelligent feature engineering and dimensionality reduction. Subsequently,\na Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as\nthe core classifier. This framework was evaluated through numerical simulations\nand deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting\nprocessor. On a real-world credit dataset of 279 samples, our QNN achieved a\nrobust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive\nAUC of 0.88 in the hardware experiment. This performance surpasses a suite of\nclassical benchmarks, with a particularly strong result on the recall metric.\nThis study provides a pragmatic blueprint for applying quantum computing to\ndata-constrained financial scenarios in the NISQ era and offers valuable\nempirical evidence supporting its potential in high-stakes applications like\ninclusive finance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u89e3\u51b3\u666e\u60e0\u91d1\u878d\u4e2d\u6570\u636e\u7a00\u7f3a\u7684\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u95ee\u9898\uff0c\u901a\u8fc7\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u7279\u5f81\u5de5\u7a0b\uff0c\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u5206\u7c7b\u5668\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u666e\u60e0\u91d1\u878d\u4e2d\u7531\u4e8e\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u96be\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u6b64\u7c7b\u6570\u636e\u53d7\u9650\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u63a2\u7d22\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u65b0\u8303\u5f0f\u3002", "method": "\u8bbe\u8ba1\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u5de5\u4f5c\u6d41\uff1a\u9996\u5148\u4f7f\u7528\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u3001XGBoost\uff09\u8fdb\u884c\u667a\u80fd\u7279\u5f81\u5de5\u7a0b\u548c\u964d\u7ef4\uff0c\u7136\u540e\u4f7f\u7528\u901a\u8fc7\u53c2\u6570\u504f\u79fb\u89c4\u5219\u8bad\u7ec3\u7684\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6838\u5fc3\u5206\u7c7b\u5668\u3002", "result": "\u5728279\u4e2a\u6837\u672c\u7684\u771f\u5b9e\u4fe1\u7528\u6570\u636e\u96c6\u4e0a\uff0c\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u5728\u6a21\u62df\u4e2d\u8fbe\u52300.852\u00b10.027\u7684\u5e73\u5747AUC\uff0c\u5728Quafu\u91cf\u5b50\u4e91\u5e73\u53f0\u7684\u8d85\u5bfc\u5904\u7406\u5668\u4e0a\u5b9e\u9a8c\u83b7\u5f970.88\u7684AUC\uff0c\u6027\u80fd\u8d85\u8d8a\u591a\u4e2a\u7ecf\u5178\u57fa\u51c6\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u53ec\u56de\u7387\u6307\u6807\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aNISQ\u65f6\u4ee3\u91cf\u5b50\u8ba1\u7b97\u5728\u6570\u636e\u53d7\u9650\u91d1\u878d\u573a\u666f\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u84dd\u56fe\uff0c\u5e76\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u9ad8\u98ce\u9669\u5e94\u7528\uff08\u5982\u666e\u60e0\u91d1\u878d\uff09\u4e2d\u7684\u6f5c\u529b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002"}}
{"id": "2509.13841", "categories": ["cs.LG", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2509.13841", "abs": "https://arxiv.org/abs/2509.13841", "authors": ["Qingqi Zhao", "Heng Xiao"], "title": "An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction", "comment": "This preprint is also available at ESS Open Archive:\n  https://essopenarchive.org/users/960205/articles/1329010", "summary": "Accurate prediction of permeability in porous media is essential for modeling\nsubsurface flow. While pure data-driven models offer computational efficiency,\nthey often lack generalization across scales and do not incorporate explicit\nphysical constraints. Pore network models (PNMs), on the other hand, are\nphysics-based and efficient but rely on idealized geometric assumptions to\nestimate pore-scale hydraulic conductance, limiting their accuracy in complex\nstructures. To overcome these limitations, we present an end-to-end\ndifferentiable hybrid framework that embeds a graph neural network (GNN) into a\nPNM. In this framework, the analytical formulas used for conductance\ncalculations are replaced by GNN-based predictions derived from pore and throat\nfeatures. The predicted conductances are then passed to the PNM solver for\npermeability computation. In this way, the model avoids the idealized geometric\nassumptions of PNM while preserving the physics-based flow calculations. The\nGNN is trained without requiring labeled conductance data, which can number in\nthe thousands per pore network; instead, it learns conductance values by using\na single scalar permeability as the training target. This is made possible by\nbackpropagating gradients through both the GNN (via automatic differentiation)\nand the PNM solver (via a discrete adjoint method), enabling fully coupled,\nend-to-end training. The resulting model achieves high accuracy and generalizes\nwell across different scales, outperforming both pure data-driven and\ntraditional PNM approaches. Gradient-based sensitivity analysis further reveals\nphysically consistent feature influences, enhancing model interpretability.\nThis approach offers a scalable and physically informed framework for\npermeability prediction in complex porous media, reducing model uncertainty and\nimproving accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u6df7\u5408\u6846\u67b6\uff0c\u5c06\u56fe\u795e\u7ecf\u7f51\u7edc\u5d4c\u5165\u5b54\u9699\u7f51\u7edc\u6a21\u578b\u4e2d\uff0c\u7528\u4e8e\u591a\u5b54\u4ecb\u8d28\u6e17\u900f\u7387\u9884\u6d4b\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u7406\u60f3\u5316\u51e0\u4f55\u5047\u8bbe\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7f3a\u4e4f\u8de8\u5c3a\u5ea6\u6cdb\u5316\u80fd\u529b\u4e14\u4e0d\u5305\u542b\u663e\u5f0f\u7269\u7406\u7ea6\u675f\uff0c\u800c\u5b54\u9699\u7f51\u7edc\u6a21\u578b\u4f9d\u8d56\u7406\u60f3\u5316\u51e0\u4f55\u5047\u8bbe\u5bfc\u81f4\u5728\u590d\u6742\u7ed3\u6784\u4e2d\u7cbe\u5ea6\u6709\u9650\uff0c\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u5b54\u9699\u7f51\u7edc\u6a21\u578b\u4e2d\u7684\u89e3\u6790\u516c\u5f0f\u8fdb\u884c\u6c34\u529b\u4f20\u5bfc\u5ea6\u8ba1\u7b97\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u8bad\u7ec3\uff0c\u4ec5\u9700\u6e17\u900f\u7387\u6807\u91cf\u4f5c\u4e3a\u8bad\u7ec3\u76ee\u6807\uff0c\u65e0\u9700\u6807\u8bb0\u7684\u4f20\u5bfc\u5ea6\u6570\u636e\u3002", "result": "\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u826f\u597d\u7684\u8de8\u5c3a\u5ea6\u6cdb\u5316\u80fd\u529b\uff0c\u4f18\u4e8e\u7eaf\u6570\u636e\u9a71\u52a8\u548c\u4f20\u7edf\u5b54\u9699\u7f51\u7edc\u6a21\u578b\u65b9\u6cd5\uff0c\u68af\u5ea6\u654f\u611f\u6027\u5206\u6790\u663e\u793a\u7269\u7406\u4e00\u81f4\u7684\u7279\u5f81\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u591a\u5b54\u4ecb\u8d28\u6e17\u900f\u7387\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7269\u7406\u4fe1\u606f\u4e30\u5bcc\u7684\u6846\u67b6\uff0c\u51cf\u5c11\u4e86\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002"}}
{"id": "2509.13855", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13855", "abs": "https://arxiv.org/abs/2509.13855", "authors": ["Shamsiiat Abdurakhmanova", "Alex Jung"], "title": "Graph-Regularized Learning of Gaussian Mixture Models", "comment": null, "summary": "We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in\ndistributed settings with heterogeneous and limited local data. The method\nexploits a provided similarity graph to guide parameter sharing among nodes,\navoiding the transfer of raw data. The resulting model allows for flexible\naggregation of neighbors' parameters and outperforms both centralized and\nlocally trained GMMs in heterogeneous, low-sample regimes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u57fa\u4e8e\u56fe\u6b63\u5219\u5316\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u76f8\u4f3c\u6027\u56fe\u6307\u5bfc\u8282\u70b9\u95f4\u53c2\u6570\u5171\u4eab\uff0c\u907f\u514d\u539f\u59cb\u6570\u636e\u4f20\u8f93\uff0c\u5728\u5f02\u6784\u5c0f\u6837\u672c\u573a\u666f\u4e0b\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u672c\u5730\u8bad\u7ec3\u65b9\u6cd5", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u6570\u636e\u5f02\u6784\u4e14\u6837\u672c\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u6709\u6548\u5b66\u4e60\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u800c\u4e0d\u9700\u8981\u4f20\u8f93\u539f\u59cb\u6570\u636e\u7684\u95ee\u9898", "method": "\u4f7f\u7528\u56fe\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u4f9b\u7684\u76f8\u4f3c\u6027\u56fe\u6765\u6307\u5bfc\u4e0d\u540c\u8282\u70b9\u95f4\u7684\u53c2\u6570\u5171\u4eab\uff0c\u5b9e\u73b0\u7075\u6d3b\u7684\u90bb\u5c45\u53c2\u6570\u805a\u5408", "result": "\u8be5\u65b9\u6cd5\u5728\u5f02\u6784\u3001\u5c0f\u6837\u672c\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u548c\u672c\u5730\u5355\u72ec\u8bad\u7ec3\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b", "conclusion": "\u56fe\u6b63\u5219\u5316\u7684\u5206\u5e03\u5f0f\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u6570\u636e\u5f02\u6784\u548c\u6837\u672c\u9650\u5236\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u65b9\u6848"}}
{"id": "2509.13866", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13866", "abs": "https://arxiv.org/abs/2509.13866", "authors": ["Sitong Chen", "Shen Nie", "Jiacheng Sun", "Zijin Feng", "Zhenguo Li", "Ji-Rong Wen", "Chongxuan Li"], "title": "Masked Diffusion Models as Energy Minimization", "comment": null, "summary": "We present a systematic theoretical framework that interprets masked\ndiffusion models (MDMs) as solutions to energy minimization problems in\ndiscrete optimal transport. Specifically, we prove that three distinct energy\nformulations--kinetic, conditional kinetic, and geodesic energy--are\nmathematically equivalent under the structure of MDMs, and that MDMs minimize\nall three when the mask schedule satisfies a closed-form optimality condition.\nThis unification not only clarifies the theoretical foundations of MDMs, but\nalso motivates practical improvements in sampling. By parameterizing\ninterpolation schedules via Beta distributions, we reduce the schedule design\nspace to a tractable 2D search, enabling efficient post-training tuning without\nmodel modification. Experiments on synthetic and real-world benchmarks\ndemonstrate that our energy-inspired schedules outperform hand-crafted\nbaselines, particularly in low-step sampling settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u63a9\u7801\u6269\u6563\u6a21\u578b\u89e3\u91ca\u4e3a\u79bb\u6563\u6700\u4f18\u4f20\u8f93\u4e2d\u7684\u80fd\u91cf\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u4e09\u79cd\u80fd\u91cf\u516c\u5f0f\u7684\u6570\u5b66\u7b49\u4ef7\u6027\uff0c\u5e76\u901a\u8fc7Beta\u5206\u5e03\u53c2\u6570\u5316\u63d2\u503c\u8c03\u5ea6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u91c7\u6837\u6539\u8fdb\u3002", "motivation": "\u7edf\u4e00\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6f84\u6e05\u5176\u6570\u5b66\u672c\u8d28\uff0c\u5e76\u4e3a\u5b9e\u9645\u91c7\u6837\u6539\u8fdb\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u4e09\u79cd\u80fd\u91cf\u516c\u5f0f\uff08\u52a8\u80fd\u3001\u6761\u4ef6\u52a8\u80fd\u548c\u6d4b\u5730\u7ebf\u80fd\u91cf\uff09\u5728MDMs\u7ed3\u6784\u4e0b\u7684\u7b49\u4ef7\u6027\uff1b\u4f7f\u7528Beta\u5206\u5e03\u53c2\u6570\u5316\u63d2\u503c\u8c03\u5ea6\uff0c\u5c06\u8c03\u5ea6\u8bbe\u8ba1\u7a7a\u95f4\u7b80\u5316\u4e3a2D\u641c\u7d22\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u57fa\u4e8e\u80fd\u91cf\u542f\u53d1\u7684\u8c03\u5ea6\u5728\u5408\u6210\u548c\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u624b\u5de5\u8bbe\u8ba1\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4f4e\u6b65\u6570\u91c7\u6837\u8bbe\u7f6e\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u63a9\u7801\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u89e3\u91ca\uff0c\u8fd8\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u8c03\u5ea6\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91c7\u6837\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2509.13895", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13895", "abs": "https://arxiv.org/abs/2509.13895", "authors": ["Zhanting Zhou", "Jinshan Lai", "Fengchun Zhang", "Zeqin Wu", "Fengli Zhang"], "title": "FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning", "comment": "4 page main text for conference", "summary": "Non-IID data and partial participation induce client drift and inconsistent\nlocal optima in federated learning, causing unstable convergence and accuracy\nloss. We present FedSSG, a stochastic sampling-guided, history-aware drift\nalignment method. FedSSG maintains a per-client drift memory that accumulates\nlocal model differences as a lightweight sketch of historical gradients;\ncrucially, it gates both the memory update and the local alignment term by a\nsmooth function of the observed/expected participation ratio (a\nphase-by-expectation signal derived from the server sampler). This\nstatistically grounded gate stays weak and smooth when sampling noise dominates\nearly, then strengthens once participation statistics stabilize, contracting\nthe local-global gap without extra communication. Across CIFAR-10/100 with\n100/500 clients and 2-15 percent participation, FedSSG consistently outperforms\nstrong drift-aware baselines and accelerates convergence; on our benchmarks it\nimproves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and\nabout +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about\n4.5x faster target-accuracy convergence on average. The method adds only O(d)\nclient memory and a constant-time gate, and degrades gracefully to a mild\nregularizer under near-IID or uniform sampling. FedSSG shows that sampling\nstatistics can be turned into a principled, history-aware phase control to\nstabilize and speed up federated training.", "AI": {"tldr": "FedSSG\u662f\u4e00\u79cd\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6f02\u79fb\u5bf9\u9f50\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u91c7\u6837\u5f15\u5bfc\u548c\u5386\u53f2\u611f\u77e5\u673a\u5236\u89e3\u51b3\u975eIID\u6570\u636e\u548c\u90e8\u5206\u53c2\u4e0e\u5bfc\u81f4\u7684\u5ba2\u6237\u7aef\u6f02\u79fb\u95ee\u9898\uff0c\u63d0\u9ad8\u6536\u655b\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u7387", "motivation": "\u975eIID\u6570\u636e\u548c\u90e8\u5206\u53c2\u4e0e\u4f1a\u5bfc\u81f4\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u7aef\u6f02\u79fb\u548c\u5c40\u90e8\u6700\u4f18\u4e0d\u4e00\u81f4\uff0c\u9020\u6210\u6536\u655b\u4e0d\u7a33\u5b9a\u548c\u51c6\u786e\u7387\u4e0b\u964d", "method": "\u7ef4\u62a4\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u6f02\u79fb\u8bb0\u5fc6\uff0c\u79ef\u7d2f\u672c\u5730\u6a21\u578b\u5dee\u5f02\u4f5c\u4e3a\u5386\u53f2\u68af\u5ea6\u7684\u8f7b\u91cf\u7ea7\u8349\u56fe\uff1b\u901a\u8fc7\u57fa\u4e8e\u53c2\u4e0e\u6bd4\u7387\u7684\u5e73\u6ed1\u95e8\u63a7\u51fd\u6570\u63a7\u5236\u8bb0\u5fc6\u66f4\u65b0\u548c\u672c\u5730\u5bf9\u9f50\u9879", "result": "\u5728CIFAR-10/100\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6d4b\u8bd5\u51c6\u786e\u7387\u63d0\u53470.9-2.7\u4e2a\u767e\u5206\u70b9\uff0c\u6536\u655b\u901f\u5ea6\u63d0\u5347\u7ea64.5\u500d", "conclusion": "\u91c7\u6837\u7edf\u8ba1\u53ef\u4ee5\u8f6c\u5316\u4e3a\u6709\u539f\u5219\u7684\u5386\u53f2\u611f\u77e5\u76f8\u4f4d\u63a7\u5236\uff0c\u7a33\u5b9a\u5e76\u52a0\u901f\u8054\u90a6\u8bad\u7ec3\uff0c\u65b9\u6cd5\u4ec5\u9700O(d)\u5ba2\u6237\u7aef\u5185\u5b58\u548c\u5e38\u6570\u65f6\u95f4\u95e8\u63a7"}}
{"id": "2509.13906", "categories": ["cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2509.13906", "abs": "https://arxiv.org/abs/2509.13906", "authors": ["Afrin Dange", "Sunita Sarawagi"], "title": "TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates", "comment": "Accepted at CIKM 2025", "summary": "Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art\nperformance in univariate forecasting on new time series simply by conditioned\non a brief history of past values. Their success demonstrates that large-scale\npretraining across diverse domains can acquire the inductive bias to generalize\nfrom temporal patterns in a brief history. However, most TSFMs are unable to\nleverage covariates -- future-available exogenous variables critical for\naccurate forecasting in many applications -- due to their domain-specific\nnature and the lack of associated inductive bias. We propose TFMAdapter, a\nlightweight, instance-level adapter that augments TSFMs with covariate\ninformation without fine-tuning. Instead of retraining, TFMAdapter operates on\nthe limited history provided during a single model call, learning a\nnon-parametric cascade that combines covariates with univariate TSFM forecasts.\nHowever, such learning would require univariate forecasts at all steps in the\nhistory, requiring too many calls to the TSFM. To enable training on the full\nhistorical context while limiting TSFM invocations, TFMAdapter uses a two-stage\nmethod: (1) generating pseudo-forecasts with a simple regression model, and (2)\ntraining a Gaussian Process regressor to refine predictions using both pseudo-\nand TSFM forecasts alongside covariates. Extensive experiments on real-world\ndatasets demonstrate that TFMAdapter consistently outperforms both foundation\nmodels and supervised baselines, achieving a 24-27\\% improvement over base\nfoundation models with minimal data and computational overhead. Our results\nhighlight the potential of lightweight adapters to bridge the gap between\ngeneric foundation models and domain-specific forecasting needs.", "AI": {"tldr": "TFMAdapter\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u4e3a\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u6dfb\u52a0\u534f\u53d8\u91cf\u4fe1\u606f\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u5728\u6709\u9650\u8ba1\u7b97\u5f00\u9500\u4e0b\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5229\u7528\u9886\u57df\u7279\u5b9a\u7684\u534f\u53d8\u91cf\u4fe1\u606f\uff0c\u800c\u8fd9\u4e9b\u5916\u751f\u53d8\u91cf\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\u5bf9\u4e8e\u51c6\u786e\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u6765\u589e\u5f3a\u57fa\u7840\u6a21\u578b\u7684\u534f\u53d8\u91cf\u5904\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faTFMAdapter\u9002\u914d\u5668\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1)\u4f7f\u7528\u7b80\u5355\u56de\u5f52\u6a21\u578b\u751f\u6210\u4f2a\u9884\u6d4b\uff1b2)\u8bad\u7ec3\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u5668\uff0c\u7ed3\u5408\u4f2a\u9884\u6d4b\u3001\u57fa\u7840\u6a21\u578b\u9884\u6d4b\u548c\u534f\u53d8\u91cf\u4fe1\u606f\u6765\u4f18\u5316\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTFMAdapter\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u548c\u76d1\u7763\u57fa\u7ebf\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u5b9e\u73b0\u4e8624-27%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u6570\u636e\u548c\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6709\u6f5c\u529b\u5f25\u5408\u901a\u7528\u57fa\u7840\u6a21\u578b\u4e0e\u9886\u57df\u7279\u5b9a\u9884\u6d4b\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6709\u6548\u7684\u534f\u53d8\u91cf\u6574\u5408\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13908", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13908", "abs": "https://arxiv.org/abs/2509.13908", "authors": ["Priyobrata Mondal", "Faizanuddin Ansari", "Swagatam Das"], "title": "APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness", "comment": null, "summary": "Ensuring fairness in machine learning models is critical, especially when\nbiases compound across intersecting protected attributes like race, gender, and\nage. While existing methods address fairness for single attributes, they fail\nto capture the nuanced, multiplicative biases faced by intersectional\nsubgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first\nframework to explicitly model intersectional fairness as a joint optimization\nproblem over the Cartesian product of sensitive attributes. APFEx combines\nthree key innovations- (1) an adaptive multi-objective optimizer that\ndynamically switches between Pareto cone projection, gradient weighting, and\nexploration strategies to navigate fairness-accuracy trade-offs, (2)\ndifferentiable intersectional fairness metrics enabling gradient-based\noptimization of non-smooth subgroup disparities, and (3) theoretical guarantees\nof convergence to Pareto-optimal solutions. Experiments on four real-world\ndatasets demonstrate APFEx's superiority, reducing fairness violations while\nmaintaining competitive accuracy. Our work bridges a critical gap in fair ML,\nproviding a scalable, model-agnostic solution for intersectional fairness.", "AI": {"tldr": "\u63d0\u51fa\u4e86APFEx\u6846\u67b6\uff0c\u9996\u4e2a\u663e\u5f0f\u5efa\u6a21\u4ea4\u53c9\u516c\u5e73\u6027\u7684\u8054\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u591a\u76ee\u6807\u4f18\u5316\u5668\u3001\u53ef\u5fae\u4ea4\u53c9\u516c\u5e73\u6307\u6807\u548c\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u516c\u5e73\u6027\u8fdd\u89c4", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u65b9\u6cd5\u53ea\u5904\u7406\u5355\u4e00\u654f\u611f\u5c5e\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u4ea4\u53c9\u5b50\u7fa4\u4f53\u9762\u4e34\u7684\u590d\u6742\u591a\u91cd\u504f\u89c1\uff0c\u9700\u8981\u89e3\u51b3\u4ea4\u53c9\u516c\u5e73\u6027\u8fd9\u4e00\u5173\u952e\u6311\u6218", "method": "APFEx\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u521b\u65b0\uff1a1\uff09\u81ea\u9002\u5e94\u591a\u76ee\u6807\u4f18\u5316\u5668\u52a8\u6001\u5207\u6362\u5e15\u7d2f\u6258\u9525\u6295\u5f71\u3001\u68af\u5ea6\u52a0\u6743\u548c\u63a2\u7d22\u7b56\u7565\uff1b2\uff09\u53ef\u5fae\u4ea4\u53c9\u516c\u5e73\u6307\u6807\u652f\u6301\u57fa\u4e8e\u68af\u5ea6\u7684\u975e\u5e73\u6ed1\u5b50\u7fa4\u4f53\u5dee\u5f02\u4f18\u5316\uff1b3\uff09\u7406\u8bba\u6536\u655b\u4fdd\u8bc1", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAPFEx\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u516c\u5e73\u6027\u8fdd\u89c4\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "APFEx\u586b\u8865\u4e86\u516c\u5e73\u673a\u5668\u5b66\u4e60\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u4ea4\u53c9\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u6a21\u578b\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13914", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13914", "abs": "https://arxiv.org/abs/2509.13914", "authors": ["Divya Thuremella", "Yi Yang", "Simon Wanna", "Lars Kunze", "Daniele De Martini"], "title": "Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction", "comment": "Accepted 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "summary": "This work explores the application of ensemble modeling to the\nmultidimensional regression problem of trajectory prediction for vehicles in\nurban environments. As newer and bigger state-of-the-art prediction models for\nautonomous driving continue to emerge, an important open challenge is the\nproblem of how to combine the strengths of these big models without the need\nfor costly re-training. We show how, perhaps surprisingly, combining\nstate-of-the-art deep learning models out-of-the-box (without retraining or\nfine-tuning) with a simple confidence-weighted average method can enhance the\noverall prediction. Indeed, while combining trajectory prediction models is not\nstraightforward, this simple approach enhances performance by 10% over the best\nprediction model, especially in the long-tailed metrics. We show that this\nperformance improvement holds on both the NuScenes and Argoverse datasets, and\nthat these improvements are made across the dataset distribution. The code for\nour work is open source.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u7f6e\u4fe1\u5ea6\u52a0\u6743\u5e73\u5747\u96c6\u6210\u65b9\u6cd5\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5c06\u591a\u4e2a\u5148\u8fdb\u7684\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u7ec4\u5408\uff0c\u5728NuScenes\u548cArgoverse\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8610%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u4e0d\u65ad\u6d8c\u73b0\u66f4\u5927\u66f4\u5f3a\u7684\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u5982\u4f55\u5728\u4e0d\u8fdb\u884c\u6602\u8d35\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6574\u5408\u8fd9\u4e9b\u5927\u578b\u6a21\u578b\u7684\u4f18\u52bf\u6210\u4e3a\u4e00\u4e2a\u91cd\u8981\u6311\u6218\u3002", "method": "\u4f7f\u7528\u7f6e\u4fe1\u5ea6\u52a0\u6743\u5e73\u5747\u65b9\u6cd5\uff0c\u76f4\u63a5\u7ec4\u5408\u591a\u4e2a\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03\u3002", "result": "\u8be5\u65b9\u6cd5\u5728NuScenes\u548cArgoverse\u6570\u636e\u96c6\u4e0a\u5747\u5b9e\u73b0\u4e8610%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u957f\u5c3e\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u6539\u8fdb\u5728\u6574\u4e2a\u6570\u636e\u5206\u5e03\u8303\u56f4\u5185\u90fd\u6709\u6548\u3002", "conclusion": "\u7b80\u5355\u7684\u7f6e\u4fe1\u5ea6\u52a0\u6743\u5e73\u5747\u96c6\u6210\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u8f68\u8ff9\u9884\u6d4b\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u65e0\u9700\u590d\u6742\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u6574\u5408\u591a\u4e2a\u5148\u8fdb\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.13933", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13933", "abs": "https://arxiv.org/abs/2509.13933", "authors": ["Qiyue Li", "Yingxin Liu", "Hang Qi", "Jieping Luo", "Zhizhang Liu", "Jingjin Wu"], "title": "Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning", "comment": null, "summary": "We consider the client selection problem in wireless Federated Learning (FL),\nwith the objective of reducing the total required time to achieve a certain\nlevel of learning accuracy. Since the server cannot observe the clients'\ndynamic states that can change their computation and communication efficiency,\nwe formulate client selection as a restless multi-armed bandit problem. We\npropose a scalable and efficient approach called the Whittle Index Learning in\nFederated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and\nupdate an approximated Whittle index associated with each client, and then\nselects the clients with the highest indices. Compared to existing approaches,\nWILF-Q does not require explicit knowledge of client state transitions or data\ndistributions, making it well-suited for deployment in practical FL settings.\nExperiment results demonstrate that WILF-Q significantly outperforms existing\nbaseline policies in terms of learning efficiency, providing a robust and\nefficient approach to client selection in wireless FL.", "AI": {"tldr": "\u63d0\u51faWILF-Q\u65b9\u6cd5\uff0c\u4f7f\u7528Q-learning\u81ea\u9002\u5e94\u5b66\u4e60\u5ba2\u6237\u7aefWhittle\u6307\u6570\uff0c\u7528\u4e8e\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u7aef\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u5b66\u4e60\u6548\u7387", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u9009\u62e9\u95ee\u9898\uff0c\u76ee\u6807\u662f\u5728\u8fbe\u5230\u7279\u5b9a\u5b66\u4e60\u7cbe\u5ea6\u65f6\u51cf\u5c11\u603b\u65f6\u95f4\u6d88\u8017\u3002\u7531\u4e8e\u670d\u52a1\u5668\u65e0\u6cd5\u89c2\u6d4b\u5ba2\u6237\u7aef\u7684\u52a8\u6001\u72b6\u6001\u53d8\u5316\uff0c\u9700\u8981\u8bbe\u8ba1\u65e0\u9700\u663e\u5f0f\u72b6\u6001\u8f6c\u79fb\u77e5\u8bc6\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5c06\u5ba2\u6237\u7aef\u9009\u62e9\u5efa\u6a21\u4e3a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63d0\u51faWILF-Q\u65b9\u6cd5\uff1a\u4f7f\u7528Q-learning\u81ea\u9002\u5e94\u5b66\u4e60\u548c\u66f4\u65b0\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u8fd1\u4f3cWhittle\u6307\u6570\uff0c\u7136\u540e\u9009\u62e9\u6307\u6570\u6700\u9ad8\u7684\u5ba2\u6237\u7aef", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eWILF-Q\u5728\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7b56\u7565\uff0c\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u9ad8\u6548\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u65b9\u6cd5", "conclusion": "WILF-Q\u4e0d\u9700\u8981\u5ba2\u6237\u7aef\u72b6\u6001\u8f6c\u79fb\u6216\u6570\u636e\u5206\u5e03\u7684\u663e\u5f0f\u77e5\u8bc6\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u8054\u90a6\u5b66\u4e60\u90e8\u7f72\uff0c\u4e3a\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13952", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.13952", "abs": "https://arxiv.org/abs/2509.13952", "authors": ["Amin Lotfalian", "Mohammad Reza Banan", "Pooyan Broumand"], "title": "eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems", "comment": null, "summary": "This paper presents eXtended Physics-Informed Neural Network (X-PINN), a\nnovel and robust framework for addressing fracture mechanics problems involving\nmultiple cracks in fractured media. To address this, an energy-based loss\nfunction, customized integration schemes, and domain decomposition procedures\nare proposed. Inspired by the Extended Finite Element Method (XFEM), the neural\nnetwork solution space is enriched with specialized functions that allow crack\nbody discontinuities and singularities at crack tips to be explicitly captured.\nFurthermore, a structured framework is introduced in which standard and\nenriched solution components are modeled using distinct neural networks,\nenabling flexible and effective simulations of complex multiple-crack problems\nin 1D and 2D domains, with convenient extensibility to 3D problems. Numerical\nexperiments are conducted to validate the effectiveness and robustness of the\nproposed method.", "AI": {"tldr": "X-PINN\u662f\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u795e\u7ecf\u7f51\u7edc\u6269\u5c55\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u542b\u591a\u88c2\u7eb9\u7684\u65ad\u88c2\u529b\u5b66\u95ee\u9898\uff0c\u901a\u8fc7\u80fd\u91cf\u635f\u5931\u51fd\u6570\u3001\u5b9a\u5236\u79ef\u5206\u65b9\u6848\u548c\u533a\u57df\u5206\u89e3\u65b9\u6cd5\uff0c\u7ed3\u5408XFEM\u601d\u60f3\u5728\u795e\u7ecf\u7f51\u7edc\u89e3\u7a7a\u95f4\u4e2d\u6dfb\u52a0\u7279\u6b8a\u51fd\u6570\u6765\u6355\u6349\u88c2\u7eb9\u4e0d\u8fde\u7eed\u6027\u548c\u5947\u5f02\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u591a\u88c2\u7eb9\u65ad\u88c2\u529b\u5b66\u95ee\u9898\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6709\u6548\u6355\u6349\u88c2\u7eb9\u4e0d\u8fde\u7eed\u6027\u548c\u5947\u5f02\u6027\u7684\u65b0\u578b\u8ba1\u7b97\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u6269\u5c55\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(X-PINN)\uff0c\u91c7\u7528\u57fa\u4e8e\u80fd\u91cf\u7684\u635f\u5931\u51fd\u6570\u3001\u5b9a\u5236\u79ef\u5206\u65b9\u6848\u548c\u533a\u57df\u5206\u89e3\uff0c\u501f\u9274XFEM\u601d\u60f3\u5728\u795e\u7ecf\u7f51\u7edc\u89e3\u7a7a\u95f4\u4e2d\u6dfb\u52a0\u7279\u6b8a\u51fd\u6570\u6765\u663e\u5f0f\u5904\u7406\u88c2\u7eb9\u4e0d\u8fde\u7eed\u6027\u548c\u5947\u5f02\u6027\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u795e\u7ecf\u7f51\u7edc\u5206\u522b\u5efa\u6a21\u6807\u51c6\u548c\u589e\u5f3a\u89e3\u5206\u91cf\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u57281D\u548c2D\u591a\u88c2\u7eb9\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6269\u5c55\u52303D\u95ee\u9898\u7684\u80fd\u529b\u3002", "conclusion": "X-PINN\u6846\u67b6\u4e3a\u590d\u6742\u591a\u88c2\u7eb9\u65ad\u88c2\u529b\u5b66\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5904\u7406\u88c2\u7eb9\u4e0d\u8fde\u7eed\u6027\u548c\u5947\u5f02\u6027\u7684\u4f18\u52bf\u3002"}}
{"id": "2509.14000", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14000", "abs": "https://arxiv.org/abs/2509.14000", "authors": ["Ivana Kesi\u0107", "Alja\u017e Blatnik", "Carolina Fortuna", "Bla\u017e Bertalani\u010d"], "title": "Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations", "comment": "20 pages, 4 figures", "summary": "Global Navigation Satellite Systems (GNSS) are increasingly disrupted by\nintentional jamming, degrading availability precisely when positioning and\ntiming must remain operational. We address this by reframing jamming mitigation\nas dynamic graph regression and introducing a receiver-centric deep temporal\ngraph network that predicts, and thus corrects, the receivers horizontal\ndeviation in real time. At each 1 Hz epoch, the satellite receiver environment\nis represented as a heterogeneous star graph (receiver center, tracked\nsatellites as leaves) with time varying attributes (e.g., SNR, azimuth,\nelevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM\n(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a\nshort history to output the 2D deviation vector applied for on the fly\ncorrection.\n  We evaluate on datasets from two distinct receivers under three jammer\nprofiles, continuous wave (cw), triple tone (cw3), and wideband FM, each\nexercised at six power levels between -45 and -70 dBm, with 50 repetitions per\nscenario (prejam/jam/recovery). Against strong multivariate time series\nbaselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains\nthe lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm\n(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and\n4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode\ndatasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),\noutperforming Seq2Point, MLP, and CNN. A split study shows superior data\nefficiency: with only 10\\% training data our approach remains well ahead of\nbaselines (20 cm vs. 36-42 cm).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u52a8\u6001\u56fe\u56de\u5f52\u7684GNSS\u5e72\u6270\u6291\u5236\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f02\u6784\u56fe\u5377\u79efLSTM\u7f51\u7edc\u5b9e\u65f6\u9884\u6d4b\u5e76\u4fee\u6b63\u63a5\u6536\u673a\u6c34\u5e73\u504f\u5dee\uff0c\u5728\u591a\u79cd\u5e72\u6270\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u57fa\u7ebf\u6a21\u578b", "motivation": "GNSS\u7cfb\u7edf\u65e5\u76ca\u53d7\u5230\u6545\u610f\u5e72\u6270\u7684\u5f71\u54cd\uff0c\u5728\u9700\u8981\u7cbe\u786e\u5b9a\u4f4d\u548c\u6388\u65f6\u7684\u5173\u952e\u65f6\u523b\u964d\u4f4e\u7cfb\u7edf\u53ef\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u5e72\u6270\u6291\u5236\u65b9\u6cd5", "method": "\u5c06GNSS\u5e72\u6270\u6291\u5236\u91cd\u6784\u4e3a\u52a8\u6001\u56fe\u56de\u5f52\u95ee\u9898\uff0c\u6784\u5efa\u63a5\u6536\u673a\u4e3a\u4e2d\u5fc3\u7684\u5f02\u6784\u661f\u578b\u56fe\u8868\u793a\u536b\u661f\u63a5\u6536\u73af\u5883\uff0c\u4f7f\u7528\u5355\u5c42\u5f02\u6784\u56fe\u5377\u79efLSTM\uff08HeteroGCLSTM\uff09\u805a\u5408\u7a7a\u95f4\u4e0a\u4e0b\u6587\u548c\u65f6\u95f4\u52a8\u6001\u4fe1\u606f", "result": "\u5728\u4e24\u79cd\u63a5\u6536\u673a\u548c\u4e09\u79cd\u5e72\u6270\u6a21\u5f0f\u4e0b\uff0c\u6a21\u578b\u5728-45dBm\u5e72\u6270\u5f3a\u5ea6\u4e0b\u8fbe\u52303.64-7.74cm\u7684MAE\uff0c\u5728-60\u81f3-70dBm\u65f6\u63d0\u5347\u81f31.65-2.08cm\uff0c\u6df7\u5408\u6a21\u5f0f\u4e0bMAE\u4e3a3.78-4.25cm\uff0c\u6570\u636e\u6548\u7387\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5b9e\u65f6\u6291\u5236GNSS\u5e72\u6270\uff0c\u5728\u4e0d\u540c\u5e72\u6270\u7c7b\u578b\u548c\u529f\u7387\u6c34\u5e73\u4e0b\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5177\u6709\u51fa\u8272\u7684\u6570\u636e\u6548\u7387\uff0c\u4ec5\u970010%\u8bad\u7ec3\u6570\u636e\u5373\u53ef\u5927\u5e45\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u6027\u80fd"}}
{"id": "2509.14024", "categories": ["cs.LG", "68T07, 68P27, 92-08, 92-10"], "pdf": "https://arxiv.org/pdf/2509.14024", "abs": "https://arxiv.org/abs/2509.14024", "authors": ["Raouf Kerkouche", "Henrik Zunker", "Mario Fritz", "Martin J. K\u00fchn"], "title": "Differentially private federated learning for localized control of infectious disease dynamics", "comment": "18 pages, 6 figures", "summary": "In times of epidemics, swift reaction is necessary to mitigate epidemic\nspreading. For this reaction, localized approaches have several advantages,\nlimiting necessary resources and reducing the impact of interventions on a\nlarger scale. However, training a separate machine learning (ML) model on a\nlocal scale is often not feasible due to limited available data. Centralizing\nthe data is also challenging because of its high sensitivity and privacy\nconstraints. In this study, we consider a localized strategy based on the\nGerman counties and communities managed by the related local health authorities\n(LHA). For the preservation of privacy to not oppose the availability of\ndetailed situational data, we propose a privacy-preserving forecasting method\nthat can assist public health experts and decision makers. ML methods with\nfederated learning (FL) train a shared model without centralizing raw data.\nConsidering the counties, communities or LHAs as clients and finding a balance\nbetween utility and privacy, we study a FL framework with client-level\ndifferential privacy (DP). We train a shared multilayer perceptron on sliding\nwindows of recent case counts to forecast the number of cases, while clients\nexchange only norm-clipped updates and the server aggregated updates with DP\nnoise. We evaluate the approach on COVID-19 data on county-level during two\nphases. As expected, very strict privacy yields unstable, unusable forecasts.\nAt a moderately strong level, the DP model closely approaches the non-DP model:\n$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in\nNovember 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,\nclient-level DP-FL can deliver useful county-level predictions with strong\nprivacy guarantees, and viable privacy budgets depend on epidemic phase,\nallowing privacy-compliant collaboration among health authorities for local\nforecasting.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u548c\u5dee\u5206\u9690\u79c1\u7684\u9690\u79c1\u4fdd\u62a4\u6d41\u884c\u75c5\u9884\u6d4b\u65b9\u6cd5\uff0c\u5728\u5fb7\u56fd\u53bf\u7ea7\u5c42\u9762\u5b9e\u73b0\u672c\u5730\u5316\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u8fbe\u5230\u63a5\u8fd1\u975e\u9690\u79c1\u4fdd\u62a4\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd", "motivation": "\u5728\u6d41\u884c\u75c5\u7206\u53d1\u65f6\u9700\u8981\u5feb\u901f\u53cd\u5e94\uff0c\u4f46\u672c\u5730\u5316\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u800c\u96c6\u4e2d\u6570\u636e\u53c8\u5b58\u5728\u9690\u79c1\u654f\u611f\u6027\u6311\u6218\u3002\u9700\u8981\u627e\u5230\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u63d0\u4f9b\u8be6\u7ec6\u60c5\u5883\u6570\u636e\u7684\u9884\u6d4b\u65b9\u6cd5", "method": "\u91c7\u7528\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u53bf/\u793e\u533a\u4f5c\u4e3a\u5ba2\u6237\u7aef\uff0c\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u673a\u5728\u6ed1\u52a8\u7a97\u53e3\u4e0a\u8fdb\u884c\u75c5\u4f8b\u6570\u9884\u6d4b\u3002\u5ba2\u6237\u7aef\u53ea\u4ea4\u6362\u7ecf\u8fc7\u8303\u6570\u88c1\u526a\u7684\u66f4\u65b0\uff0c\u670d\u52a1\u5668\u4f7f\u7528\u5dee\u5206\u9690\u79c1\u566a\u58f0\u805a\u5408\u66f4\u65b0", "result": "\u5728\u9002\u5ea6\u9690\u79c1\u4fdd\u62a4\u6c34\u5e73\u4e0b\uff0cDP\u6a21\u578b\u63a5\u8fd1\u975eDP\u6a21\u578b\u6027\u80fd\uff1a2020\u5e7411\u6708R\u00b2=0.94\uff08vs 0.95\uff09\uff0cMAPE=26%\uff1b2022\u5e743\u6708R\u00b2=0.88\uff08vs 0.93\uff09\uff0cMAPE=21%", "conclusion": "\u5ba2\u6237\u7aef\u7ea7\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60\u80fd\u591f\u63d0\u4f9b\u6709\u7528\u7684\u53bf\u7ea7\u9884\u6d4b\uff0c\u5177\u6709\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u8bc1\u3002\u53ef\u884c\u7684\u9690\u79c1\u9884\u7b97\u53d6\u51b3\u4e8e\u6d41\u884c\u75c5\u9636\u6bb5\uff0c\u5141\u8bb8\u536b\u751f\u5f53\u5c40\u8fdb\u884c\u9690\u79c1\u5408\u89c4\u7684\u672c\u5730\u9884\u6d4b\u534f\u4f5c"}}
{"id": "2509.14061", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14061", "abs": "https://arxiv.org/abs/2509.14061", "authors": ["Chiara De Luca", "Elisa Donati"], "title": "Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing", "comment": null, "summary": "Queen bee presence is essential for the health and stability of honeybee\ncolonies, yet current monitoring methods rely on manual inspections that are\nlabor-intensive, disruptive, and impractical for large-scale beekeeping. While\nrecent audio-based approaches have shown promise, they often require high power\nconsumption, complex preprocessing, and are susceptible to ambient noise. To\novercome these limitations, we propose a lightweight, multimodal system for\nqueen detection based on environmental sensor fusion-specifically, temperature,\nhumidity, and pressure differentials between the inside and outside of the\nhive. Our approach employs quantized decision tree inference on a commercial\nSTM32 microcontroller, enabling real-time, low-power edge computing without\ncompromising accuracy. We show that our system achieves over 99% queen\ndetection accuracy using only environmental inputs, with audio features\noffering no significant performance gain. This work presents a scalable and\nsustainable solution for non-invasive hive monitoring, paving the way for\nautonomous, precision beekeeping using off-the-shelf, energy-efficient\nhardware.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6e29\u5ea6\u3001\u6e7f\u5ea6\u548c\u538b\u529b\u5dee\u7684\u73af\u5883\u4f20\u611f\u5668\u878d\u5408\u8f7b\u91cf\u7ea7\u7cfb\u7edf\uff0c\u4f7f\u7528\u91cf\u5316\u51b3\u7b56\u6811\u5728STM32\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u4f4e\u529f\u8017\u8702\u738b\u68c0\u6d4b\uff0c\u51c6\u786e\u7387\u8d8599%", "motivation": "\u4f20\u7edf\u8702\u738b\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u68c0\u67e5\uff0c\u52b3\u52a8\u5f3a\u5ea6\u5927\u4e14\u5e72\u6270\u8702\u7fa4\uff1b\u73b0\u6709\u97f3\u9891\u65b9\u6cd5\u529f\u8017\u9ad8\u3001\u9884\u5904\u7406\u590d\u6742\u4e14\u6613\u53d7\u73af\u5883\u566a\u58f0\u5f71\u54cd", "method": "\u91c7\u7528\u73af\u5883\u4f20\u611f\u5668\u878d\u5408\uff08\u5185\u5916\u8702\u7bb1\u6e29\u6e7f\u5ea6\u538b\u529b\u5dee\uff09\uff0c\u5728\u5546\u7528STM32\u5fae\u63a7\u5236\u5668\u4e0a\u90e8\u7f72\u91cf\u5316\u51b3\u7b56\u6811\u63a8\u7406\uff0c\u5b9e\u73b0\u8fb9\u7f18\u5b9e\u65f6\u8ba1\u7b97", "result": "\u4ec5\u4f7f\u7528\u73af\u5883\u8f93\u5165\u5373\u53ef\u8fbe\u523099%\u4ee5\u4e0a\u7684\u8702\u738b\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u97f3\u9891\u7279\u5f81\u672a\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u53ef\u6301\u7eed\u7684\u975e\u4fb5\u5165\u5f0f\u8702\u7bb1\u76d1\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u4f7f\u7528\u73b0\u6210\u8282\u80fd\u786c\u4ef6\u7684\u81ea\u4e3b\u7cbe\u51c6\u517b\u8702\u94fa\u5e73\u9053\u8def"}}
{"id": "2509.14077", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14077", "abs": "https://arxiv.org/abs/2509.14077", "authors": ["Yuhao Wang", "Enlu Zhou"], "title": "Online Bayesian Risk-Averse Reinforcement Learning", "comment": null, "summary": "In this paper, we study the Bayesian risk-averse formulation in reinforcement\nlearning (RL). To address the epistemic uncertainty due to a lack of data, we\nadopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the\nparameter uncertainty of the unknown underlying model. We derive the asymptotic\nnormality that characterizes the difference between the Bayesian risk value\nfunction and the original value function under the true unknown distribution.\nThe results indicate that the Bayesian risk-averse approach tends to\npessimistically underestimate the original value function. This discrepancy\nincreases with stronger risk aversion and decreases as more data become\navailable. We then utilize this adaptive property in the setting of online RL\nas well as online contextual multi-arm bandits (CMAB), a special case of online\nRL. We provide two procedures using posterior sampling for both the general RL\nproblem and the CMAB problem. We establish a sub-linear regret bound, with the\nregret defined as the conventional regret for both the RL and CMAB settings.\nAdditionally, we establish a sub-linear regret bound for the CMAB setting with\nthe regret defined as the Bayesian risk regret. Finally, we conduct numerical\nexperiments to demonstrate the effectiveness of the proposed algorithm in\naddressing epistemic uncertainty and verifying the theoretical properties.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8d1d\u53f6\u65af\u98ce\u9669\u89c4\u907f\u65b9\u6cd5\uff0c\u901a\u8fc7BRMDP\u5904\u7406\u6a21\u578b\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u8bc1\u660e\u4e86\u8d1d\u53f6\u65af\u98ce\u9669\u503c\u51fd\u6570\u76f8\u5bf9\u4e8e\u771f\u5b9e\u503c\u51fd\u6570\u7684\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u5e76\u5728\u7ebf\u6027RL\u548cCMAB\u4e2d\u5efa\u7acb\u4e86\u6b21\u7ebf\u6027\u9057\u61be\u754c\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7531\u4e8e\u6570\u636e\u4e0d\u8db3\u5bfc\u81f4\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u98ce\u9669\u89c4\u907f\u65b9\u6cd5\u6765\u5904\u7406\u672a\u77e5\u57fa\u7840\u6a21\u578b\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u98ce\u9669\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(BRMDP)\uff0c\u63a8\u5bfc\u8d1d\u53f6\u65af\u98ce\u9669\u503c\u51fd\u6570\u4e0e\u539f\u59cb\u503c\u51fd\u6570\u5dee\u5f02\u7684\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u5e76\u5728\u5728\u7ebfRL\u548cCMAB\u4e2d\u4f7f\u7528\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u3002", "result": "\u8d1d\u53f6\u65af\u98ce\u9669\u89c4\u907f\u65b9\u6cd5\u4f1a\u60b2\u89c2\u5730\u4f4e\u4f30\u539f\u59cb\u503c\u51fd\u6570\uff0c\u8fd9\u79cd\u5dee\u5f02\u968f\u98ce\u9669\u538c\u6076\u7a0b\u5ea6\u589e\u5f3a\u800c\u589e\u5927\uff0c\u968f\u6570\u636e\u589e\u52a0\u800c\u51cf\u5c0f\u3002\u5efa\u7acb\u4e86\u6b21\u7ebf\u6027\u9057\u61be\u754c\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u8d1d\u53f6\u65af\u98ce\u9669\u89c4\u907f\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5728\u7ebfRL\u548cCMAB\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u7406\u8bba\u6027\u8d28\u548c\u5b9e\u9645\u6548\u679c\uff0c\u98ce\u9669\u538c\u6076\u7a0b\u5ea6\u548c\u6570\u636e\u91cf\u662f\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2509.14078", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14078", "abs": "https://arxiv.org/abs/2509.14078", "authors": ["Robiul Islam", "Dmitry I. Ignatov", "Karl Kaberg", "Roman Nabatchikov"], "title": "Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques", "comment": null, "summary": "This study investigates classifier performance across EEG frequency bands\nusing various optimizers and evaluates efficient class prediction for the left\nand right hemispheres. Three neural network architectures - a deep dense\nnetwork, a shallow three-layer network, and a convolutional neural network\n(CNN) - are implemented and compared using the TensorFlow and PyTorch\nframeworks. Results indicate that the Adagrad and RMSprop optimizers\nconsistently perform well across different frequency bands, with Adadelta\nexhibiting robust performance in cross-model evaluations. Specifically, Adagrad\nexcels in the beta band, while RMSprop achieves superior performance in the\ngamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among\nthe models, the CNN demonstrates the second highest accuracy, particularly in\ncapturing spatial features of EEG data. The deep dense network shows\ncompetitive performance in learning complex patterns, whereas the shallow\nthree-layer network, sometimes being less accurate, provides computational\nefficiency. SHAP (Shapley Additive Explanations) plots are employed to identify\nefficient class prediction, revealing nuanced contributions of EEG frequency\nbands to model accuracy. Overall, the study highlights the importance of\noptimizer selection, model architecture, and EEG frequency band analysis in\nenhancing classifier performance and understanding feature importance in\nneuroimaging-based classification tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4e0d\u540c\u4f18\u5316\u5668\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5728EEG\u9891\u6bb5\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0Adagrad\u548cRMSprop\u4f18\u5316\u5668\u8868\u73b0\u7a33\u5b9a\uff0cCNN\u5728\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0cSHAP\u5206\u6790\u63ed\u793a\u4e86EEG\u9891\u6bb5\u5bf9\u5206\u7c7b\u51c6\u786e\u6027\u7684\u8d21\u732e\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u4f18\u5316\u5668\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5728EEG\u9891\u6bb5\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4ee5\u53ca\u8bc4\u4f30\u5de6\u53f3\u534a\u7403\u9ad8\u6548\u5206\u7c7b\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u4e3a\u795e\u7ecf\u5f71\u50cf\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4f18\u5316\u7b56\u7565\u548c\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u3002", "method": "\u4f7f\u7528TensorFlow\u548cPyTorch\u6846\u67b6\u5b9e\u73b0\u4e09\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff08\u6df1\u5ea6\u5bc6\u96c6\u7f51\u7edc\u3001\u6d45\u5c42\u4e09\u5c42\u7f51\u7edc\u548cCNN\uff09\uff0c\u6bd4\u8f83\u591a\u79cd\u4f18\u5316\u5668\uff08Adagrad\u3001RMSprop\u3001Adadelta\u3001SGD\u3001FTRL\uff09\u5728\u4e0d\u540cEEG\u9891\u6bb5\u7684\u6027\u80fd\uff0c\u5e76\u91c7\u7528SHAP\u8fdb\u884c\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u3002", "result": "Adagrad\u548cRMSprop\u4f18\u5316\u5668\u5728\u4e0d\u540c\u9891\u6bb5\u8868\u73b0\u7a33\u5b9a\uff0cAdagrad\u5728beta\u9891\u6bb5\u8868\u73b0\u6700\u4f73\uff0cRMSprop\u5728gamma\u9891\u6bb5\u8868\u73b0\u6700\u4f18\u3002CNN\u83b7\u5f97\u7b2c\u4e8c\u9ad8\u51c6\u786e\u7387\uff0c\u6df1\u5ea6\u5bc6\u96c6\u7f51\u7edc\u5728\u5b66\u4e60\u590d\u6742\u6a21\u5f0f\u65b9\u9762\u5177\u6709\u7ade\u4e89\u529b\uff0c\u6d45\u5c42\u7f51\u7edc\u8ba1\u7b97\u6548\u7387\u9ad8\u4f46\u51c6\u786e\u7387\u8f83\u4f4e\u3002", "conclusion": "\u4f18\u5316\u5668\u9009\u62e9\u3001\u6a21\u578b\u67b6\u6784\u548cEEG\u9891\u6bb5\u5206\u6790\u5bf9\u5206\u7c7b\u5668\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u7814\u7a76\u4e3a\u795e\u7ecf\u5f71\u50cf\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u4f18\u5316\u7b56\u7565\u548c\u7279\u5f81\u8d21\u732e\u7406\u89e3\u3002SHAP\u5206\u6790\u6709\u52a9\u4e8e\u8bc6\u522bEEG\u9891\u6bb5\u5bf9\u6a21\u578b\u51c6\u786e\u6027\u7684\u7ec6\u5fae\u8d21\u732e\u3002"}}
{"id": "2509.14113", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14113", "abs": "https://arxiv.org/abs/2509.14113", "authors": ["Alessandro Brusaferri", "Danial Ramin", "Andrea Ballarino"], "title": "From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting", "comment": "6 pages", "summary": "While neural networks are achieving high predictive accuracy in multi-horizon\nprobabilistic forecasting, understanding the underlying mechanisms that lead to\nfeature-conditioned outputs remains a significant challenge for forecasters. In\nthis work, we take a further step toward addressing this critical issue by\nintroducing the Quantile Neural Basis Model, which incorporates the\ninterpretability principles of Quantile Generalized Additive Models into an\nend-to-end neural network training framework. To this end, we leverage shared\nbasis decomposition and weight factorization, complementing Neural Models for\nLocation, Scale, and Shape by avoiding any parametric distributional\nassumptions. We validate our approach on day-ahead electricity price\nforecasting, achieving predictive performance comparable to distributional and\nquantile regression neural networks, while offering valuable insights into\nmodel behavior through the learned nonlinear mappings from input features to\noutput predictions across the horizon.", "AI": {"tldr": "\u63d0\u51fa\u4e86Quantile Neural Basis Model\uff0c\u5c06\u5206\u4f4d\u6570\u5e7f\u4e49\u53ef\u52a0\u6a21\u578b\u7684\u89e3\u91ca\u6027\u539f\u7406\u878d\u5165\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u6a21\u578b\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u867d\u7136\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u6c34\u5e73\u6982\u7387\u9884\u6d4b\u4e2d\u53d6\u5f97\u4e86\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u7406\u89e3\u7279\u5f81\u6761\u4ef6\u8f93\u51fa\u7684\u5e95\u5c42\u673a\u5236\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5229\u7528\u5171\u4eab\u57fa\u5206\u89e3\u548c\u6743\u91cd\u5206\u89e3\uff0c\u5c06Quantile Generalized Additive Models\u7684\u53ef\u89e3\u91ca\u6027\u539f\u5219\u6574\u5408\u5230\u7aef\u5230\u7aef\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6846\u67b6\u4e2d\uff0c\u907f\u514d\u53c2\u6570\u5206\u5e03\u5047\u8bbe\u3002", "result": "\u5728\u65e5\u524d\u7535\u4ef7\u9884\u6d4b\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff0c\u9884\u6d4b\u6027\u80fd\u4e0e\u5206\u5e03\u548c\u5206\u4f4d\u6570\u56de\u5f52\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\uff0c\u540c\u65f6\u901a\u8fc7\u5b66\u4e60\u5230\u7684\u4ece\u8f93\u5165\u7279\u5f81\u5230\u8f93\u51fa\u9884\u6d4b\u7684\u975e\u7ebf\u6027\u6620\u5c04\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u6a21\u578b\u884c\u4e3a\u6d1e\u5bdf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u53ef\u89e3\u91ca\u6027\u878d\u5165\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u5bf9\u6a21\u578b\u673a\u5236\u7684\u6df1\u5165\u7406\u89e3\uff0c\u4e3a\u6982\u7387\u9884\u6d4b\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u91ca\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14129", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.14129", "abs": "https://arxiv.org/abs/2509.14129", "authors": ["Kit T. Rodolfa", "Erika Salomon", "Jin Yao", "Steve Yoder", "Robert Sullivan", "Kevin McGuire", "Allie Dickinson", "Rob MacDougall", "Brian Seidler", "Christina Sung", "Claire Herdeman", "Rayid Ghani"], "title": "Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy", "comment": null, "summary": "Many incarcerated individuals face significant and complex challenges,\nincluding mental illness, substance dependence, and homelessness, yet jails and\nprisons are often poorly equipped to address these needs. With little support\nfrom the existing criminal justice system, these needs can remain untreated and\nworsen, often leading to further offenses and a cycle of incarceration with\nadverse outcomes both for the individual and for public safety, with\nparticularly large impacts on communities of color that continue to widen the\nalready extensive racial disparities in criminal justice outcomes. Responding\nto these failures, a growing number of criminal justice stakeholders are\nseeking to break this cycle through innovative approaches such as\ncommunity-driven and alternative approaches to policing, mentoring, community\nbuilding, restorative justice, pretrial diversion, holistic defense, and social\nservice connections. Here we report on a collaboration between Johnson County,\nKansas, and Carnegie Mellon University to perform targeted, proactive mental\nhealth outreach in an effort to reduce reincarceration rates.\n  This paper describes the data used, our predictive modeling approach and\nresults, as well as the design and analysis of a field trial conducted to\nconfirm our model's predictive power, evaluate the impact of this targeted\noutreach, and understand at what level of reincarceration risk outreach might\nbe most effective. Through this trial, we find that our model is highly\npredictive of new jail bookings, with more than half of individuals in the\ntrial's highest-risk group returning to jail in the following year. Outreach\nwas most effective among these highest-risk individuals, with impacts on mental\nhealth utilization, EMS dispatches, and criminal justice involvement.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u9884\u6d4b\u5efa\u6a21\u548c\u5b9e\u5730\u8bd5\u9a8c\uff0c\u53d1\u73b0\u5bf9\u9ad8\u98ce\u9669\u4e2a\u4f53\u8fdb\u884c\u9488\u5bf9\u6027\u5fc3\u7406\u5065\u5eb7\u5e72\u9884\u80fd\u6709\u6548\u964d\u4f4e\u518d\u76d1\u7981\u7387\uff0c\u6539\u5584\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u4f7f\u7528\u548c\u51cf\u5c11\u53f8\u6cd5\u7cfb\u7edf\u4ecb\u5165\u3002", "motivation": "\u76d1\u72f1\u7cfb\u7edf\u96be\u4ee5\u6709\u6548\u5904\u7406\u56da\u72af\u7684\u5fc3\u7406\u5065\u5eb7\u3001\u836f\u7269\u4f9d\u8d56\u548c\u65e0\u5bb6\u53ef\u5f52\u7b49\u590d\u6742\u95ee\u9898\uff0c\u5bfc\u81f4\u518d\u72af\u7f6a\u548c\u76d1\u7981\u5faa\u73af\uff0c\u7279\u522b\u662f\u5bf9\u6709\u8272\u4eba\u79cd\u793e\u533a\u9020\u6210\u4e25\u91cd\u79cd\u65cf\u5dee\u5f02\u3002\u9700\u8981\u521b\u65b0\u65b9\u6cd5\u6253\u7834\u8fd9\u4e00\u5faa\u73af\u3002", "method": "\u91c7\u7528\u9884\u6d4b\u5efa\u6a21\u65b9\u6cd5\u8bc6\u522b\u9ad8\u98ce\u9669\u4e2a\u4f53\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u65bd\u5b9e\u5730\u8bd5\u9a8c\u8fdb\u884c\u9488\u5bf9\u6027\u5fc3\u7406\u5065\u5eb7\u5916\u5c55\u5e72\u9884\uff0c\u8bc4\u4f30\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u548c\u5e72\u9884\u6548\u679c\u3002", "result": "\u6a21\u578b\u9ad8\u5ea6\u9884\u6d4b\u65b0\u76d1\u72f1\u6536\u5bb9\u60c5\u51b5\uff0c\u6700\u9ad8\u98ce\u9669\u7ec4\u4e2d\u8d85\u8fc7\u4e00\u534a\u4eba\u5728\u4e00\u5e74\u5185\u91cd\u8fd4\u76d1\u72f1\u3002\u5bf9\u6700\u9ad8\u98ce\u9669\u4e2a\u4f53\u7684\u5e72\u9884\u5728\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u4f7f\u7528\u3001\u6025\u6551\u8c03\u5ea6\u548c\u53f8\u6cd5\u4ecb\u5165\u65b9\u9762\u6548\u679c\u663e\u8457\u3002", "conclusion": "\u9488\u5bf9\u6027\u5fc3\u7406\u5065\u5eb7\u5916\u5c55\u5e72\u9884\u5bf9\u9ad8\u98ce\u9669\u4e2a\u4f53\u6700\u4e3a\u6709\u6548\uff0c\u80fd\u591f\u6253\u7834\u76d1\u7981\u5faa\u73af\uff0c\u6539\u5584\u4e2a\u4f53\u7ed3\u5c40\u548c\u516c\u5171\u5b89\u5168\uff0c\u7279\u522b\u662f\u5bf9\u53d7\u79cd\u65cf\u5dee\u5f02\u5f71\u54cd\u6700\u4e25\u91cd\u7684\u7fa4\u4f53\u3002"}}
{"id": "2509.14158", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.14158", "abs": "https://arxiv.org/abs/2509.14158", "authors": ["Feng Ruan", "Keli Liu", "Michael Jordan"], "title": "A Compositional Kernel Model for Feature Learning", "comment": null, "summary": "We study a compositional variant of kernel ridge regression in which the\npredictor is applied to a coordinate-wise reweighting of the inputs. Formulated\nas a variational problem, this model provides a simple testbed for feature\nlearning in compositional architectures. From the perspective of variable\nselection, we show how relevant variables are recovered while noise variables\nare eliminated. We establish guarantees showing that both global minimizers and\nstationary points discard noise coordinates when the noise variables are\nGaussian distributed. A central finding is that $\\ell_1$-type kernels, such as\nthe Laplace kernel, succeed in recovering features contributing to nonlinear\neffects at stationary points, whereas Gaussian kernels recover only linear\nones.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u7ec4\u5408\u5f0f\u6838\u5cad\u56de\u5f52\u53d8\u4f53\uff0c\u901a\u8fc7\u5750\u6807\u91cd\u52a0\u6743\u8fdb\u884c\u7279\u5f81\u5b66\u4e60\uff0c\u8bc1\u660e\u4e86\u5728\u566a\u58f0\u53d8\u91cf\u4e3a\u9ad8\u65af\u5206\u5e03\u65f6\uff0c\u5168\u5c40\u6700\u5c0f\u503c\u548c\u9a7b\u70b9\u90fd\u80fd\u6709\u6548\u6d88\u9664\u566a\u58f0\u5750\u6807\uff0c\u53d1\u73b0\u62c9\u666e\u62c9\u65af\u6838\u7b49\u21131\u578b\u6838\u80fd\u6062\u590d\u975e\u7ebf\u6027\u7279\u5f81\uff0c\u800c\u9ad8\u65af\u6838\u53ea\u80fd\u6062\u590d\u7ebf\u6027\u7279\u5f81\u3002", "motivation": "\u7814\u7a76\u7ec4\u5408\u5f0f\u6838\u5cad\u56de\u5f52\u6a21\u578b\uff0c\u4e3a\u7ec4\u5408\u67b6\u6784\u4e2d\u7684\u7279\u5f81\u5b66\u4e60\u63d0\u4f9b\u7b80\u5355\u6d4b\u8bd5\u5e73\u53f0\uff0c\u63a2\u7d22\u53d8\u91cf\u9009\u62e9\u4e2d\u76f8\u5173\u53d8\u91cf\u7684\u6062\u590d\u548c\u566a\u58f0\u53d8\u91cf\u7684\u6d88\u9664\u673a\u5236\u3002", "method": "\u91c7\u7528\u53d8\u5206\u95ee\u9898\u5f62\u5f0f\u7684\u7ec4\u5408\u5f0f\u6838\u5cad\u56de\u5f52\u6a21\u578b\uff0c\u5bf9\u8f93\u5165\u8fdb\u884c\u5750\u6807\u91cd\u52a0\u6743\uff0c\u5206\u6790\u5168\u5c40\u6700\u5c0f\u503c\u548c\u9a7b\u70b9\u7684\u7279\u5f81\u9009\u62e9\u6027\u80fd\uff0c\u6bd4\u8f83\u21131\u578b\u6838\uff08\u5982\u62c9\u666e\u62c9\u65af\u6838\uff09\u548c\u9ad8\u65af\u6838\u7684\u7279\u5f81\u6062\u590d\u80fd\u529b\u3002", "result": "\u8bc1\u660e\u4e86\u5f53\u566a\u58f0\u53d8\u91cf\u4e3a\u9ad8\u65af\u5206\u5e03\u65f6\uff0c\u5168\u5c40\u6700\u5c0f\u503c\u548c\u9a7b\u70b9\u90fd\u80fd\u6210\u529f\u6d88\u9664\u566a\u58f0\u5750\u6807\uff1b\u53d1\u73b0\u21131\u578b\u6838\u80fd\u591f\u5728\u9a7b\u70b9\u6062\u590d\u975e\u7ebf\u6027\u6548\u5e94\u7684\u7279\u5f81\uff0c\u800c\u9ad8\u65af\u6838\u53ea\u80fd\u6062\u590d\u7ebf\u6027\u7279\u5f81\u3002", "conclusion": "\u7ec4\u5408\u5f0f\u6838\u5cad\u56de\u5f52\u4e3a\u7279\u5f81\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u21131\u578b\u6838\u5728\u975e\u7ebf\u6027\u7279\u5f81\u6062\u590d\u65b9\u9762\u4f18\u4e8e\u9ad8\u65af\u6838\uff0c\u8fd9\u4e3a\u7ec4\u5408\u67b6\u6784\u4e2d\u7684\u7279\u5f81\u9009\u62e9\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2509.14167", "categories": ["cs.LG", "q-bio.QM", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.14167", "abs": "https://arxiv.org/abs/2509.14167", "authors": ["Md Rezwan Jaher", "Abul Mukid Mohammad Mukaddes", "A. B. M. Abdul Malek"], "title": "Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework", "comment": "43 pages, 10 figures (including supplementary material)", "summary": "Many critical healthcare decisions are challenged by the inability to measure\nkey underlying parameters. Glaucoma, a leading cause of irreversible blindness\ndriven by elevated intraocular pressure (IOP), provides a stark example. The\nprimary determinant of IOP, a tissue property called trabecular meshwork\npermeability, cannot be measured in vivo, forcing clinicians to depend on\nindirect surrogates. This clinical challenge is compounded by a broader\ncomputational one: developing predictive models for such ill-posed inverse\nproblems is hindered by a lack of ground-truth data and prohibitive cost of\nlarge-scale, high-fidelity simulations. We address both challenges with an\nend-to-end framework to noninvasively estimate unmeasurable variables from\nsparse, routine data. Our approach combines a multi-stage artificial\nintelligence architecture to functionally separate the problem; a novel data\ngeneration strategy we term PCDS that obviates the need for hundreds of\nthousands of costly simulations, reducing the effective computational time from\nyears to hours; and a Bayesian engine to quantify predictive uncertainty. Our\nframework deconstructs a single IOP measurement into its fundamental components\nfrom routine inputs only, yielding estimates for the unmeasurable tissue\npermeability and a patient's outflow facility. Our noninvasively estimated\noutflow facility achieved excellent agreement with state-of-the-art tonography\nwith precision comparable to direct physical instruments. Furthermore, the\nnewly derived permeability biomarker demonstrates high accuracy in stratifying\nclinical cohorts by disease risk, highlighting its diagnostic potential. More\nbroadly, our framework establishes a generalizable blueprint for solving\nsimilar inverse problems in other data-scarce, computationally-intensive\ndomains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\u67b6\u6784\u548c\u975e\u4fb5\u5165\u6027\u65b9\u6cd5\u4ece\u7a00\u758f\u5e38\u89c4\u6570\u636e\u4e2d\u4f30\u8ba1\u9752\u5149\u773c\u6cbb\u7597\u4e2d\u65e0\u6cd5\u6d4b\u91cf\u7684\u5173\u952e\u53c2\u6570\uff08\u5982\u5c0f\u6881\u7f51\u6e17\u900f\u6027\uff09\uff0c\u89e3\u51b3\u4e86\u533b\u7597\u51b3\u7b56\u4e2d\u7f3a\u4e4f\u5730\u9762\u771f\u5b9e\u6570\u636e\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u9752\u5149\u773c\u6cbb\u7597\u4e2d\u5173\u952e\u53c2\u6570\uff08\u5982\u773c\u5185\u538b\u7684\u51b3\u5b9a\u56e0\u7d20\u5c0f\u6881\u7f51\u6e17\u900f\u6027\uff09\u65e0\u6cd5\u5728\u4f53\u5185\u6d4b\u91cf\uff0c\u4e34\u5e8a\u533b\u751f\u53ea\u80fd\u4f9d\u8d56\u95f4\u63a5\u66ff\u4ee3\u6307\u6807\uff0c\u540c\u65f6\u7f3a\u4e4f\u771f\u5b9e\u6570\u636e\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u6a21\u62df\u963b\u788d\u4e86\u9884\u6d4b\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u4eba\u5de5\u667a\u80fd\u67b6\u6784\u529f\u80fd\u5206\u79bb\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u9896\u7684PCDS\u6570\u636e\u751f\u6210\u7b56\u7565\u907f\u514d\u5927\u91cf\u6602\u8d35\u6a21\u62df\uff0c\u5c06\u6709\u6548\u8ba1\u7b97\u65f6\u95f4\u4ece\u6570\u5e74\u7f29\u77ed\u5230\u6570\u5c0f\u65f6\uff0c\u5e76\u4f7f\u7528\u8d1d\u53f6\u65af\u5f15\u64ce\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u975e\u4fb5\u5165\u6027\u4f30\u8ba1\u7684\u6d41\u51fa\u8bbe\u65bd\u4e0e\u6700\u5148\u8fdb\u7684\u773c\u538b\u6d4b\u91cf\u6280\u672f\u8fbe\u6210\u4f18\u79c0\u4e00\u81f4\uff0c\u7cbe\u5ea6\u582a\u6bd4\u76f4\u63a5\u7269\u7406\u4eea\u5668\uff1b\u65b0\u63a8\u5bfc\u7684\u6e17\u900f\u6027\u751f\u7269\u6807\u5fd7\u7269\u5728\u6309\u75be\u75c5\u98ce\u9669\u5206\u5c42\u4e34\u5e8a\u961f\u5217\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5176\u4ed6\u6570\u636e\u7a00\u7f3a\u3001\u8ba1\u7b97\u5bc6\u96c6\u578b\u9886\u57df\u7684\u7c7b\u4f3c\u9006\u95ee\u9898\u89e3\u51b3\u63d0\u4f9b\u4e86\u53ef\u63a8\u5e7f\u7684\u84dd\u56fe\uff0c\u5c55\u793a\u4e86\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.14169", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14169", "abs": "https://arxiv.org/abs/2509.14169", "authors": ["Ziming Wei", "Zichen Kong", "Yuan Wang", "David Z. Pan", "Xiyuan Tang"], "title": "TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits", "comment": null, "summary": "Analog and mixed-signal circuit design remains challenging due to the\nshortage of high-quality data and the difficulty of embedding domain knowledge\ninto automated flows. Traditional black-box optimization achieves sampling\nefficiency but lacks circuit understanding, which often causes evaluations to\nbe wasted in low-value regions of the design space. In contrast, learning-based\nmethods embed structural knowledge but are case-specific and costly to retrain.\nRecent attempts with large language models show potential, yet they often rely\non manual intervention, limiting generality and transparency. We propose\nTopoSizing, an end-to-end framework that performs robust circuit understanding\ndirectly from raw netlists and translates this knowledge into optimization\ngains. Our approach first applies graph algorithms to organize circuits into a\nhierarchical device-module-stage representation. LLM agents then execute an\niterative hypothesis-verification-refinement loop with built-in consistency\nchecks, producing explicit annotations. Verified insights are integrated into\nBayesian optimization through LLM-guided initial sampling and\nstagnation-triggered trust-region updates, improving efficiency while\npreserving feasibility.", "AI": {"tldr": "TopoSizing\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u7b97\u6cd5\u548cLLM\u4ee3\u7406\u5b9e\u73b0\u7535\u8def\u5c42\u6b21\u5316\u7406\u89e3\uff0c\u5e76\u5c06\u9886\u57df\u77e5\u8bc6\u6574\u5408\u5230\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\uff0c\u63d0\u9ad8\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u7684\u91c7\u6837\u6548\u7387\u548c\u4f18\u5316\u6548\u679c\u3002", "motivation": "\u6a21\u62df\u548c\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u8bbe\u8ba1\u9762\u4e34\u9ad8\u8d28\u91cf\u6570\u636e\u77ed\u7f3a\u548c\u9886\u57df\u77e5\u8bc6\u96be\u4ee5\u5d4c\u5165\u81ea\u52a8\u5316\u6d41\u7a0b\u7684\u6311\u6218\uff0c\u4f20\u7edf\u9ed1\u76d2\u4f18\u5316\u7f3a\u4e4f\u7535\u8def\u7406\u89e3\uff0c\u5b66\u4e60\u578b\u65b9\u6cd5\u6210\u672c\u9ad8\u4e14\u7f3a\u4e4f\u901a\u7528\u6027\u3002", "method": "\u9996\u5148\u4f7f\u7528\u56fe\u7b97\u6cd5\u5c06\u7535\u8def\u7ec4\u7ec7\u4e3a\u5c42\u6b21\u5316\u8868\u793a\uff0c\u7136\u540eLLM\u4ee3\u7406\u6267\u884c\u5047\u8bbe-\u9a8c\u8bc1-\u7cbe\u70bc\u5faa\u73af\u8fdb\u884c\u663e\u5f0f\u6807\u6ce8\uff0c\u6700\u540e\u5c06\u9a8c\u8bc1\u540e\u7684\u6d1e\u5bdf\u6574\u5408\u5230\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\uff0c\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u521d\u59cb\u91c7\u6837\u548c\u505c\u6ede\u89e6\u53d1\u4fe1\u4efb\u533a\u57df\u66f4\u65b0\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u76f4\u63a5\u4ece\u539f\u59cb\u7f51\u8868\u5b9e\u73b0\u7a33\u5065\u7684\u7535\u8def\u7406\u89e3\uff0c\u5e76\u5c06\u77e5\u8bc6\u8f6c\u5316\u4e3a\u4f18\u5316\u589e\u76ca\uff0c\u63d0\u9ad8\u6548\u7387\u540c\u65f6\u4fdd\u6301\u53ef\u884c\u6027\u3002", "conclusion": "TopoSizing\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u77e5\u8bc6\u5d4c\u5165\u548c\u4f18\u5316\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u7535\u8def\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14172", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14172", "abs": "https://arxiv.org/abs/2509.14172", "authors": ["Ziyuan Chen", "Zhenghui Zhao", "Zhangye Han", "Miancan Liu", "Xianhang Ye", "Yiqing Li", "Hongbo Min", "Jinkui Ren", "Xiantao Zhang", "Guitao Cao"], "title": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning", "comment": null, "summary": "With the rapid advancement of large language models and vision-language\nmodels, employing large models as Web Agents has become essential for automated\nweb interaction. However, training Web Agents with reinforcement learning faces\ncritical challenges including credit assignment misallocation, prohibitively\nhigh annotation costs, and reward sparsity. To address these issues, we propose\nTree-Guided Preference Optimization (TGPO), an offline reinforcement learning\nframework that proposes a tree-structured trajectory representation merging\nsemantically identical states across trajectories to eliminate label conflicts.\nOur framework incorporates a Process Reward Model that automatically generates\nfine-grained rewards through subgoal progress, redundancy detection, and action\nverification. Additionally, a dynamic weighting mechanism prioritizes\nhigh-impact decision points during training. Experiments on Online-Mind2Web and\nour self-constructed C-WebShop datasets demonstrate that TGPO significantly\noutperforms existing methods, achieving higher success rates with fewer\nredundant steps.", "AI": {"tldr": "TGPO\u662f\u4e00\u4e2a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6811\u5f62\u8f68\u8ff9\u8868\u793a\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u89e3\u51b3Web\u667a\u80fd\u4f53\u8bad\u7ec3\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u3001\u6807\u6ce8\u6210\u672c\u548c\u5956\u52b1\u7a00\u758f\u6027\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4f7f\u7528\u5927\u6a21\u578b\u4f5c\u4e3aWeb\u667a\u80fd\u4f53\u53d8\u5f97\u91cd\u8981\uff0c\u4f46\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u9762\u4e34\u4fe1\u7528\u5206\u914d\u4e0d\u5f53\u3001\u6807\u6ce8\u6210\u672c\u8fc7\u9ad8\u548c\u5956\u52b1\u7a00\u758f\u7b49\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51faTree-Guided Preference Optimization (TGPO)\u6846\u67b6\uff0c\u4f7f\u7528\u6811\u5f62\u8f68\u8ff9\u8868\u793a\u5408\u5e76\u8bed\u4e49\u76f8\u540c\u7684\u72b6\u6001\u6d88\u9664\u6807\u7b7e\u51b2\u7a81\uff0c\u5305\u542b\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u81ea\u52a8\u751f\u6210\u7ec6\u7c92\u5ea6\u5956\u52b1\uff0c\u4ee5\u53ca\u52a8\u6001\u6743\u91cd\u673a\u5236\u4f18\u5148\u5904\u7406\u9ad8\u5f71\u54cd\u529b\u51b3\u7b56\u70b9\u3002", "result": "\u5728Online-Mind2Web\u548c\u81ea\u5efaC-WebShop\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTGPO\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee5\u66f4\u5c11\u7684\u5197\u4f59\u6b65\u9aa4\u5b9e\u73b0\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3002", "conclusion": "TGPO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86Web\u667a\u80fd\u4f53\u8bad\u7ec3\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316Web\u4ea4\u4e92\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14181", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14181", "abs": "https://arxiv.org/abs/2509.14181", "authors": ["Yifan Hu", "Jie Yang", "Tian Zhou", "Peiyuan Liu", "Yujin Tang", "Rong Jin", "Liang Sun"], "title": "Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting", "comment": null, "summary": "Representation learning techniques like contrastive learning have long been\nexplored in time series forecasting, mirroring their success in computer vision\nand natural language processing. Yet recent state-of-the-art (SOTA) forecasters\nseldom adopt these representation approaches because they have shown little\nperformance advantage. We challenge this view and demonstrate that explicit\nrepresentation alignment can supply critical information that bridges the\ndistributional gap between input histories and future targets. To this end, we\nintroduce TimeAlign, a lightweight, plug-and-play framework that learns\nauxiliary features via a simple reconstruction task and feeds them back to any\nbase forecaster. Extensive experiments across eight benchmarks verify its\nsuperior performance. Further studies indicate that the gains arises primarily\nfrom correcting frequency mismatches between historical inputs and future\noutputs. We also provide a theoretical justification for the effectiveness of\nTimeAlign in increasing the mutual information between learned representations\nand predicted targets. As it is architecture-agnostic and incurs negligible\noverhead, TimeAlign can serve as a general alignment module for modern deep\nlearning time-series forecasting systems. The code is available at\nhttps://github.com/TROUBADOUR000/TimeAlign.", "AI": {"tldr": "TimeAlign\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u91cd\u6784\u4efb\u52a1\u5b66\u4e60\u8f85\u52a9\u7279\u5f81\uff0c\u7ea0\u6b63\u5386\u53f2\u8f93\u5165\u4e0e\u672a\u6765\u8f93\u51fa\u4e4b\u95f4\u7684\u9891\u7387\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5bf9\u6bd4\u5b66\u4e60\u7b49\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4f5c\u8005\u8ba4\u4e3a\u663e\u5f0f\u7684\u8868\u793a\u5bf9\u9f50\u53ef\u4ee5\u5f25\u8865\u8f93\u5165\u5386\u53f2\u4e0e\u672a\u6765\u76ee\u6807\u4e4b\u95f4\u7684\u5206\u5e03\u5dee\u8ddd\u3002", "method": "\u63d0\u51faTimeAlign\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u6784\u4efb\u52a1\u5b66\u4e60\u8f85\u52a9\u7279\u5f81\u5e76\u53cd\u9988\u7ed9\u4efb\u4f55\u57fa\u7840\u9884\u6d4b\u5668\uff0c\u67b6\u6784\u65e0\u5173\u4e14\u5f00\u9500\u6781\u5c0f\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\uff0c\u589e\u76ca\u4e3b\u8981\u6765\u81ea\u7ea0\u6b63\u9891\u7387\u4e0d\u5339\u914d\uff0c\u7406\u8bba\u8bc1\u660e\u589e\u52a0\u4e86\u5b66\u4e60\u8868\u793a\u4e0e\u9884\u6d4b\u76ee\u6807\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u3002", "conclusion": "TimeAlign\u53ef\u4f5c\u4e3a\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7cfb\u7edf\u7684\u901a\u7528\u5bf9\u9f50\u6a21\u5757\uff0c\u5177\u6709\u67b6\u6784\u65e0\u5173\u6027\u548c\u53ef\u5ffd\u7565\u7684\u5f00\u9500\u4f18\u52bf\u3002"}}
{"id": "2509.14198", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2509.14198", "abs": "https://arxiv.org/abs/2509.14198", "authors": ["Juan Diego Toscano", "Daniel T. Chen", "Vivek Oommen", "George Em Karniadakis"], "title": "A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning", "comment": null, "summary": "Residual-based adaptive strategies are widely used in scientific machine\nlearning but remain largely heuristic. We introduce a unifying variational\nframework that formalizes these methods by integrating convex transformations\nof the residual. Different transformations correspond to distinct objective\nfunctionals: exponential weights target the minimization of uniform error,\nwhile linear weights recover the minimization of quadratic error. Within this\nperspective, adaptive weighting is equivalent to selecting sampling\ndistributions that optimize the primal objective, thereby linking\ndiscretization choices directly to error metrics. This principled approach\nyields three benefits: (1) it enables systematic design of adaptive schemes\nacross norms, (2) reduces discretization error through variance reduction of\nthe loss estimator, and (3) enhances learning dynamics by improving the\ngradient signal-to-noise ratio. Extending the framework to operator learning,\nwe demonstrate substantial performance gains across optimizers and\narchitectures. Our results provide a theoretical justification of\nresidual-based adaptivity and establish a foundation for principled\ndiscretization and training strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u53d8\u5206\u6846\u67b6\u6765\u5f62\u5f0f\u5316\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u7b56\u7565\uff0c\u901a\u8fc7\u51f8\u53d8\u6362\u5c06\u79bb\u6563\u5316\u9009\u62e9\u4e0e\u8bef\u5dee\u5ea6\u91cf\u76f4\u63a5\u5173\u8054\uff0c\u7cfb\u7edf\u5316\u8bbe\u8ba1\u81ea\u9002\u5e94\u65b9\u6848\u5e76\u63d0\u5347\u6027\u80fd", "motivation": "\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u7b56\u7565\u5728\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u4f46\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u5f62\u5f0f\u5316\u8fd9\u4e9b\u542f\u53d1\u5f0f\u65b9\u6cd5", "method": "\u5f15\u5165\u53d8\u5206\u6846\u67b6\uff0c\u901a\u8fc7\u51f8\u53d8\u6362\u6574\u5408\u6b8b\u5dee\uff0c\u4e0d\u540c\u53d8\u6362\u5bf9\u5e94\u4e0d\u540c\u76ee\u6807\u51fd\u6570\uff08\u6307\u6570\u6743\u91cd\u5bf9\u5e94\u5747\u5300\u8bef\u5dee\u6700\u5c0f\u5316\uff0c\u7ebf\u6027\u6743\u91cd\u5bf9\u5e94\u4e8c\u6b21\u8bef\u5dee\u6700\u5c0f\u5316\uff09\uff0c\u5c06\u81ea\u9002\u5e94\u52a0\u6743\u7b49\u4ef7\u4e8e\u9009\u62e9\u4f18\u5316\u539f\u59cb\u76ee\u6807\u7684\u91c7\u6837\u5206\u5e03", "result": "\u6846\u67b6\u5e26\u6765\u4e09\u4e2a\u597d\u5904\uff1a\u7cfb\u7edf\u5316\u8bbe\u8ba1\u8de8\u8303\u6570\u7684\u81ea\u9002\u5e94\u65b9\u6848\u3001\u901a\u8fc7\u635f\u5931\u4f30\u8ba1\u5668\u65b9\u5dee\u51cf\u5c11\u964d\u4f4e\u79bb\u6563\u5316\u8bef\u5dee\u3001\u901a\u8fc7\u6539\u5584\u68af\u5ea6\u4fe1\u566a\u6bd4\u589e\u5f3a\u5b66\u4e60\u52a8\u6001\uff0c\u5728\u7b97\u5b50\u5b66\u4e60\u4e2d\u5c55\u793a\u663e\u8457\u6027\u80fd\u63d0\u5347", "conclusion": "\u4e3a\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5efa\u7acb\u4e86\u539f\u5219\u6027\u79bb\u6563\u5316\u548c\u8bad\u7ec3\u7b56\u7565\u7684\u57fa\u7840"}}
{"id": "2509.14216", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14216", "abs": "https://arxiv.org/abs/2509.14216", "authors": ["Johnny R. Zhang", "Xiaomei Mi", "Gaoyuan Du", "Qianyi Sun", "Shiqi Wang", "Jiaxuan Li", "Wenhua Zhou"], "title": "A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training", "comment": "69 pages, 10 figures. Preprint", "summary": "Stochastic optimization powers the scalability of modern artificial\nintelligence, spanning machine learning, deep learning, reinforcement learning,\nand large language model training. Yet, existing theory remains largely\nconfined to Hilbert spaces, relying on inner-product frameworks and\northogonality. This paradigm fails to capture non-Euclidean settings, such as\nmirror descent on simplices, Bregman proximal methods for sparse learning,\nnatural gradient descent in information geometry, or\nKullback--Leibler-regularized language model training. Unlike Euclidean-based\nHilbert-space methods, this approach embraces general Banach spaces. This work\nintroduces a pioneering Banach--Bregman framework for stochastic iterations,\nestablishing Bregman geometry as a foundation for next-generation optimization.\nIt (i) provides a unified template via Bregman projections and Bregman--Fejer\nmonotonicity, encompassing stochastic approximation, mirror descent, natural\ngradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations\n($\\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and\nelucidating their acceleration effect; and (iii) delivers convergence theorems\nspanning almost-sure boundedness to geometric rates, validated on synthetic and\nreal-world tasks. Empirical studies across machine learning (UCI benchmarks),\ndeep learning (e.g., Transformer training), reinforcement learning\n(actor--critic), and large language models (WikiText-2 with distilGPT-2) show\nup to 20% faster convergence, reduced variance, and enhanced accuracy over\nclassical baselines. These results position Banach--Bregman geometry as a\ncornerstone unifying optimization theory and practice across core AI paradigms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u521b\u6027\u7684Banach-Bregman\u6846\u67b6\uff0c\u5c06\u968f\u673a\u4f18\u5316\u4eceHilbert\u7a7a\u95f4\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684Banach\u7a7a\u95f4\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u4f18\u5316\u65b9\u6cd5\u5e76\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6", "motivation": "\u73b0\u6709\u4f18\u5316\u7406\u8bba\u4e3b\u8981\u5c40\u9650\u4e8eHilbert\u7a7a\u95f4\uff0c\u65e0\u6cd5\u5904\u7406\u975e\u6b27\u51e0\u91cc\u5f97\u8bbe\u7f6e\uff0c\u5982\u5355\u7eaf\u5f62\u4e0a\u7684\u955c\u50cf\u4e0b\u964d\u3001\u7a00\u758f\u5b66\u4e60\u7684Bregman\u8fd1\u7aef\u65b9\u6cd5\u3001\u4fe1\u606f\u51e0\u4f55\u4e2d\u7684\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u7b49", "method": "\u5f15\u5165Banach-Bregman\u6846\u67b6\uff0c\u901a\u8fc7Bregman\u6295\u5f71\u548cBregman-Fejer\u5355\u8c03\u6027\u63d0\u4f9b\u7edf\u4e00\u6a21\u677f\uff0c\u5efa\u7acb\u8d85\u677e\u5f1b\u65b9\u6cd5\uff08\u03bb>2\uff09\uff0c\u5e76\u5728\u975eHilbert\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u7075\u6d3b\u7684\u51e0\u4f55\u7ed3\u6784", "result": "\u5728\u673a\u5668\u5b66\u4e60\uff08UCI\u57fa\u51c6\uff09\u3001\u6df1\u5ea6\u5b66\u4e60\uff08Transformer\u8bad\u7ec3\uff09\u3001\u5f3a\u5316\u5b66\u4e60\uff08actor-critic\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08WikiText-2\u4e0edistilGPT-2\uff09\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u7ecf\u5178\u57fa\u7ebf\u65b9\u6cd5\u6536\u655b\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe20%\uff0c\u65b9\u5dee\u51cf\u5c0f\uff0c\u51c6\u786e\u6027\u63d0\u9ad8", "conclusion": "Banach-Bregman\u51e0\u4f55\u6210\u4e3a\u7edf\u4e00\u4f18\u5316\u7406\u8bba\u548cAI\u6838\u5fc3\u8303\u5f0f\u5b9e\u8df5\u7684\u57fa\u77f3\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4f18\u5316\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2509.14219", "categories": ["cs.LG", "math.DS", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2509.14219", "abs": "https://arxiv.org/abs/2509.14219", "authors": ["Jiaqi Yao", "Lewis Mitchell", "John Maclean", "Hemanth Saratchandran"], "title": "Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems", "comment": null, "summary": "Data-driven modeling of nonlinear dynamical systems is often hampered by\nmeasurement noise. We propose a denoising framework, called Runge-Kutta and\nTotal Variation Based Implicit Neural Representation (RKTV-INR), that\nrepresents the state trajectory with an implicit neural representation (INR)\nfitted directly to noisy observations. Runge-Kutta integration and total\nvariation are imposed as constraints to ensure that the reconstructed state is\na trajectory of a dynamical system that remains close to the original data. The\ntrained INR yields a clean, continuous trajectory and provides accurate\nfirst-order derivatives via automatic differentiation. These denoised states\nand derivatives are then supplied to Sparse Identification of Nonlinear\nDynamics (SINDy) to recover the governing equations. Experiments demonstrate\neffective noise suppression, precise derivative estimation, and reliable system\nidentification.", "AI": {"tldr": "\u63d0\u51fa\u4e86RKTV-INR\u53bb\u566a\u6846\u67b6\uff0c\u7ed3\u5408\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u3001\u9f99\u683c-\u5e93\u5854\u79ef\u5206\u548c\u5168\u53d8\u5206\u7ea6\u675f\uff0c\u4ece\u566a\u58f0\u89c2\u6d4b\u4e2d\u91cd\u5efa\u52a8\u529b\u5b66\u7cfb\u7edf\u8f68\u8ff9\uff0c\u4e3aSINDy\u63d0\u4f9b\u5e72\u51c0\u7684\u8f68\u8ff9\u548c\u5bfc\u6570\u4ee5\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\u3002", "motivation": "\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u5e38\u53d7\u6d4b\u91cf\u566a\u58f0\u5f71\u54cd\uff0c\u9700\u8981\u6709\u6548\u53bb\u566a\u65b9\u6cd5\u6765\u83b7\u5f97\u51c6\u786e\u7684\u72b6\u6001\u8f68\u8ff9\u548c\u5bfc\u6570\uff0c\u4ee5\u4fbf\u53ef\u9760\u5730\u8bc6\u522b\u7cfb\u7edf\u63a7\u5236\u65b9\u7a0b\u3002", "method": "\u4f7f\u7528\u9690\u5f0f\u795e\u7ecf\u8868\u793a(INR)\u76f4\u63a5\u62df\u5408\u566a\u58f0\u89c2\u6d4b\uff0c\u901a\u8fc7\u9f99\u683c-\u5e93\u5854\u79ef\u5206\u548c\u5168\u53d8\u5206\u7ea6\u675f\u786e\u4fdd\u91cd\u5efa\u72b6\u6001\u7b26\u5408\u52a8\u529b\u5b66\u7cfb\u7edf\u8f68\u8ff9\uff0c\u5229\u7528\u81ea\u52a8\u5fae\u5206\u83b7\u5f97\u7cbe\u786e\u5bfc\u6570\uff0c\u6700\u540e\u7528SINDy\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6291\u5236\u566a\u58f0\uff0c\u63d0\u4f9b\u7cbe\u786e\u7684\u5bfc\u6570\u4f30\u8ba1\uff0c\u5e76\u5b9e\u73b0\u53ef\u9760\u7684\u7cfb\u7edf\u8bc6\u522b\u3002", "conclusion": "RKTV-INR\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u566a\u58f0\u73af\u5883\u4e0b\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\u5efa\u6a21\u95ee\u9898\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u7cfb\u7edf\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53bb\u566a\u548c\u5bfc\u6570\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14223", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14223", "abs": "https://arxiv.org/abs/2509.14223", "authors": ["Dmitrii Krasheninnikov", "Richard E. Turner", "David Krueger"], "title": "Language models' activations linearly encode training-order recency", "comment": null, "summary": "We show that language models' activations linearly encode when information\nwas learned during training. Our setup involves creating a model with a known\ntraining order by sequentially fine-tuning Llama-3.2-1B on six disjoint but\notherwise similar datasets about named entities. We find that the average\nactivations of test samples for the six training datasets encode the training\norder: when projected into a 2D subspace, these centroids are arranged exactly\nin the order of training and lie on a straight line. Further, we show that\nlinear probes can accurately (~90%) distinguish \"early\" vs. \"late\" entities,\ngeneralizing to entities unseen during the probes' own training. The model can\nalso be fine-tuned to explicitly report an unseen entity's training stage (~80%\naccuracy). Interestingly, this temporal signal does not seem attributable to\nsimple differences in activation magnitudes, losses, or model confidence. Our\npaper demonstrates that models are capable of differentiating information by\nits acquisition time, and carries significant implications for how they might\nmanage conflicting data and respond to knowledge modifications.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u6fc0\u6d3b\u503c\u7ebf\u6027\u7f16\u7801\u4e86\u4fe1\u606f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u88ab\u5b66\u4e60\u7684\u65f6\u95f4\u987a\u5e8f\uff0c\u901a\u8fc7\u987a\u5e8f\u5fae\u8c03\u5b9e\u9a8c\u8bc1\u660e\u6a21\u578b\u80fd\u591f\u533a\u5206\u4e0d\u540c\u65f6\u95f4\u5b66\u4e60\u7684\u4fe1\u606f", "motivation": "\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4ee5\u53ca\u5982\u4f55\u7f16\u7801\u4fe1\u606f\u88ab\u5b66\u4e60\u7684\u65f6\u95f4\u987a\u5e8f\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u6a21\u578b\u5982\u4f55\u5904\u7406\u51b2\u7a81\u6570\u636e\u548c\u77e5\u8bc6\u4fee\u6539\u5177\u6709\u91cd\u8981\u610f\u4e49", "method": "\u901a\u8fc7\u987a\u5e8f\u5fae\u8c03Llama-3.2-1B\u6a21\u578b\u5728\u516d\u4e2a\u4e0d\u76f8\u4ea4\u4f46\u76f8\u4f3c\u7684\u547d\u540d\u5b9e\u4f53\u6570\u636e\u96c6\u4e0a\uff0c\u5206\u6790\u6fc0\u6d3b\u503c\u7684\u7ebf\u6027\u7f16\u7801\u7279\u6027\uff0c\u5e76\u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u548c\u5fae\u8c03\u65b9\u6cd5\u9a8c\u8bc1\u65f6\u95f4\u4fe1\u53f7\u7684\u68c0\u6d4b\u80fd\u529b", "result": "\u6fc0\u6d3b\u503c\u4e2d\u5fc3\u70b9\u57282D\u5b50\u7a7a\u95f4\u4e2d\u6309\u8bad\u7ec3\u987a\u5e8f\u76f4\u7ebf\u6392\u5217\uff1b\u7ebf\u6027\u63a2\u9488\u80fd\u51c6\u786e\u533a\u5206\u65e9\u671f\u548c\u665a\u671f\u5b9e\u4f53\uff08\u7ea690%\u51c6\u786e\u7387\uff09\uff1b\u6a21\u578b\u53ef\u5fae\u8c03\u4ee5\u62a5\u544a\u672a\u89c1\u5b9e\u4f53\u7684\u8bad\u7ec3\u9636\u6bb5\uff08\u7ea680%\u51c6\u786e\u7387\uff09\uff1b\u65f6\u95f4\u4fe1\u53f7\u4e0e\u6fc0\u6d3b\u5e45\u5ea6\u3001\u635f\u5931\u6216\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7b49\u7b80\u5355\u5dee\u5f02\u65e0\u5173", "conclusion": "\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u6fc0\u6d3b\u503c\u7ebf\u6027\u7f16\u7801\u6765\u533a\u5206\u4fe1\u606f\u7684\u5b66\u4e60\u65f6\u95f4\uff0c\u8fd9\u4e00\u53d1\u73b0\u5bf9\u6a21\u578b\u5904\u7406\u51b2\u7a81\u6570\u636e\u548c\u77e5\u8bc6\u4fee\u6539\u7684\u65b9\u5f0f\u5177\u6709\u91cd\u8981\u542f\u793a\u610f\u4e49"}}
{"id": "2509.14230", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14230", "abs": "https://arxiv.org/abs/2509.14230", "authors": ["Mengting Ai", "Tianxin Wei", "Sirui Chen", "Jingrui He"], "title": "NIRVANA: Structured pruning reimagined for large language models compression", "comment": null, "summary": "Structured pruning of large language models (LLMs) offers substantial\nefficiency improvements by removing entire hidden units, yet current approaches\noften suffer from significant performance degradation, particularly in\nzero-shot settings, and necessitate costly recovery techniques such as\nsupervised fine-tuning (SFT) or adapter insertion. To address these critical\nshortcomings, we introduce NIRVANA, a novel pruning method explicitly designed\nto balance immediate zero-shot accuracy preservation with robust fine-tuning\ncapability. Leveraging a first-order saliency criterion derived from the Neural\nTangent Kernel under Adam optimization dynamics, NIRVANA provides a\ntheoretically grounded pruning strategy that respects essential model training\nbehaviors. To further address the unique challenges posed by structured\npruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across\nlayers and modules (attention vs. MLP), which adjusts pruning intensity between\nmodules in a globally balanced manner. Additionally, to mitigate the high\nsensitivity of pruning decisions to calibration data quality, we propose a\nsimple yet effective KL divergence-based calibration data selection strategy,\nensuring more reliable and task-agnostic pruning outcomes. Comprehensive\nexperiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA\noutperforms existing structured pruning methods under equivalent sparsity\nconstraints, providing a theoretically sound and practical approach to LLM\ncompression. The code is available at\nhttps://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.", "AI": {"tldr": "NIRVANA\u662f\u4e00\u79cd\u65b0\u9896\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u795e\u7ecf\u6b63\u5207\u6838\u7406\u8bba\u6307\u5bfc\u7684\u663e\u8457\u6027\u51c6\u5219\u548c\u81ea\u9002\u5e94\u7a00\u758f\u5206\u914d\u673a\u5236\uff0c\u5728\u4fdd\u6301\u96f6\u6837\u672c\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u5347LLM\u6548\u7387\uff0c\u65e0\u9700\u6602\u8d35\u7684\u6062\u590d\u6280\u672f\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709LLM\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3001\u9700\u8981\u6602\u8d35\u6062\u590d\u6280\u672f\uff08\u5982\u76d1\u7763\u5fae\u8c03\u6216\u9002\u914d\u5668\u63d2\u5165\uff09\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eAdam\u4f18\u5316\u52a8\u6001\u4e0b\u795e\u7ecf\u6b63\u5207\u6838\u7684\u4e00\u9636\u663e\u8457\u6027\u51c6\u5219\uff0c\u7ed3\u5408\u8de8\u5c42\u548c\u6a21\u5757\u7684\u81ea\u9002\u5e94\u7a00\u758f\u5206\u914d\u673a\u5236\uff0c\u4ee5\u53ca\u57fa\u4e8eKL\u6563\u5ea6\u7684\u6821\u51c6\u6570\u636e\u9009\u62e9\u7b56\u7565\u3002", "result": "\u5728Llama3\u3001Qwen\u548cT5\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNIRVANA\u5728\u540c\u7b49\u7a00\u758f\u5ea6\u7ea6\u675f\u4e0b\u4f18\u4e8e\u73b0\u6709\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u3002", "conclusion": "NIRVANA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u4e0a\u6709\u4f9d\u636e\u4e14\u5b9e\u7528\u7684LLM\u538b\u7f29\u65b9\u6cd5\uff0c\u5e73\u8861\u4e86\u96f6\u6837\u672c\u51c6\u786e\u6027\u4fdd\u6301\u548c\u5fae\u8c03\u80fd\u529b\u3002"}}
{"id": "2509.14234", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14234", "abs": "https://arxiv.org/abs/2509.14234", "authors": ["Dulhan Jayalath", "Shashwat Goel", "Thomas Foster", "Parag Jain", "Suchin Gururangan", "Cheng Zhang", "Anirudh Goyal", "Alan Schelten"], "title": "Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision", "comment": "22 pages, 8 figures, 2 tables", "summary": "Where do learning signals come from when there is no ground truth in\npost-training? We propose turning exploration into supervision through Compute\nas Teacher (CaT), which converts the model's own exploration at inference-time\ninto reference-free supervision by synthesizing a single reference from a group\nof parallel rollouts and then optimizing toward it. Concretely, the current\npolicy produces a group of rollouts; a frozen anchor (the initial policy)\nreconciles omissions and contradictions to estimate a reference, turning extra\ninference-time compute into a teacher signal. We turn this into rewards in two\nregimes: (i) verifiable tasks use programmatic equivalence on final answers;\n(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria\nscored by an independent LLM judge, with reward given by the fraction\nsatisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge\nscores), synthesis may disagree with the majority and be correct even when all\nrollouts are wrong; performance scales with the number of rollouts. As a\ntest-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up\nto +27% on MATH-500; +12% on HealthBench). With reinforcement learning\n(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained\npolicy surpassing the initial teacher signal.", "AI": {"tldr": "Compute as Teacher (CaT) \u901a\u8fc7\u5c06\u6a21\u578b\u5728\u63a8\u7406\u65f6\u7684\u63a2\u7d22\u8f6c\u5316\u4e3a\u65e0\u53c2\u8003\u76d1\u7763\uff0c\u5229\u7528\u5e76\u884crollouts\u5408\u6210\u53c2\u8003\u4fe1\u53f7\uff0c\u5728\u53ef\u9a8c\u8bc1\u548c\u4e0d\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6027\u80fd\u63d0\u5347", "motivation": "\u89e3\u51b3\u540e\u8bad\u7ec3\u4e2d\u7f3a\u4e4f\u771f\u5b9e\u76d1\u7763\u4fe1\u53f7\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u5982\u4f55\u5c06\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u8d44\u6e90\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u5b66\u4e60\u4fe1\u53f7", "method": "\u4f7f\u7528\u5f53\u524d\u7b56\u7565\u751f\u6210\u4e00\u7ec4\u5e76\u884crollouts\uff0c\u901a\u8fc7\u51bb\u7ed3\u7684\u521d\u59cb\u7b56\u7565\uff08anchor\uff09\u534f\u8c03\u51b2\u7a81\u548c\u9057\u6f0f\u6765\u4f30\u8ba1\u53c2\u8003\u4fe1\u53f7\uff0c\u5728\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u4f7f\u7528\u7a0b\u5e8f\u7b49\u4ef7\u6027\uff0c\u5728\u4e0d\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u4f7f\u7528\u81ea\u63d0\u8bae\u7684\u8bc4\u5206\u6807\u51c6\u548c\u72ec\u7acbLLM\u6cd5\u5b98", "result": "\u5728Gemma 3 4B\u3001Qwen 3 4B\u548cLlama 3.1 8B\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff08MATH-500\u4e0a\u6700\u9ad8+27%\uff0cHealthBench\u4e0a+12%\uff09\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\uff08CaT-RL\uff09\u540e\u83b7\u5f97\u8fdb\u4e00\u6b65\u589e\u76ca\uff08\u6700\u9ad8+33%\u548c+30%\uff09", "conclusion": "CaT\u80fd\u591f\u6709\u6548\u5c06\u63a8\u7406\u65f6\u8ba1\u7b97\u8f6c\u5316\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u5408\u6210\u65b9\u6cd5\u4f18\u4e8e\u9009\u62e9\u65b9\u6cd5\uff0c\u6027\u80fd\u968frollouts\u6570\u91cf\u6269\u5c55\uff0c\u8bad\u7ec3\u540e\u7684\u7b56\u7565\u53ef\u4ee5\u8d85\u8d8a\u521d\u59cb\u6559\u5e08\u4fe1\u53f7"}}
{"id": "2509.12510", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12510", "abs": "https://arxiv.org/abs/2509.12510", "authors": ["Wei Shao", "Ruoyu Zhang", "Zequan Liang", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun"], "title": "Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device", "comment": "In the proceedings of IEEE-EMBS BSN 2025", "summary": "Wearable photoplethysmography (PPG) is embedded in billions of devices, yet\nits optical waveform is easily corrupted by motion, perfusion loss, and ambient\nlight, jeopardizing downstream cardiometric analytics. Existing signal-quality\nassessment (SQA) methods rely either on brittle heuristics or on data-hungry\nsupervised models. We introduce the first fully unsupervised SQA pipeline for\nwrist PPG. Stage 1 trains a contrastive 1-D ResNet-18 on 276 h of raw,\nunlabeled data from heterogeneous sources (varying in device and sampling\nfrequency), yielding optical-emitter- and motion-invariant embeddings (i.e.,\nthe learned representation is stable across differences in LED wavelength,\ndrive intensity, and device optics, as well as wrist motion). Stage 2 converts\neach 512-D encoder embedding into a 4-D topological signature via persistent\nhomology (PH) and clusters these signatures with HDBSCAN. To produce a binary\nsignal-quality index (SQI), the acceptable PPG signals are represented by the\ndensest cluster while the remaining clusters are assumed to mainly contain\npoor-quality PPG signals. Without re-tuning, the SQI attains Silhouette,\nDavies-Bouldin, and Calinski-Harabasz scores of 0.72, 0.34, and 6173,\nrespectively, on a stratified sample of 10,000 windows. In this study, we\npropose a hybrid self-supervised-learning--topological-data-analysis (SSL--TDA)\nframework that offers a drop-in, scalable, cross-device quality gate for PPG\nsignals.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u8155\u90e8PPG\u4fe1\u53f7\u8d28\u91cf\u8bc4\u4f30\u7ba1\u9053\uff0c\u7ed3\u5408\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u62d3\u6251\u6570\u636e\u5206\u6790\uff0c\u5b9e\u73b0\u8de8\u8bbe\u5907\u7684\u4fe1\u53f7\u8d28\u91cf\u68c0\u6d4b\u3002", "motivation": "\u53ef\u7a7f\u6234\u5149\u7535\u5bb9\u79ef\u8109\u640f\u6ce2(PPG)\u4fe1\u53f7\u6613\u53d7\u8fd0\u52a8\u3001\u704c\u6ce8\u635f\u5931\u548c\u73af\u5883\u5149\u5e72\u6270\uff0c\u73b0\u6709\u4fe1\u53f7\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u8106\u5f31\u7684\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u8981\u4e48\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec31-D ResNet-18\uff0c\u83b7\u5f97\u5149\u5b66\u53d1\u5c04\u5668\u548c\u8fd0\u52a8\u4e0d\u53d8\u7684\u5d4c\u5165\u8868\u793a\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u6301\u4e45\u540c\u6784\u5c06\u5d4c\u5165\u8f6c\u6362\u4e3a\u62d3\u6251\u7279\u5f81\uff0c\u4f7f\u7528HDBSCAN\u805a\u7c7b\u751f\u6210\u4e8c\u8fdb\u5236\u4fe1\u53f7\u8d28\u91cf\u6307\u6570\u3002", "result": "\u572810,000\u4e2a\u7a97\u53e3\u7684\u5206\u5c42\u6837\u672c\u4e0a\uff0c\u83b7\u5f97Silhouette\u5f97\u52060.72\u3001Davies-Bouldin\u5f97\u52060.34\u3001Calinski-Harabasz\u5f97\u52066173\uff0c\u65e0\u9700\u91cd\u65b0\u8c03\u53c2\u3002", "conclusion": "\u63d0\u51fa\u7684SSL-TDA\u6846\u67b6\u4e3aPPG\u4fe1\u53f7\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u3001\u53ef\u6269\u5c55\u3001\u8de8\u8bbe\u5907\u7684\u8d28\u91cf\u95e8\u63a7\u89e3\u51b3\u65b9\u6848\u3002"}}
